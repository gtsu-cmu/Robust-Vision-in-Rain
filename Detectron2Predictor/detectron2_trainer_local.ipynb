{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "34e6eddb",
   "metadata": {
    "id": "-4OJq6c4oPqR"
   },
   "source": [
    "# Google Colab initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8fad179",
   "metadata": {
    "id": "7150dd93"
   },
   "outputs": [],
   "source": [
    "# !pip install pyyaml==5.1\n",
    "\n",
    "# import torch\n",
    "# TORCH_VERSION = \".\".join(torch.__version__.split(\".\")[:2])\n",
    "# CUDA_VERSION = torch.__version__.split(\"+\")[-1]\n",
    "# print(\"torch: \", TORCH_VERSION, \"; cuda: \", CUDA_VERSION)\n",
    "# # Install detectron2 that matches the above pytorch version\n",
    "# # See https://detectron2.readthedocs.io/tutorials/install.html for instructions\n",
    "# !pip install detectron2 -f https://dl.fbaipublicfiles.com/detectron2/wheels/$CUDA_VERSION/torch$TORCH_VERSION/index.html > /dev/null \n",
    "# # If there is not yet a detectron2 release that matches the given torch + CUDA version, you need to install a different pytorch.\n",
    "\n",
    "# exit(0)  # After installation, you may need to \"restart runtime\" in Colab. This line can also restart runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "684d6e40",
   "metadata": {
    "id": "868f1a31-1da7-479c-9bd0-35eabef2ad1d"
   },
   "outputs": [],
   "source": [
    "GOOGLE_COLAB = False\n",
    "# GOOGLE_COLAB = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "990c9aee",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1301,
     "status": "ok",
     "timestamp": 1650750032069,
     "user": {
      "displayName": "Tũn Tũn",
      "userId": "10147808466179585969"
     },
     "user_tz": 240
    },
    "id": "73d376c0",
    "outputId": "b5338b24-a47e-44f6-8740-afaef44df672"
   },
   "outputs": [],
   "source": [
    "if GOOGLE_COLAB == True:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fdab6dd6",
   "metadata": {
    "id": "T1wp5irN5qw9"
   },
   "outputs": [],
   "source": [
    "# if GOOGLE_COLAB == True:\n",
    "#     !ls '/content/drive/MyDrive/18744/data/Cityscapes/'\n",
    "\n",
    "#     !mkdir '/content/data/'\n",
    "#     !mkdir '/content/data/Cityscapes/'\n",
    "\n",
    "#     !unzip -n '/content/drive/MyDrive/18744/data/Cityscapes/gtFine_trainvaltest.zip' -d '/content/data/Cityscapes/' > /dev/null\n",
    "#     !unzip -n '/content/drive/MyDrive/18744/data/Cityscapes/leftImg8bit_trainvaltest.zip' -d '/content/data/Cityscapes/' > /dev/null\n",
    "#     !tar -xf '/content/drive/MyDrive/18744/data/Cityscapes/mapped_labels.tar' --skip-old-files --directory '/content/data/Cityscapes/'\n",
    "\n",
    "#     ##################################################\n",
    "\n",
    "#     !ls '/content/drive/MyDrive/18744/data/Carla/packaging/'\n",
    "\n",
    "#     !mkdir '/content/data/'\n",
    "#     !mkdir '/content/data/Carla/'\n",
    "#     !mkdir '/content/data/Carla/packaging/'\n",
    "\n",
    "#     !unzip -n '/content/drive/MyDrive/18744/data/Carla/packaging/package2.zip' -d '/content/data/Carla/packaging/' > /dev/null\n",
    "#     !unzip -n '/content/drive/MyDrive/18744/data/Carla/packaging/package3.zip' -d '/content/data/Carla/packaging/' > /dev/null\n",
    "#     !unzip -n '/content/drive/MyDrive/18744/data/Carla/packaging/package4.zip' -d '/content/data/Carla/packaging/' > /dev/null\n",
    "#     !unzip -n '/content/drive/MyDrive/18744/data/Carla/packaging/package5.zip' -d '/content/data/Carla/packaging/' > /dev/null\n",
    "#     !unzip -n '/content/drive/MyDrive/18744/data/Carla/packaging/package6.zip' -d '/content/data/Carla/packaging/' > /dev/null\n",
    "#     !unzip -n '/content/drive/MyDrive/18744/data/Carla/packaging/package7.zip' -d '/content/data/Carla/packaging/' > /dev/null\n",
    "#     !unzip -n '/content/drive/MyDrive/18744/data/Carla/packaging/package8.zip' -d '/content/data/Carla/packaging/' > /dev/null\n",
    "#     !unzip -n '/content/drive/MyDrive/18744/data/Carla/packaging/package9.zip' -d '/content/data/Carla/packaging/' > /dev/null\n",
    "#     !tar -xf '/content/drive/MyDrive/18744/data/Carla/packaging/semantic_train.tar' --skip-old-files --directory '/content/data/Carla/packaging/'\n",
    "\n",
    "#     ##################################################\n",
    "\n",
    "#     !ls '/content/drive/MyDrive/18744/data/CarlaNight/night_packaging/'\n",
    "\n",
    "#     !mkdir '/content/data/'\n",
    "#     !mkdir '/content/data/CarlaNight/'\n",
    "#     !mkdir '/content/data/CarlaNight/night_packaging/'\n",
    "    \n",
    "#     !tar -xf '/content/drive/MyDrive/18744/data/CarlaNight/night_packaging/package10.tar' --skip-old-files --directory '/content/data/CarlaNight/night_packaging/'\n",
    "#     !tar -xf '/content/drive/MyDrive/18744/data/CarlaNight/night_packaging/package11.tar' --skip-old-files --directory '/content/data/CarlaNight/night_packaging/'\n",
    "\n",
    "#     ##################################################\n",
    "\n",
    "#     !ls '/content/drive/MyDrive/18744/data/RainAddition/train/'\n",
    "\n",
    "#     !mkdir '/content/data/'\n",
    "#     !mkdir '/content/data/RainAddition/'\n",
    "#     !mkdir '/content/data/RainAddition/train/'\n",
    "\n",
    "#     !tar -xf '/content/drive/MyDrive/18744/data/RainAddition/train/1.tar' --skip-old-files --directory '/content/data/RainAddition/train/'\n",
    "#     !tar -xf '/content/drive/MyDrive/18744/data/RainAddition/train/2.tar' --skip-old-files --directory '/content/data/RainAddition/train/'\n",
    "#     !tar -xf '/content/drive/MyDrive/18744/data/RainAddition/train/3.tar' --skip-old-files --directory '/content/data/RainAddition/train/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d1b4bf2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1650750032070,
     "user": {
      "displayName": "Tũn Tũn",
      "userId": "10147808466179585969"
     },
     "user_tz": 240
    },
    "id": "2854f46b",
    "outputId": "88560d5b-3976-4d4a-96a0-baf4c1024b23"
   },
   "outputs": [],
   "source": [
    "if GOOGLE_COLAB == True:\n",
    "    !ls '/content/drive/MyDrive/18744/data/'\n",
    "    %cd '/content/drive/MyDrive/18744/Robust-Vision-in-Rain/Detectron2Predictor/'\n",
    "    !ls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50cf16c0",
   "metadata": {
    "id": "vOI__nJ2oiYZ"
   },
   "source": [
    "# Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4dbc1b08",
   "metadata": {
    "id": "78860d72-d62b-442a-aac9-b7499a37d343"
   },
   "outputs": [],
   "source": [
    "main_dir = './'\n",
    "#data_dir = '/home/tunx404/Miscellaneous/data/' # Local Jupyter\n",
    "data_dir = '/home/gregory/Documents/RainPerception/'\n",
    "#data_dir = '/home/gregory/Documents/RainPerception/RainRemoval/Copied/generated_tests/'\n",
    "#data_dir = '/home/gregory/Documents/RainPerception/RainRemoval/Copied/generated_test_both/'\n",
    "\n",
    "if GOOGLE_COLAB == True:\n",
    "    # data_dir = '/content/drive/MyDrive/18744/data/'\n",
    "    data_dir = '/content/data/'\n",
    "    \n",
    "DEBUG = False\n",
    "DEBUG = True\n",
    "\n",
    "EVAL_LEVEL_LIST = ['H', 'M', 'S']\n",
    "#EVAL_LEVEL_LIST = ['S']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0d8aa54",
   "metadata": {
    "id": "7dfd639d-5b7a-4280-9689-32aa4d40a9cd"
   },
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "795067b5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4214,
     "status": "ok",
     "timestamp": 1650750036279,
     "user": {
      "displayName": "Tũn Tũn",
      "userId": "10147808466179585969"
     },
     "user_tz": 240
    },
    "id": "11d2a715-8cb4-4df1-9ef7-00b18f834f32",
    "outputId": "8d20260c-67f9-4bb2-d49d-fbbb01996099"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train images: 0\n",
      "Number of val images:   0\n"
     ]
    }
   ],
   "source": [
    "##################################################\n",
    "# Local libraries\n",
    "\n",
    "from detectron2_predictor import Detectron2Predictor\n",
    "from detectron2_trainer import Detectron2Trainer\n",
    "from detectron2_dataset import Detectron2CustomDataset\n",
    "from utilities import create_file_list, imshow_jupyter\n",
    "from datasets import get_carla_file_list, get_carla_dicts, get_cityscapes_file_list, get_cityscapes_dicts\n",
    "from datasets import convert_carla, convert_cityscapes\n",
    "\n",
    "##################################################\n",
    "# Libraries\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "import os, json, cv2, random\n",
    "\n",
    "##################################################\n",
    "# Detectron2\n",
    "\n",
    "import detectron2\n",
    "\n",
    "from detectron2.utils.logger import setup_logger\n",
    "setup_logger()\n",
    "\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import DatasetCatalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "267cbca6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.7.6 (default, May 29 2020, 16:22:44) \n",
      "[GCC 5.4.0 20160609]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a981d8b",
   "metadata": {
    "id": "WG-v-IBXo7e7"
   },
   "source": [
    "# Image lists & dicts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56d2d19b",
   "metadata": {
    "id": "bJEp7LRapA9e"
   },
   "source": [
    "## Carla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "07f6bd58",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 234,
     "status": "ok",
     "timestamp": 1650750036503,
     "user": {
      "displayName": "Tũn Tũn",
      "userId": "10147808466179585969"
     },
     "user_tz": 240
    },
    "id": "5ae5b712-4f0f-4c81-91f2-6b704a73b2d9",
    "outputId": "0228aa52-81e4-48ea-b5b4-d5ee6463449a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images: 8868\n",
      "Number of images: 3258\n"
     ]
    }
   ],
   "source": [
    "data_carla_dir = data_dir + 'Carla/packaging/'\n",
    "\n",
    "# Dir structure:\n",
    "# <data_carla_dir>\n",
    "#     packages2\n",
    "#     packages3\n",
    "#     ...\n",
    "\n",
    "data_carla_train_file_list = get_carla_file_list(data_carla_dir, packages=['package2', 'package3', 'package4', 'package5', 'package6', 'package7', 'package9', 'carla_data_day_2'], levels=EVAL_LEVEL_LIST)\n",
    "data_carla_val_file_list = get_carla_file_list(data_carla_dir, packages=['package8', 'carla_data_day_1'], levels=EVAL_LEVEL_LIST)\n",
    "\n",
    "# data_carla_train_file_list = get_carla_file_list(data_carla_dir, packages=['package2'], levels=['H', 'M', 'S'])\n",
    "# data_carla_val_file_list = get_carla_file_list(data_carla_dir, packages=['package8'], levels=['H', 'M', 'S'])\n",
    "\n",
    "#data_carla_train_file_list = get_carla_file_list(data_carla_dir, packages=['test'], levels=EVAL_LEVEL_LIST)\n",
    "#data_carla_val_file_list = get_carla_file_list(data_carla_dir, packages=['test'], levels=EVAL_LEVEL_LIST)\n",
    "\n",
    "# # Toy example\n",
    "# data_carla_train_file_list = data_carla_train_file_list[:10]\n",
    "# data_carla_val_file_list = data_carla_val_file_list[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fb06988e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_carla_dir = data_dir + 'RainRemoval/CarlaDerained/'\n",
    "\n",
    "# # Dir structure:\n",
    "# # <data_carla_dir>\n",
    "# #     packages2\n",
    "# #     packages3\n",
    "# #     ...\n",
    "\n",
    "# data_carla_train_file_list = get_carla_file_list(data_carla_dir, packages=['package8'], levels=EVAL_LEVEL_LIST)\n",
    "# data_carla_val_file_list = get_carla_file_list(data_carla_dir, packages=['package8'], levels=EVAL_LEVEL_LIST)\n",
    "\n",
    "# # # Toy example\n",
    "# # data_carla_train_file_list = data_carla_train_file_list[:10]\n",
    "# # data_carla_val_file_list = data_carla_val_file_list[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8800419b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1221,
     "status": "ok",
     "timestamp": 1650750037718,
     "user": {
      "displayName": "Tũn Tũn",
      "userId": "10147808466179585969"
     },
     "user_tz": 240
    },
    "id": "e7ff3fc8-60ad-4f66-8081-26b25a515d8c",
    "outputId": "a51d5273-c290-4071-8351-a2a4192f6944"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n",
      "Carla clear\n",
      "{'file_name': '/home/gregory/Documents/RainPerception/Carla/packaging/package2/1647144040.0070002_clear.png', 'height': 720, 'width': 1280, 'image_id': '1647144040.0070002_clear', 'sem_seg_file_name': '/home/gregory/Documents/RainPerception/Carla/packaging/package2/1647144040.0070002_semantic_train.png'}\n",
      "{'file_name': '/home/gregory/Documents/RainPerception/Carla/packaging/package2/1647144051.8223236_clear.png', 'height': 720, 'width': 1280, 'image_id': '1647144051.8223236_clear', 'sem_seg_file_name': '/home/gregory/Documents/RainPerception/Carla/packaging/package2/1647144051.8223236_semantic_train.png'}\n",
      "{'file_name': '/home/gregory/Documents/RainPerception/Carla/packaging/package2/1647144063.4320533_clear.png', 'height': 720, 'width': 1280, 'image_id': '1647144063.4320533_clear', 'sem_seg_file_name': '/home/gregory/Documents/RainPerception/Carla/packaging/package2/1647144063.4320533_semantic_train.png'}\n",
      "{'file_name': '/home/gregory/Documents/RainPerception/Carla/packaging/package2/1647144076.9520714_clear.png', 'height': 720, 'width': 1280, 'image_id': '1647144076.9520714_clear', 'sem_seg_file_name': '/home/gregory/Documents/RainPerception/Carla/packaging/package2/1647144076.9520714_semantic_train.png'}\n",
      "8868\n",
      "3258\n",
      "\n",
      "**************************************************\n",
      "Carla rain\n",
      "{'file_name': '/home/gregory/Documents/RainPerception/Carla/packaging/package8/1647661109.8690557_rain_S.png', 'height': 720, 'width': 1280, 'image_id': '1647661109.8690557_rain', 'sem_seg_file_name': '/home/gregory/Documents/RainPerception/Carla/packaging/package8/1647661109.8690557_semantic_train.png'}\n",
      "{'file_name': '/home/gregory/Documents/RainPerception/Carla/packaging/package8/1647661117.1132371_rain_H.png', 'height': 720, 'width': 1280, 'image_id': '1647661117.1132371_rain', 'sem_seg_file_name': '/home/gregory/Documents/RainPerception/Carla/packaging/package8/1647661117.1132371_semantic_train.png'}\n",
      "{'file_name': '/home/gregory/Documents/RainPerception/Carla/packaging/package8/1647661123.9885252_rain_S.png', 'height': 720, 'width': 1280, 'image_id': '1647661123.9885252_rain', 'sem_seg_file_name': '/home/gregory/Documents/RainPerception/Carla/packaging/package8/1647661123.9885252_semantic_train.png'}\n",
      "{'file_name': '/home/gregory/Documents/RainPerception/Carla/packaging/package8/1647661130.8618288_rain_H.png', 'height': 720, 'width': 1280, 'image_id': '1647661130.8618288_rain', 'sem_seg_file_name': '/home/gregory/Documents/RainPerception/Carla/packaging/package8/1647661130.8618288_semantic_train.png'}\n",
      "8868\n",
      "3258\n",
      "\n",
      "**************************************************\n",
      "Carla all\n",
      "{'file_name': '/home/gregory/Documents/RainPerception/Carla/packaging/package8/1647661109.8690557_clear.png', 'height': 720, 'width': 1280, 'image_id': '1647661109.8690557_clear', 'sem_seg_file_name': '/home/gregory/Documents/RainPerception/Carla/packaging/package8/1647661109.8690557_semantic_train.png'}\n",
      "{'file_name': '/home/gregory/Documents/RainPerception/Carla/packaging/package8/1647661109.8690557_rain_S.png', 'height': 720, 'width': 1280, 'image_id': '1647661109.8690557_rain', 'sem_seg_file_name': '/home/gregory/Documents/RainPerception/Carla/packaging/package8/1647661109.8690557_semantic_train.png'}\n",
      "{'file_name': '/home/gregory/Documents/RainPerception/Carla/packaging/package8/1647661117.1132371_clear.png', 'height': 720, 'width': 1280, 'image_id': '1647661117.1132371_clear', 'sem_seg_file_name': '/home/gregory/Documents/RainPerception/Carla/packaging/package8/1647661117.1132371_semantic_train.png'}\n",
      "{'file_name': '/home/gregory/Documents/RainPerception/Carla/packaging/package8/1647661117.1132371_rain_H.png', 'height': 720, 'width': 1280, 'image_id': '1647661117.1132371_rain', 'sem_seg_file_name': '/home/gregory/Documents/RainPerception/Carla/packaging/package8/1647661117.1132371_semantic_train.png'}\n",
      "17736\n",
      "6516\n"
     ]
    }
   ],
   "source": [
    "print('**************************************************')\n",
    "print('Carla clear')\n",
    "\n",
    "def get_carla_clear_train_dicts():\n",
    "    return get_carla_dicts(data_carla_train_file_list, data_carla_dir, clear=True, rain=False)\n",
    "\n",
    "def get_carla_clear_val_dicts():\n",
    "    return get_carla_dicts(data_carla_val_file_list, data_carla_dir, clear=True, rain=False)\n",
    "\n",
    "if DEBUG == True:\n",
    "    for dict in get_carla_clear_train_dicts()[:4]:\n",
    "        print(dict)\n",
    "    \n",
    "print(len(get_carla_clear_train_dicts())) # 2990\n",
    "print(len(get_carla_clear_val_dicts()))   # 1173\n",
    "\n",
    "print('\\n**************************************************')\n",
    "print('Carla rain')\n",
    "\n",
    "def get_carla_rain_train_dicts():\n",
    "    return get_carla_dicts(data_carla_train_file_list, data_carla_dir, clear=False, rain=True)\n",
    "\n",
    "def get_carla_rain_val_dicts():\n",
    "    return get_carla_dicts(data_carla_val_file_list, data_carla_dir, clear=False, rain=True)\n",
    "\n",
    "if DEBUG == True:\n",
    "    for dict in get_carla_rain_val_dicts()[:4]:\n",
    "        print(dict)\n",
    "    \n",
    "print(len(get_carla_rain_train_dicts())) # 2990\n",
    "print(len(get_carla_rain_val_dicts()))   # 1173\n",
    "\n",
    "print('\\n**************************************************')\n",
    "print('Carla all')\n",
    "\n",
    "def get_carla_all_train_dicts():\n",
    "    return get_carla_dicts(data_carla_train_file_list, data_carla_dir, clear=True, rain=True)\n",
    "\n",
    "def get_carla_all_val_dicts():\n",
    "    return get_carla_dicts(data_carla_val_file_list, data_carla_dir, clear=True, rain=True)\n",
    "\n",
    "if DEBUG == True:\n",
    "    for dict in get_carla_all_val_dicts()[:4]:\n",
    "        print(dict)\n",
    "    \n",
    "print(len(get_carla_all_train_dicts())) # 2990*2 = 5980\n",
    "print(len(get_carla_all_val_dicts()))   # 1173*2 = 2346"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb72f010",
   "metadata": {
    "id": "cdea5e2a-78f6-477c-8a07-31ad4eb7f753"
   },
   "source": [
    "## Carla night"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e22eb94c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1650750037719,
     "user": {
      "displayName": "Tũn Tũn",
      "userId": "10147808466179585969"
     },
     "user_tz": 240
    },
    "id": "200e99e5-062a-49c7-bfac-9c47e86464a2",
    "outputId": "e8fa2703-52f4-4a8c-f964-ec040a49e2c6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images: 7723\n",
      "Number of images: 3273\n"
     ]
    }
   ],
   "source": [
    "data_carla_night_dir = data_dir + 'CarlaNight/night_packaging/'\n",
    "\n",
    "# Dir structure:\n",
    "# <data_carla_night_dir>\n",
    "#     packages10\n",
    "#     packages11\n",
    "#     ...\n",
    "\n",
    "data_carla_night_train_file_list = get_carla_file_list(data_carla_night_dir, packages=['package10', 'carla_data_night_1', 'carla_data_night_3', 'carla_data_night_4'], levels=EVAL_LEVEL_LIST)\n",
    "data_carla_night_val_file_list = get_carla_file_list(data_carla_night_dir, packages=['package11', 'carla_data_night_2'], levels=EVAL_LEVEL_LIST)\n",
    "\n",
    "# data_carla_night_train_file_list = get_carla_file_list(data_carla_night_dir, packages=['carla_data_pennstate_night_1'], levels=['H', 'M', 'S'])\n",
    "# data_carla_night_val_file_list = get_carla_file_list(data_carla_night_dir, packages=['package11'], levels=['H', 'M', 'S'])\n",
    "\n",
    "#data_carla_night_train_file_list = get_carla_file_list(data_carla_night_dir, packages=['test'], levels=EVAL_LEVEL_LIST)\n",
    "#data_carla_night_val_file_list = get_carla_file_list(data_carla_night_dir, packages=['test'], levels=EVAL_LEVEL_LIST)\n",
    "\n",
    "# # Toy example\n",
    "# data_carla_night_train_file_list = data_carla_night_train_file_list[:10]\n",
    "# data_carla_night_val_file_list = data_carla_night_val_file_list[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9cac6bdf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 623,
     "status": "ok",
     "timestamp": 1650750038336,
     "user": {
      "displayName": "Tũn Tũn",
      "userId": "10147808466179585969"
     },
     "user_tz": 240
    },
    "id": "94f8319d-9a96-4c21-b142-f95f87226731",
    "outputId": "67bb9551-c439-4f9f-ed20-abe1cbf15f56"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n",
      "Carla night clear\n",
      "{'file_name': '/home/gregory/Documents/RainPerception/CarlaNight/night_packaging/package11/1650004471.747364_clear.png', 'height': 720, 'width': 1280, 'image_id': '1650004471.747364_clear', 'sem_seg_file_name': '/home/gregory/Documents/RainPerception/CarlaNight/night_packaging/package11/1650004471.747364_semantic_train.png'}\n",
      "{'file_name': '/home/gregory/Documents/RainPerception/CarlaNight/night_packaging/package11/1650004480.8757513_clear.png', 'height': 720, 'width': 1280, 'image_id': '1650004480.8757513_clear', 'sem_seg_file_name': '/home/gregory/Documents/RainPerception/CarlaNight/night_packaging/package11/1650004480.8757513_semantic_train.png'}\n",
      "{'file_name': '/home/gregory/Documents/RainPerception/CarlaNight/night_packaging/package11/1650004489.9787946_clear.png', 'height': 720, 'width': 1280, 'image_id': '1650004489.9787946_clear', 'sem_seg_file_name': '/home/gregory/Documents/RainPerception/CarlaNight/night_packaging/package11/1650004489.9787946_semantic_train.png'}\n",
      "{'file_name': '/home/gregory/Documents/RainPerception/CarlaNight/night_packaging/package11/1650004499.1453662_clear.png', 'height': 720, 'width': 1280, 'image_id': '1650004499.1453662_clear', 'sem_seg_file_name': '/home/gregory/Documents/RainPerception/CarlaNight/night_packaging/package11/1650004499.1453662_semantic_train.png'}\n",
      "7723\n",
      "3273\n",
      "\n",
      "**************************************************\n",
      "Carla night rain\n",
      "{'file_name': '/home/gregory/Documents/RainPerception/CarlaNight/night_packaging/package11/1650004471.747364_rain_H.png', 'height': 720, 'width': 1280, 'image_id': '1650004471.747364_rain', 'sem_seg_file_name': '/home/gregory/Documents/RainPerception/CarlaNight/night_packaging/package11/1650004471.747364_semantic_train.png'}\n",
      "{'file_name': '/home/gregory/Documents/RainPerception/CarlaNight/night_packaging/package11/1650004480.8757513_rain_S.png', 'height': 720, 'width': 1280, 'image_id': '1650004480.8757513_rain', 'sem_seg_file_name': '/home/gregory/Documents/RainPerception/CarlaNight/night_packaging/package11/1650004480.8757513_semantic_train.png'}\n",
      "{'file_name': '/home/gregory/Documents/RainPerception/CarlaNight/night_packaging/package11/1650004489.9787946_rain_M.png', 'height': 720, 'width': 1280, 'image_id': '1650004489.9787946_rain', 'sem_seg_file_name': '/home/gregory/Documents/RainPerception/CarlaNight/night_packaging/package11/1650004489.9787946_semantic_train.png'}\n",
      "{'file_name': '/home/gregory/Documents/RainPerception/CarlaNight/night_packaging/package11/1650004499.1453662_rain_S.png', 'height': 720, 'width': 1280, 'image_id': '1650004499.1453662_rain', 'sem_seg_file_name': '/home/gregory/Documents/RainPerception/CarlaNight/night_packaging/package11/1650004499.1453662_semantic_train.png'}\n",
      "7723\n",
      "3273\n",
      "\n",
      "**************************************************\n",
      "Carla night all\n",
      "{'file_name': '/home/gregory/Documents/RainPerception/CarlaNight/night_packaging/package11/1650004471.747364_clear.png', 'height': 720, 'width': 1280, 'image_id': '1650004471.747364_clear', 'sem_seg_file_name': '/home/gregory/Documents/RainPerception/CarlaNight/night_packaging/package11/1650004471.747364_semantic_train.png'}\n",
      "{'file_name': '/home/gregory/Documents/RainPerception/CarlaNight/night_packaging/package11/1650004471.747364_rain_H.png', 'height': 720, 'width': 1280, 'image_id': '1650004471.747364_rain', 'sem_seg_file_name': '/home/gregory/Documents/RainPerception/CarlaNight/night_packaging/package11/1650004471.747364_semantic_train.png'}\n",
      "{'file_name': '/home/gregory/Documents/RainPerception/CarlaNight/night_packaging/package11/1650004480.8757513_clear.png', 'height': 720, 'width': 1280, 'image_id': '1650004480.8757513_clear', 'sem_seg_file_name': '/home/gregory/Documents/RainPerception/CarlaNight/night_packaging/package11/1650004480.8757513_semantic_train.png'}\n",
      "{'file_name': '/home/gregory/Documents/RainPerception/CarlaNight/night_packaging/package11/1650004480.8757513_rain_S.png', 'height': 720, 'width': 1280, 'image_id': '1650004480.8757513_rain', 'sem_seg_file_name': '/home/gregory/Documents/RainPerception/CarlaNight/night_packaging/package11/1650004480.8757513_semantic_train.png'}\n",
      "15446\n",
      "6546\n"
     ]
    }
   ],
   "source": [
    "print('**************************************************')\n",
    "print('Carla night clear')\n",
    "\n",
    "def get_carla_night_clear_train_dicts():\n",
    "    return get_carla_dicts(data_carla_night_train_file_list, data_carla_night_dir, clear=True, rain=False)\n",
    "\n",
    "def get_carla_night_clear_val_dicts():\n",
    "    return get_carla_dicts(data_carla_night_val_file_list, data_carla_night_dir, clear=True, rain=False)\n",
    "\n",
    "def get_carla_night_clear_val_dicts_sub():\n",
    "    return get_carla_night_clear_val_dicts()[:1000]\n",
    "\n",
    "if DEBUG == True:\n",
    "    for dict in get_carla_night_clear_val_dicts()[:4]:\n",
    "        print(dict)\n",
    "    \n",
    "print(len(get_carla_night_clear_train_dicts())) # 2842\n",
    "print(len(get_carla_night_clear_val_dicts()))   # 2974\n",
    "\n",
    "print('\\n**************************************************')\n",
    "print('Carla night rain')\n",
    "\n",
    "def get_carla_night_rain_train_dicts():\n",
    "    return get_carla_dicts(data_carla_night_train_file_list, data_carla_night_dir, clear=False, rain=True)\n",
    "\n",
    "def get_carla_night_rain_val_dicts():\n",
    "    return get_carla_dicts(data_carla_night_val_file_list, data_carla_night_dir, clear=False, rain=True)\n",
    "\n",
    "if DEBUG == True:\n",
    "    for dict in get_carla_night_rain_val_dicts()[:4]:\n",
    "        print(dict)\n",
    "    \n",
    "print(len(get_carla_night_rain_train_dicts())) # 2842\n",
    "print(len(get_carla_night_rain_val_dicts()))   # 2974\n",
    "\n",
    "print('\\n**************************************************')\n",
    "print('Carla night all')\n",
    "\n",
    "def get_carla_night_all_train_dicts():\n",
    "    return get_carla_dicts(data_carla_night_train_file_list, data_carla_night_dir, clear=True, rain=True)\n",
    "\n",
    "def get_carla_night_all_val_dicts():\n",
    "    return get_carla_dicts(data_carla_night_val_file_list, data_carla_night_dir, clear=True, rain=True)\n",
    "\n",
    "def get_carla_night_all_val_dicts_sub():\n",
    "    return get_carla_night_clear_val_dicts()[:1000] + get_carla_night_rain_val_dicts()[:1000]\n",
    "\n",
    "if DEBUG == True:\n",
    "    for dict in get_carla_night_all_val_dicts()[:4]:\n",
    "        print(dict)\n",
    "    \n",
    "print(len(get_carla_night_all_train_dicts())) # 2842*2 = 5684\n",
    "print(len(get_carla_night_all_val_dicts()))   # 2974*2 = 5948"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6ebc3b8",
   "metadata": {
    "id": "CEjETjkApDCI"
   },
   "source": [
    "## Cityscapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aae44f95",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1650750038337,
     "user": {
      "displayName": "Tũn Tũn",
      "userId": "10147808466179585969"
     },
     "user_tz": 240
    },
    "id": "959352e0-9de4-478e-8a51-f6ca3fa1bb3b",
    "outputId": "295d485e-3887-4f44-fdce-9e9e01724772"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of cities: 18\n",
      "Number of images: 95\n",
      "Number of images: 2975\n"
     ]
    }
   ],
   "source": [
    "data_dir_cityscapes = data_dir + 'Cityscapes/leftImg8bit/train/'\n",
    "#data_dir_cityscapes = data_dir + 'original/'\n",
    "# data_dir_rain_addition = data_dir + 'RainAddition/train/'\n",
    "data_dir_rain_addition = data_dir + 'RainRemoval/RainAddition/'\n",
    "#data_dir_rain_addition = data_dir + 'city/'\n",
    "anno_dir_cityscapes = data_dir + 'Cityscapes/gtFine/train/'\n",
    "# anno_dir_cityscapes = data_dir + 'Cityscapes/mapped_labels/train/'\n",
    "#anno_dir_cityscapes = data_dir + 'labels/'\n",
    "\n",
    "city_name_list, _ = create_file_list(data_dir_cityscapes)\n",
    "print(f'Number of cities: {len(city_name_list)}')\n",
    "\n",
    "#data_cityscapes_train_file_list = get_cityscapes_file_list(data_dir_cityscapes, cities=city_name_list[:13])\n",
    "#data_cityscapes_val_file_list   = get_cityscapes_file_list(data_dir_cityscapes, cities=city_name_list[13:])\n",
    "\n",
    "data_cityscapes_train_file_list = get_cityscapes_file_list(data_dir_cityscapes, cities=['ulm'])\n",
    "data_cityscapes_val_file_list   = get_cityscapes_file_list(data_dir_cityscapes, cities=city_name_list)\n",
    "\n",
    "# # Toy example\n",
    "# data_cityscapes_train_file_list = data_cityscapes_train_file_list[:10]\n",
    "# data_cityscapes_val_file_list = data_cityscapes_val_file_list[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a6b5166b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_dir_cityscapes = data_dir + 'RainRemoval/RainAddition/'\n",
    "# # data_dir_rain_addition = data_dir + 'RainAddition/train/'\n",
    "# data_dir_rain_addition = data_dir + 'RainRemoval/RainAddition/'\n",
    "# # anno_dir_cityscapes = data_dir + 'Cityscapes/gtFine/train/'\n",
    "# anno_dir_cityscapes = data_dir + 'Cityscapes/mapped_labels/train/'\n",
    "\n",
    "# city_name_list, _ = create_file_list(data_dir_cityscapes)\n",
    "# print(f'Number of cities: {len(city_name_list)}')\n",
    "\n",
    "# data_cityscapes_train_file_list = get_cityscapes_file_list(data_dir_cityscapes, cities=city_name_list)\n",
    "# data_cityscapes_val_file_list   = get_cityscapes_file_list(data_dir_cityscapes, cities=city_name_list)\n",
    "\n",
    "# # # Toy example\n",
    "# # data_cityscapes_train_file_list = data_cityscapes_train_file_list[:10]\n",
    "# # data_cityscapes_val_file_list = data_cityscapes_val_file_list[:10\n",
    "\n",
    "# def get_cityscapes_dicts(file_list, data_dir_main, data_dir_rain, anno_dir, clear=True, rain=True, levels=[]):\n",
    "#     dicts = []\n",
    "    \n",
    "#     # for file in file_list:\n",
    "#     for index, file in enumerate(file_list):\n",
    "#         file_name, city = file\n",
    "\n",
    "#         image_clear_path = os.path.join(data_dir_main, city, file_name)\n",
    "        \n",
    "#         file_name_split = file_name.split('_')\n",
    "        \n",
    "#         level = file_name_split[3][0]\n",
    "        \n",
    "#         # anno_name = file_name_split[0] + '_' + file_name_split[1] + '_' + file_name_split[2] + '_gtFine_labelIds.png' # Default\n",
    "#         image_id = file_name_split[0] + '_' + file_name_split[1] + '_' + file_name_split[2]\n",
    "#         anno_name = image_id + '_train.png' # Mapped\n",
    "#         image_semantic_path = os.path.join(anno_dir, city, anno_name)\n",
    "        \n",
    "#         if level in levels:\n",
    "#             if clear == True:\n",
    "#                 record = {}\n",
    "#                 record['file_name'] = image_clear_path\n",
    "#                 record['height'] = 1024 # shape[0]\n",
    "#                 record['width'] = 2048 # shape[1]\n",
    "#                 record['image_id'] = image_id + '_clear'\n",
    "#                 record['sem_seg_file_name'] = image_semantic_path\n",
    "#                 dicts.append(record)\n",
    "\n",
    "#             if rain == True:\n",
    "#                 image_rain_name = image_id + '_' + level + '.png'\n",
    "#                 image_rain_path = os.path.join(data_dir_rain, city, image_rain_name)\n",
    "\n",
    "#                 record = {}\n",
    "#                 record['file_name'] = image_rain_path\n",
    "#                 record['height'] = 1024\n",
    "#                 record['width'] = 2048\n",
    "#                 record['image_id'] = image_id + '_rain'\n",
    "#                 record['sem_seg_file_name'] = image_semantic_path\n",
    "#                 dicts.append(record)\n",
    "#     return dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5129bee9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 244,
     "status": "ok",
     "timestamp": 1650750038571,
     "user": {
      "displayName": "Tũn Tũn",
      "userId": "10147808466179585969"
     },
     "user_tz": 240
    },
    "id": "e964bcb7-123a-4a4a-975b-d3b7554551d7",
    "outputId": "7f378cd1-36fa-4078-dba3-71451602ec1d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n",
      "Cityscapes clear\n",
      "{'file_name': '/home/gregory/Documents/RainPerception/Cityscapes/leftImg8bit/train/aachen/aachen_000000_000019_leftImg8bit.png', 'height': 1024, 'width': 2048, 'image_id': 'aachen_000000_000019_clear', 'sem_seg_file_name': '/home/gregory/Documents/RainPerception/Cityscapes/gtFine/train/aachen/aachen_000000_000019_train.png'}\n",
      "{'file_name': '/home/gregory/Documents/RainPerception/Cityscapes/leftImg8bit/train/aachen/aachen_000001_000019_leftImg8bit.png', 'height': 1024, 'width': 2048, 'image_id': 'aachen_000001_000019_clear', 'sem_seg_file_name': '/home/gregory/Documents/RainPerception/Cityscapes/gtFine/train/aachen/aachen_000001_000019_train.png'}\n",
      "{'file_name': '/home/gregory/Documents/RainPerception/Cityscapes/leftImg8bit/train/aachen/aachen_000002_000019_leftImg8bit.png', 'height': 1024, 'width': 2048, 'image_id': 'aachen_000002_000019_clear', 'sem_seg_file_name': '/home/gregory/Documents/RainPerception/Cityscapes/gtFine/train/aachen/aachen_000002_000019_train.png'}\n",
      "{'file_name': '/home/gregory/Documents/RainPerception/Cityscapes/leftImg8bit/train/aachen/aachen_000003_000019_leftImg8bit.png', 'height': 1024, 'width': 2048, 'image_id': 'aachen_000003_000019_clear', 'sem_seg_file_name': '/home/gregory/Documents/RainPerception/Cityscapes/gtFine/train/aachen/aachen_000003_000019_train.png'}\n",
      "95\n",
      "2975\n",
      "\n",
      "**************************************************\n",
      "Cityscapes rain\n",
      "{'file_name': '/home/gregory/Documents/RainPerception/RainRemoval/RainAddition/aachen/aachen_000000_000019_H.png', 'height': 1024, 'width': 2048, 'image_id': 'aachen_000000_000019_rain', 'sem_seg_file_name': '/home/gregory/Documents/RainPerception/Cityscapes/gtFine/train/aachen/aachen_000000_000019_train.png'}\n",
      "{'file_name': '/home/gregory/Documents/RainPerception/RainRemoval/RainAddition/aachen/aachen_000001_000019_M.png', 'height': 1024, 'width': 2048, 'image_id': 'aachen_000001_000019_rain', 'sem_seg_file_name': '/home/gregory/Documents/RainPerception/Cityscapes/gtFine/train/aachen/aachen_000001_000019_train.png'}\n",
      "{'file_name': '/home/gregory/Documents/RainPerception/RainRemoval/RainAddition/aachen/aachen_000002_000019_S.png', 'height': 1024, 'width': 2048, 'image_id': 'aachen_000002_000019_rain', 'sem_seg_file_name': '/home/gregory/Documents/RainPerception/Cityscapes/gtFine/train/aachen/aachen_000002_000019_train.png'}\n",
      "{'file_name': '/home/gregory/Documents/RainPerception/RainRemoval/RainAddition/aachen/aachen_000003_000019_H.png', 'height': 1024, 'width': 2048, 'image_id': 'aachen_000003_000019_rain', 'sem_seg_file_name': '/home/gregory/Documents/RainPerception/Cityscapes/gtFine/train/aachen/aachen_000003_000019_train.png'}\n",
      "95\n",
      "2975\n",
      "\n",
      "**************************************************\n",
      "Cityscapes all\n",
      "{'file_name': '/home/gregory/Documents/RainPerception/Cityscapes/leftImg8bit/train/aachen/aachen_000000_000019_leftImg8bit.png', 'height': 1024, 'width': 2048, 'image_id': 'aachen_000000_000019_clear', 'sem_seg_file_name': '/home/gregory/Documents/RainPerception/Cityscapes/gtFine/train/aachen/aachen_000000_000019_train.png'}\n",
      "{'file_name': '/home/gregory/Documents/RainPerception/RainRemoval/RainAddition/aachen/aachen_000000_000019_H.png', 'height': 1024, 'width': 2048, 'image_id': 'aachen_000000_000019_rain', 'sem_seg_file_name': '/home/gregory/Documents/RainPerception/Cityscapes/gtFine/train/aachen/aachen_000000_000019_train.png'}\n",
      "{'file_name': '/home/gregory/Documents/RainPerception/Cityscapes/leftImg8bit/train/aachen/aachen_000001_000019_leftImg8bit.png', 'height': 1024, 'width': 2048, 'image_id': 'aachen_000001_000019_clear', 'sem_seg_file_name': '/home/gregory/Documents/RainPerception/Cityscapes/gtFine/train/aachen/aachen_000001_000019_train.png'}\n",
      "{'file_name': '/home/gregory/Documents/RainPerception/RainRemoval/RainAddition/aachen/aachen_000001_000019_M.png', 'height': 1024, 'width': 2048, 'image_id': 'aachen_000001_000019_rain', 'sem_seg_file_name': '/home/gregory/Documents/RainPerception/Cityscapes/gtFine/train/aachen/aachen_000001_000019_train.png'}\n",
      "190\n",
      "5950\n"
     ]
    }
   ],
   "source": [
    "print('**************************************************')\n",
    "print('Cityscapes clear')\n",
    "\n",
    "def get_cityscapes_clear_train_dicts():\n",
    "    return get_cityscapes_dicts(data_cityscapes_train_file_list, data_dir_cityscapes, data_dir_rain_addition, anno_dir_cityscapes, clear=True, rain=False, levels=EVAL_LEVEL_LIST)\n",
    "\n",
    "def get_cityscapes_clear_val_dicts():\n",
    "    return get_cityscapes_dicts(data_cityscapes_val_file_list, data_dir_cityscapes, data_dir_rain_addition, anno_dir_cityscapes, clear=True, rain=False, levels=EVAL_LEVEL_LIST)\n",
    "\n",
    "if DEBUG == True:\n",
    "    for dict in get_cityscapes_clear_val_dicts()[:4]:\n",
    "        print(dict)\n",
    "    \n",
    "print(len(get_cityscapes_clear_train_dicts())) # 2276\n",
    "print(len(get_cityscapes_clear_val_dicts()))   # 699\n",
    "\n",
    "print('\\n**************************************************')\n",
    "print('Cityscapes rain')\n",
    "\n",
    "def get_cityscapes_rain_train_dicts():\n",
    "    return get_cityscapes_dicts(data_cityscapes_train_file_list, data_dir_cityscapes, data_dir_rain_addition, anno_dir_cityscapes, clear=False, rain=True, levels=EVAL_LEVEL_LIST)\n",
    "\n",
    "def get_cityscapes_rain_val_dicts():\n",
    "    # return get_cityscapes_dicts(data_cityscapes_val_file_list, data_dir_cityscapes, data_dir_rain_addition, anno_dir_cityscapes, clear=False, rain=True, levels=['H', 'M', 'S'])\n",
    "    return get_cityscapes_dicts(data_cityscapes_val_file_list, data_dir_cityscapes, data_dir_rain_addition, anno_dir_cityscapes, clear=False, rain=True, levels=EVAL_LEVEL_LIST)\n",
    "\n",
    "if DEBUG == True:\n",
    "    for dict in get_cityscapes_rain_val_dicts()[:4]:\n",
    "        print(dict)\n",
    "    \n",
    "print(len(get_cityscapes_rain_train_dicts())) # 2276\n",
    "print(len(get_cityscapes_rain_val_dicts()))   # 699\n",
    "\n",
    "print('\\n**************************************************')\n",
    "print('Cityscapes all')\n",
    "\n",
    "def get_cityscapes_all_train_dicts():\n",
    "    return get_cityscapes_dicts(data_cityscapes_train_file_list, data_dir_cityscapes, data_dir_rain_addition, anno_dir_cityscapes, clear=True, rain=True, levels=EVAL_LEVEL_LIST)\n",
    "\n",
    "def get_cityscapes_all_val_dicts():\n",
    "    return get_cityscapes_dicts(data_cityscapes_val_file_list, data_dir_cityscapes, data_dir_rain_addition, anno_dir_cityscapes, clear=True, rain=True, levels=EVAL_LEVEL_LIST)\n",
    "\n",
    "if DEBUG == True:\n",
    "    for dict in get_cityscapes_all_val_dicts()[:4]:\n",
    "        print(dict)\n",
    "\n",
    "print(len(get_cityscapes_all_train_dicts())) # 2276*2 = 4552\n",
    "print(len(get_cityscapes_all_val_dicts()))   # 699*2  = 1398"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c822457",
   "metadata": {
    "id": "0gefPQJF9bmn"
   },
   "source": [
    "## Combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0caf40ba",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 631,
     "status": "ok",
     "timestamp": 1650750039196,
     "user": {
      "displayName": "Tũn Tũn",
      "userId": "10147808466179585969"
     },
     "user_tz": 240
    },
    "id": "8wECyKDe9bCj",
    "outputId": "383538b1-c424-4e39-a8c2-07eed27bf439"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n",
      "Combined clear\n",
      "{'file_name': '/home/gregory/Documents/RainPerception/Carla/packaging/package2/1647144040.0070002_clear.png', 'height': 720, 'width': 1280, 'image_id': '1647144040.0070002_clear', 'sem_seg_file_name': '/home/gregory/Documents/RainPerception/Carla/packaging/package2/1647144040.0070002_semantic_train.png'}\n",
      "{'file_name': '/home/gregory/Documents/RainPerception/Carla/packaging/package2/1647144051.8223236_clear.png', 'height': 720, 'width': 1280, 'image_id': '1647144051.8223236_clear', 'sem_seg_file_name': '/home/gregory/Documents/RainPerception/Carla/packaging/package2/1647144051.8223236_semantic_train.png'}\n",
      "{'file_name': '/home/gregory/Documents/RainPerception/Carla/packaging/package2/1647144063.4320533_clear.png', 'height': 720, 'width': 1280, 'image_id': '1647144063.4320533_clear', 'sem_seg_file_name': '/home/gregory/Documents/RainPerception/Carla/packaging/package2/1647144063.4320533_semantic_train.png'}\n",
      "{'file_name': '/home/gregory/Documents/RainPerception/Carla/packaging/package2/1647144076.9520714_clear.png', 'height': 720, 'width': 1280, 'image_id': '1647144076.9520714_clear', 'sem_seg_file_name': '/home/gregory/Documents/RainPerception/Carla/packaging/package2/1647144076.9520714_semantic_train.png'}\n",
      "{'file_name': '/home/gregory/Documents/RainPerception/Cityscapes/leftImg8bit/train/ulm/ulm_000091_000019_leftImg8bit.png', 'height': 1024, 'width': 2048, 'image_id': 'ulm_000091_000019_clear', 'sem_seg_file_name': '/home/gregory/Documents/RainPerception/Cityscapes/gtFine/train/ulm/ulm_000091_000019_train.png'}\n",
      "{'file_name': '/home/gregory/Documents/RainPerception/Cityscapes/leftImg8bit/train/ulm/ulm_000092_000019_leftImg8bit.png', 'height': 1024, 'width': 2048, 'image_id': 'ulm_000092_000019_clear', 'sem_seg_file_name': '/home/gregory/Documents/RainPerception/Cityscapes/gtFine/train/ulm/ulm_000092_000019_train.png'}\n",
      "{'file_name': '/home/gregory/Documents/RainPerception/Cityscapes/leftImg8bit/train/ulm/ulm_000093_000019_leftImg8bit.png', 'height': 1024, 'width': 2048, 'image_id': 'ulm_000093_000019_clear', 'sem_seg_file_name': '/home/gregory/Documents/RainPerception/Cityscapes/gtFine/train/ulm/ulm_000093_000019_train.png'}\n",
      "{'file_name': '/home/gregory/Documents/RainPerception/Cityscapes/leftImg8bit/train/ulm/ulm_000094_000019_leftImg8bit.png', 'height': 1024, 'width': 2048, 'image_id': 'ulm_000094_000019_clear', 'sem_seg_file_name': '/home/gregory/Documents/RainPerception/Cityscapes/gtFine/train/ulm/ulm_000094_000019_train.png'}\n",
      "8963\n",
      "6233\n",
      "\n",
      "**************************************************\n",
      "Combined rain\n",
      "{'file_name': '/home/gregory/Documents/RainPerception/Carla/packaging/package2/1647144040.0070002_rain_S.png', 'height': 720, 'width': 1280, 'image_id': '1647144040.0070002_rain', 'sem_seg_file_name': '/home/gregory/Documents/RainPerception/Carla/packaging/package2/1647144040.0070002_semantic_train.png'}\n",
      "{'file_name': '/home/gregory/Documents/RainPerception/Carla/packaging/package2/1647144051.8223236_rain_H.png', 'height': 720, 'width': 1280, 'image_id': '1647144051.8223236_rain', 'sem_seg_file_name': '/home/gregory/Documents/RainPerception/Carla/packaging/package2/1647144051.8223236_semantic_train.png'}\n",
      "{'file_name': '/home/gregory/Documents/RainPerception/Carla/packaging/package2/1647144063.4320533_rain_H.png', 'height': 720, 'width': 1280, 'image_id': '1647144063.4320533_rain', 'sem_seg_file_name': '/home/gregory/Documents/RainPerception/Carla/packaging/package2/1647144063.4320533_semantic_train.png'}\n",
      "{'file_name': '/home/gregory/Documents/RainPerception/Carla/packaging/package2/1647144076.9520714_rain_S.png', 'height': 720, 'width': 1280, 'image_id': '1647144076.9520714_rain', 'sem_seg_file_name': '/home/gregory/Documents/RainPerception/Carla/packaging/package2/1647144076.9520714_semantic_train.png'}\n",
      "{'file_name': '/home/gregory/Documents/RainPerception/RainRemoval/RainAddition/ulm/ulm_000091_000019_M.png', 'height': 1024, 'width': 2048, 'image_id': 'ulm_000091_000019_rain', 'sem_seg_file_name': '/home/gregory/Documents/RainPerception/Cityscapes/gtFine/train/ulm/ulm_000091_000019_train.png'}\n",
      "{'file_name': '/home/gregory/Documents/RainPerception/RainRemoval/RainAddition/ulm/ulm_000092_000019_S.png', 'height': 1024, 'width': 2048, 'image_id': 'ulm_000092_000019_rain', 'sem_seg_file_name': '/home/gregory/Documents/RainPerception/Cityscapes/gtFine/train/ulm/ulm_000092_000019_train.png'}\n",
      "{'file_name': '/home/gregory/Documents/RainPerception/RainRemoval/RainAddition/ulm/ulm_000093_000019_H.png', 'height': 1024, 'width': 2048, 'image_id': 'ulm_000093_000019_rain', 'sem_seg_file_name': '/home/gregory/Documents/RainPerception/Cityscapes/gtFine/train/ulm/ulm_000093_000019_train.png'}\n",
      "{'file_name': '/home/gregory/Documents/RainPerception/RainRemoval/RainAddition/ulm/ulm_000094_000019_M.png', 'height': 1024, 'width': 2048, 'image_id': 'ulm_000094_000019_rain', 'sem_seg_file_name': '/home/gregory/Documents/RainPerception/Cityscapes/gtFine/train/ulm/ulm_000094_000019_train.png'}\n",
      "8963\n",
      "6233\n",
      "\n",
      "**************************************************\n",
      "Combined all\n",
      "{'file_name': '/home/gregory/Documents/RainPerception/Carla/packaging/package2/1647144040.0070002_clear.png', 'height': 720, 'width': 1280, 'image_id': '1647144040.0070002_clear', 'sem_seg_file_name': '/home/gregory/Documents/RainPerception/Carla/packaging/package2/1647144040.0070002_semantic_train.png'}\n",
      "{'file_name': '/home/gregory/Documents/RainPerception/Carla/packaging/package2/1647144040.0070002_rain_S.png', 'height': 720, 'width': 1280, 'image_id': '1647144040.0070002_rain', 'sem_seg_file_name': '/home/gregory/Documents/RainPerception/Carla/packaging/package2/1647144040.0070002_semantic_train.png'}\n",
      "{'file_name': '/home/gregory/Documents/RainPerception/Carla/packaging/package2/1647144051.8223236_clear.png', 'height': 720, 'width': 1280, 'image_id': '1647144051.8223236_clear', 'sem_seg_file_name': '/home/gregory/Documents/RainPerception/Carla/packaging/package2/1647144051.8223236_semantic_train.png'}\n",
      "{'file_name': '/home/gregory/Documents/RainPerception/Carla/packaging/package2/1647144051.8223236_rain_H.png', 'height': 720, 'width': 1280, 'image_id': '1647144051.8223236_rain', 'sem_seg_file_name': '/home/gregory/Documents/RainPerception/Carla/packaging/package2/1647144051.8223236_semantic_train.png'}\n",
      "{'file_name': '/home/gregory/Documents/RainPerception/Cityscapes/leftImg8bit/train/ulm/ulm_000093_000019_leftImg8bit.png', 'height': 1024, 'width': 2048, 'image_id': 'ulm_000093_000019_clear', 'sem_seg_file_name': '/home/gregory/Documents/RainPerception/Cityscapes/gtFine/train/ulm/ulm_000093_000019_train.png'}\n",
      "{'file_name': '/home/gregory/Documents/RainPerception/RainRemoval/RainAddition/ulm/ulm_000093_000019_H.png', 'height': 1024, 'width': 2048, 'image_id': 'ulm_000093_000019_rain', 'sem_seg_file_name': '/home/gregory/Documents/RainPerception/Cityscapes/gtFine/train/ulm/ulm_000093_000019_train.png'}\n",
      "{'file_name': '/home/gregory/Documents/RainPerception/Cityscapes/leftImg8bit/train/ulm/ulm_000094_000019_leftImg8bit.png', 'height': 1024, 'width': 2048, 'image_id': 'ulm_000094_000019_clear', 'sem_seg_file_name': '/home/gregory/Documents/RainPerception/Cityscapes/gtFine/train/ulm/ulm_000094_000019_train.png'}\n",
      "{'file_name': '/home/gregory/Documents/RainPerception/RainRemoval/RainAddition/ulm/ulm_000094_000019_M.png', 'height': 1024, 'width': 2048, 'image_id': 'ulm_000094_000019_rain', 'sem_seg_file_name': '/home/gregory/Documents/RainPerception/Cityscapes/gtFine/train/ulm/ulm_000094_000019_train.png'}\n",
      "17926\n",
      "12466\n",
      "\n",
      "**************************************************\n",
      "Combined all night\n",
      "{'file_name': '/home/gregory/Documents/RainPerception/Carla/packaging/package2/1647144040.0070002_clear.png', 'height': 720, 'width': 1280, 'image_id': '1647144040.0070002_clear', 'sem_seg_file_name': '/home/gregory/Documents/RainPerception/Carla/packaging/package2/1647144040.0070002_semantic_train.png'}\n",
      "{'file_name': '/home/gregory/Documents/RainPerception/Carla/packaging/package2/1647144040.0070002_rain_S.png', 'height': 720, 'width': 1280, 'image_id': '1647144040.0070002_rain', 'sem_seg_file_name': '/home/gregory/Documents/RainPerception/Carla/packaging/package2/1647144040.0070002_semantic_train.png'}\n",
      "{'file_name': '/home/gregory/Documents/RainPerception/Carla/packaging/package2/1647144051.8223236_clear.png', 'height': 720, 'width': 1280, 'image_id': '1647144051.8223236_clear', 'sem_seg_file_name': '/home/gregory/Documents/RainPerception/Carla/packaging/package2/1647144051.8223236_semantic_train.png'}\n",
      "{'file_name': '/home/gregory/Documents/RainPerception/Carla/packaging/package2/1647144051.8223236_rain_H.png', 'height': 720, 'width': 1280, 'image_id': '1647144051.8223236_rain', 'sem_seg_file_name': '/home/gregory/Documents/RainPerception/Carla/packaging/package2/1647144051.8223236_semantic_train.png'}\n",
      "{'file_name': '/home/gregory/Documents/RainPerception/CarlaNight/night_packaging/carla_data_night_2/1656198969.8900688_clear.png', 'height': 720, 'width': 1280, 'image_id': '1656198969.8900688_clear', 'sem_seg_file_name': '/home/gregory/Documents/RainPerception/CarlaNight/night_packaging/carla_data_night_2/1656198969.8900688_semantic_train.png'}\n",
      "{'file_name': '/home/gregory/Documents/RainPerception/CarlaNight/night_packaging/carla_data_night_2/1656198969.8900688_rain_S.png', 'height': 720, 'width': 1280, 'image_id': '1656198969.8900688_rain', 'sem_seg_file_name': '/home/gregory/Documents/RainPerception/CarlaNight/night_packaging/carla_data_night_2/1656198969.8900688_semantic_train.png'}\n",
      "{'file_name': '/home/gregory/Documents/RainPerception/CarlaNight/night_packaging/carla_data_night_2/1656198980.7042713_clear.png', 'height': 720, 'width': 1280, 'image_id': '1656198980.7042713_clear', 'sem_seg_file_name': '/home/gregory/Documents/RainPerception/CarlaNight/night_packaging/carla_data_night_2/1656198980.7042713_semantic_train.png'}\n",
      "{'file_name': '/home/gregory/Documents/RainPerception/CarlaNight/night_packaging/carla_data_night_2/1656198980.7042713_rain_S.png', 'height': 720, 'width': 1280, 'image_id': '1656198980.7042713_rain', 'sem_seg_file_name': '/home/gregory/Documents/RainPerception/CarlaNight/night_packaging/carla_data_night_2/1656198980.7042713_semantic_train.png'}\n",
      "33372\n",
      "19012\n",
      "\n",
      "**************************************************\n",
      "Others\n"
     ]
    }
   ],
   "source": [
    "print('**************************************************')\n",
    "print('Combined clear')\n",
    "\n",
    "def get_combined_clear_train_dicts():\n",
    "    return get_carla_clear_train_dicts() + get_cityscapes_clear_train_dicts()\n",
    "\n",
    "def get_combined_clear_val_dicts():\n",
    "    return get_carla_clear_val_dicts() + get_cityscapes_clear_val_dicts()\n",
    "\n",
    "if DEBUG == True:\n",
    "    for dict in get_combined_clear_train_dicts()[:4]:\n",
    "        print(dict)\n",
    "    for dict in get_combined_clear_train_dicts()[-4:]:\n",
    "        print(dict)\n",
    "    \n",
    "print(len(get_combined_clear_train_dicts())) # 2990 + 2276 = 5266\n",
    "print(len(get_combined_clear_val_dicts()))   # 1173 + 699  = 1872\n",
    "\n",
    "print('\\n**************************************************')\n",
    "print('Combined rain')\n",
    "\n",
    "def get_combined_rain_train_dicts():\n",
    "    return get_carla_rain_train_dicts() + get_cityscapes_rain_train_dicts()\n",
    "\n",
    "def get_combined_rain_val_dicts():\n",
    "    return get_carla_rain_val_dicts() + get_cityscapes_rain_val_dicts()\n",
    "\n",
    "if DEBUG == True:\n",
    "    for dict in get_combined_rain_train_dicts()[:4]:\n",
    "        print(dict)\n",
    "    for dict in get_combined_rain_train_dicts()[-4:]:\n",
    "        print(dict)\n",
    "    \n",
    "print(len(get_combined_rain_train_dicts())) # 2990 + 2276 = 5266\n",
    "print(len(get_combined_rain_val_dicts()))   # 1173 + 699  = 1872\n",
    "\n",
    "print('\\n**************************************************')\n",
    "print('Combined all')\n",
    "\n",
    "def get_combined_all_train_dicts():\n",
    "    return get_carla_all_train_dicts() + get_cityscapes_all_train_dicts()\n",
    "\n",
    "def get_combined_all_val_dicts():\n",
    "    return get_carla_all_val_dicts() + get_cityscapes_all_val_dicts()\n",
    "\n",
    "if DEBUG == True:\n",
    "    for dict in get_combined_all_train_dicts()[:4]:\n",
    "        print(dict)\n",
    "    for dict in get_combined_all_train_dicts()[-4:]:\n",
    "        print(dict)\n",
    "\n",
    "print(len(get_combined_all_train_dicts())) # 5266*2 = 10532\n",
    "print(len(get_combined_all_val_dicts()))   # 1872*2 = 3744\n",
    "\n",
    "print('\\n**************************************************')\n",
    "print('Combined all night')\n",
    "\n",
    "def get_combined_clear_both_train_dicts():\n",
    "    return get_combined_clear_train_dicts() + get_carla_night_clear_train_dicts()\n",
    "\n",
    "def get_combined_clear_both_val_dicts():\n",
    "    return get_combined_clear_val_dicts() + get_carla_night_clear_val_dicts()\n",
    "\n",
    "def get_combined_all_night_train_dicts():\n",
    "    return get_combined_all_train_dicts() + get_carla_night_all_train_dicts()\n",
    "\n",
    "def get_combined_all_night_val_dicts():\n",
    "    return get_combined_all_val_dicts() + get_carla_night_all_val_dicts()\n",
    "\n",
    "if DEBUG == True:\n",
    "    for dict in get_combined_all_night_train_dicts()[:4]:\n",
    "        print(dict)\n",
    "    for dict in get_combined_all_night_val_dicts()[-4:]:\n",
    "        print(dict)\n",
    "\n",
    "print(len(get_combined_all_night_train_dicts())) # 10532 + 5684 = 16216\n",
    "print(len(get_combined_all_night_val_dicts()))   # 3744  + 5948 = 9692\n",
    "\n",
    "\n",
    "print('\\n**************************************************')\n",
    "print('Others')\n",
    "def get_carla_both_clear_val_dicts():\n",
    "    return get_carla_clear_val_dicts() + get_carla_night_clear_val_dicts()\n",
    "\n",
    "def get_carla_both_rain_val_dicts():\n",
    "    return get_carla_rain_val_dicts() + get_carla_night_rain_val_dicts()\n",
    "\n",
    "def get_combined_both_rain_val_dicts():\n",
    "    return get_carla_both_rain_val_dicts() + get_cityscapes_rain_val_dicts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7173710",
   "metadata": {
    "id": "KVqmnxQOn4Nm"
   },
   "source": [
    "# Convert labels to train IDs\n",
    "Execute only once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a785cab8",
   "metadata": {
    "id": "d467859a-d17d-481f-aa6f-553a513bdfc7"
   },
   "outputs": [],
   "source": [
    "# %cd '/home/tunx404/Miscellaneous/data/Cityscapes/mapped_labels/train/'\n",
    "# for city_name in city_name_list:\n",
    "#     !mkdir $city_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d3317c56",
   "metadata": {
    "id": "80ddac12"
   },
   "outputs": [],
   "source": [
    "# convert_carla(data_carla_train_file_list, data_carla_dir)\n",
    "# convert_carla(data_carla_val_file_list, data_carla_dir)\n",
    "\n",
    "# convert_carla(data_carla_night_train_file_list, data_carla_night_dir)\n",
    "# convert_carla(data_carla_night_val_file_list, data_carla_night_dir)\n",
    "\n",
    "#convert_cityscapes(data_cityscapes_train_file_list, anno_dir_cityscapes, output_dir='/home/gregory/Documents/RainPerception/Cityscapes/gtFine/train/')\n",
    "#convert_cityscapes(data_cityscapes_val_file_list, anno_dir_cityscapes, output_dir='/home/gregory/Documents/RainPerception/Cityscapes/gtFine/val/')\n",
    "\n",
    "#convert_cityscapes(data_cityscapes_val_file_list, anno_dir_cityscapes, output_dir=data_dir+'labels/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01b58218",
   "metadata": {
    "id": "25818909"
   },
   "source": [
    "# Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "27cd5899",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 588,
     "status": "ok",
     "timestamp": 1650750039781,
     "user": {
      "displayName": "Tũn Tũn",
      "userId": "10147808466179585969"
     },
     "user_tz": 240
    },
    "id": "33d9e8dd",
    "outputId": "90ce465b-86ec-4a75-a9a9-cfc4affb6a48"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n",
      "Carla clear dataset\n",
      "Number of train images: 8868\n",
      "Number of val images:   3258\n",
      "\n",
      "Carla rain dataset\n",
      "Number of train images: 8868\n",
      "Number of val images:   3258\n",
      "\n",
      "Carla all dataset\n",
      "Number of train images: 8868\n",
      "Number of val images:   6516\n",
      "\n",
      "**************************************************\n",
      "Carla night clear dataset\n",
      "Number of train images: 7723\n",
      "Number of val images:   3273\n",
      "\n",
      "Carla night rain dataset\n",
      "Number of train images: 7723\n",
      "Number of val images:   3273\n",
      "\n",
      "Carla night all dataset\n",
      "Number of train images: 15446\n",
      "Number of val images:   6546\n",
      "\n",
      "**************************************************\n",
      "Cityscapes clear dataset\n",
      "Number of train images: 95\n",
      "Number of val images:   2975\n",
      "\n",
      "Cityscapes rain dataset\n",
      "Number of train images: 95\n",
      "Number of val images:   2975\n",
      "\n",
      "Cityscapes day dataset\n",
      "Number of train images: 190\n",
      "Number of val images:   5950\n",
      "\n",
      "**************************************************\n",
      "Combined clear dataset\n",
      "Number of train images: 8963\n",
      "Number of val images:   6233\n",
      "\n",
      "Combined rain dataset\n",
      "Number of train images: 8963\n",
      "Number of val images:   6233\n",
      "\n",
      "Combined all dataset\n",
      "Number of train images: 17926\n",
      "Number of val images:   12466\n",
      "\n",
      "**************************************************\n",
      "Combined all night dataset (rain+clear, day+night)\n",
      "Number of train images: 33372\n",
      "Number of val images:   19012\n",
      "\n",
      "Combined clear both dataset\n",
      "Number of train images: 16686\n",
      "Number of val images:   9506\n",
      "\n",
      "Combined rain both dataset\n",
      "Number of train images: 16686\n",
      "Number of val images:   9506\n",
      "\n",
      "**************************************************\n",
      "Number of train images: 16686\n",
      "Number of val images:   6531\n",
      "Number of train images: 16686\n",
      "Number of val images:   6531\n",
      "Number of train images: 16686\n",
      "Number of val images:   9506\n"
     ]
    }
   ],
   "source": [
    "DatasetCatalog.clear()\n",
    "\n",
    "print('**************************************************')\n",
    "\n",
    "print('Carla clear dataset')\n",
    "carla_clear_dataset = Detectron2CustomDataset('carla_clear_train', 'carla_clear_val', get_carla_clear_train_dicts, get_carla_clear_val_dicts)\n",
    "# carla_clear_dataset.visualize_dataset(num_samples=4, size=(20, 10), show_original=True)\n",
    "            \n",
    "print('\\nCarla rain dataset')\n",
    "carla_rain_dataset = Detectron2CustomDataset('carla_rain_train', 'carla_rain_val', get_carla_rain_train_dicts, get_carla_rain_val_dicts)\n",
    "# carla_rain_dataset.visualize_dataset(num_samples=1, size=(20, 10), show_original=True)\n",
    "\n",
    "print('\\nCarla all dataset')\n",
    "carla_day_dataset = Detectron2CustomDataset('carla_rain_train_2', 'carla_day_val', get_carla_rain_train_dicts, get_carla_all_val_dicts)\n",
    "\n",
    "# print('\\nCarla derained dataset')\n",
    "# carla_derained_dataset = Detectron2CustomDataset('carla_derained_train', 'carla_derained_val', get_carla_rain_train_dicts, get_carla_derained_val_dicts)\n",
    "# # carla_rain_dataset.visualize_dataset(num_samples=1, size=(20, 10), show_original=True)\n",
    "\n",
    "##################################################\n",
    "\n",
    "print('\\n**************************************************')\n",
    "\n",
    "print('Carla night clear dataset')\n",
    "carla_night_clear_dataset = Detectron2CustomDataset('carla_night_clear_train', 'carla_night_clear_val', get_carla_night_clear_train_dicts, get_carla_night_clear_val_dicts)\n",
    "# carla_night_clear_dataset.visualize_dataset(num_samples=1, size=(20, 10), show_original=True)\n",
    "            \n",
    "print('\\nCarla night rain dataset')\n",
    "carla_night_rain_dataset = Detectron2CustomDataset('carla_night_rain_train', 'carla_night_rain_val', get_carla_night_rain_train_dicts, get_carla_night_rain_val_dicts)\n",
    "# carla_night_rain_dataset.visualize_dataset(num_samples=1, size=(20, 10), show_original=True)\n",
    "\n",
    "print('\\nCarla night all dataset')\n",
    "carla_night_all_dataset = Detectron2CustomDataset('carla_night_all_train', 'carla_night_all_val', get_carla_night_all_train_dicts, get_carla_night_all_val_dicts)\n",
    "# carla_night_all_dataset.visualize_dataset(num_samples=1, size=(20, 10), show_original=True)\n",
    "\n",
    "##################################################\n",
    "\n",
    "print('\\n**************************************************')\n",
    "\n",
    "print('Cityscapes clear dataset')\n",
    "cityscapes_clear_dataset = Detectron2CustomDataset('cityscapes_clear_train', 'cityscapes_clear_val', get_cityscapes_clear_train_dicts, get_cityscapes_clear_val_dicts)\n",
    "# cityscapes_clear_dataset.visualize_dataset(num_samples=10, size=(20, 10), show_original=True)\n",
    "\n",
    "print('\\nCityscapes rain dataset')\n",
    "cityscapes_rain_dataset = Detectron2CustomDataset('cityscapes_rain_train', 'cityscapes_rain_val', get_cityscapes_rain_train_dicts, get_cityscapes_rain_val_dicts)\n",
    "# cityscapes_rain_dataset.visualize_dataset(num_samples=1, size=(20, 10), show_original=True)\n",
    "\n",
    "print('\\nCityscapes day dataset')\n",
    "cityscapes_day_dataset = Detectron2CustomDataset('cityscapes_day_train', 'cityscapes_day_val', get_cityscapes_all_train_dicts, get_cityscapes_all_val_dicts)\n",
    "\n",
    "##################################################\n",
    "\n",
    "print('\\n**************************************************')\n",
    "            \n",
    "print('Combined clear dataset')\n",
    "combined_clear_dataset = Detectron2CustomDataset('combined_clear_train', 'combined_clear_val', get_combined_clear_train_dicts, get_combined_clear_val_dicts)\n",
    "# combined_clear_dataset.visualize_dataset(num_samples=1, size=(20, 10), show_original=True)\n",
    "            \n",
    "print('\\nCombined rain dataset')\n",
    "combined_rain_dataset = Detectron2CustomDataset('combined_rain_train', 'combined_rain_val', get_combined_rain_train_dicts, get_combined_rain_val_dicts)\n",
    "# combined_rain_dataset.visualize_dataset(num_samples=1, size=(20, 10), show_original=True)\n",
    "            \n",
    "print('\\nCombined all dataset')\n",
    "combined_all_dataset = Detectron2CustomDataset('combined_all_train', 'combined_all_val', get_combined_all_train_dicts, get_combined_all_val_dicts)\n",
    "# combined_all_dataset.visualize_dataset(num_samples=1, size=(20, 10), show_original=True)\n",
    "\n",
    "##################################################\n",
    "\n",
    "print('\\n**************************************************')\n",
    "            \n",
    "print('Combined all night dataset (rain+clear, day+night)')\n",
    "combined_all_night_dataset = Detectron2CustomDataset('combined_all_night_train', 'combined_all_night_val', get_combined_all_night_train_dicts, get_combined_all_night_val_dicts)\n",
    "# combined_all_dataset.visualize_dataset(num_samples=20, size=(20, 10), show_original=True)\n",
    "\n",
    "print('\\nCombined clear both dataset')\n",
    "combined_clear_both_dataset = Detectron2CustomDataset('combined_clear_both_train', 'combined_clear_both_val', get_combined_clear_both_train_dicts, get_combined_clear_both_val_dicts)\n",
    "# combined_all_dataset.visualize_dataset(num_samples=20, size=(20, 10), show_original=True)\n",
    "\n",
    "print('\\nCombined rain both dataset')\n",
    "combined_rain_both_dataset = Detectron2CustomDataset('combined_rain_both_train', 'combined_rain_both_val', get_combined_clear_both_train_dicts, get_combined_clear_both_val_dicts)\n",
    "# combined_all_dataset.visualize_dataset(num_samples=20, size=(20, 10), show_original=True)\n",
    "\n",
    "print('\\n**************************************************')\n",
    "carla_both_clear_dataset = Detectron2CustomDataset('combined_rain_both_train2', 'carla_both_clear_val', get_combined_clear_both_train_dicts, get_carla_both_clear_val_dicts)\n",
    "\n",
    "carla_both_rain_dataset = Detectron2CustomDataset('combined_rain_both_train3', 'carla_both_rain_val', get_combined_clear_both_train_dicts, get_carla_both_rain_val_dicts)\n",
    "\n",
    "combined_both_rain_dataset = Detectron2CustomDataset('combined_rain_both_train4', 'combined_both_rain_val', get_combined_clear_both_train_dicts, get_combined_both_rain_val_dicts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d1d838d",
   "metadata": {
    "id": "l0TtWq0-DxjT"
   },
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8cda77fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import os\n",
    "#os.environ['CUDA_VISIBLE_DEVICES'] = '0, 1'\n",
    "#os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
    "#print(os.environ['CUDA_VISIBLE_DEVICES'])\n",
    "#print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "76a6100e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6bd2452e",
    "outputId": "6b55e451-4d71-4cef-94a4-680b0b443221"
   },
   "outputs": [],
   "source": [
    "#trainer_all = Detectron2Trainer('combined_all_night_train', 'combined_all_night_val', output_folder='./output_part_night_40k')\n",
    "#trainer_all.load()\n",
    "#trainer_all.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ef085596",
   "metadata": {
    "id": "mPFpcmeBIxQQ"
   },
   "outputs": [],
   "source": [
    "#trainer_clear = Detectron2Trainer('cityscapes_clear_train', 'cityscapes_clear_val', output_folder='./output_combined_all_40k')\n",
    "#trainer_clear.load()\n",
    "#detectron2.engine.launch(trainer_clear.train, 3)\n",
    "#trainer_clear.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4e4a5c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainer_clear.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5fb7936d",
   "metadata": {
    "id": "39c385b8"
   },
   "outputs": [],
   "source": [
    "# %load_ext tensorboard\n",
    "# %tensorboard --logdir output_all_40k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "53a3227e",
   "metadata": {
    "id": "aVfRixZjJS_a"
   },
   "outputs": [],
   "source": [
    "# %load_ext tensorboard\n",
    "# %tensorboard --logdir output_clear_20k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "43236661",
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainer_all = Detectron2Trainer('carla_night_all_train', 'carla_night_all_val', output_folder='./output_test_night_40k')\n",
    "#trainer_all.load()\n",
    "#trainer_all.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "065008d1",
   "metadata": {},
   "source": [
    "## Models for Construction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f731fb42",
   "metadata": {},
   "source": [
    "### -3. Day Clear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b9bd2377",
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainer_all = Detectron2Trainer('combined_clear_train', 'combined_clear_val', output_folder='./output_day_clear_40k')\n",
    "#trainer_all.load()\n",
    "#trainer_all.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3c67313",
   "metadata": {},
   "source": [
    "### -2. Night Clear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7dab72c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainer_all = Detectron2Trainer('carla_night_clear_train', 'carla_night_clear_val', output_folder='./output_night_clear_40k')\n",
    "#trainer_all.load()\n",
    "#trainer_all.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d6e5ca3",
   "metadata": {},
   "source": [
    "### -1. Day and Night Clear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "99f3d6bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainer_all = Detectron2Trainer('combined_clear_both_train', 'combined_clear_both_val', output_folder='./output_both_clear_40k') # Actually has both day and night\n",
    "#trainer_all.load()\n",
    "#trainer_all.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8926ed79",
   "metadata": {},
   "source": [
    "### 1. Day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1cc2fc38",
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainer_all = Detectron2Trainer('combined_all_train', 'combined_all_val', output_folder='./output_day_40k')\n",
    "#trainer_all.load()\n",
    "#trainer_all.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "604a2c13",
   "metadata": {},
   "source": [
    "### 2. Night"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "43312109",
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainer_all = Detectron2Trainer('carla_night_all_train', 'carla_night_all_val', output_folder='./output_night_40k')\n",
    "#trainer_all.load()\n",
    "#trainer_all.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f86e255",
   "metadata": {},
   "source": [
    "### 3. Day and Night"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d6eafb86",
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainer_all = Detectron2Trainer('combined_all_night_train', 'combined_all_night_val', output_folder='./output_both_40k') # Actually has both day and night\n",
    "#trainer_all.load()\n",
    "#trainer_all.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c17fe47",
   "metadata": {
    "id": "t5iO65WNDzRa"
   },
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48b19e0f",
   "metadata": {},
   "source": [
    "## Models for Construction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef56ace8",
   "metadata": {},
   "source": [
    "### 1. Day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bdedfc49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/06 22:21:07 d2.engine.defaults]: \u001b[0mModel:\n",
      "SemanticSegmentor(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (sem_seg_head): SemSegFPNHead(\n",
      "    (p2): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "    )\n",
      "    (p3): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (1): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "    )\n",
      "    (p4): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (1): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      (2): Conv2d(\n",
      "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (3): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "    )\n",
      "    (p5): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (1): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      (2): Conv2d(\n",
      "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (3): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      (4): Conv2d(\n",
      "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (5): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "    )\n",
      "    (predictor): Conv2d(128, 17, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/06 22:21:07 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(720, 720), max_size=2048, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[07/06 22:21:07 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[07/06 22:21:07 d2.data.common]: \u001b[0mSerializing 3353 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[07/06 22:21:07 d2.data.common]: \u001b[0mSerialized dataset takes 1.18 MiB\n",
      "Last checkpoint: model_final.pth\n",
      "\u001b[32m[07/06 22:21:08 d2.checkpoint.c2_model_loading]: \u001b[0mFollowing weights matched with model:\n",
      "| Names in Model                       | Names in Checkpoint                                                                                  | Shapes                                          |\n",
      "|:-------------------------------------|:-----------------------------------------------------------------------------------------------------|:------------------------------------------------|\n",
      "| backbone.bottom_up.res2.0.conv1.*    | backbone.bottom_up.res2.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,1,1)             |\n",
      "| backbone.bottom_up.res2.0.conv2.*    | backbone.bottom_up.res2.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |\n",
      "| backbone.bottom_up.res2.0.conv3.*    | backbone.bottom_up.res2.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res2.0.shortcut.* | backbone.bottom_up.res2.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res2.1.conv1.*    | backbone.bottom_up.res2.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |\n",
      "| backbone.bottom_up.res2.1.conv2.*    | backbone.bottom_up.res2.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |\n",
      "| backbone.bottom_up.res2.1.conv3.*    | backbone.bottom_up.res2.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res2.2.conv1.*    | backbone.bottom_up.res2.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |\n",
      "| backbone.bottom_up.res2.2.conv2.*    | backbone.bottom_up.res2.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |\n",
      "| backbone.bottom_up.res2.2.conv3.*    | backbone.bottom_up.res2.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res3.0.conv1.*    | backbone.bottom_up.res3.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,256,1,1)       |\n",
      "| backbone.bottom_up.res3.0.conv2.*    | backbone.bottom_up.res3.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.0.conv3.*    | backbone.bottom_up.res3.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res3.0.shortcut.* | backbone.bottom_up.res3.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (512,) (512,) (512,) (512,) (512,256,1,1)       |\n",
      "| backbone.bottom_up.res3.1.conv1.*    | backbone.bottom_up.res3.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |\n",
      "| backbone.bottom_up.res3.1.conv2.*    | backbone.bottom_up.res3.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.1.conv3.*    | backbone.bottom_up.res3.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res3.2.conv1.*    | backbone.bottom_up.res3.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |\n",
      "| backbone.bottom_up.res3.2.conv2.*    | backbone.bottom_up.res3.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.2.conv3.*    | backbone.bottom_up.res3.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res3.3.conv1.*    | backbone.bottom_up.res3.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |\n",
      "| backbone.bottom_up.res3.3.conv2.*    | backbone.bottom_up.res3.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.3.conv3.*    | backbone.bottom_up.res3.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res4.0.conv1.*    | backbone.bottom_up.res4.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,512,1,1)       |\n",
      "| backbone.bottom_up.res4.0.conv2.*    | backbone.bottom_up.res4.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.0.conv3.*    | backbone.bottom_up.res4.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.0.shortcut.* | backbone.bottom_up.res4.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (1024,) (1024,) (1024,) (1024,) (1024,512,1,1)  |\n",
      "| backbone.bottom_up.res4.1.conv1.*    | backbone.bottom_up.res4.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.1.conv2.*    | backbone.bottom_up.res4.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.1.conv3.*    | backbone.bottom_up.res4.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.2.conv1.*    | backbone.bottom_up.res4.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.2.conv2.*    | backbone.bottom_up.res4.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.2.conv3.*    | backbone.bottom_up.res4.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.3.conv1.*    | backbone.bottom_up.res4.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.3.conv2.*    | backbone.bottom_up.res4.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.3.conv3.*    | backbone.bottom_up.res4.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.4.conv1.*    | backbone.bottom_up.res4.4.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.4.conv2.*    | backbone.bottom_up.res4.4.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.4.conv3.*    | backbone.bottom_up.res4.4.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.5.conv1.*    | backbone.bottom_up.res4.5.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.5.conv2.*    | backbone.bottom_up.res4.5.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.5.conv3.*    | backbone.bottom_up.res4.5.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res5.0.conv1.*    | backbone.bottom_up.res5.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,1024,1,1)      |\n",
      "| backbone.bottom_up.res5.0.conv2.*    | backbone.bottom_up.res5.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |\n",
      "| backbone.bottom_up.res5.0.conv3.*    | backbone.bottom_up.res5.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
      "| backbone.bottom_up.res5.0.shortcut.* | backbone.bottom_up.res5.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (2048,) (2048,) (2048,) (2048,) (2048,1024,1,1) |\n",
      "| backbone.bottom_up.res5.1.conv1.*    | backbone.bottom_up.res5.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |\n",
      "| backbone.bottom_up.res5.1.conv2.*    | backbone.bottom_up.res5.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |\n",
      "| backbone.bottom_up.res5.1.conv3.*    | backbone.bottom_up.res5.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
      "| backbone.bottom_up.res5.2.conv1.*    | backbone.bottom_up.res5.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |\n",
      "| backbone.bottom_up.res5.2.conv2.*    | backbone.bottom_up.res5.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |\n",
      "| backbone.bottom_up.res5.2.conv3.*    | backbone.bottom_up.res5.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
      "| backbone.bottom_up.stem.conv1.*      | backbone.bottom_up.stem.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}      | (64,) (64,) (64,) (64,) (64,3,7,7)              |\n",
      "| backbone.fpn_lateral2.*              | backbone.fpn_lateral2.{bias,weight}                                                                  | (256,) (256,256,1,1)                            |\n",
      "| backbone.fpn_lateral3.*              | backbone.fpn_lateral3.{bias,weight}                                                                  | (256,) (256,512,1,1)                            |\n",
      "| backbone.fpn_lateral4.*              | backbone.fpn_lateral4.{bias,weight}                                                                  | (256,) (256,1024,1,1)                           |\n",
      "| backbone.fpn_lateral5.*              | backbone.fpn_lateral5.{bias,weight}                                                                  | (256,) (256,2048,1,1)                           |\n",
      "| backbone.fpn_output2.*               | backbone.fpn_output2.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| backbone.fpn_output3.*               | backbone.fpn_output3.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| backbone.fpn_output4.*               | backbone.fpn_output4.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| backbone.fpn_output5.*               | backbone.fpn_output5.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| sem_seg_head.p2.0.*                  | sem_seg_head.p2.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p3.0.*                  | sem_seg_head.p3.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p4.0.*                  | sem_seg_head.p4.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p4.2.*                  | sem_seg_head.p4.2.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,128,3,3)                     |\n",
      "| sem_seg_head.p5.0.*                  | sem_seg_head.p5.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p5.2.*                  | sem_seg_head.p5.2.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,128,3,3)                     |\n",
      "| sem_seg_head.p5.4.*                  | sem_seg_head.p5.4.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,128,3,3)                     |\n",
      "| sem_seg_head.predictor.*             | sem_seg_head.predictor.{bias,weight}                                                                 | (17,) (17,128,1,1)                              |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/06 22:21:08 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(720, 720), max_size=2048, sample_style='choice')]\n",
      "\u001b[32m[07/06 22:21:08 d2.data.common]: \u001b[0mSerializing 3258 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[07/06 22:21:08 d2.data.common]: \u001b[0mSerialized dataset takes 1.15 MiB\n",
      "\u001b[32m[07/06 22:21:08 d2.evaluation.evaluator]: \u001b[0mStart inference on 3258 batches\n",
      "\u001b[32m[07/06 22:21:09 d2.evaluation.evaluator]: \u001b[0mInference done 11/3258. Dataloading: 0.0016 s/iter. Inference: 0.0349 s/iter. Eval: 0.0438 s/iter. Total: 0.0804 s/iter. ETA=0:04:20\n",
      "\u001b[32m[07/06 22:21:14 d2.evaluation.evaluator]: \u001b[0mInference done 76/3258. Dataloading: 0.0020 s/iter. Inference: 0.0347 s/iter. Eval: 0.0415 s/iter. Total: 0.0782 s/iter. ETA=0:04:08\n",
      "\u001b[32m[07/06 22:21:19 d2.evaluation.evaluator]: \u001b[0mInference done 144/3258. Dataloading: 0.0020 s/iter. Inference: 0.0347 s/iter. Eval: 0.0395 s/iter. Total: 0.0764 s/iter. ETA=0:03:57\n",
      "\u001b[32m[07/06 22:21:24 d2.evaluation.evaluator]: \u001b[0mInference done 212/3258. Dataloading: 0.0020 s/iter. Inference: 0.0348 s/iter. Eval: 0.0388 s/iter. Total: 0.0757 s/iter. ETA=0:03:50\n",
      "\u001b[32m[07/06 22:21:29 d2.evaluation.evaluator]: \u001b[0mInference done 280/3258. Dataloading: 0.0021 s/iter. Inference: 0.0348 s/iter. Eval: 0.0383 s/iter. Total: 0.0752 s/iter. ETA=0:03:44\n",
      "\u001b[32m[07/06 22:21:34 d2.evaluation.evaluator]: \u001b[0mInference done 348/3258. Dataloading: 0.0021 s/iter. Inference: 0.0348 s/iter. Eval: 0.0381 s/iter. Total: 0.0751 s/iter. ETA=0:03:38\n",
      "\u001b[32m[07/06 22:21:39 d2.evaluation.evaluator]: \u001b[0mInference done 416/3258. Dataloading: 0.0021 s/iter. Inference: 0.0349 s/iter. Eval: 0.0378 s/iter. Total: 0.0749 s/iter. ETA=0:03:32\n",
      "\u001b[32m[07/06 22:21:44 d2.evaluation.evaluator]: \u001b[0mInference done 485/3258. Dataloading: 0.0021 s/iter. Inference: 0.0349 s/iter. Eval: 0.0375 s/iter. Total: 0.0745 s/iter. ETA=0:03:26\n",
      "\u001b[32m[07/06 22:21:49 d2.evaluation.evaluator]: \u001b[0mInference done 554/3258. Dataloading: 0.0021 s/iter. Inference: 0.0350 s/iter. Eval: 0.0372 s/iter. Total: 0.0744 s/iter. ETA=0:03:21\n",
      "\u001b[32m[07/06 22:21:55 d2.evaluation.evaluator]: \u001b[0mInference done 622/3258. Dataloading: 0.0021 s/iter. Inference: 0.0350 s/iter. Eval: 0.0372 s/iter. Total: 0.0744 s/iter. ETA=0:03:16\n",
      "\u001b[32m[07/06 22:22:00 d2.evaluation.evaluator]: \u001b[0mInference done 689/3258. Dataloading: 0.0021 s/iter. Inference: 0.0350 s/iter. Eval: 0.0373 s/iter. Total: 0.0745 s/iter. ETA=0:03:11\n",
      "\u001b[32m[07/06 22:22:05 d2.evaluation.evaluator]: \u001b[0mInference done 753/3258. Dataloading: 0.0022 s/iter. Inference: 0.0350 s/iter. Eval: 0.0374 s/iter. Total: 0.0748 s/iter. ETA=0:03:07\n",
      "\u001b[32m[07/06 22:22:10 d2.evaluation.evaluator]: \u001b[0mInference done 819/3258. Dataloading: 0.0022 s/iter. Inference: 0.0351 s/iter. Eval: 0.0375 s/iter. Total: 0.0749 s/iter. ETA=0:03:02\n",
      "\u001b[32m[07/06 22:22:15 d2.evaluation.evaluator]: \u001b[0mInference done 885/3258. Dataloading: 0.0022 s/iter. Inference: 0.0351 s/iter. Eval: 0.0376 s/iter. Total: 0.0750 s/iter. ETA=0:02:58\n",
      "\u001b[32m[07/06 22:22:20 d2.evaluation.evaluator]: \u001b[0mInference done 951/3258. Dataloading: 0.0022 s/iter. Inference: 0.0351 s/iter. Eval: 0.0377 s/iter. Total: 0.0751 s/iter. ETA=0:02:53\n",
      "\u001b[32m[07/06 22:22:25 d2.evaluation.evaluator]: \u001b[0mInference done 1017/3258. Dataloading: 0.0022 s/iter. Inference: 0.0351 s/iter. Eval: 0.0378 s/iter. Total: 0.0752 s/iter. ETA=0:02:48\n",
      "\u001b[32m[07/06 22:22:30 d2.evaluation.evaluator]: \u001b[0mInference done 1083/3258. Dataloading: 0.0022 s/iter. Inference: 0.0351 s/iter. Eval: 0.0379 s/iter. Total: 0.0753 s/iter. ETA=0:02:43\n",
      "\u001b[32m[07/06 22:22:35 d2.evaluation.evaluator]: \u001b[0mInference done 1147/3258. Dataloading: 0.0022 s/iter. Inference: 0.0351 s/iter. Eval: 0.0381 s/iter. Total: 0.0755 s/iter. ETA=0:02:39\n",
      "\u001b[32m[07/06 22:22:40 d2.evaluation.evaluator]: \u001b[0mInference done 1212/3258. Dataloading: 0.0022 s/iter. Inference: 0.0351 s/iter. Eval: 0.0382 s/iter. Total: 0.0756 s/iter. ETA=0:02:34\n",
      "\u001b[32m[07/06 22:22:45 d2.evaluation.evaluator]: \u001b[0mInference done 1278/3258. Dataloading: 0.0022 s/iter. Inference: 0.0351 s/iter. Eval: 0.0382 s/iter. Total: 0.0757 s/iter. ETA=0:02:29\n",
      "\u001b[32m[07/06 22:22:50 d2.evaluation.evaluator]: \u001b[0mInference done 1343/3258. Dataloading: 0.0022 s/iter. Inference: 0.0351 s/iter. Eval: 0.0383 s/iter. Total: 0.0757 s/iter. ETA=0:02:25\n",
      "\u001b[32m[07/06 22:22:55 d2.evaluation.evaluator]: \u001b[0mInference done 1410/3258. Dataloading: 0.0022 s/iter. Inference: 0.0352 s/iter. Eval: 0.0383 s/iter. Total: 0.0757 s/iter. ETA=0:02:19\n",
      "\u001b[32m[07/06 22:23:00 d2.evaluation.evaluator]: \u001b[0mInference done 1476/3258. Dataloading: 0.0022 s/iter. Inference: 0.0352 s/iter. Eval: 0.0383 s/iter. Total: 0.0757 s/iter. ETA=0:02:14\n",
      "\u001b[32m[07/06 22:23:05 d2.evaluation.evaluator]: \u001b[0mInference done 1541/3258. Dataloading: 0.0022 s/iter. Inference: 0.0352 s/iter. Eval: 0.0384 s/iter. Total: 0.0758 s/iter. ETA=0:02:10\n",
      "\u001b[32m[07/06 22:23:10 d2.evaluation.evaluator]: \u001b[0mInference done 1607/3258. Dataloading: 0.0022 s/iter. Inference: 0.0352 s/iter. Eval: 0.0384 s/iter. Total: 0.0758 s/iter. ETA=0:02:05\n",
      "\u001b[32m[07/06 22:23:15 d2.evaluation.evaluator]: \u001b[0mInference done 1671/3258. Dataloading: 0.0022 s/iter. Inference: 0.0352 s/iter. Eval: 0.0384 s/iter. Total: 0.0759 s/iter. ETA=0:02:00\n",
      "\u001b[32m[07/06 22:23:20 d2.evaluation.evaluator]: \u001b[0mInference done 1735/3258. Dataloading: 0.0022 s/iter. Inference: 0.0352 s/iter. Eval: 0.0385 s/iter. Total: 0.0760 s/iter. ETA=0:01:55\n",
      "\u001b[32m[07/06 22:23:25 d2.evaluation.evaluator]: \u001b[0mInference done 1801/3258. Dataloading: 0.0022 s/iter. Inference: 0.0352 s/iter. Eval: 0.0386 s/iter. Total: 0.0761 s/iter. ETA=0:01:50\n",
      "\u001b[32m[07/06 22:23:30 d2.evaluation.evaluator]: \u001b[0mInference done 1865/3258. Dataloading: 0.0022 s/iter. Inference: 0.0352 s/iter. Eval: 0.0387 s/iter. Total: 0.0762 s/iter. ETA=0:01:46\n",
      "\u001b[32m[07/06 22:23:35 d2.evaluation.evaluator]: \u001b[0mInference done 1930/3258. Dataloading: 0.0022 s/iter. Inference: 0.0352 s/iter. Eval: 0.0387 s/iter. Total: 0.0762 s/iter. ETA=0:01:41\n",
      "\u001b[32m[07/06 22:23:40 d2.evaluation.evaluator]: \u001b[0mInference done 1995/3258. Dataloading: 0.0022 s/iter. Inference: 0.0352 s/iter. Eval: 0.0387 s/iter. Total: 0.0762 s/iter. ETA=0:01:36\n",
      "\u001b[32m[07/06 22:23:45 d2.evaluation.evaluator]: \u001b[0mInference done 2061/3258. Dataloading: 0.0022 s/iter. Inference: 0.0352 s/iter. Eval: 0.0387 s/iter. Total: 0.0762 s/iter. ETA=0:01:31\n",
      "\u001b[32m[07/06 22:23:50 d2.evaluation.evaluator]: \u001b[0mInference done 2127/3258. Dataloading: 0.0022 s/iter. Inference: 0.0352 s/iter. Eval: 0.0387 s/iter. Total: 0.0762 s/iter. ETA=0:01:26\n",
      "\u001b[32m[07/06 22:23:55 d2.evaluation.evaluator]: \u001b[0mInference done 2193/3258. Dataloading: 0.0022 s/iter. Inference: 0.0352 s/iter. Eval: 0.0387 s/iter. Total: 0.0762 s/iter. ETA=0:01:21\n",
      "\u001b[32m[07/06 22:24:01 d2.evaluation.evaluator]: \u001b[0mInference done 2260/3258. Dataloading: 0.0022 s/iter. Inference: 0.0353 s/iter. Eval: 0.0387 s/iter. Total: 0.0762 s/iter. ETA=0:01:16\n",
      "\u001b[32m[07/06 22:24:06 d2.evaluation.evaluator]: \u001b[0mInference done 2327/3258. Dataloading: 0.0022 s/iter. Inference: 0.0353 s/iter. Eval: 0.0386 s/iter. Total: 0.0762 s/iter. ETA=0:01:10\n",
      "\u001b[32m[07/06 22:24:11 d2.evaluation.evaluator]: \u001b[0mInference done 2393/3258. Dataloading: 0.0022 s/iter. Inference: 0.0353 s/iter. Eval: 0.0386 s/iter. Total: 0.0762 s/iter. ETA=0:01:05\n",
      "\u001b[32m[07/06 22:24:16 d2.evaluation.evaluator]: \u001b[0mInference done 2459/3258. Dataloading: 0.0022 s/iter. Inference: 0.0353 s/iter. Eval: 0.0386 s/iter. Total: 0.0762 s/iter. ETA=0:01:00\n",
      "\u001b[32m[07/06 22:24:21 d2.evaluation.evaluator]: \u001b[0mInference done 2524/3258. Dataloading: 0.0022 s/iter. Inference: 0.0353 s/iter. Eval: 0.0387 s/iter. Total: 0.0762 s/iter. ETA=0:00:55\n",
      "\u001b[32m[07/06 22:24:26 d2.evaluation.evaluator]: \u001b[0mInference done 2590/3258. Dataloading: 0.0022 s/iter. Inference: 0.0353 s/iter. Eval: 0.0386 s/iter. Total: 0.0762 s/iter. ETA=0:00:50\n",
      "\u001b[32m[07/06 22:24:31 d2.evaluation.evaluator]: \u001b[0mInference done 2656/3258. Dataloading: 0.0022 s/iter. Inference: 0.0353 s/iter. Eval: 0.0386 s/iter. Total: 0.0762 s/iter. ETA=0:00:45\n",
      "\u001b[32m[07/06 22:24:36 d2.evaluation.evaluator]: \u001b[0mInference done 2723/3258. Dataloading: 0.0022 s/iter. Inference: 0.0353 s/iter. Eval: 0.0386 s/iter. Total: 0.0762 s/iter. ETA=0:00:40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/06 22:24:41 d2.evaluation.evaluator]: \u001b[0mInference done 2789/3258. Dataloading: 0.0022 s/iter. Inference: 0.0353 s/iter. Eval: 0.0386 s/iter. Total: 0.0762 s/iter. ETA=0:00:35\n",
      "\u001b[32m[07/06 22:24:46 d2.evaluation.evaluator]: \u001b[0mInference done 2855/3258. Dataloading: 0.0022 s/iter. Inference: 0.0353 s/iter. Eval: 0.0386 s/iter. Total: 0.0762 s/iter. ETA=0:00:30\n",
      "\u001b[32m[07/06 22:24:51 d2.evaluation.evaluator]: \u001b[0mInference done 2921/3258. Dataloading: 0.0022 s/iter. Inference: 0.0353 s/iter. Eval: 0.0386 s/iter. Total: 0.0762 s/iter. ETA=0:00:25\n",
      "\u001b[32m[07/06 22:24:56 d2.evaluation.evaluator]: \u001b[0mInference done 2986/3258. Dataloading: 0.0022 s/iter. Inference: 0.0353 s/iter. Eval: 0.0386 s/iter. Total: 0.0762 s/iter. ETA=0:00:20\n",
      "\u001b[32m[07/06 22:25:01 d2.evaluation.evaluator]: \u001b[0mInference done 3052/3258. Dataloading: 0.0022 s/iter. Inference: 0.0353 s/iter. Eval: 0.0386 s/iter. Total: 0.0763 s/iter. ETA=0:00:15\n",
      "\u001b[32m[07/06 22:25:06 d2.evaluation.evaluator]: \u001b[0mInference done 3117/3258. Dataloading: 0.0022 s/iter. Inference: 0.0353 s/iter. Eval: 0.0387 s/iter. Total: 0.0763 s/iter. ETA=0:00:10\n",
      "\u001b[32m[07/06 22:25:11 d2.evaluation.evaluator]: \u001b[0mInference done 3182/3258. Dataloading: 0.0022 s/iter. Inference: 0.0353 s/iter. Eval: 0.0387 s/iter. Total: 0.0763 s/iter. ETA=0:00:05\n",
      "\u001b[32m[07/06 22:25:16 d2.evaluation.evaluator]: \u001b[0mInference done 3248/3258. Dataloading: 0.0022 s/iter. Inference: 0.0353 s/iter. Eval: 0.0387 s/iter. Total: 0.0763 s/iter. ETA=0:00:00\n",
      "\u001b[32m[07/06 22:25:17 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:04:08.302275 (0.076330 s / iter per device, on 1 devices)\n",
      "\u001b[32m[07/06 22:25:17 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:01:54 (0.035327 s / iter per device, on 1 devices)\n",
      "\u001b[32m[07/06 22:25:17 d2.evaluation.sem_seg_evaluation]: \u001b[0mOrderedDict([('sem_seg', {'mIoU': 70.44104763684214, 'fwIoU': 93.20099104046147, 'IoU-Unlabeled': nan, 'IoU-Building': 91.74125948985314, 'IoU-Fence': 33.28761853589716, 'IoU-Pedestrian': 44.840195807575775, 'IoU-Pole': 58.36590435883116, 'IoU-Road': 98.8258867179598, 'IoU-SideWalk': 88.14808001143209, 'IoU-Vegetation': 82.40144067068617, 'IoU-Vehicles': 87.53235780471368, 'IoU-Wall': 82.14021658471346, 'IoU-TrafficSign': 47.22268938235373, 'IoU-Sky': 96.94030880386694, 'IoU-TrafficLight': 70.79274862559011, 'IoU-Terrain': 69.34845095532584, 'IoU-ConstructionVehicle': 88.64365013844638, 'IoU-workzone_object': 76.36397308441603, 'IoU-Detour': 10.461981217812784, 'mACC': 77.4536538822634, 'pACC': 96.31589965098259, 'ACC-Unlabeled': nan, 'ACC-Building': 97.32019250403123, 'ACC-Fence': 40.20515341349296, 'ACC-Pedestrian': 69.31498896812506, 'ACC-Pole': 68.00358597592397, 'ACC-Road': 99.35771645432706, 'ACC-SideWalk': 94.99892611301335, 'ACC-Vegetation': 90.93056951108014, 'ACC-Vehicles': 89.84632491456252, 'ACC-Wall': 90.78875081187395, 'ACC-TrafficSign': 55.997956393939305, 'ACC-Sky': 98.02150762542496, 'ACC-TrafficLight': 81.44175420011261, 'ACC-Terrain': 76.82034226801898, 'ACC-ConstructionVehicle': 93.00089463751456, 'ACC-workzone_object': 82.44989054810361, 'ACC-Detour': 10.75990777666999})])\n",
      "\u001b[32m[07/06 22:25:17 d2.engine.defaults]: \u001b[0mEvaluation results for carla_clear_val in csv format:\n",
      "\u001b[32m[07/06 22:25:17 d2.evaluation.testing]: \u001b[0mcopypaste: Task: sem_seg\n",
      "\u001b[32m[07/06 22:25:17 d2.evaluation.testing]: \u001b[0mcopypaste: mIoU,fwIoU,mACC,pACC\n",
      "\u001b[32m[07/06 22:25:17 d2.evaluation.testing]: \u001b[0mcopypaste: 70.4410,93.2010,77.4537,96.3159\n"
     ]
    }
   ],
   "source": [
    "trainer_day = Detectron2Trainer('combined_clear_train', 'carla_clear_val', output_folder='./output_day_clear_40k')\n",
    "trainer_day.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "20bea117",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/06 22:26:56 d2.engine.defaults]: \u001b[0mModel:\n",
      "SemanticSegmentor(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (sem_seg_head): SemSegFPNHead(\n",
      "    (p2): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "    )\n",
      "    (p3): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (1): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "    )\n",
      "    (p4): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (1): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      (2): Conv2d(\n",
      "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (3): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "    )\n",
      "    (p5): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (1): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      (2): Conv2d(\n",
      "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (3): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      (4): Conv2d(\n",
      "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (5): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "    )\n",
      "    (predictor): Conv2d(128, 17, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/06 22:26:56 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(720, 720), max_size=2048, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[07/06 22:26:56 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[07/06 22:26:56 d2.data.common]: \u001b[0mSerializing 3353 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[07/06 22:26:56 d2.data.common]: \u001b[0mSerialized dataset takes 1.18 MiB\n",
      "Last checkpoint: model_final.pth\n",
      "\u001b[32m[07/06 22:26:56 d2.checkpoint.c2_model_loading]: \u001b[0mFollowing weights matched with model:\n",
      "| Names in Model                       | Names in Checkpoint                                                                                  | Shapes                                          |\n",
      "|:-------------------------------------|:-----------------------------------------------------------------------------------------------------|:------------------------------------------------|\n",
      "| backbone.bottom_up.res2.0.conv1.*    | backbone.bottom_up.res2.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,1,1)             |\n",
      "| backbone.bottom_up.res2.0.conv2.*    | backbone.bottom_up.res2.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |\n",
      "| backbone.bottom_up.res2.0.conv3.*    | backbone.bottom_up.res2.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res2.0.shortcut.* | backbone.bottom_up.res2.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res2.1.conv1.*    | backbone.bottom_up.res2.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |\n",
      "| backbone.bottom_up.res2.1.conv2.*    | backbone.bottom_up.res2.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |\n",
      "| backbone.bottom_up.res2.1.conv3.*    | backbone.bottom_up.res2.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res2.2.conv1.*    | backbone.bottom_up.res2.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |\n",
      "| backbone.bottom_up.res2.2.conv2.*    | backbone.bottom_up.res2.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |\n",
      "| backbone.bottom_up.res2.2.conv3.*    | backbone.bottom_up.res2.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res3.0.conv1.*    | backbone.bottom_up.res3.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,256,1,1)       |\n",
      "| backbone.bottom_up.res3.0.conv2.*    | backbone.bottom_up.res3.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.0.conv3.*    | backbone.bottom_up.res3.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res3.0.shortcut.* | backbone.bottom_up.res3.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (512,) (512,) (512,) (512,) (512,256,1,1)       |\n",
      "| backbone.bottom_up.res3.1.conv1.*    | backbone.bottom_up.res3.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |\n",
      "| backbone.bottom_up.res3.1.conv2.*    | backbone.bottom_up.res3.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.1.conv3.*    | backbone.bottom_up.res3.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res3.2.conv1.*    | backbone.bottom_up.res3.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |\n",
      "| backbone.bottom_up.res3.2.conv2.*    | backbone.bottom_up.res3.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.2.conv3.*    | backbone.bottom_up.res3.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res3.3.conv1.*    | backbone.bottom_up.res3.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |\n",
      "| backbone.bottom_up.res3.3.conv2.*    | backbone.bottom_up.res3.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.3.conv3.*    | backbone.bottom_up.res3.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res4.0.conv1.*    | backbone.bottom_up.res4.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,512,1,1)       |\n",
      "| backbone.bottom_up.res4.0.conv2.*    | backbone.bottom_up.res4.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.0.conv3.*    | backbone.bottom_up.res4.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.0.shortcut.* | backbone.bottom_up.res4.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (1024,) (1024,) (1024,) (1024,) (1024,512,1,1)  |\n",
      "| backbone.bottom_up.res4.1.conv1.*    | backbone.bottom_up.res4.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.1.conv2.*    | backbone.bottom_up.res4.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.1.conv3.*    | backbone.bottom_up.res4.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.2.conv1.*    | backbone.bottom_up.res4.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.2.conv2.*    | backbone.bottom_up.res4.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.2.conv3.*    | backbone.bottom_up.res4.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.3.conv1.*    | backbone.bottom_up.res4.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.3.conv2.*    | backbone.bottom_up.res4.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.3.conv3.*    | backbone.bottom_up.res4.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.4.conv1.*    | backbone.bottom_up.res4.4.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.4.conv2.*    | backbone.bottom_up.res4.4.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.4.conv3.*    | backbone.bottom_up.res4.4.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.5.conv1.*    | backbone.bottom_up.res4.5.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.5.conv2.*    | backbone.bottom_up.res4.5.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.5.conv3.*    | backbone.bottom_up.res4.5.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res5.0.conv1.*    | backbone.bottom_up.res5.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,1024,1,1)      |\n",
      "| backbone.bottom_up.res5.0.conv2.*    | backbone.bottom_up.res5.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |\n",
      "| backbone.bottom_up.res5.0.conv3.*    | backbone.bottom_up.res5.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
      "| backbone.bottom_up.res5.0.shortcut.* | backbone.bottom_up.res5.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (2048,) (2048,) (2048,) (2048,) (2048,1024,1,1) |\n",
      "| backbone.bottom_up.res5.1.conv1.*    | backbone.bottom_up.res5.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |\n",
      "| backbone.bottom_up.res5.1.conv2.*    | backbone.bottom_up.res5.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |\n",
      "| backbone.bottom_up.res5.1.conv3.*    | backbone.bottom_up.res5.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
      "| backbone.bottom_up.res5.2.conv1.*    | backbone.bottom_up.res5.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |\n",
      "| backbone.bottom_up.res5.2.conv2.*    | backbone.bottom_up.res5.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |\n",
      "| backbone.bottom_up.res5.2.conv3.*    | backbone.bottom_up.res5.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
      "| backbone.bottom_up.stem.conv1.*      | backbone.bottom_up.stem.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}      | (64,) (64,) (64,) (64,) (64,3,7,7)              |\n",
      "| backbone.fpn_lateral2.*              | backbone.fpn_lateral2.{bias,weight}                                                                  | (256,) (256,256,1,1)                            |\n",
      "| backbone.fpn_lateral3.*              | backbone.fpn_lateral3.{bias,weight}                                                                  | (256,) (256,512,1,1)                            |\n",
      "| backbone.fpn_lateral4.*              | backbone.fpn_lateral4.{bias,weight}                                                                  | (256,) (256,1024,1,1)                           |\n",
      "| backbone.fpn_lateral5.*              | backbone.fpn_lateral5.{bias,weight}                                                                  | (256,) (256,2048,1,1)                           |\n",
      "| backbone.fpn_output2.*               | backbone.fpn_output2.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| backbone.fpn_output3.*               | backbone.fpn_output3.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| backbone.fpn_output4.*               | backbone.fpn_output4.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| backbone.fpn_output5.*               | backbone.fpn_output5.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| sem_seg_head.p2.0.*                  | sem_seg_head.p2.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p3.0.*                  | sem_seg_head.p3.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p4.0.*                  | sem_seg_head.p4.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p4.2.*                  | sem_seg_head.p4.2.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,128,3,3)                     |\n",
      "| sem_seg_head.p5.0.*                  | sem_seg_head.p5.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p5.2.*                  | sem_seg_head.p5.2.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,128,3,3)                     |\n",
      "| sem_seg_head.p5.4.*                  | sem_seg_head.p5.4.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,128,3,3)                     |\n",
      "| sem_seg_head.predictor.*             | sem_seg_head.predictor.{bias,weight}                                                                 | (17,) (17,128,1,1)                              |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/06 22:26:56 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(720, 720), max_size=2048, sample_style='choice')]\n",
      "\u001b[32m[07/06 22:26:56 d2.data.common]: \u001b[0mSerializing 699 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[07/06 22:26:56 d2.data.common]: \u001b[0mSerialized dataset takes 0.24 MiB\n",
      "\u001b[32m[07/06 22:26:56 d2.evaluation.evaluator]: \u001b[0mStart inference on 699 batches\n",
      "\u001b[32m[07/06 22:26:59 d2.evaluation.evaluator]: \u001b[0mInference done 11/699. Dataloading: 0.0019 s/iter. Inference: 0.0468 s/iter. Eval: 0.1563 s/iter. Total: 0.2050 s/iter. ETA=0:02:21\n",
      "\u001b[32m[07/06 22:27:04 d2.evaluation.evaluator]: \u001b[0mInference done 36/699. Dataloading: 0.0022 s/iter. Inference: 0.0468 s/iter. Eval: 0.1556 s/iter. Total: 0.2047 s/iter. ETA=0:02:15\n",
      "\u001b[32m[07/06 22:27:09 d2.evaluation.evaluator]: \u001b[0mInference done 61/699. Dataloading: 0.0023 s/iter. Inference: 0.0467 s/iter. Eval: 0.1555 s/iter. Total: 0.2046 s/iter. ETA=0:02:10\n",
      "\u001b[32m[07/06 22:27:14 d2.evaluation.evaluator]: \u001b[0mInference done 87/699. Dataloading: 0.0023 s/iter. Inference: 0.0467 s/iter. Eval: 0.1534 s/iter. Total: 0.2025 s/iter. ETA=0:02:03\n",
      "\u001b[32m[07/06 22:27:19 d2.evaluation.evaluator]: \u001b[0mInference done 113/699. Dataloading: 0.0023 s/iter. Inference: 0.0467 s/iter. Eval: 0.1522 s/iter. Total: 0.2013 s/iter. ETA=0:01:57\n",
      "\u001b[32m[07/06 22:27:24 d2.evaluation.evaluator]: \u001b[0mInference done 139/699. Dataloading: 0.0023 s/iter. Inference: 0.0467 s/iter. Eval: 0.1505 s/iter. Total: 0.1996 s/iter. ETA=0:01:51\n",
      "\u001b[32m[07/06 22:27:29 d2.evaluation.evaluator]: \u001b[0mInference done 165/699. Dataloading: 0.0023 s/iter. Inference: 0.0467 s/iter. Eval: 0.1494 s/iter. Total: 0.1985 s/iter. ETA=0:01:45\n",
      "\u001b[32m[07/06 22:27:34 d2.evaluation.evaluator]: \u001b[0mInference done 190/699. Dataloading: 0.0023 s/iter. Inference: 0.0467 s/iter. Eval: 0.1505 s/iter. Total: 0.1996 s/iter. ETA=0:01:41\n",
      "\u001b[32m[07/06 22:27:40 d2.evaluation.evaluator]: \u001b[0mInference done 215/699. Dataloading: 0.0023 s/iter. Inference: 0.0467 s/iter. Eval: 0.1512 s/iter. Total: 0.2003 s/iter. ETA=0:01:36\n",
      "\u001b[32m[07/06 22:27:45 d2.evaluation.evaluator]: \u001b[0mInference done 240/699. Dataloading: 0.0023 s/iter. Inference: 0.0467 s/iter. Eval: 0.1519 s/iter. Total: 0.2010 s/iter. ETA=0:01:32\n",
      "\u001b[32m[07/06 22:27:50 d2.evaluation.evaluator]: \u001b[0mInference done 265/699. Dataloading: 0.0023 s/iter. Inference: 0.0467 s/iter. Eval: 0.1520 s/iter. Total: 0.2011 s/iter. ETA=0:01:27\n",
      "\u001b[32m[07/06 22:27:55 d2.evaluation.evaluator]: \u001b[0mInference done 291/699. Dataloading: 0.0023 s/iter. Inference: 0.0467 s/iter. Eval: 0.1517 s/iter. Total: 0.2008 s/iter. ETA=0:01:21\n",
      "\u001b[32m[07/06 22:28:00 d2.evaluation.evaluator]: \u001b[0mInference done 316/699. Dataloading: 0.0023 s/iter. Inference: 0.0467 s/iter. Eval: 0.1518 s/iter. Total: 0.2010 s/iter. ETA=0:01:16\n",
      "\u001b[32m[07/06 22:28:05 d2.evaluation.evaluator]: \u001b[0mInference done 341/699. Dataloading: 0.0023 s/iter. Inference: 0.0467 s/iter. Eval: 0.1521 s/iter. Total: 0.2012 s/iter. ETA=0:01:12\n",
      "\u001b[32m[07/06 22:28:10 d2.evaluation.evaluator]: \u001b[0mInference done 366/699. Dataloading: 0.0023 s/iter. Inference: 0.0467 s/iter. Eval: 0.1522 s/iter. Total: 0.2013 s/iter. ETA=0:01:07\n",
      "\u001b[32m[07/06 22:28:15 d2.evaluation.evaluator]: \u001b[0mInference done 391/699. Dataloading: 0.0023 s/iter. Inference: 0.0467 s/iter. Eval: 0.1525 s/iter. Total: 0.2016 s/iter. ETA=0:01:02\n",
      "\u001b[32m[07/06 22:28:20 d2.evaluation.evaluator]: \u001b[0mInference done 416/699. Dataloading: 0.0023 s/iter. Inference: 0.0467 s/iter. Eval: 0.1525 s/iter. Total: 0.2017 s/iter. ETA=0:00:57\n",
      "\u001b[32m[07/06 22:28:25 d2.evaluation.evaluator]: \u001b[0mInference done 441/699. Dataloading: 0.0023 s/iter. Inference: 0.0467 s/iter. Eval: 0.1525 s/iter. Total: 0.2017 s/iter. ETA=0:00:52\n",
      "\u001b[32m[07/06 22:28:30 d2.evaluation.evaluator]: \u001b[0mInference done 467/699. Dataloading: 0.0023 s/iter. Inference: 0.0467 s/iter. Eval: 0.1522 s/iter. Total: 0.2014 s/iter. ETA=0:00:46\n",
      "\u001b[32m[07/06 22:28:36 d2.evaluation.evaluator]: \u001b[0mInference done 492/699. Dataloading: 0.0023 s/iter. Inference: 0.0467 s/iter. Eval: 0.1523 s/iter. Total: 0.2015 s/iter. ETA=0:00:41\n",
      "\u001b[32m[07/06 22:28:41 d2.evaluation.evaluator]: \u001b[0mInference done 517/699. Dataloading: 0.0023 s/iter. Inference: 0.0467 s/iter. Eval: 0.1523 s/iter. Total: 0.2014 s/iter. ETA=0:00:36\n",
      "\u001b[32m[07/06 22:28:46 d2.evaluation.evaluator]: \u001b[0mInference done 543/699. Dataloading: 0.0023 s/iter. Inference: 0.0467 s/iter. Eval: 0.1522 s/iter. Total: 0.2013 s/iter. ETA=0:00:31\n",
      "\u001b[32m[07/06 22:28:51 d2.evaluation.evaluator]: \u001b[0mInference done 568/699. Dataloading: 0.0023 s/iter. Inference: 0.0467 s/iter. Eval: 0.1522 s/iter. Total: 0.2014 s/iter. ETA=0:00:26\n",
      "\u001b[32m[07/06 22:28:56 d2.evaluation.evaluator]: \u001b[0mInference done 593/699. Dataloading: 0.0023 s/iter. Inference: 0.0467 s/iter. Eval: 0.1524 s/iter. Total: 0.2015 s/iter. ETA=0:00:21\n",
      "\u001b[32m[07/06 22:29:01 d2.evaluation.evaluator]: \u001b[0mInference done 618/699. Dataloading: 0.0023 s/iter. Inference: 0.0467 s/iter. Eval: 0.1525 s/iter. Total: 0.2017 s/iter. ETA=0:00:16\n",
      "\u001b[32m[07/06 22:29:06 d2.evaluation.evaluator]: \u001b[0mInference done 643/699. Dataloading: 0.0023 s/iter. Inference: 0.0467 s/iter. Eval: 0.1526 s/iter. Total: 0.2017 s/iter. ETA=0:00:11\n",
      "\u001b[32m[07/06 22:29:11 d2.evaluation.evaluator]: \u001b[0mInference done 669/699. Dataloading: 0.0023 s/iter. Inference: 0.0467 s/iter. Eval: 0.1523 s/iter. Total: 0.2015 s/iter. ETA=0:00:06\n",
      "\u001b[32m[07/06 22:29:16 d2.evaluation.evaluator]: \u001b[0mInference done 693/699. Dataloading: 0.0023 s/iter. Inference: 0.0467 s/iter. Eval: 0.1526 s/iter. Total: 0.2017 s/iter. ETA=0:00:01\n",
      "\u001b[32m[07/06 22:29:18 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:02:20.110092 (0.201888 s / iter per device, on 1 devices)\n",
      "\u001b[32m[07/06 22:29:18 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:32 (0.046731 s / iter per device, on 1 devices)\n",
      "\u001b[32m[07/06 22:29:18 d2.evaluation.sem_seg_evaluation]: \u001b[0mOrderedDict([('sem_seg', {'mIoU': 61.577865241528905, 'fwIoU': 89.11602459169133, 'IoU-Unlabeled': nan, 'IoU-Building': 88.99588442081956, 'IoU-Fence': 48.77037376886059, 'IoU-Pedestrian': 75.98669162227984, 'IoU-Pole': 50.85139930962696, 'IoU-Road': 96.04497172835397, 'IoU-SideWalk': 76.60923702662885, 'IoU-Vegetation': 89.81240629415734, 'IoU-Vehicles': 89.93780885354744, 'IoU-Wall': 44.59364074069405, 'IoU-TrafficSign': 63.783541556702396, 'IoU-Sky': 86.53893361972682, 'IoU-TrafficLight': 53.537649278257234, 'IoU-Terrain': 58.20544040327867, 'IoU-ConstructionVehicle': nan, 'IoU-workzone_object': nan, 'IoU-Detour': nan, 'mACC': 79.78792593059823, 'pACC': 93.99478485046595, 'ACC-Unlabeled': nan, 'ACC-Building': 96.01127971301631, 'ACC-Fence': 60.00489011916778, 'ACC-Pedestrian': 88.13788431671257, 'ACC-Pole': 64.19174133497735, 'ACC-Road': 97.92610054728934, 'ACC-SideWalk': 85.36596943689246, 'ACC-Vegetation': 95.07393378591624, 'ACC-Vehicles': 94.16587355447794, 'ACC-Wall': 56.4638183123457, 'ACC-TrafficSign': 71.87297640484186, 'ACC-Sky': 88.68800838706477, 'ACC-TrafficLight': 63.63297781719659, 'ACC-Terrain': 75.70758336787824, 'ACC-ConstructionVehicle': nan, 'ACC-workzone_object': nan, 'ACC-Detour': nan})])\n",
      "\u001b[32m[07/06 22:29:18 d2.engine.defaults]: \u001b[0mEvaluation results for cityscapes_clear_val in csv format:\n",
      "\u001b[32m[07/06 22:29:18 d2.evaluation.testing]: \u001b[0mcopypaste: Task: sem_seg\n",
      "\u001b[32m[07/06 22:29:18 d2.evaluation.testing]: \u001b[0mcopypaste: mIoU,fwIoU,mACC,pACC\n",
      "\u001b[32m[07/06 22:29:18 d2.evaluation.testing]: \u001b[0mcopypaste: 61.5779,89.1160,79.7879,93.9948\n"
     ]
    }
   ],
   "source": [
    "trainer_day = Detectron2Trainer('combined_clear_train', 'cityscapes_clear_val', output_folder='./output_day_clear_40k')\n",
    "trainer_day.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7edb38d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/06 22:29:18 d2.engine.defaults]: \u001b[0mModel:\n",
      "SemanticSegmentor(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (sem_seg_head): SemSegFPNHead(\n",
      "    (p2): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "    )\n",
      "    (p3): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (1): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "    )\n",
      "    (p4): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (1): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      (2): Conv2d(\n",
      "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (3): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "    )\n",
      "    (p5): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (1): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      (2): Conv2d(\n",
      "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (3): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      (4): Conv2d(\n",
      "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (5): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "    )\n",
      "    (predictor): Conv2d(128, 17, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/06 22:29:18 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(720, 720), max_size=2048, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[07/06 22:29:18 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[07/06 22:29:18 d2.data.common]: \u001b[0mSerializing 3353 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[07/06 22:29:18 d2.data.common]: \u001b[0mSerialized dataset takes 1.18 MiB\n",
      "Last checkpoint: model_final.pth\n",
      "\u001b[32m[07/06 22:29:18 d2.checkpoint.c2_model_loading]: \u001b[0mFollowing weights matched with model:\n",
      "| Names in Model                       | Names in Checkpoint                                                                                  | Shapes                                          |\n",
      "|:-------------------------------------|:-----------------------------------------------------------------------------------------------------|:------------------------------------------------|\n",
      "| backbone.bottom_up.res2.0.conv1.*    | backbone.bottom_up.res2.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,1,1)             |\n",
      "| backbone.bottom_up.res2.0.conv2.*    | backbone.bottom_up.res2.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |\n",
      "| backbone.bottom_up.res2.0.conv3.*    | backbone.bottom_up.res2.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res2.0.shortcut.* | backbone.bottom_up.res2.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res2.1.conv1.*    | backbone.bottom_up.res2.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |\n",
      "| backbone.bottom_up.res2.1.conv2.*    | backbone.bottom_up.res2.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |\n",
      "| backbone.bottom_up.res2.1.conv3.*    | backbone.bottom_up.res2.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res2.2.conv1.*    | backbone.bottom_up.res2.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |\n",
      "| backbone.bottom_up.res2.2.conv2.*    | backbone.bottom_up.res2.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |\n",
      "| backbone.bottom_up.res2.2.conv3.*    | backbone.bottom_up.res2.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res3.0.conv1.*    | backbone.bottom_up.res3.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,256,1,1)       |\n",
      "| backbone.bottom_up.res3.0.conv2.*    | backbone.bottom_up.res3.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.0.conv3.*    | backbone.bottom_up.res3.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res3.0.shortcut.* | backbone.bottom_up.res3.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (512,) (512,) (512,) (512,) (512,256,1,1)       |\n",
      "| backbone.bottom_up.res3.1.conv1.*    | backbone.bottom_up.res3.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |\n",
      "| backbone.bottom_up.res3.1.conv2.*    | backbone.bottom_up.res3.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.1.conv3.*    | backbone.bottom_up.res3.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res3.2.conv1.*    | backbone.bottom_up.res3.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |\n",
      "| backbone.bottom_up.res3.2.conv2.*    | backbone.bottom_up.res3.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.2.conv3.*    | backbone.bottom_up.res3.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res3.3.conv1.*    | backbone.bottom_up.res3.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |\n",
      "| backbone.bottom_up.res3.3.conv2.*    | backbone.bottom_up.res3.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.3.conv3.*    | backbone.bottom_up.res3.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res4.0.conv1.*    | backbone.bottom_up.res4.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,512,1,1)       |\n",
      "| backbone.bottom_up.res4.0.conv2.*    | backbone.bottom_up.res4.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.0.conv3.*    | backbone.bottom_up.res4.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.0.shortcut.* | backbone.bottom_up.res4.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (1024,) (1024,) (1024,) (1024,) (1024,512,1,1)  |\n",
      "| backbone.bottom_up.res4.1.conv1.*    | backbone.bottom_up.res4.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.1.conv2.*    | backbone.bottom_up.res4.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.1.conv3.*    | backbone.bottom_up.res4.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.2.conv1.*    | backbone.bottom_up.res4.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.2.conv2.*    | backbone.bottom_up.res4.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.2.conv3.*    | backbone.bottom_up.res4.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.3.conv1.*    | backbone.bottom_up.res4.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.3.conv2.*    | backbone.bottom_up.res4.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.3.conv3.*    | backbone.bottom_up.res4.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.4.conv1.*    | backbone.bottom_up.res4.4.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.4.conv2.*    | backbone.bottom_up.res4.4.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.4.conv3.*    | backbone.bottom_up.res4.4.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.5.conv1.*    | backbone.bottom_up.res4.5.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.5.conv2.*    | backbone.bottom_up.res4.5.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.5.conv3.*    | backbone.bottom_up.res4.5.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res5.0.conv1.*    | backbone.bottom_up.res5.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,1024,1,1)      |\n",
      "| backbone.bottom_up.res5.0.conv2.*    | backbone.bottom_up.res5.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |\n",
      "| backbone.bottom_up.res5.0.conv3.*    | backbone.bottom_up.res5.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
      "| backbone.bottom_up.res5.0.shortcut.* | backbone.bottom_up.res5.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (2048,) (2048,) (2048,) (2048,) (2048,1024,1,1) |\n",
      "| backbone.bottom_up.res5.1.conv1.*    | backbone.bottom_up.res5.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |\n",
      "| backbone.bottom_up.res5.1.conv2.*    | backbone.bottom_up.res5.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |\n",
      "| backbone.bottom_up.res5.1.conv3.*    | backbone.bottom_up.res5.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
      "| backbone.bottom_up.res5.2.conv1.*    | backbone.bottom_up.res5.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |\n",
      "| backbone.bottom_up.res5.2.conv2.*    | backbone.bottom_up.res5.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |\n",
      "| backbone.bottom_up.res5.2.conv3.*    | backbone.bottom_up.res5.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
      "| backbone.bottom_up.stem.conv1.*      | backbone.bottom_up.stem.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}      | (64,) (64,) (64,) (64,) (64,3,7,7)              |\n",
      "| backbone.fpn_lateral2.*              | backbone.fpn_lateral2.{bias,weight}                                                                  | (256,) (256,256,1,1)                            |\n",
      "| backbone.fpn_lateral3.*              | backbone.fpn_lateral3.{bias,weight}                                                                  | (256,) (256,512,1,1)                            |\n",
      "| backbone.fpn_lateral4.*              | backbone.fpn_lateral4.{bias,weight}                                                                  | (256,) (256,1024,1,1)                           |\n",
      "| backbone.fpn_lateral5.*              | backbone.fpn_lateral5.{bias,weight}                                                                  | (256,) (256,2048,1,1)                           |\n",
      "| backbone.fpn_output2.*               | backbone.fpn_output2.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| backbone.fpn_output3.*               | backbone.fpn_output3.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| backbone.fpn_output4.*               | backbone.fpn_output4.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| backbone.fpn_output5.*               | backbone.fpn_output5.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| sem_seg_head.p2.0.*                  | sem_seg_head.p2.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p3.0.*                  | sem_seg_head.p3.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p4.0.*                  | sem_seg_head.p4.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p4.2.*                  | sem_seg_head.p4.2.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,128,3,3)                     |\n",
      "| sem_seg_head.p5.0.*                  | sem_seg_head.p5.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p5.2.*                  | sem_seg_head.p5.2.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,128,3,3)                     |\n",
      "| sem_seg_head.p5.4.*                  | sem_seg_head.p5.4.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,128,3,3)                     |\n",
      "| sem_seg_head.predictor.*             | sem_seg_head.predictor.{bias,weight}                                                                 | (17,) (17,128,1,1)                              |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/06 22:29:19 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(720, 720), max_size=2048, sample_style='choice')]\n",
      "\u001b[32m[07/06 22:29:19 d2.data.common]: \u001b[0mSerializing 3957 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[07/06 22:29:19 d2.data.common]: \u001b[0mSerialized dataset takes 1.39 MiB\n",
      "\u001b[32m[07/06 22:29:19 d2.evaluation.evaluator]: \u001b[0mStart inference on 3957 batches\n",
      "\u001b[32m[07/06 22:29:21 d2.evaluation.evaluator]: \u001b[0mInference done 30/3957. Dataloading: 0.0021 s/iter. Inference: 0.0352 s/iter. Eval: 0.0433 s/iter. Total: 0.0806 s/iter. ETA=0:05:16\n",
      "\u001b[32m[07/06 22:29:26 d2.evaluation.evaluator]: \u001b[0mInference done 95/3957. Dataloading: 0.0022 s/iter. Inference: 0.0351 s/iter. Eval: 0.0412 s/iter. Total: 0.0785 s/iter. ETA=0:05:03\n",
      "\u001b[32m[07/06 22:29:31 d2.evaluation.evaluator]: \u001b[0mInference done 161/3957. Dataloading: 0.0022 s/iter. Inference: 0.0352 s/iter. Eval: 0.0400 s/iter. Total: 0.0774 s/iter. ETA=0:04:53\n",
      "\u001b[32m[07/06 22:29:36 d2.evaluation.evaluator]: \u001b[0mInference done 227/3957. Dataloading: 0.0022 s/iter. Inference: 0.0352 s/iter. Eval: 0.0395 s/iter. Total: 0.0770 s/iter. ETA=0:04:47\n",
      "\u001b[32m[07/06 22:29:41 d2.evaluation.evaluator]: \u001b[0mInference done 293/3957. Dataloading: 0.0022 s/iter. Inference: 0.0352 s/iter. Eval: 0.0393 s/iter. Total: 0.0768 s/iter. ETA=0:04:41\n",
      "\u001b[32m[07/06 22:29:46 d2.evaluation.evaluator]: \u001b[0mInference done 359/3957. Dataloading: 0.0022 s/iter. Inference: 0.0353 s/iter. Eval: 0.0391 s/iter. Total: 0.0767 s/iter. ETA=0:04:35\n",
      "\u001b[32m[07/06 22:29:51 d2.evaluation.evaluator]: \u001b[0mInference done 426/3957. Dataloading: 0.0022 s/iter. Inference: 0.0353 s/iter. Eval: 0.0389 s/iter. Total: 0.0765 s/iter. ETA=0:04:30\n",
      "\u001b[32m[07/06 22:29:57 d2.evaluation.evaluator]: \u001b[0mInference done 493/3957. Dataloading: 0.0022 s/iter. Inference: 0.0353 s/iter. Eval: 0.0388 s/iter. Total: 0.0764 s/iter. ETA=0:04:24\n",
      "\u001b[32m[07/06 22:30:02 d2.evaluation.evaluator]: \u001b[0mInference done 560/3957. Dataloading: 0.0022 s/iter. Inference: 0.0353 s/iter. Eval: 0.0386 s/iter. Total: 0.0762 s/iter. ETA=0:04:18\n",
      "\u001b[32m[07/06 22:30:07 d2.evaluation.evaluator]: \u001b[0mInference done 625/3957. Dataloading: 0.0022 s/iter. Inference: 0.0353 s/iter. Eval: 0.0387 s/iter. Total: 0.0764 s/iter. ETA=0:04:14\n",
      "\u001b[32m[07/06 22:30:12 d2.evaluation.evaluator]: \u001b[0mInference done 689/3957. Dataloading: 0.0022 s/iter. Inference: 0.0353 s/iter. Eval: 0.0389 s/iter. Total: 0.0765 s/iter. ETA=0:04:10\n",
      "\u001b[32m[07/06 22:30:17 d2.evaluation.evaluator]: \u001b[0mInference done 753/3957. Dataloading: 0.0022 s/iter. Inference: 0.0354 s/iter. Eval: 0.0391 s/iter. Total: 0.0768 s/iter. ETA=0:04:05\n",
      "\u001b[32m[07/06 22:30:22 d2.evaluation.evaluator]: \u001b[0mInference done 817/3957. Dataloading: 0.0022 s/iter. Inference: 0.0354 s/iter. Eval: 0.0393 s/iter. Total: 0.0769 s/iter. ETA=0:04:01\n",
      "\u001b[32m[07/06 22:30:27 d2.evaluation.evaluator]: \u001b[0mInference done 881/3957. Dataloading: 0.0022 s/iter. Inference: 0.0354 s/iter. Eval: 0.0394 s/iter. Total: 0.0771 s/iter. ETA=0:03:57\n",
      "\u001b[32m[07/06 22:30:32 d2.evaluation.evaluator]: \u001b[0mInference done 945/3957. Dataloading: 0.0022 s/iter. Inference: 0.0354 s/iter. Eval: 0.0396 s/iter. Total: 0.0772 s/iter. ETA=0:03:52\n",
      "\u001b[32m[07/06 22:30:37 d2.evaluation.evaluator]: \u001b[0mInference done 1010/3957. Dataloading: 0.0022 s/iter. Inference: 0.0354 s/iter. Eval: 0.0396 s/iter. Total: 0.0773 s/iter. ETA=0:03:47\n",
      "\u001b[32m[07/06 22:30:42 d2.evaluation.evaluator]: \u001b[0mInference done 1075/3957. Dataloading: 0.0022 s/iter. Inference: 0.0354 s/iter. Eval: 0.0396 s/iter. Total: 0.0773 s/iter. ETA=0:03:42\n",
      "\u001b[32m[07/06 22:30:47 d2.evaluation.evaluator]: \u001b[0mInference done 1139/3957. Dataloading: 0.0022 s/iter. Inference: 0.0354 s/iter. Eval: 0.0397 s/iter. Total: 0.0774 s/iter. ETA=0:03:38\n",
      "\u001b[32m[07/06 22:30:52 d2.evaluation.evaluator]: \u001b[0mInference done 1204/3957. Dataloading: 0.0022 s/iter. Inference: 0.0354 s/iter. Eval: 0.0397 s/iter. Total: 0.0774 s/iter. ETA=0:03:33\n",
      "\u001b[32m[07/06 22:30:57 d2.evaluation.evaluator]: \u001b[0mInference done 1269/3957. Dataloading: 0.0022 s/iter. Inference: 0.0354 s/iter. Eval: 0.0397 s/iter. Total: 0.0774 s/iter. ETA=0:03:28\n",
      "\u001b[32m[07/06 22:31:02 d2.evaluation.evaluator]: \u001b[0mInference done 1333/3957. Dataloading: 0.0022 s/iter. Inference: 0.0354 s/iter. Eval: 0.0397 s/iter. Total: 0.0775 s/iter. ETA=0:03:23\n",
      "\u001b[32m[07/06 22:31:07 d2.evaluation.evaluator]: \u001b[0mInference done 1399/3957. Dataloading: 0.0022 s/iter. Inference: 0.0354 s/iter. Eval: 0.0397 s/iter. Total: 0.0774 s/iter. ETA=0:03:18\n",
      "\u001b[32m[07/06 22:31:12 d2.evaluation.evaluator]: \u001b[0mInference done 1464/3957. Dataloading: 0.0022 s/iter. Inference: 0.0354 s/iter. Eval: 0.0397 s/iter. Total: 0.0774 s/iter. ETA=0:03:12\n",
      "\u001b[32m[07/06 22:31:17 d2.evaluation.evaluator]: \u001b[0mInference done 1528/3957. Dataloading: 0.0022 s/iter. Inference: 0.0354 s/iter. Eval: 0.0397 s/iter. Total: 0.0775 s/iter. ETA=0:03:08\n",
      "\u001b[32m[07/06 22:31:22 d2.evaluation.evaluator]: \u001b[0mInference done 1592/3957. Dataloading: 0.0022 s/iter. Inference: 0.0354 s/iter. Eval: 0.0397 s/iter. Total: 0.0775 s/iter. ETA=0:03:03\n",
      "\u001b[32m[07/06 22:31:27 d2.evaluation.evaluator]: \u001b[0mInference done 1657/3957. Dataloading: 0.0022 s/iter. Inference: 0.0354 s/iter. Eval: 0.0397 s/iter. Total: 0.0775 s/iter. ETA=0:02:58\n",
      "\u001b[32m[07/06 22:31:32 d2.evaluation.evaluator]: \u001b[0mInference done 1722/3957. Dataloading: 0.0022 s/iter. Inference: 0.0354 s/iter. Eval: 0.0398 s/iter. Total: 0.0775 s/iter. ETA=0:02:53\n",
      "\u001b[32m[07/06 22:31:37 d2.evaluation.evaluator]: \u001b[0mInference done 1788/3957. Dataloading: 0.0022 s/iter. Inference: 0.0354 s/iter. Eval: 0.0397 s/iter. Total: 0.0775 s/iter. ETA=0:02:48\n",
      "\u001b[32m[07/06 22:31:42 d2.evaluation.evaluator]: \u001b[0mInference done 1851/3957. Dataloading: 0.0022 s/iter. Inference: 0.0355 s/iter. Eval: 0.0398 s/iter. Total: 0.0776 s/iter. ETA=0:02:43\n",
      "\u001b[32m[07/06 22:31:48 d2.evaluation.evaluator]: \u001b[0mInference done 1915/3957. Dataloading: 0.0022 s/iter. Inference: 0.0355 s/iter. Eval: 0.0398 s/iter. Total: 0.0776 s/iter. ETA=0:02:38\n",
      "\u001b[32m[07/06 22:31:53 d2.evaluation.evaluator]: \u001b[0mInference done 1980/3957. Dataloading: 0.0022 s/iter. Inference: 0.0355 s/iter. Eval: 0.0398 s/iter. Total: 0.0776 s/iter. ETA=0:02:33\n",
      "\u001b[32m[07/06 22:31:58 d2.evaluation.evaluator]: \u001b[0mInference done 2046/3957. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0397 s/iter. Total: 0.0776 s/iter. ETA=0:02:28\n",
      "\u001b[32m[07/06 22:32:03 d2.evaluation.evaluator]: \u001b[0mInference done 2112/3957. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0397 s/iter. Total: 0.0775 s/iter. ETA=0:02:23\n",
      "\u001b[32m[07/06 22:32:08 d2.evaluation.evaluator]: \u001b[0mInference done 2178/3957. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0396 s/iter. Total: 0.0775 s/iter. ETA=0:02:17\n",
      "\u001b[32m[07/06 22:32:13 d2.evaluation.evaluator]: \u001b[0mInference done 2244/3957. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0396 s/iter. Total: 0.0774 s/iter. ETA=0:02:12\n",
      "\u001b[32m[07/06 22:32:18 d2.evaluation.evaluator]: \u001b[0mInference done 2310/3957. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0396 s/iter. Total: 0.0774 s/iter. ETA=0:02:07\n",
      "\u001b[32m[07/06 22:32:23 d2.evaluation.evaluator]: \u001b[0mInference done 2376/3957. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0395 s/iter. Total: 0.0773 s/iter. ETA=0:02:02\n",
      "\u001b[32m[07/06 22:32:28 d2.evaluation.evaluator]: \u001b[0mInference done 2442/3957. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0395 s/iter. Total: 0.0773 s/iter. ETA=0:01:57\n",
      "\u001b[32m[07/06 22:32:33 d2.evaluation.evaluator]: \u001b[0mInference done 2508/3957. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0394 s/iter. Total: 0.0773 s/iter. ETA=0:01:51\n",
      "\u001b[32m[07/06 22:32:38 d2.evaluation.evaluator]: \u001b[0mInference done 2574/3957. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0394 s/iter. Total: 0.0772 s/iter. ETA=0:01:46\n",
      "\u001b[32m[07/06 22:32:43 d2.evaluation.evaluator]: \u001b[0mInference done 2640/3957. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0394 s/iter. Total: 0.0772 s/iter. ETA=0:01:41\n",
      "\u001b[32m[07/06 22:32:48 d2.evaluation.evaluator]: \u001b[0mInference done 2707/3957. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0393 s/iter. Total: 0.0772 s/iter. ETA=0:01:36\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/06 22:32:53 d2.evaluation.evaluator]: \u001b[0mInference done 2773/3957. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0393 s/iter. Total: 0.0771 s/iter. ETA=0:01:31\n",
      "\u001b[32m[07/06 22:32:58 d2.evaluation.evaluator]: \u001b[0mInference done 2839/3957. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0393 s/iter. Total: 0.0771 s/iter. ETA=0:01:26\n",
      "\u001b[32m[07/06 22:33:03 d2.evaluation.evaluator]: \u001b[0mInference done 2906/3957. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0392 s/iter. Total: 0.0771 s/iter. ETA=0:01:21\n",
      "\u001b[32m[07/06 22:33:08 d2.evaluation.evaluator]: \u001b[0mInference done 2973/3957. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0392 s/iter. Total: 0.0771 s/iter. ETA=0:01:15\n",
      "\u001b[32m[07/06 22:33:13 d2.evaluation.evaluator]: \u001b[0mInference done 3040/3957. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0392 s/iter. Total: 0.0770 s/iter. ETA=0:01:10\n",
      "\u001b[32m[07/06 22:33:18 d2.evaluation.evaluator]: \u001b[0mInference done 3107/3957. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0391 s/iter. Total: 0.0770 s/iter. ETA=0:01:05\n",
      "\u001b[32m[07/06 22:33:23 d2.evaluation.evaluator]: \u001b[0mInference done 3173/3957. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0391 s/iter. Total: 0.0770 s/iter. ETA=0:01:00\n",
      "\u001b[32m[07/06 22:33:28 d2.evaluation.evaluator]: \u001b[0mInference done 3239/3957. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0391 s/iter. Total: 0.0769 s/iter. ETA=0:00:55\n",
      "\u001b[32m[07/06 22:33:33 d2.evaluation.evaluator]: \u001b[0mInference done 3276/3957. Dataloading: 0.0023 s/iter. Inference: 0.0356 s/iter. Eval: 0.0397 s/iter. Total: 0.0776 s/iter. ETA=0:00:52\n",
      "\u001b[32m[07/06 22:33:38 d2.evaluation.evaluator]: \u001b[0mInference done 3301/3957. Dataloading: 0.0023 s/iter. Inference: 0.0356 s/iter. Eval: 0.0406 s/iter. Total: 0.0786 s/iter. ETA=0:00:51\n",
      "\u001b[32m[07/06 22:33:43 d2.evaluation.evaluator]: \u001b[0mInference done 3326/3957. Dataloading: 0.0023 s/iter. Inference: 0.0357 s/iter. Eval: 0.0414 s/iter. Total: 0.0795 s/iter. ETA=0:00:50\n",
      "\u001b[32m[07/06 22:33:48 d2.evaluation.evaluator]: \u001b[0mInference done 3351/3957. Dataloading: 0.0023 s/iter. Inference: 0.0358 s/iter. Eval: 0.0423 s/iter. Total: 0.0804 s/iter. ETA=0:00:48\n",
      "\u001b[32m[07/06 22:33:53 d2.evaluation.evaluator]: \u001b[0mInference done 3377/3957. Dataloading: 0.0023 s/iter. Inference: 0.0359 s/iter. Eval: 0.0430 s/iter. Total: 0.0813 s/iter. ETA=0:00:47\n",
      "\u001b[32m[07/06 22:33:58 d2.evaluation.evaluator]: \u001b[0mInference done 3404/3957. Dataloading: 0.0023 s/iter. Inference: 0.0360 s/iter. Eval: 0.0438 s/iter. Total: 0.0821 s/iter. ETA=0:00:45\n",
      "\u001b[32m[07/06 22:34:04 d2.evaluation.evaluator]: \u001b[0mInference done 3430/3957. Dataloading: 0.0023 s/iter. Inference: 0.0361 s/iter. Eval: 0.0446 s/iter. Total: 0.0830 s/iter. ETA=0:00:43\n",
      "\u001b[32m[07/06 22:34:09 d2.evaluation.evaluator]: \u001b[0mInference done 3455/3957. Dataloading: 0.0023 s/iter. Inference: 0.0361 s/iter. Eval: 0.0454 s/iter. Total: 0.0839 s/iter. ETA=0:00:42\n",
      "\u001b[32m[07/06 22:34:14 d2.evaluation.evaluator]: \u001b[0mInference done 3480/3957. Dataloading: 0.0023 s/iter. Inference: 0.0362 s/iter. Eval: 0.0462 s/iter. Total: 0.0848 s/iter. ETA=0:00:40\n",
      "\u001b[32m[07/06 22:34:19 d2.evaluation.evaluator]: \u001b[0mInference done 3505/3957. Dataloading: 0.0023 s/iter. Inference: 0.0363 s/iter. Eval: 0.0470 s/iter. Total: 0.0856 s/iter. ETA=0:00:38\n",
      "\u001b[32m[07/06 22:34:24 d2.evaluation.evaluator]: \u001b[0mInference done 3530/3957. Dataloading: 0.0023 s/iter. Inference: 0.0364 s/iter. Eval: 0.0477 s/iter. Total: 0.0864 s/iter. ETA=0:00:36\n",
      "\u001b[32m[07/06 22:34:29 d2.evaluation.evaluator]: \u001b[0mInference done 3556/3957. Dataloading: 0.0023 s/iter. Inference: 0.0364 s/iter. Eval: 0.0485 s/iter. Total: 0.0873 s/iter. ETA=0:00:34\n",
      "\u001b[32m[07/06 22:34:34 d2.evaluation.evaluator]: \u001b[0mInference done 3581/3957. Dataloading: 0.0023 s/iter. Inference: 0.0365 s/iter. Eval: 0.0492 s/iter. Total: 0.0881 s/iter. ETA=0:00:33\n",
      "\u001b[32m[07/06 22:34:39 d2.evaluation.evaluator]: \u001b[0mInference done 3606/3957. Dataloading: 0.0023 s/iter. Inference: 0.0366 s/iter. Eval: 0.0499 s/iter. Total: 0.0889 s/iter. ETA=0:00:31\n",
      "\u001b[32m[07/06 22:34:44 d2.evaluation.evaluator]: \u001b[0mInference done 3631/3957. Dataloading: 0.0023 s/iter. Inference: 0.0367 s/iter. Eval: 0.0507 s/iter. Total: 0.0897 s/iter. ETA=0:00:29\n",
      "\u001b[32m[07/06 22:34:50 d2.evaluation.evaluator]: \u001b[0mInference done 3656/3957. Dataloading: 0.0023 s/iter. Inference: 0.0367 s/iter. Eval: 0.0514 s/iter. Total: 0.0905 s/iter. ETA=0:00:27\n",
      "\u001b[32m[07/06 22:34:55 d2.evaluation.evaluator]: \u001b[0mInference done 3681/3957. Dataloading: 0.0023 s/iter. Inference: 0.0368 s/iter. Eval: 0.0521 s/iter. Total: 0.0912 s/iter. ETA=0:00:25\n",
      "\u001b[32m[07/06 22:35:00 d2.evaluation.evaluator]: \u001b[0mInference done 3706/3957. Dataloading: 0.0023 s/iter. Inference: 0.0369 s/iter. Eval: 0.0527 s/iter. Total: 0.0919 s/iter. ETA=0:00:23\n",
      "\u001b[32m[07/06 22:35:05 d2.evaluation.evaluator]: \u001b[0mInference done 3732/3957. Dataloading: 0.0023 s/iter. Inference: 0.0369 s/iter. Eval: 0.0534 s/iter. Total: 0.0927 s/iter. ETA=0:00:20\n",
      "\u001b[32m[07/06 22:35:10 d2.evaluation.evaluator]: \u001b[0mInference done 3757/3957. Dataloading: 0.0023 s/iter. Inference: 0.0370 s/iter. Eval: 0.0541 s/iter. Total: 0.0934 s/iter. ETA=0:00:18\n",
      "\u001b[32m[07/06 22:35:15 d2.evaluation.evaluator]: \u001b[0mInference done 3782/3957. Dataloading: 0.0023 s/iter. Inference: 0.0371 s/iter. Eval: 0.0547 s/iter. Total: 0.0941 s/iter. ETA=0:00:16\n",
      "\u001b[32m[07/06 22:35:20 d2.evaluation.evaluator]: \u001b[0mInference done 3807/3957. Dataloading: 0.0023 s/iter. Inference: 0.0371 s/iter. Eval: 0.0553 s/iter. Total: 0.0948 s/iter. ETA=0:00:14\n",
      "\u001b[32m[07/06 22:35:25 d2.evaluation.evaluator]: \u001b[0mInference done 3832/3957. Dataloading: 0.0023 s/iter. Inference: 0.0372 s/iter. Eval: 0.0560 s/iter. Total: 0.0955 s/iter. ETA=0:00:11\n",
      "\u001b[32m[07/06 22:35:30 d2.evaluation.evaluator]: \u001b[0mInference done 3857/3957. Dataloading: 0.0023 s/iter. Inference: 0.0373 s/iter. Eval: 0.0566 s/iter. Total: 0.0962 s/iter. ETA=0:00:09\n",
      "\u001b[32m[07/06 22:35:35 d2.evaluation.evaluator]: \u001b[0mInference done 3882/3957. Dataloading: 0.0023 s/iter. Inference: 0.0373 s/iter. Eval: 0.0572 s/iter. Total: 0.0969 s/iter. ETA=0:00:07\n",
      "\u001b[32m[07/06 22:35:40 d2.evaluation.evaluator]: \u001b[0mInference done 3907/3957. Dataloading: 0.0023 s/iter. Inference: 0.0374 s/iter. Eval: 0.0578 s/iter. Total: 0.0976 s/iter. ETA=0:00:04\n",
      "\u001b[32m[07/06 22:35:45 d2.evaluation.evaluator]: \u001b[0mInference done 3932/3957. Dataloading: 0.0023 s/iter. Inference: 0.0374 s/iter. Eval: 0.0584 s/iter. Total: 0.0982 s/iter. ETA=0:00:02\n",
      "\u001b[32m[07/06 22:35:50 d2.evaluation.evaluator]: \u001b[0mInference done 3957/3957. Dataloading: 0.0023 s/iter. Inference: 0.0375 s/iter. Eval: 0.0591 s/iter. Total: 0.0989 s/iter. ETA=0:00:00\n",
      "\u001b[32m[07/06 22:35:50 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:06:31.015739 (0.098941 s / iter per device, on 1 devices)\n",
      "\u001b[32m[07/06 22:35:50 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:02:28 (0.037492 s / iter per device, on 1 devices)\n",
      "\u001b[32m[07/06 22:35:51 d2.evaluation.sem_seg_evaluation]: \u001b[0mOrderedDict([('sem_seg', {'mIoU': 72.00502353561453, 'fwIoU': 91.86109590935872, 'IoU-Unlabeled': nan, 'IoU-Building': 90.87733923495604, 'IoU-Fence': 40.63599712614458, 'IoU-Pedestrian': 73.55229823940338, 'IoU-Pole': 56.55990072334386, 'IoU-Road': 97.98995128868438, 'IoU-SideWalk': 83.51962800974599, 'IoU-Vegetation': 86.36442269085872, 'IoU-Vehicles': 88.83338584525625, 'IoU-Wall': 74.52265283347967, 'IoU-TrafficSign': 57.61968879751891, 'IoU-Sky': 95.92533891020827, 'IoU-TrafficLight': 64.96303464515891, 'IoU-Terrain': 65.36853516942669, 'IoU-ConstructionVehicle': 88.6196598711867, 'IoU-workzone_object': 76.26656196664736, 'IoU-Detour': 10.461981217812784, 'mACC': 78.88268726825119, 'pACC': 95.57755399732912, 'ACC-Unlabeled': nan, 'ACC-Building': 96.91304013879642, 'ACC-Fence': 49.51118518473249, 'ACC-Pedestrian': 87.01200647526565, 'ACC-Pole': 67.14207012690562, 'ACC-Road': 98.93158740392157, 'ACC-SideWalk': 91.21194923344844, 'ACC-Vegetation': 93.18899114228635, 'ACC-Vehicles': 92.16131815670327, 'ACC-Wall': 84.54885197754899, 'ACC-TrafficSign': 66.15243271267516, 'ACC-Sky': 97.12172710615945, 'ACC-TrafficLight': 75.55422132291962, 'ACC-Terrain': 76.46292234836793, 'ACC-ConstructionVehicle': 93.00089463751456, 'ACC-workzone_object': 82.44989054810361, 'ACC-Detour': 10.75990777666999})])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/06 22:35:51 d2.engine.defaults]: \u001b[0mEvaluation results for combined_clear_val in csv format:\n",
      "\u001b[32m[07/06 22:35:51 d2.evaluation.testing]: \u001b[0mcopypaste: Task: sem_seg\n",
      "\u001b[32m[07/06 22:35:51 d2.evaluation.testing]: \u001b[0mcopypaste: mIoU,fwIoU,mACC,pACC\n",
      "\u001b[32m[07/06 22:35:51 d2.evaluation.testing]: \u001b[0mcopypaste: 72.0050,91.8611,78.8827,95.5776\n"
     ]
    }
   ],
   "source": [
    "trainer_day = Detectron2Trainer('combined_clear_train', 'combined_clear_val', output_folder='./output_day_clear_40k')\n",
    "trainer_day.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1522f940",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/06 03:29:11 d2.engine.defaults]: \u001b[0mModel:\n",
      "SemanticSegmentor(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (sem_seg_head): SemSegFPNHead(\n",
      "    (p2): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "    )\n",
      "    (p3): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (1): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "    )\n",
      "    (p4): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (1): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      (2): Conv2d(\n",
      "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (3): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "    )\n",
      "    (p5): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (1): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      (2): Conv2d(\n",
      "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (3): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      (4): Conv2d(\n",
      "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (5): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "    )\n",
      "    (predictor): Conv2d(128, 17, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/06 03:29:11 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(720, 720), max_size=2048, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[07/06 03:29:11 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[07/06 03:29:11 d2.data.common]: \u001b[0mSerializing 1176 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[07/06 03:29:11 d2.data.common]: \u001b[0mSerialized dataset takes 0.41 MiB\n",
      "Last checkpoint: model_final.pth\n",
      "\u001b[32m[07/06 03:29:12 d2.checkpoint.c2_model_loading]: \u001b[0mFollowing weights matched with model:\n",
      "| Names in Model                       | Names in Checkpoint                                                                                  | Shapes                                          |\n",
      "|:-------------------------------------|:-----------------------------------------------------------------------------------------------------|:------------------------------------------------|\n",
      "| backbone.bottom_up.res2.0.conv1.*    | backbone.bottom_up.res2.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,1,1)             |\n",
      "| backbone.bottom_up.res2.0.conv2.*    | backbone.bottom_up.res2.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |\n",
      "| backbone.bottom_up.res2.0.conv3.*    | backbone.bottom_up.res2.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res2.0.shortcut.* | backbone.bottom_up.res2.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res2.1.conv1.*    | backbone.bottom_up.res2.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |\n",
      "| backbone.bottom_up.res2.1.conv2.*    | backbone.bottom_up.res2.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |\n",
      "| backbone.bottom_up.res2.1.conv3.*    | backbone.bottom_up.res2.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res2.2.conv1.*    | backbone.bottom_up.res2.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |\n",
      "| backbone.bottom_up.res2.2.conv2.*    | backbone.bottom_up.res2.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |\n",
      "| backbone.bottom_up.res2.2.conv3.*    | backbone.bottom_up.res2.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res3.0.conv1.*    | backbone.bottom_up.res3.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,256,1,1)       |\n",
      "| backbone.bottom_up.res3.0.conv2.*    | backbone.bottom_up.res3.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.0.conv3.*    | backbone.bottom_up.res3.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res3.0.shortcut.* | backbone.bottom_up.res3.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (512,) (512,) (512,) (512,) (512,256,1,1)       |\n",
      "| backbone.bottom_up.res3.1.conv1.*    | backbone.bottom_up.res3.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |\n",
      "| backbone.bottom_up.res3.1.conv2.*    | backbone.bottom_up.res3.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.1.conv3.*    | backbone.bottom_up.res3.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res3.2.conv1.*    | backbone.bottom_up.res3.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |\n",
      "| backbone.bottom_up.res3.2.conv2.*    | backbone.bottom_up.res3.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.2.conv3.*    | backbone.bottom_up.res3.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res3.3.conv1.*    | backbone.bottom_up.res3.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |\n",
      "| backbone.bottom_up.res3.3.conv2.*    | backbone.bottom_up.res3.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.3.conv3.*    | backbone.bottom_up.res3.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res4.0.conv1.*    | backbone.bottom_up.res4.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,512,1,1)       |\n",
      "| backbone.bottom_up.res4.0.conv2.*    | backbone.bottom_up.res4.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.0.conv3.*    | backbone.bottom_up.res4.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.0.shortcut.* | backbone.bottom_up.res4.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (1024,) (1024,) (1024,) (1024,) (1024,512,1,1)  |\n",
      "| backbone.bottom_up.res4.1.conv1.*    | backbone.bottom_up.res4.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.1.conv2.*    | backbone.bottom_up.res4.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.1.conv3.*    | backbone.bottom_up.res4.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.2.conv1.*    | backbone.bottom_up.res4.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.2.conv2.*    | backbone.bottom_up.res4.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.2.conv3.*    | backbone.bottom_up.res4.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.3.conv1.*    | backbone.bottom_up.res4.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.3.conv2.*    | backbone.bottom_up.res4.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.3.conv3.*    | backbone.bottom_up.res4.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.4.conv1.*    | backbone.bottom_up.res4.4.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.4.conv2.*    | backbone.bottom_up.res4.4.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.4.conv3.*    | backbone.bottom_up.res4.4.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.5.conv1.*    | backbone.bottom_up.res4.5.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.5.conv2.*    | backbone.bottom_up.res4.5.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.5.conv3.*    | backbone.bottom_up.res4.5.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res5.0.conv1.*    | backbone.bottom_up.res5.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,1024,1,1)      |\n",
      "| backbone.bottom_up.res5.0.conv2.*    | backbone.bottom_up.res5.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |\n",
      "| backbone.bottom_up.res5.0.conv3.*    | backbone.bottom_up.res5.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
      "| backbone.bottom_up.res5.0.shortcut.* | backbone.bottom_up.res5.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (2048,) (2048,) (2048,) (2048,) (2048,1024,1,1) |\n",
      "| backbone.bottom_up.res5.1.conv1.*    | backbone.bottom_up.res5.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |\n",
      "| backbone.bottom_up.res5.1.conv2.*    | backbone.bottom_up.res5.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |\n",
      "| backbone.bottom_up.res5.1.conv3.*    | backbone.bottom_up.res5.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
      "| backbone.bottom_up.res5.2.conv1.*    | backbone.bottom_up.res5.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |\n",
      "| backbone.bottom_up.res5.2.conv2.*    | backbone.bottom_up.res5.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |\n",
      "| backbone.bottom_up.res5.2.conv3.*    | backbone.bottom_up.res5.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
      "| backbone.bottom_up.stem.conv1.*      | backbone.bottom_up.stem.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}      | (64,) (64,) (64,) (64,) (64,3,7,7)              |\n",
      "| backbone.fpn_lateral2.*              | backbone.fpn_lateral2.{bias,weight}                                                                  | (256,) (256,256,1,1)                            |\n",
      "| backbone.fpn_lateral3.*              | backbone.fpn_lateral3.{bias,weight}                                                                  | (256,) (256,512,1,1)                            |\n",
      "| backbone.fpn_lateral4.*              | backbone.fpn_lateral4.{bias,weight}                                                                  | (256,) (256,1024,1,1)                           |\n",
      "| backbone.fpn_lateral5.*              | backbone.fpn_lateral5.{bias,weight}                                                                  | (256,) (256,2048,1,1)                           |\n",
      "| backbone.fpn_output2.*               | backbone.fpn_output2.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| backbone.fpn_output3.*               | backbone.fpn_output3.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| backbone.fpn_output4.*               | backbone.fpn_output4.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| backbone.fpn_output5.*               | backbone.fpn_output5.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| sem_seg_head.p2.0.*                  | sem_seg_head.p2.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p3.0.*                  | sem_seg_head.p3.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p4.0.*                  | sem_seg_head.p4.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p4.2.*                  | sem_seg_head.p4.2.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,128,3,3)                     |\n",
      "| sem_seg_head.p5.0.*                  | sem_seg_head.p5.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p5.2.*                  | sem_seg_head.p5.2.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,128,3,3)                     |\n",
      "| sem_seg_head.p5.4.*                  | sem_seg_head.p5.4.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,128,3,3)                     |\n",
      "| sem_seg_head.predictor.*             | sem_seg_head.predictor.{bias,weight}                                                                 | (17,) (17,128,1,1)                              |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/06 03:29:12 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(720, 720), max_size=2048, sample_style='choice')]\n",
      "\u001b[32m[07/06 03:29:12 d2.data.common]: \u001b[0mSerializing 1081 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[07/06 03:29:12 d2.data.common]: \u001b[0mSerialized dataset takes 0.38 MiB\n",
      "\u001b[32m[07/06 03:29:12 d2.evaluation.evaluator]: \u001b[0mStart inference on 1081 batches\n",
      "\u001b[32m[07/06 03:29:13 d2.evaluation.evaluator]: \u001b[0mInference done 11/1081. Dataloading: 0.0016 s/iter. Inference: 0.0353 s/iter. Eval: 0.0426 s/iter. Total: 0.0795 s/iter. ETA=0:01:25\n",
      "\u001b[32m[07/06 03:29:18 d2.evaluation.evaluator]: \u001b[0mInference done 78/1081. Dataloading: 0.0020 s/iter. Inference: 0.0349 s/iter. Eval: 0.0386 s/iter. Total: 0.0756 s/iter. ETA=0:01:15\n",
      "\u001b[32m[07/06 03:29:23 d2.evaluation.evaluator]: \u001b[0mInference done 145/1081. Dataloading: 0.0021 s/iter. Inference: 0.0349 s/iter. Eval: 0.0382 s/iter. Total: 0.0753 s/iter. ETA=0:01:10\n",
      "\u001b[32m[07/06 03:29:28 d2.evaluation.evaluator]: \u001b[0mInference done 212/1081. Dataloading: 0.0021 s/iter. Inference: 0.0349 s/iter. Eval: 0.0382 s/iter. Total: 0.0753 s/iter. ETA=0:01:05\n",
      "\u001b[32m[07/06 03:29:33 d2.evaluation.evaluator]: \u001b[0mInference done 277/1081. Dataloading: 0.0021 s/iter. Inference: 0.0350 s/iter. Eval: 0.0387 s/iter. Total: 0.0758 s/iter. ETA=0:01:00\n",
      "\u001b[32m[07/06 03:29:38 d2.evaluation.evaluator]: \u001b[0mInference done 342/1081. Dataloading: 0.0021 s/iter. Inference: 0.0350 s/iter. Eval: 0.0390 s/iter. Total: 0.0761 s/iter. ETA=0:00:56\n",
      "\u001b[32m[07/06 03:29:43 d2.evaluation.evaluator]: \u001b[0mInference done 408/1081. Dataloading: 0.0021 s/iter. Inference: 0.0350 s/iter. Eval: 0.0390 s/iter. Total: 0.0763 s/iter. ETA=0:00:51\n",
      "\u001b[32m[07/06 03:29:48 d2.evaluation.evaluator]: \u001b[0mInference done 473/1081. Dataloading: 0.0021 s/iter. Inference: 0.0350 s/iter. Eval: 0.0392 s/iter. Total: 0.0764 s/iter. ETA=0:00:46\n",
      "\u001b[32m[07/06 03:29:53 d2.evaluation.evaluator]: \u001b[0mInference done 538/1081. Dataloading: 0.0022 s/iter. Inference: 0.0350 s/iter. Eval: 0.0392 s/iter. Total: 0.0765 s/iter. ETA=0:00:41\n",
      "\u001b[32m[07/06 03:29:58 d2.evaluation.evaluator]: \u001b[0mInference done 604/1081. Dataloading: 0.0022 s/iter. Inference: 0.0351 s/iter. Eval: 0.0392 s/iter. Total: 0.0765 s/iter. ETA=0:00:36\n",
      "\u001b[32m[07/06 03:30:03 d2.evaluation.evaluator]: \u001b[0mInference done 669/1081. Dataloading: 0.0022 s/iter. Inference: 0.0351 s/iter. Eval: 0.0393 s/iter. Total: 0.0766 s/iter. ETA=0:00:31\n",
      "\u001b[32m[07/06 03:30:08 d2.evaluation.evaluator]: \u001b[0mInference done 733/1081. Dataloading: 0.0023 s/iter. Inference: 0.0351 s/iter. Eval: 0.0393 s/iter. Total: 0.0768 s/iter. ETA=0:00:26\n",
      "\u001b[32m[07/06 03:30:13 d2.evaluation.evaluator]: \u001b[0mInference done 799/1081. Dataloading: 0.0023 s/iter. Inference: 0.0351 s/iter. Eval: 0.0393 s/iter. Total: 0.0768 s/iter. ETA=0:00:21\n",
      "\u001b[32m[07/06 03:30:18 d2.evaluation.evaluator]: \u001b[0mInference done 865/1081. Dataloading: 0.0023 s/iter. Inference: 0.0351 s/iter. Eval: 0.0393 s/iter. Total: 0.0768 s/iter. ETA=0:00:16\n",
      "\u001b[32m[07/06 03:30:23 d2.evaluation.evaluator]: \u001b[0mInference done 931/1081. Dataloading: 0.0023 s/iter. Inference: 0.0351 s/iter. Eval: 0.0392 s/iter. Total: 0.0767 s/iter. ETA=0:00:11\n",
      "\u001b[32m[07/06 03:30:28 d2.evaluation.evaluator]: \u001b[0mInference done 996/1081. Dataloading: 0.0023 s/iter. Inference: 0.0351 s/iter. Eval: 0.0393 s/iter. Total: 0.0768 s/iter. ETA=0:00:06\n",
      "\u001b[32m[07/06 03:30:34 d2.evaluation.evaluator]: \u001b[0mInference done 1062/1081. Dataloading: 0.0023 s/iter. Inference: 0.0352 s/iter. Eval: 0.0393 s/iter. Total: 0.0768 s/iter. ETA=0:00:01\n",
      "\u001b[32m[07/06 03:30:35 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:01:22.740144 (0.076896 s / iter per device, on 1 devices)\n",
      "\u001b[32m[07/06 03:30:35 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:37 (0.035171 s / iter per device, on 1 devices)\n",
      "\u001b[32m[07/06 03:30:35 d2.evaluation.sem_seg_evaluation]: \u001b[0mOrderedDict([('sem_seg', {'mIoU': 60.782390522192095, 'fwIoU': 86.39222099521021, 'IoU-Unlabeled': nan, 'IoU-Building': 82.00768838030547, 'IoU-Fence': 23.980245597737664, 'IoU-Pedestrian': 24.67731618097914, 'IoU-Pole': 45.354827775170406, 'IoU-Road': 96.92406593746054, 'IoU-SideWalk': 75.57696318915517, 'IoU-Vegetation': 72.8918690396316, 'IoU-Vehicles': 83.86934153835871, 'IoU-Wall': 63.21148783764416, 'IoU-TrafficSign': 48.12156891583644, 'IoU-Sky': 87.33018545445951, 'IoU-TrafficLight': 68.84062771588401, 'IoU-Terrain': 51.70566552997561, 'IoU-ConstructionVehicle': 82.6088477731545, 'IoU-workzone_object': 65.41754748932074, 'IoU-Detour': 0.0, 'mACC': 70.80357335047619, 'pACC': 92.29566764739894, 'ACC-Unlabeled': nan, 'ACC-Building': 96.73244395769464, 'ACC-Fence': 30.359504579066886, 'ACC-Pedestrian': 66.0056205175486, 'ACC-Pole': 51.673934908049446, 'ACC-Road': 97.83298639755849, 'ACC-SideWalk': 88.91156192504427, 'ACC-Vegetation': 81.12245398929755, 'ACC-Vehicles': 88.00484257450542, 'ACC-Wall': 80.61274821938967, 'ACC-TrafficSign': 60.39929851361776, 'ACC-Sky': 88.67969731206688, 'ACC-TrafficLight': 79.12514446596153, 'ACC-Terrain': 61.941751305462404, 'ACC-ConstructionVehicle': 86.8761766796154, 'ACC-workzone_object': 74.57900826273995, 'ACC-Detour': 0.0})])\n",
      "\u001b[32m[07/06 03:30:35 d2.engine.defaults]: \u001b[0mEvaluation results for carla_rain_val in csv format:\n",
      "\u001b[32m[07/06 03:30:35 d2.evaluation.testing]: \u001b[0mcopypaste: Task: sem_seg\n",
      "\u001b[32m[07/06 03:30:35 d2.evaluation.testing]: \u001b[0mcopypaste: mIoU,fwIoU,mACC,pACC\n",
      "\u001b[32m[07/06 03:30:35 d2.evaluation.testing]: \u001b[0mcopypaste: 60.7824,86.3922,70.8036,92.2957\n"
     ]
    }
   ],
   "source": [
    "trainer_day = Detectron2Trainer('combined_clear_train', 'carla_rain_val', output_folder='./output_day_clear_40k')\n",
    "trainer_day.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6bc44c70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/06 03:30:36 d2.engine.defaults]: \u001b[0mModel:\n",
      "SemanticSegmentor(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (sem_seg_head): SemSegFPNHead(\n",
      "    (p2): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "    )\n",
      "    (p3): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (1): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "    )\n",
      "    (p4): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (1): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      (2): Conv2d(\n",
      "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (3): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "    )\n",
      "    (p5): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (1): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      (2): Conv2d(\n",
      "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (3): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      (4): Conv2d(\n",
      "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (5): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "    )\n",
      "    (predictor): Conv2d(128, 17, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/06 03:30:36 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(720, 720), max_size=2048, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[07/06 03:30:36 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[07/06 03:30:36 d2.data.common]: \u001b[0mSerializing 1176 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[07/06 03:30:36 d2.data.common]: \u001b[0mSerialized dataset takes 0.41 MiB\n",
      "Last checkpoint: model_final.pth\n",
      "\u001b[32m[07/06 03:30:36 d2.checkpoint.c2_model_loading]: \u001b[0mFollowing weights matched with model:\n",
      "| Names in Model                       | Names in Checkpoint                                                                                  | Shapes                                          |\n",
      "|:-------------------------------------|:-----------------------------------------------------------------------------------------------------|:------------------------------------------------|\n",
      "| backbone.bottom_up.res2.0.conv1.*    | backbone.bottom_up.res2.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,1,1)             |\n",
      "| backbone.bottom_up.res2.0.conv2.*    | backbone.bottom_up.res2.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |\n",
      "| backbone.bottom_up.res2.0.conv3.*    | backbone.bottom_up.res2.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res2.0.shortcut.* | backbone.bottom_up.res2.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res2.1.conv1.*    | backbone.bottom_up.res2.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |\n",
      "| backbone.bottom_up.res2.1.conv2.*    | backbone.bottom_up.res2.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |\n",
      "| backbone.bottom_up.res2.1.conv3.*    | backbone.bottom_up.res2.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res2.2.conv1.*    | backbone.bottom_up.res2.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |\n",
      "| backbone.bottom_up.res2.2.conv2.*    | backbone.bottom_up.res2.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |\n",
      "| backbone.bottom_up.res2.2.conv3.*    | backbone.bottom_up.res2.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res3.0.conv1.*    | backbone.bottom_up.res3.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,256,1,1)       |\n",
      "| backbone.bottom_up.res3.0.conv2.*    | backbone.bottom_up.res3.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.0.conv3.*    | backbone.bottom_up.res3.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res3.0.shortcut.* | backbone.bottom_up.res3.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (512,) (512,) (512,) (512,) (512,256,1,1)       |\n",
      "| backbone.bottom_up.res3.1.conv1.*    | backbone.bottom_up.res3.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |\n",
      "| backbone.bottom_up.res3.1.conv2.*    | backbone.bottom_up.res3.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.1.conv3.*    | backbone.bottom_up.res3.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res3.2.conv1.*    | backbone.bottom_up.res3.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |\n",
      "| backbone.bottom_up.res3.2.conv2.*    | backbone.bottom_up.res3.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.2.conv3.*    | backbone.bottom_up.res3.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res3.3.conv1.*    | backbone.bottom_up.res3.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |\n",
      "| backbone.bottom_up.res3.3.conv2.*    | backbone.bottom_up.res3.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.3.conv3.*    | backbone.bottom_up.res3.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res4.0.conv1.*    | backbone.bottom_up.res4.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,512,1,1)       |\n",
      "| backbone.bottom_up.res4.0.conv2.*    | backbone.bottom_up.res4.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.0.conv3.*    | backbone.bottom_up.res4.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.0.shortcut.* | backbone.bottom_up.res4.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (1024,) (1024,) (1024,) (1024,) (1024,512,1,1)  |\n",
      "| backbone.bottom_up.res4.1.conv1.*    | backbone.bottom_up.res4.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.1.conv2.*    | backbone.bottom_up.res4.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.1.conv3.*    | backbone.bottom_up.res4.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.2.conv1.*    | backbone.bottom_up.res4.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.2.conv2.*    | backbone.bottom_up.res4.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.2.conv3.*    | backbone.bottom_up.res4.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.3.conv1.*    | backbone.bottom_up.res4.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.3.conv2.*    | backbone.bottom_up.res4.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.3.conv3.*    | backbone.bottom_up.res4.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.4.conv1.*    | backbone.bottom_up.res4.4.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.4.conv2.*    | backbone.bottom_up.res4.4.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.4.conv3.*    | backbone.bottom_up.res4.4.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.5.conv1.*    | backbone.bottom_up.res4.5.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.5.conv2.*    | backbone.bottom_up.res4.5.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.5.conv3.*    | backbone.bottom_up.res4.5.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res5.0.conv1.*    | backbone.bottom_up.res5.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,1024,1,1)      |\n",
      "| backbone.bottom_up.res5.0.conv2.*    | backbone.bottom_up.res5.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |\n",
      "| backbone.bottom_up.res5.0.conv3.*    | backbone.bottom_up.res5.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
      "| backbone.bottom_up.res5.0.shortcut.* | backbone.bottom_up.res5.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (2048,) (2048,) (2048,) (2048,) (2048,1024,1,1) |\n",
      "| backbone.bottom_up.res5.1.conv1.*    | backbone.bottom_up.res5.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |\n",
      "| backbone.bottom_up.res5.1.conv2.*    | backbone.bottom_up.res5.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |\n",
      "| backbone.bottom_up.res5.1.conv3.*    | backbone.bottom_up.res5.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
      "| backbone.bottom_up.res5.2.conv1.*    | backbone.bottom_up.res5.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |\n",
      "| backbone.bottom_up.res5.2.conv2.*    | backbone.bottom_up.res5.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |\n",
      "| backbone.bottom_up.res5.2.conv3.*    | backbone.bottom_up.res5.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
      "| backbone.bottom_up.stem.conv1.*      | backbone.bottom_up.stem.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}      | (64,) (64,) (64,) (64,) (64,3,7,7)              |\n",
      "| backbone.fpn_lateral2.*              | backbone.fpn_lateral2.{bias,weight}                                                                  | (256,) (256,256,1,1)                            |\n",
      "| backbone.fpn_lateral3.*              | backbone.fpn_lateral3.{bias,weight}                                                                  | (256,) (256,512,1,1)                            |\n",
      "| backbone.fpn_lateral4.*              | backbone.fpn_lateral4.{bias,weight}                                                                  | (256,) (256,1024,1,1)                           |\n",
      "| backbone.fpn_lateral5.*              | backbone.fpn_lateral5.{bias,weight}                                                                  | (256,) (256,2048,1,1)                           |\n",
      "| backbone.fpn_output2.*               | backbone.fpn_output2.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| backbone.fpn_output3.*               | backbone.fpn_output3.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| backbone.fpn_output4.*               | backbone.fpn_output4.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| backbone.fpn_output5.*               | backbone.fpn_output5.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| sem_seg_head.p2.0.*                  | sem_seg_head.p2.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p3.0.*                  | sem_seg_head.p3.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p4.0.*                  | sem_seg_head.p4.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p4.2.*                  | sem_seg_head.p4.2.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,128,3,3)                     |\n",
      "| sem_seg_head.p5.0.*                  | sem_seg_head.p5.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p5.2.*                  | sem_seg_head.p5.2.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,128,3,3)                     |\n",
      "| sem_seg_head.p5.4.*                  | sem_seg_head.p5.4.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,128,3,3)                     |\n",
      "| sem_seg_head.predictor.*             | sem_seg_head.predictor.{bias,weight}                                                                 | (17,) (17,128,1,1)                              |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/06 03:30:36 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(720, 720), max_size=2048, sample_style='choice')]\n",
      "\u001b[32m[07/06 03:30:36 d2.data.common]: \u001b[0mSerializing 699 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[07/06 03:30:36 d2.data.common]: \u001b[0mSerialized dataset takes 0.23 MiB\n",
      "\u001b[32m[07/06 03:30:36 d2.evaluation.evaluator]: \u001b[0mStart inference on 699 batches\n",
      "\u001b[32m[07/06 03:30:39 d2.evaluation.evaluator]: \u001b[0mInference done 11/699. Dataloading: 0.0017 s/iter. Inference: 0.0470 s/iter. Eval: 0.1530 s/iter. Total: 0.2017 s/iter. ETA=0:02:18\n",
      "\u001b[32m[07/06 03:30:44 d2.evaluation.evaluator]: \u001b[0mInference done 37/699. Dataloading: 0.0021 s/iter. Inference: 0.0469 s/iter. Eval: 0.1504 s/iter. Total: 0.1996 s/iter. ETA=0:02:12\n",
      "\u001b[32m[07/06 03:30:49 d2.evaluation.evaluator]: \u001b[0mInference done 62/699. Dataloading: 0.0021 s/iter. Inference: 0.0469 s/iter. Eval: 0.1506 s/iter. Total: 0.1998 s/iter. ETA=0:02:07\n",
      "\u001b[32m[07/06 03:30:54 d2.evaluation.evaluator]: \u001b[0mInference done 88/699. Dataloading: 0.0021 s/iter. Inference: 0.0469 s/iter. Eval: 0.1489 s/iter. Total: 0.1980 s/iter. ETA=0:02:00\n",
      "\u001b[32m[07/06 03:30:59 d2.evaluation.evaluator]: \u001b[0mInference done 115/699. Dataloading: 0.0021 s/iter. Inference: 0.0469 s/iter. Eval: 0.1467 s/iter. Total: 0.1958 s/iter. ETA=0:01:54\n",
      "\u001b[32m[07/06 03:31:04 d2.evaluation.evaluator]: \u001b[0mInference done 142/699. Dataloading: 0.0021 s/iter. Inference: 0.0469 s/iter. Eval: 0.1451 s/iter. Total: 0.1941 s/iter. ETA=0:01:48\n",
      "\u001b[32m[07/06 03:31:09 d2.evaluation.evaluator]: \u001b[0mInference done 169/699. Dataloading: 0.0021 s/iter. Inference: 0.0467 s/iter. Eval: 0.1442 s/iter. Total: 0.1931 s/iter. ETA=0:01:42\n",
      "\u001b[32m[07/06 03:31:14 d2.evaluation.evaluator]: \u001b[0mInference done 194/699. Dataloading: 0.0021 s/iter. Inference: 0.0467 s/iter. Eval: 0.1456 s/iter. Total: 0.1945 s/iter. ETA=0:01:38\n",
      "\u001b[32m[07/06 03:31:19 d2.evaluation.evaluator]: \u001b[0mInference done 219/699. Dataloading: 0.0021 s/iter. Inference: 0.0467 s/iter. Eval: 0.1466 s/iter. Total: 0.1955 s/iter. ETA=0:01:33\n",
      "\u001b[32m[07/06 03:31:24 d2.evaluation.evaluator]: \u001b[0mInference done 245/699. Dataloading: 0.0021 s/iter. Inference: 0.0467 s/iter. Eval: 0.1468 s/iter. Total: 0.1957 s/iter. ETA=0:01:28\n",
      "\u001b[32m[07/06 03:31:30 d2.evaluation.evaluator]: \u001b[0mInference done 271/699. Dataloading: 0.0021 s/iter. Inference: 0.0467 s/iter. Eval: 0.1470 s/iter. Total: 0.1959 s/iter. ETA=0:01:23\n",
      "\u001b[32m[07/06 03:31:35 d2.evaluation.evaluator]: \u001b[0mInference done 297/699. Dataloading: 0.0021 s/iter. Inference: 0.0467 s/iter. Eval: 0.1471 s/iter. Total: 0.1960 s/iter. ETA=0:01:18\n",
      "\u001b[32m[07/06 03:31:40 d2.evaluation.evaluator]: \u001b[0mInference done 323/699. Dataloading: 0.0021 s/iter. Inference: 0.0467 s/iter. Eval: 0.1470 s/iter. Total: 0.1959 s/iter. ETA=0:01:13\n",
      "\u001b[32m[07/06 03:31:45 d2.evaluation.evaluator]: \u001b[0mInference done 349/699. Dataloading: 0.0021 s/iter. Inference: 0.0467 s/iter. Eval: 0.1472 s/iter. Total: 0.1960 s/iter. ETA=0:01:08\n",
      "\u001b[32m[07/06 03:31:50 d2.evaluation.evaluator]: \u001b[0mInference done 375/699. Dataloading: 0.0021 s/iter. Inference: 0.0467 s/iter. Eval: 0.1474 s/iter. Total: 0.1963 s/iter. ETA=0:01:03\n",
      "\u001b[32m[07/06 03:31:55 d2.evaluation.evaluator]: \u001b[0mInference done 400/699. Dataloading: 0.0021 s/iter. Inference: 0.0467 s/iter. Eval: 0.1478 s/iter. Total: 0.1967 s/iter. ETA=0:00:58\n",
      "\u001b[32m[07/06 03:32:00 d2.evaluation.evaluator]: \u001b[0mInference done 426/699. Dataloading: 0.0021 s/iter. Inference: 0.0467 s/iter. Eval: 0.1480 s/iter. Total: 0.1969 s/iter. ETA=0:00:53\n",
      "\u001b[32m[07/06 03:32:05 d2.evaluation.evaluator]: \u001b[0mInference done 452/699. Dataloading: 0.0021 s/iter. Inference: 0.0467 s/iter. Eval: 0.1478 s/iter. Total: 0.1967 s/iter. ETA=0:00:48\n",
      "\u001b[32m[07/06 03:32:11 d2.evaluation.evaluator]: \u001b[0mInference done 479/699. Dataloading: 0.0021 s/iter. Inference: 0.0467 s/iter. Eval: 0.1473 s/iter. Total: 0.1963 s/iter. ETA=0:00:43\n",
      "\u001b[32m[07/06 03:32:16 d2.evaluation.evaluator]: \u001b[0mInference done 505/699. Dataloading: 0.0021 s/iter. Inference: 0.0467 s/iter. Eval: 0.1474 s/iter. Total: 0.1963 s/iter. ETA=0:00:38\n",
      "\u001b[32m[07/06 03:32:21 d2.evaluation.evaluator]: \u001b[0mInference done 531/699. Dataloading: 0.0021 s/iter. Inference: 0.0467 s/iter. Eval: 0.1473 s/iter. Total: 0.1962 s/iter. ETA=0:00:32\n",
      "\u001b[32m[07/06 03:32:26 d2.evaluation.evaluator]: \u001b[0mInference done 557/699. Dataloading: 0.0021 s/iter. Inference: 0.0467 s/iter. Eval: 0.1472 s/iter. Total: 0.1961 s/iter. ETA=0:00:27\n",
      "\u001b[32m[07/06 03:32:31 d2.evaluation.evaluator]: \u001b[0mInference done 583/699. Dataloading: 0.0021 s/iter. Inference: 0.0467 s/iter. Eval: 0.1473 s/iter. Total: 0.1962 s/iter. ETA=0:00:22\n",
      "\u001b[32m[07/06 03:32:36 d2.evaluation.evaluator]: \u001b[0mInference done 609/699. Dataloading: 0.0021 s/iter. Inference: 0.0467 s/iter. Eval: 0.1474 s/iter. Total: 0.1963 s/iter. ETA=0:00:17\n",
      "\u001b[32m[07/06 03:32:41 d2.evaluation.evaluator]: \u001b[0mInference done 635/699. Dataloading: 0.0021 s/iter. Inference: 0.0467 s/iter. Eval: 0.1475 s/iter. Total: 0.1964 s/iter. ETA=0:00:12\n",
      "\u001b[32m[07/06 03:32:46 d2.evaluation.evaluator]: \u001b[0mInference done 661/699. Dataloading: 0.0021 s/iter. Inference: 0.0467 s/iter. Eval: 0.1474 s/iter. Total: 0.1963 s/iter. ETA=0:00:07\n",
      "\u001b[32m[07/06 03:32:51 d2.evaluation.evaluator]: \u001b[0mInference done 687/699. Dataloading: 0.0021 s/iter. Inference: 0.0467 s/iter. Eval: 0.1474 s/iter. Total: 0.1963 s/iter. ETA=0:00:02\n",
      "\u001b[32m[07/06 03:32:54 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:02:16.401972 (0.196545 s / iter per device, on 1 devices)\n",
      "\u001b[32m[07/06 03:32:54 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:32 (0.046731 s / iter per device, on 1 devices)\n",
      "\u001b[32m[07/06 03:32:54 d2.evaluation.sem_seg_evaluation]: \u001b[0mOrderedDict([('sem_seg', {'mIoU': 56.73016122708587, 'fwIoU': 84.32250106786894, 'IoU-Unlabeled': nan, 'IoU-Building': 81.33642727579495, 'IoU-Fence': 41.88404854680119, 'IoU-Pedestrian': 71.09721003303277, 'IoU-Pole': 44.976748900747396, 'IoU-Road': 94.92799923385024, 'IoU-SideWalk': 71.7089316503013, 'IoU-Vegetation': 80.53040286287113, 'IoU-Vehicles': 86.34138207675134, 'IoU-Wall': 32.0236780844832, 'IoU-TrafficSign': 58.407017364803885, 'IoU-Sky': 84.29985501380426, 'IoU-TrafficLight': 48.482926724524106, 'IoU-Terrain': 54.935790638522306, 'IoU-ConstructionVehicle': nan, 'IoU-workzone_object': nan, 'IoU-Detour': nan, 'mACC': 74.8323010450807, 'pACC': 91.06547140805176, 'ACC-Unlabeled': nan, 'ACC-Building': 96.67855394958005, 'ACC-Fence': 51.187572441368815, 'ACC-Pedestrian': 86.27566039994836, 'ACC-Pole': 54.283467306967715, 'ACC-Road': 96.7499613632782, 'ACC-SideWalk': 82.59501339371171, 'ACC-Vegetation': 84.46880248344027, 'ACC-Vehicles': 91.70853752290617, 'ACC-Wall': 51.95117439432529, 'ACC-TrafficSign': 64.29413605720174, 'ACC-Sky': 87.29132376072309, 'ACC-TrafficLight': 55.362228654552716, 'ACC-Terrain': 69.97348185804483, 'ACC-ConstructionVehicle': nan, 'ACC-workzone_object': nan, 'ACC-Detour': nan})])\n",
      "\u001b[32m[07/06 03:32:54 d2.engine.defaults]: \u001b[0mEvaluation results for cityscapes_rain_val in csv format:\n",
      "\u001b[32m[07/06 03:32:54 d2.evaluation.testing]: \u001b[0mcopypaste: Task: sem_seg\n",
      "\u001b[32m[07/06 03:32:54 d2.evaluation.testing]: \u001b[0mcopypaste: mIoU,fwIoU,mACC,pACC\n",
      "\u001b[32m[07/06 03:32:54 d2.evaluation.testing]: \u001b[0mcopypaste: 56.7302,84.3225,74.8323,91.0655\n"
     ]
    }
   ],
   "source": [
    "trainer_day = Detectron2Trainer('combined_clear_train', 'cityscapes_rain_val', output_folder='./output_day_clear_40k')\n",
    "trainer_day.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "57075e1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/06 03:32:54 d2.engine.defaults]: \u001b[0mModel:\n",
      "SemanticSegmentor(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (sem_seg_head): SemSegFPNHead(\n",
      "    (p2): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "    )\n",
      "    (p3): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (1): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "    )\n",
      "    (p4): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (1): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      (2): Conv2d(\n",
      "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (3): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "    )\n",
      "    (p5): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (1): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      (2): Conv2d(\n",
      "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (3): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      (4): Conv2d(\n",
      "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (5): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "    )\n",
      "    (predictor): Conv2d(128, 17, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/06 03:32:54 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(720, 720), max_size=2048, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[07/06 03:32:54 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[07/06 03:32:54 d2.data.common]: \u001b[0mSerializing 1176 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[07/06 03:32:54 d2.data.common]: \u001b[0mSerialized dataset takes 0.41 MiB\n",
      "Last checkpoint: model_final.pth\n",
      "\u001b[32m[07/06 03:32:55 d2.checkpoint.c2_model_loading]: \u001b[0mFollowing weights matched with model:\n",
      "| Names in Model                       | Names in Checkpoint                                                                                  | Shapes                                          |\n",
      "|:-------------------------------------|:-----------------------------------------------------------------------------------------------------|:------------------------------------------------|\n",
      "| backbone.bottom_up.res2.0.conv1.*    | backbone.bottom_up.res2.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,1,1)             |\n",
      "| backbone.bottom_up.res2.0.conv2.*    | backbone.bottom_up.res2.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |\n",
      "| backbone.bottom_up.res2.0.conv3.*    | backbone.bottom_up.res2.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res2.0.shortcut.* | backbone.bottom_up.res2.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res2.1.conv1.*    | backbone.bottom_up.res2.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |\n",
      "| backbone.bottom_up.res2.1.conv2.*    | backbone.bottom_up.res2.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |\n",
      "| backbone.bottom_up.res2.1.conv3.*    | backbone.bottom_up.res2.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res2.2.conv1.*    | backbone.bottom_up.res2.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |\n",
      "| backbone.bottom_up.res2.2.conv2.*    | backbone.bottom_up.res2.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |\n",
      "| backbone.bottom_up.res2.2.conv3.*    | backbone.bottom_up.res2.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res3.0.conv1.*    | backbone.bottom_up.res3.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,256,1,1)       |\n",
      "| backbone.bottom_up.res3.0.conv2.*    | backbone.bottom_up.res3.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.0.conv3.*    | backbone.bottom_up.res3.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res3.0.shortcut.* | backbone.bottom_up.res3.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (512,) (512,) (512,) (512,) (512,256,1,1)       |\n",
      "| backbone.bottom_up.res3.1.conv1.*    | backbone.bottom_up.res3.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |\n",
      "| backbone.bottom_up.res3.1.conv2.*    | backbone.bottom_up.res3.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.1.conv3.*    | backbone.bottom_up.res3.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res3.2.conv1.*    | backbone.bottom_up.res3.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |\n",
      "| backbone.bottom_up.res3.2.conv2.*    | backbone.bottom_up.res3.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.2.conv3.*    | backbone.bottom_up.res3.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res3.3.conv1.*    | backbone.bottom_up.res3.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |\n",
      "| backbone.bottom_up.res3.3.conv2.*    | backbone.bottom_up.res3.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.3.conv3.*    | backbone.bottom_up.res3.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res4.0.conv1.*    | backbone.bottom_up.res4.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,512,1,1)       |\n",
      "| backbone.bottom_up.res4.0.conv2.*    | backbone.bottom_up.res4.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.0.conv3.*    | backbone.bottom_up.res4.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.0.shortcut.* | backbone.bottom_up.res4.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (1024,) (1024,) (1024,) (1024,) (1024,512,1,1)  |\n",
      "| backbone.bottom_up.res4.1.conv1.*    | backbone.bottom_up.res4.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.1.conv2.*    | backbone.bottom_up.res4.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.1.conv3.*    | backbone.bottom_up.res4.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.2.conv1.*    | backbone.bottom_up.res4.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.2.conv2.*    | backbone.bottom_up.res4.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.2.conv3.*    | backbone.bottom_up.res4.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.3.conv1.*    | backbone.bottom_up.res4.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.3.conv2.*    | backbone.bottom_up.res4.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.3.conv3.*    | backbone.bottom_up.res4.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.4.conv1.*    | backbone.bottom_up.res4.4.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.4.conv2.*    | backbone.bottom_up.res4.4.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.4.conv3.*    | backbone.bottom_up.res4.4.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.5.conv1.*    | backbone.bottom_up.res4.5.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.5.conv2.*    | backbone.bottom_up.res4.5.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.5.conv3.*    | backbone.bottom_up.res4.5.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res5.0.conv1.*    | backbone.bottom_up.res5.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,1024,1,1)      |\n",
      "| backbone.bottom_up.res5.0.conv2.*    | backbone.bottom_up.res5.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |\n",
      "| backbone.bottom_up.res5.0.conv3.*    | backbone.bottom_up.res5.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
      "| backbone.bottom_up.res5.0.shortcut.* | backbone.bottom_up.res5.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (2048,) (2048,) (2048,) (2048,) (2048,1024,1,1) |\n",
      "| backbone.bottom_up.res5.1.conv1.*    | backbone.bottom_up.res5.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |\n",
      "| backbone.bottom_up.res5.1.conv2.*    | backbone.bottom_up.res5.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |\n",
      "| backbone.bottom_up.res5.1.conv3.*    | backbone.bottom_up.res5.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
      "| backbone.bottom_up.res5.2.conv1.*    | backbone.bottom_up.res5.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |\n",
      "| backbone.bottom_up.res5.2.conv2.*    | backbone.bottom_up.res5.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |\n",
      "| backbone.bottom_up.res5.2.conv3.*    | backbone.bottom_up.res5.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
      "| backbone.bottom_up.stem.conv1.*      | backbone.bottom_up.stem.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}      | (64,) (64,) (64,) (64,) (64,3,7,7)              |\n",
      "| backbone.fpn_lateral2.*              | backbone.fpn_lateral2.{bias,weight}                                                                  | (256,) (256,256,1,1)                            |\n",
      "| backbone.fpn_lateral3.*              | backbone.fpn_lateral3.{bias,weight}                                                                  | (256,) (256,512,1,1)                            |\n",
      "| backbone.fpn_lateral4.*              | backbone.fpn_lateral4.{bias,weight}                                                                  | (256,) (256,1024,1,1)                           |\n",
      "| backbone.fpn_lateral5.*              | backbone.fpn_lateral5.{bias,weight}                                                                  | (256,) (256,2048,1,1)                           |\n",
      "| backbone.fpn_output2.*               | backbone.fpn_output2.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| backbone.fpn_output3.*               | backbone.fpn_output3.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| backbone.fpn_output4.*               | backbone.fpn_output4.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| backbone.fpn_output5.*               | backbone.fpn_output5.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| sem_seg_head.p2.0.*                  | sem_seg_head.p2.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p3.0.*                  | sem_seg_head.p3.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p4.0.*                  | sem_seg_head.p4.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p4.2.*                  | sem_seg_head.p4.2.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,128,3,3)                     |\n",
      "| sem_seg_head.p5.0.*                  | sem_seg_head.p5.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p5.2.*                  | sem_seg_head.p5.2.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,128,3,3)                     |\n",
      "| sem_seg_head.p5.4.*                  | sem_seg_head.p5.4.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,128,3,3)                     |\n",
      "| sem_seg_head.predictor.*             | sem_seg_head.predictor.{bias,weight}                                                                 | (17,) (17,128,1,1)                              |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/06 03:32:55 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(720, 720), max_size=2048, sample_style='choice')]\n",
      "\u001b[32m[07/06 03:32:55 d2.data.common]: \u001b[0mSerializing 1780 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[07/06 03:32:55 d2.data.common]: \u001b[0mSerialized dataset takes 0.61 MiB\n",
      "\u001b[32m[07/06 03:32:55 d2.evaluation.evaluator]: \u001b[0mStart inference on 1780 batches\n",
      "\u001b[32m[07/06 03:32:56 d2.evaluation.evaluator]: \u001b[0mInference done 15/1780. Dataloading: 0.0019 s/iter. Inference: 0.0348 s/iter. Eval: 0.0436 s/iter. Total: 0.0804 s/iter. ETA=0:02:21\n",
      "\u001b[32m[07/06 03:33:01 d2.evaluation.evaluator]: \u001b[0mInference done 81/1780. Dataloading: 0.0021 s/iter. Inference: 0.0351 s/iter. Eval: 0.0396 s/iter. Total: 0.0768 s/iter. ETA=0:02:10\n",
      "\u001b[32m[07/06 03:33:06 d2.evaluation.evaluator]: \u001b[0mInference done 147/1780. Dataloading: 0.0021 s/iter. Inference: 0.0351 s/iter. Eval: 0.0391 s/iter. Total: 0.0764 s/iter. ETA=0:02:04\n",
      "\u001b[32m[07/06 03:33:12 d2.evaluation.evaluator]: \u001b[0mInference done 213/1780. Dataloading: 0.0021 s/iter. Inference: 0.0351 s/iter. Eval: 0.0390 s/iter. Total: 0.0764 s/iter. ETA=0:01:59\n",
      "\u001b[32m[07/06 03:33:17 d2.evaluation.evaluator]: \u001b[0mInference done 277/1780. Dataloading: 0.0021 s/iter. Inference: 0.0351 s/iter. Eval: 0.0395 s/iter. Total: 0.0768 s/iter. ETA=0:01:55\n",
      "\u001b[32m[07/06 03:33:22 d2.evaluation.evaluator]: \u001b[0mInference done 341/1780. Dataloading: 0.0022 s/iter. Inference: 0.0351 s/iter. Eval: 0.0399 s/iter. Total: 0.0773 s/iter. ETA=0:01:51\n",
      "\u001b[32m[07/06 03:33:27 d2.evaluation.evaluator]: \u001b[0mInference done 405/1780. Dataloading: 0.0022 s/iter. Inference: 0.0352 s/iter. Eval: 0.0401 s/iter. Total: 0.0775 s/iter. ETA=0:01:46\n",
      "\u001b[32m[07/06 03:33:32 d2.evaluation.evaluator]: \u001b[0mInference done 469/1780. Dataloading: 0.0022 s/iter. Inference: 0.0352 s/iter. Eval: 0.0402 s/iter. Total: 0.0777 s/iter. ETA=0:01:41\n",
      "\u001b[32m[07/06 03:33:37 d2.evaluation.evaluator]: \u001b[0mInference done 534/1780. Dataloading: 0.0022 s/iter. Inference: 0.0352 s/iter. Eval: 0.0402 s/iter. Total: 0.0777 s/iter. ETA=0:01:36\n",
      "\u001b[32m[07/06 03:33:42 d2.evaluation.evaluator]: \u001b[0mInference done 599/1780. Dataloading: 0.0022 s/iter. Inference: 0.0352 s/iter. Eval: 0.0402 s/iter. Total: 0.0777 s/iter. ETA=0:01:31\n",
      "\u001b[32m[07/06 03:33:47 d2.evaluation.evaluator]: \u001b[0mInference done 663/1780. Dataloading: 0.0022 s/iter. Inference: 0.0352 s/iter. Eval: 0.0402 s/iter. Total: 0.0777 s/iter. ETA=0:01:26\n",
      "\u001b[32m[07/06 03:33:52 d2.evaluation.evaluator]: \u001b[0mInference done 728/1780. Dataloading: 0.0022 s/iter. Inference: 0.0352 s/iter. Eval: 0.0403 s/iter. Total: 0.0777 s/iter. ETA=0:01:21\n",
      "\u001b[32m[07/06 03:33:57 d2.evaluation.evaluator]: \u001b[0mInference done 793/1780. Dataloading: 0.0022 s/iter. Inference: 0.0352 s/iter. Eval: 0.0402 s/iter. Total: 0.0777 s/iter. ETA=0:01:16\n",
      "\u001b[32m[07/06 03:34:02 d2.evaluation.evaluator]: \u001b[0mInference done 857/1780. Dataloading: 0.0022 s/iter. Inference: 0.0352 s/iter. Eval: 0.0402 s/iter. Total: 0.0778 s/iter. ETA=0:01:11\n",
      "\u001b[32m[07/06 03:34:07 d2.evaluation.evaluator]: \u001b[0mInference done 921/1780. Dataloading: 0.0022 s/iter. Inference: 0.0352 s/iter. Eval: 0.0403 s/iter. Total: 0.0778 s/iter. ETA=0:01:06\n",
      "\u001b[32m[07/06 03:34:12 d2.evaluation.evaluator]: \u001b[0mInference done 984/1780. Dataloading: 0.0022 s/iter. Inference: 0.0354 s/iter. Eval: 0.0403 s/iter. Total: 0.0779 s/iter. ETA=0:01:02\n",
      "\u001b[32m[07/06 03:34:17 d2.evaluation.evaluator]: \u001b[0mInference done 1049/1780. Dataloading: 0.0022 s/iter. Inference: 0.0354 s/iter. Eval: 0.0402 s/iter. Total: 0.0779 s/iter. ETA=0:00:56\n",
      "\u001b[32m[07/06 03:34:22 d2.evaluation.evaluator]: \u001b[0mInference done 1094/1780. Dataloading: 0.0022 s/iter. Inference: 0.0355 s/iter. Eval: 0.0416 s/iter. Total: 0.0794 s/iter. ETA=0:00:54\n",
      "\u001b[32m[07/06 03:34:27 d2.evaluation.evaluator]: \u001b[0mInference done 1120/1780. Dataloading: 0.0022 s/iter. Inference: 0.0357 s/iter. Eval: 0.0441 s/iter. Total: 0.0821 s/iter. ETA=0:00:54\n",
      "\u001b[32m[07/06 03:34:32 d2.evaluation.evaluator]: \u001b[0mInference done 1146/1780. Dataloading: 0.0022 s/iter. Inference: 0.0360 s/iter. Eval: 0.0465 s/iter. Total: 0.0847 s/iter. ETA=0:00:53\n",
      "\u001b[32m[07/06 03:34:37 d2.evaluation.evaluator]: \u001b[0mInference done 1172/1780. Dataloading: 0.0022 s/iter. Inference: 0.0362 s/iter. Eval: 0.0487 s/iter. Total: 0.0872 s/iter. ETA=0:00:53\n",
      "\u001b[32m[07/06 03:34:43 d2.evaluation.evaluator]: \u001b[0mInference done 1199/1780. Dataloading: 0.0022 s/iter. Inference: 0.0365 s/iter. Eval: 0.0508 s/iter. Total: 0.0895 s/iter. ETA=0:00:52\n",
      "\u001b[32m[07/06 03:34:48 d2.evaluation.evaluator]: \u001b[0mInference done 1226/1780. Dataloading: 0.0022 s/iter. Inference: 0.0367 s/iter. Eval: 0.0527 s/iter. Total: 0.0917 s/iter. ETA=0:00:50\n",
      "\u001b[32m[07/06 03:34:53 d2.evaluation.evaluator]: \u001b[0mInference done 1253/1780. Dataloading: 0.0022 s/iter. Inference: 0.0369 s/iter. Eval: 0.0547 s/iter. Total: 0.0939 s/iter. ETA=0:00:49\n",
      "\u001b[32m[07/06 03:34:58 d2.evaluation.evaluator]: \u001b[0mInference done 1277/1780. Dataloading: 0.0022 s/iter. Inference: 0.0371 s/iter. Eval: 0.0567 s/iter. Total: 0.0961 s/iter. ETA=0:00:48\n",
      "\u001b[32m[07/06 03:35:03 d2.evaluation.evaluator]: \u001b[0mInference done 1302/1780. Dataloading: 0.0022 s/iter. Inference: 0.0373 s/iter. Eval: 0.0587 s/iter. Total: 0.0982 s/iter. ETA=0:00:46\n",
      "\u001b[32m[07/06 03:35:08 d2.evaluation.evaluator]: \u001b[0mInference done 1328/1780. Dataloading: 0.0022 s/iter. Inference: 0.0375 s/iter. Eval: 0.0605 s/iter. Total: 0.1002 s/iter. ETA=0:00:45\n",
      "\u001b[32m[07/06 03:35:13 d2.evaluation.evaluator]: \u001b[0mInference done 1353/1780. Dataloading: 0.0022 s/iter. Inference: 0.0376 s/iter. Eval: 0.0622 s/iter. Total: 0.1021 s/iter. ETA=0:00:43\n",
      "\u001b[32m[07/06 03:35:18 d2.evaluation.evaluator]: \u001b[0mInference done 1378/1780. Dataloading: 0.0022 s/iter. Inference: 0.0378 s/iter. Eval: 0.0638 s/iter. Total: 0.1039 s/iter. ETA=0:00:41\n",
      "\u001b[32m[07/06 03:35:23 d2.evaluation.evaluator]: \u001b[0mInference done 1403/1780. Dataloading: 0.0022 s/iter. Inference: 0.0380 s/iter. Eval: 0.0655 s/iter. Total: 0.1057 s/iter. ETA=0:00:39\n",
      "\u001b[32m[07/06 03:35:29 d2.evaluation.evaluator]: \u001b[0mInference done 1428/1780. Dataloading: 0.0022 s/iter. Inference: 0.0381 s/iter. Eval: 0.0671 s/iter. Total: 0.1075 s/iter. ETA=0:00:37\n",
      "\u001b[32m[07/06 03:35:34 d2.evaluation.evaluator]: \u001b[0mInference done 1454/1780. Dataloading: 0.0022 s/iter. Inference: 0.0383 s/iter. Eval: 0.0685 s/iter. Total: 0.1091 s/iter. ETA=0:00:35\n",
      "\u001b[32m[07/06 03:35:39 d2.evaluation.evaluator]: \u001b[0mInference done 1479/1780. Dataloading: 0.0022 s/iter. Inference: 0.0384 s/iter. Eval: 0.0700 s/iter. Total: 0.1107 s/iter. ETA=0:00:33\n",
      "\u001b[32m[07/06 03:35:44 d2.evaluation.evaluator]: \u001b[0mInference done 1505/1780. Dataloading: 0.0022 s/iter. Inference: 0.0386 s/iter. Eval: 0.0714 s/iter. Total: 0.1122 s/iter. ETA=0:00:30\n",
      "\u001b[32m[07/06 03:35:49 d2.evaluation.evaluator]: \u001b[0mInference done 1531/1780. Dataloading: 0.0022 s/iter. Inference: 0.0387 s/iter. Eval: 0.0727 s/iter. Total: 0.1137 s/iter. ETA=0:00:28\n",
      "\u001b[32m[07/06 03:35:54 d2.evaluation.evaluator]: \u001b[0mInference done 1557/1780. Dataloading: 0.0022 s/iter. Inference: 0.0389 s/iter. Eval: 0.0740 s/iter. Total: 0.1151 s/iter. ETA=0:00:25\n",
      "\u001b[32m[07/06 03:35:59 d2.evaluation.evaluator]: \u001b[0mInference done 1582/1780. Dataloading: 0.0022 s/iter. Inference: 0.0390 s/iter. Eval: 0.0753 s/iter. Total: 0.1165 s/iter. ETA=0:00:23\n",
      "\u001b[32m[07/06 03:36:04 d2.evaluation.evaluator]: \u001b[0mInference done 1607/1780. Dataloading: 0.0022 s/iter. Inference: 0.0391 s/iter. Eval: 0.0765 s/iter. Total: 0.1179 s/iter. ETA=0:00:20\n",
      "\u001b[32m[07/06 03:36:10 d2.evaluation.evaluator]: \u001b[0mInference done 1632/1780. Dataloading: 0.0022 s/iter. Inference: 0.0392 s/iter. Eval: 0.0777 s/iter. Total: 0.1192 s/iter. ETA=0:00:17\n",
      "\u001b[32m[07/06 03:36:15 d2.evaluation.evaluator]: \u001b[0mInference done 1657/1780. Dataloading: 0.0022 s/iter. Inference: 0.0393 s/iter. Eval: 0.0788 s/iter. Total: 0.1205 s/iter. ETA=0:00:14\n",
      "\u001b[32m[07/06 03:36:20 d2.evaluation.evaluator]: \u001b[0mInference done 1682/1780. Dataloading: 0.0022 s/iter. Inference: 0.0394 s/iter. Eval: 0.0800 s/iter. Total: 0.1218 s/iter. ETA=0:00:11\n",
      "\u001b[32m[07/06 03:36:25 d2.evaluation.evaluator]: \u001b[0mInference done 1707/1780. Dataloading: 0.0022 s/iter. Inference: 0.0396 s/iter. Eval: 0.0812 s/iter. Total: 0.1230 s/iter. ETA=0:00:08\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/06 03:36:30 d2.evaluation.evaluator]: \u001b[0mInference done 1733/1780. Dataloading: 0.0022 s/iter. Inference: 0.0397 s/iter. Eval: 0.0822 s/iter. Total: 0.1242 s/iter. ETA=0:00:05\n",
      "\u001b[32m[07/06 03:36:35 d2.evaluation.evaluator]: \u001b[0mInference done 1758/1780. Dataloading: 0.0022 s/iter. Inference: 0.0398 s/iter. Eval: 0.0832 s/iter. Total: 0.1253 s/iter. ETA=0:00:02\n",
      "\u001b[32m[07/06 03:36:40 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:03:44.272093 (0.126350 s / iter per device, on 1 devices)\n",
      "\u001b[32m[07/06 03:36:40 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:01:10 (0.039852 s / iter per device, on 1 devices)\n",
      "\u001b[32m[07/06 03:36:40 d2.evaluation.sem_seg_evaluation]: \u001b[0mOrderedDict([('sem_seg', {'mIoU': 63.502572210261796, 'fwIoU': 85.13722649872068, 'IoU-Unlabeled': nan, 'IoU-Building': 81.61962867325423, 'IoU-Fence': 36.699013485367026, 'IoU-Pedestrian': 69.24265979471905, 'IoU-Pole': 45.165703100424864, 'IoU-Road': 95.8009276481106, 'IoU-SideWalk': 73.03533542494377, 'IoU-Vegetation': 78.76527504634268, 'IoU-Vehicles': 85.8430594304369, 'IoU-Wall': 48.83640161856003, 'IoU-TrafficSign': 56.637425559958, 'IoU-Sky': 86.58213623829513, 'IoU-TrafficLight': 56.57270469913951, 'IoU-Terrain': 53.58353258641891, 'IoU-ConstructionVehicle': 82.4296637657435, 'IoU-workzone_object': 65.22768829247455, 'IoU-Detour': 0.0, 'mACC': 71.95826840673026, 'pACC': 91.57676985707694, 'ACC-Unlabeled': nan, 'ACC-Building': 96.70139061412996, 'ACC-Fence': 45.30573366481263, 'ACC-Pedestrian': 85.90006021590443, 'ACC-Pole': 52.9416978281917, 'ACC-Road': 97.22617505236728, 'ACC-SideWalk': 84.73103812478769, 'ACC-Vegetation': 83.73017994233393, 'ACC-Vehicles': 90.95464987618442, 'ACC-Wall': 69.09188904354981, 'ACC-TrafficSign': 63.693736558876616, 'ACC-Sky': 88.34198947285063, 'ACC-TrafficLight': 64.76792483769475, 'ACC-Terrain': 66.4906443336448, 'ACC-ConstructionVehicle': 86.8761766796154, 'ACC-workzone_object': 74.57900826273995, 'ACC-Detour': 0.0})])\n",
      "\u001b[32m[07/06 03:36:40 d2.engine.defaults]: \u001b[0mEvaluation results for combined_rain_val in csv format:\n",
      "\u001b[32m[07/06 03:36:40 d2.evaluation.testing]: \u001b[0mcopypaste: Task: sem_seg\n",
      "\u001b[32m[07/06 03:36:40 d2.evaluation.testing]: \u001b[0mcopypaste: mIoU,fwIoU,mACC,pACC\n",
      "\u001b[32m[07/06 03:36:40 d2.evaluation.testing]: \u001b[0mcopypaste: 63.5026,85.1372,71.9583,91.5768\n"
     ]
    }
   ],
   "source": [
    "trainer_day = Detectron2Trainer('combined_clear_train', 'combined_rain_val', output_folder='./output_day_clear_40k')\n",
    "trainer_day.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d2cc0423",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/06 22:35:51 d2.engine.defaults]: \u001b[0mModel:\n",
      "SemanticSegmentor(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (sem_seg_head): SemSegFPNHead(\n",
      "    (p2): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "    )\n",
      "    (p3): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (1): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "    )\n",
      "    (p4): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (1): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      (2): Conv2d(\n",
      "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (3): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "    )\n",
      "    (p5): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (1): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      (2): Conv2d(\n",
      "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (3): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      (4): Conv2d(\n",
      "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (5): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "    )\n",
      "    (predictor): Conv2d(128, 17, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/06 22:35:51 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(720, 720), max_size=2048, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[07/06 22:35:51 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[07/06 22:35:51 d2.data.common]: \u001b[0mSerializing 3353 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[07/06 22:35:51 d2.data.common]: \u001b[0mSerialized dataset takes 1.18 MiB\n",
      "Last checkpoint: model_final.pth\n",
      "\u001b[32m[07/06 22:35:52 d2.checkpoint.c2_model_loading]: \u001b[0mFollowing weights matched with model:\n",
      "| Names in Model                       | Names in Checkpoint                                                                                  | Shapes                                          |\n",
      "|:-------------------------------------|:-----------------------------------------------------------------------------------------------------|:------------------------------------------------|\n",
      "| backbone.bottom_up.res2.0.conv1.*    | backbone.bottom_up.res2.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,1,1)             |\n",
      "| backbone.bottom_up.res2.0.conv2.*    | backbone.bottom_up.res2.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |\n",
      "| backbone.bottom_up.res2.0.conv3.*    | backbone.bottom_up.res2.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res2.0.shortcut.* | backbone.bottom_up.res2.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res2.1.conv1.*    | backbone.bottom_up.res2.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |\n",
      "| backbone.bottom_up.res2.1.conv2.*    | backbone.bottom_up.res2.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |\n",
      "| backbone.bottom_up.res2.1.conv3.*    | backbone.bottom_up.res2.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res2.2.conv1.*    | backbone.bottom_up.res2.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |\n",
      "| backbone.bottom_up.res2.2.conv2.*    | backbone.bottom_up.res2.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |\n",
      "| backbone.bottom_up.res2.2.conv3.*    | backbone.bottom_up.res2.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res3.0.conv1.*    | backbone.bottom_up.res3.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,256,1,1)       |\n",
      "| backbone.bottom_up.res3.0.conv2.*    | backbone.bottom_up.res3.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.0.conv3.*    | backbone.bottom_up.res3.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res3.0.shortcut.* | backbone.bottom_up.res3.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (512,) (512,) (512,) (512,) (512,256,1,1)       |\n",
      "| backbone.bottom_up.res3.1.conv1.*    | backbone.bottom_up.res3.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |\n",
      "| backbone.bottom_up.res3.1.conv2.*    | backbone.bottom_up.res3.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.1.conv3.*    | backbone.bottom_up.res3.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res3.2.conv1.*    | backbone.bottom_up.res3.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |\n",
      "| backbone.bottom_up.res3.2.conv2.*    | backbone.bottom_up.res3.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.2.conv3.*    | backbone.bottom_up.res3.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res3.3.conv1.*    | backbone.bottom_up.res3.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |\n",
      "| backbone.bottom_up.res3.3.conv2.*    | backbone.bottom_up.res3.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.3.conv3.*    | backbone.bottom_up.res3.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res4.0.conv1.*    | backbone.bottom_up.res4.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,512,1,1)       |\n",
      "| backbone.bottom_up.res4.0.conv2.*    | backbone.bottom_up.res4.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.0.conv3.*    | backbone.bottom_up.res4.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.0.shortcut.* | backbone.bottom_up.res4.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (1024,) (1024,) (1024,) (1024,) (1024,512,1,1)  |\n",
      "| backbone.bottom_up.res4.1.conv1.*    | backbone.bottom_up.res4.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.1.conv2.*    | backbone.bottom_up.res4.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.1.conv3.*    | backbone.bottom_up.res4.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.2.conv1.*    | backbone.bottom_up.res4.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.2.conv2.*    | backbone.bottom_up.res4.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.2.conv3.*    | backbone.bottom_up.res4.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.3.conv1.*    | backbone.bottom_up.res4.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.3.conv2.*    | backbone.bottom_up.res4.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.3.conv3.*    | backbone.bottom_up.res4.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.4.conv1.*    | backbone.bottom_up.res4.4.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.4.conv2.*    | backbone.bottom_up.res4.4.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.4.conv3.*    | backbone.bottom_up.res4.4.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.5.conv1.*    | backbone.bottom_up.res4.5.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.5.conv2.*    | backbone.bottom_up.res4.5.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.5.conv3.*    | backbone.bottom_up.res4.5.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res5.0.conv1.*    | backbone.bottom_up.res5.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,1024,1,1)      |\n",
      "| backbone.bottom_up.res5.0.conv2.*    | backbone.bottom_up.res5.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |\n",
      "| backbone.bottom_up.res5.0.conv3.*    | backbone.bottom_up.res5.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
      "| backbone.bottom_up.res5.0.shortcut.* | backbone.bottom_up.res5.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (2048,) (2048,) (2048,) (2048,) (2048,1024,1,1) |\n",
      "| backbone.bottom_up.res5.1.conv1.*    | backbone.bottom_up.res5.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |\n",
      "| backbone.bottom_up.res5.1.conv2.*    | backbone.bottom_up.res5.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |\n",
      "| backbone.bottom_up.res5.1.conv3.*    | backbone.bottom_up.res5.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
      "| backbone.bottom_up.res5.2.conv1.*    | backbone.bottom_up.res5.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |\n",
      "| backbone.bottom_up.res5.2.conv2.*    | backbone.bottom_up.res5.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |\n",
      "| backbone.bottom_up.res5.2.conv3.*    | backbone.bottom_up.res5.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
      "| backbone.bottom_up.stem.conv1.*      | backbone.bottom_up.stem.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}      | (64,) (64,) (64,) (64,) (64,3,7,7)              |\n",
      "| backbone.fpn_lateral2.*              | backbone.fpn_lateral2.{bias,weight}                                                                  | (256,) (256,256,1,1)                            |\n",
      "| backbone.fpn_lateral3.*              | backbone.fpn_lateral3.{bias,weight}                                                                  | (256,) (256,512,1,1)                            |\n",
      "| backbone.fpn_lateral4.*              | backbone.fpn_lateral4.{bias,weight}                                                                  | (256,) (256,1024,1,1)                           |\n",
      "| backbone.fpn_lateral5.*              | backbone.fpn_lateral5.{bias,weight}                                                                  | (256,) (256,2048,1,1)                           |\n",
      "| backbone.fpn_output2.*               | backbone.fpn_output2.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| backbone.fpn_output3.*               | backbone.fpn_output3.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| backbone.fpn_output4.*               | backbone.fpn_output4.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| backbone.fpn_output5.*               | backbone.fpn_output5.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| sem_seg_head.p2.0.*                  | sem_seg_head.p2.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p3.0.*                  | sem_seg_head.p3.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p4.0.*                  | sem_seg_head.p4.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p4.2.*                  | sem_seg_head.p4.2.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,128,3,3)                     |\n",
      "| sem_seg_head.p5.0.*                  | sem_seg_head.p5.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p5.2.*                  | sem_seg_head.p5.2.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,128,3,3)                     |\n",
      "| sem_seg_head.p5.4.*                  | sem_seg_head.p5.4.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,128,3,3)                     |\n",
      "| sem_seg_head.predictor.*             | sem_seg_head.predictor.{bias,weight}                                                                 | (17,) (17,128,1,1)                              |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/06 22:35:52 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(720, 720), max_size=2048, sample_style='choice')]\n",
      "\u001b[32m[07/06 22:35:52 d2.data.common]: \u001b[0mSerializing 7914 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[07/06 22:35:52 d2.data.common]: \u001b[0mSerialized dataset takes 2.77 MiB\n",
      "\u001b[32m[07/06 22:35:52 d2.evaluation.evaluator]: \u001b[0mStart inference on 7914 batches\n",
      "\u001b[32m[07/06 22:35:55 d2.evaluation.evaluator]: \u001b[0mInference done 38/7914. Dataloading: 0.0022 s/iter. Inference: 0.0351 s/iter. Eval: 0.0415 s/iter. Total: 0.0789 s/iter. ETA=0:10:21\n",
      "\u001b[32m[07/06 22:36:00 d2.evaluation.evaluator]: \u001b[0mInference done 102/7914. Dataloading: 0.0022 s/iter. Inference: 0.0352 s/iter. Eval: 0.0409 s/iter. Total: 0.0784 s/iter. ETA=0:10:12\n",
      "\u001b[32m[07/06 22:36:05 d2.evaluation.evaluator]: \u001b[0mInference done 169/7914. Dataloading: 0.0022 s/iter. Inference: 0.0352 s/iter. Eval: 0.0395 s/iter. Total: 0.0769 s/iter. ETA=0:09:55\n",
      "\u001b[32m[07/06 22:36:10 d2.evaluation.evaluator]: \u001b[0mInference done 237/7914. Dataloading: 0.0022 s/iter. Inference: 0.0352 s/iter. Eval: 0.0387 s/iter. Total: 0.0762 s/iter. ETA=0:09:45\n",
      "\u001b[32m[07/06 22:36:15 d2.evaluation.evaluator]: \u001b[0mInference done 304/7914. Dataloading: 0.0022 s/iter. Inference: 0.0355 s/iter. Eval: 0.0381 s/iter. Total: 0.0760 s/iter. ETA=0:09:38\n",
      "\u001b[32m[07/06 22:36:20 d2.evaluation.evaluator]: \u001b[0mInference done 370/7914. Dataloading: 0.0022 s/iter. Inference: 0.0355 s/iter. Eval: 0.0382 s/iter. Total: 0.0760 s/iter. ETA=0:09:33\n",
      "\u001b[32m[07/06 22:36:25 d2.evaluation.evaluator]: \u001b[0mInference done 437/7914. Dataloading: 0.0022 s/iter. Inference: 0.0355 s/iter. Eval: 0.0381 s/iter. Total: 0.0759 s/iter. ETA=0:09:27\n",
      "\u001b[32m[07/06 22:36:30 d2.evaluation.evaluator]: \u001b[0mInference done 503/7914. Dataloading: 0.0022 s/iter. Inference: 0.0355 s/iter. Eval: 0.0381 s/iter. Total: 0.0759 s/iter. ETA=0:09:22\n",
      "\u001b[32m[07/06 22:36:35 d2.evaluation.evaluator]: \u001b[0mInference done 569/7914. Dataloading: 0.0022 s/iter. Inference: 0.0355 s/iter. Eval: 0.0382 s/iter. Total: 0.0760 s/iter. ETA=0:09:18\n",
      "\u001b[32m[07/06 22:36:41 d2.evaluation.evaluator]: \u001b[0mInference done 636/7914. Dataloading: 0.0022 s/iter. Inference: 0.0354 s/iter. Eval: 0.0382 s/iter. Total: 0.0760 s/iter. ETA=0:09:12\n",
      "\u001b[32m[07/06 22:36:46 d2.evaluation.evaluator]: \u001b[0mInference done 702/7914. Dataloading: 0.0022 s/iter. Inference: 0.0354 s/iter. Eval: 0.0383 s/iter. Total: 0.0760 s/iter. ETA=0:09:08\n",
      "\u001b[32m[07/06 22:36:51 d2.evaluation.evaluator]: \u001b[0mInference done 770/7914. Dataloading: 0.0022 s/iter. Inference: 0.0354 s/iter. Eval: 0.0381 s/iter. Total: 0.0759 s/iter. ETA=0:09:02\n",
      "\u001b[32m[07/06 22:36:56 d2.evaluation.evaluator]: \u001b[0mInference done 836/7914. Dataloading: 0.0022 s/iter. Inference: 0.0355 s/iter. Eval: 0.0381 s/iter. Total: 0.0759 s/iter. ETA=0:08:57\n",
      "\u001b[32m[07/06 22:37:01 d2.evaluation.evaluator]: \u001b[0mInference done 903/7914. Dataloading: 0.0022 s/iter. Inference: 0.0355 s/iter. Eval: 0.0381 s/iter. Total: 0.0759 s/iter. ETA=0:08:51\n",
      "\u001b[32m[07/06 22:37:06 d2.evaluation.evaluator]: \u001b[0mInference done 970/7914. Dataloading: 0.0022 s/iter. Inference: 0.0355 s/iter. Eval: 0.0380 s/iter. Total: 0.0758 s/iter. ETA=0:08:46\n",
      "\u001b[32m[07/06 22:37:11 d2.evaluation.evaluator]: \u001b[0mInference done 1037/7914. Dataloading: 0.0022 s/iter. Inference: 0.0355 s/iter. Eval: 0.0380 s/iter. Total: 0.0758 s/iter. ETA=0:08:41\n",
      "\u001b[32m[07/06 22:37:16 d2.evaluation.evaluator]: \u001b[0mInference done 1105/7914. Dataloading: 0.0022 s/iter. Inference: 0.0355 s/iter. Eval: 0.0379 s/iter. Total: 0.0757 s/iter. ETA=0:08:35\n",
      "\u001b[32m[07/06 22:37:21 d2.evaluation.evaluator]: \u001b[0mInference done 1173/7914. Dataloading: 0.0022 s/iter. Inference: 0.0355 s/iter. Eval: 0.0378 s/iter. Total: 0.0756 s/iter. ETA=0:08:29\n",
      "\u001b[32m[07/06 22:37:26 d2.evaluation.evaluator]: \u001b[0mInference done 1239/7914. Dataloading: 0.0022 s/iter. Inference: 0.0355 s/iter. Eval: 0.0378 s/iter. Total: 0.0756 s/iter. ETA=0:08:24\n",
      "\u001b[32m[07/06 22:37:31 d2.evaluation.evaluator]: \u001b[0mInference done 1303/7914. Dataloading: 0.0022 s/iter. Inference: 0.0355 s/iter. Eval: 0.0379 s/iter. Total: 0.0757 s/iter. ETA=0:08:20\n",
      "\u001b[32m[07/06 22:37:36 d2.evaluation.evaluator]: \u001b[0mInference done 1369/7914. Dataloading: 0.0022 s/iter. Inference: 0.0355 s/iter. Eval: 0.0379 s/iter. Total: 0.0758 s/iter. ETA=0:08:15\n",
      "\u001b[32m[07/06 22:37:41 d2.evaluation.evaluator]: \u001b[0mInference done 1434/7914. Dataloading: 0.0022 s/iter. Inference: 0.0355 s/iter. Eval: 0.0380 s/iter. Total: 0.0759 s/iter. ETA=0:08:11\n",
      "\u001b[32m[07/06 22:37:46 d2.evaluation.evaluator]: \u001b[0mInference done 1497/7914. Dataloading: 0.0022 s/iter. Inference: 0.0355 s/iter. Eval: 0.0382 s/iter. Total: 0.0760 s/iter. ETA=0:08:07\n",
      "\u001b[32m[07/06 22:37:51 d2.evaluation.evaluator]: \u001b[0mInference done 1562/7914. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0383 s/iter. Total: 0.0761 s/iter. ETA=0:08:03\n",
      "\u001b[32m[07/06 22:37:56 d2.evaluation.evaluator]: \u001b[0mInference done 1626/7914. Dataloading: 0.0022 s/iter. Inference: 0.0355 s/iter. Eval: 0.0384 s/iter. Total: 0.0762 s/iter. ETA=0:07:59\n",
      "\u001b[32m[07/06 22:38:01 d2.evaluation.evaluator]: \u001b[0mInference done 1690/7914. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0384 s/iter. Total: 0.0763 s/iter. ETA=0:07:54\n",
      "\u001b[32m[07/06 22:38:06 d2.evaluation.evaluator]: \u001b[0mInference done 1754/7914. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0385 s/iter. Total: 0.0763 s/iter. ETA=0:07:50\n",
      "\u001b[32m[07/06 22:38:11 d2.evaluation.evaluator]: \u001b[0mInference done 1819/7914. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0386 s/iter. Total: 0.0764 s/iter. ETA=0:07:45\n",
      "\u001b[32m[07/06 22:38:16 d2.evaluation.evaluator]: \u001b[0mInference done 1885/7914. Dataloading: 0.0022 s/iter. Inference: 0.0355 s/iter. Eval: 0.0386 s/iter. Total: 0.0764 s/iter. ETA=0:07:40\n",
      "\u001b[32m[07/06 22:38:21 d2.evaluation.evaluator]: \u001b[0mInference done 1950/7914. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0386 s/iter. Total: 0.0764 s/iter. ETA=0:07:35\n",
      "\u001b[32m[07/06 22:38:26 d2.evaluation.evaluator]: \u001b[0mInference done 2016/7914. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0386 s/iter. Total: 0.0764 s/iter. ETA=0:07:30\n",
      "\u001b[32m[07/06 22:38:31 d2.evaluation.evaluator]: \u001b[0mInference done 2082/7914. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0386 s/iter. Total: 0.0764 s/iter. ETA=0:07:25\n",
      "\u001b[32m[07/06 22:38:36 d2.evaluation.evaluator]: \u001b[0mInference done 2148/7914. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0386 s/iter. Total: 0.0764 s/iter. ETA=0:07:20\n",
      "\u001b[32m[07/06 22:38:41 d2.evaluation.evaluator]: \u001b[0mInference done 2214/7914. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0386 s/iter. Total: 0.0764 s/iter. ETA=0:07:15\n",
      "\u001b[32m[07/06 22:38:47 d2.evaluation.evaluator]: \u001b[0mInference done 2280/7914. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0386 s/iter. Total: 0.0764 s/iter. ETA=0:07:10\n",
      "\u001b[32m[07/06 22:38:52 d2.evaluation.evaluator]: \u001b[0mInference done 2347/7914. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0386 s/iter. Total: 0.0764 s/iter. ETA=0:07:05\n",
      "\u001b[32m[07/06 22:38:57 d2.evaluation.evaluator]: \u001b[0mInference done 2413/7914. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0386 s/iter. Total: 0.0764 s/iter. ETA=0:07:00\n",
      "\u001b[32m[07/06 22:39:02 d2.evaluation.evaluator]: \u001b[0mInference done 2480/7914. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0385 s/iter. Total: 0.0764 s/iter. ETA=0:06:55\n",
      "\u001b[32m[07/06 22:39:07 d2.evaluation.evaluator]: \u001b[0mInference done 2545/7914. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0386 s/iter. Total: 0.0764 s/iter. ETA=0:06:50\n",
      "\u001b[32m[07/06 22:39:12 d2.evaluation.evaluator]: \u001b[0mInference done 2611/7914. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0386 s/iter. Total: 0.0764 s/iter. ETA=0:06:45\n",
      "\u001b[32m[07/06 22:39:17 d2.evaluation.evaluator]: \u001b[0mInference done 2677/7914. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0386 s/iter. Total: 0.0764 s/iter. ETA=0:06:40\n",
      "\u001b[32m[07/06 22:39:22 d2.evaluation.evaluator]: \u001b[0mInference done 2743/7914. Dataloading: 0.0022 s/iter. Inference: 0.0355 s/iter. Eval: 0.0386 s/iter. Total: 0.0764 s/iter. ETA=0:06:35\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/06 22:39:27 d2.evaluation.evaluator]: \u001b[0mInference done 2810/7914. Dataloading: 0.0022 s/iter. Inference: 0.0355 s/iter. Eval: 0.0385 s/iter. Total: 0.0764 s/iter. ETA=0:06:29\n",
      "\u001b[32m[07/06 22:39:32 d2.evaluation.evaluator]: \u001b[0mInference done 2874/7914. Dataloading: 0.0022 s/iter. Inference: 0.0355 s/iter. Eval: 0.0386 s/iter. Total: 0.0764 s/iter. ETA=0:06:25\n",
      "\u001b[32m[07/06 22:39:37 d2.evaluation.evaluator]: \u001b[0mInference done 2939/7914. Dataloading: 0.0022 s/iter. Inference: 0.0356 s/iter. Eval: 0.0386 s/iter. Total: 0.0765 s/iter. ETA=0:06:20\n",
      "\u001b[32m[07/06 22:39:42 d2.evaluation.evaluator]: \u001b[0mInference done 3004/7914. Dataloading: 0.0022 s/iter. Inference: 0.0356 s/iter. Eval: 0.0386 s/iter. Total: 0.0765 s/iter. ETA=0:06:15\n",
      "\u001b[32m[07/06 22:39:47 d2.evaluation.evaluator]: \u001b[0mInference done 3069/7914. Dataloading: 0.0022 s/iter. Inference: 0.0356 s/iter. Eval: 0.0386 s/iter. Total: 0.0765 s/iter. ETA=0:06:10\n",
      "\u001b[32m[07/06 22:39:52 d2.evaluation.evaluator]: \u001b[0mInference done 3134/7914. Dataloading: 0.0022 s/iter. Inference: 0.0356 s/iter. Eval: 0.0387 s/iter. Total: 0.0765 s/iter. ETA=0:06:05\n",
      "\u001b[32m[07/06 22:39:57 d2.evaluation.evaluator]: \u001b[0mInference done 3200/7914. Dataloading: 0.0022 s/iter. Inference: 0.0356 s/iter. Eval: 0.0387 s/iter. Total: 0.0765 s/iter. ETA=0:06:00\n",
      "\u001b[32m[07/06 22:40:02 d2.evaluation.evaluator]: \u001b[0mInference done 3266/7914. Dataloading: 0.0022 s/iter. Inference: 0.0356 s/iter. Eval: 0.0386 s/iter. Total: 0.0765 s/iter. ETA=0:05:55\n",
      "\u001b[32m[07/06 22:40:07 d2.evaluation.evaluator]: \u001b[0mInference done 3331/7914. Dataloading: 0.0022 s/iter. Inference: 0.0355 s/iter. Eval: 0.0387 s/iter. Total: 0.0765 s/iter. ETA=0:05:50\n",
      "\u001b[32m[07/06 22:40:12 d2.evaluation.evaluator]: \u001b[0mInference done 3397/7914. Dataloading: 0.0022 s/iter. Inference: 0.0356 s/iter. Eval: 0.0387 s/iter. Total: 0.0765 s/iter. ETA=0:05:45\n",
      "\u001b[32m[07/06 22:40:17 d2.evaluation.evaluator]: \u001b[0mInference done 3463/7914. Dataloading: 0.0022 s/iter. Inference: 0.0355 s/iter. Eval: 0.0386 s/iter. Total: 0.0765 s/iter. ETA=0:05:40\n",
      "\u001b[32m[07/06 22:40:22 d2.evaluation.evaluator]: \u001b[0mInference done 3530/7914. Dataloading: 0.0022 s/iter. Inference: 0.0355 s/iter. Eval: 0.0386 s/iter. Total: 0.0765 s/iter. ETA=0:05:35\n",
      "\u001b[32m[07/06 22:40:27 d2.evaluation.evaluator]: \u001b[0mInference done 3595/7914. Dataloading: 0.0022 s/iter. Inference: 0.0355 s/iter. Eval: 0.0387 s/iter. Total: 0.0765 s/iter. ETA=0:05:30\n",
      "\u001b[32m[07/06 22:40:32 d2.evaluation.evaluator]: \u001b[0mInference done 3662/7914. Dataloading: 0.0022 s/iter. Inference: 0.0355 s/iter. Eval: 0.0386 s/iter. Total: 0.0765 s/iter. ETA=0:05:25\n",
      "\u001b[32m[07/06 22:40:37 d2.evaluation.evaluator]: \u001b[0mInference done 3725/7914. Dataloading: 0.0022 s/iter. Inference: 0.0355 s/iter. Eval: 0.0387 s/iter. Total: 0.0765 s/iter. ETA=0:05:20\n",
      "\u001b[32m[07/06 22:40:42 d2.evaluation.evaluator]: \u001b[0mInference done 3791/7914. Dataloading: 0.0022 s/iter. Inference: 0.0355 s/iter. Eval: 0.0387 s/iter. Total: 0.0765 s/iter. ETA=0:05:15\n",
      "\u001b[32m[07/06 22:40:47 d2.evaluation.evaluator]: \u001b[0mInference done 3856/7914. Dataloading: 0.0022 s/iter. Inference: 0.0355 s/iter. Eval: 0.0387 s/iter. Total: 0.0765 s/iter. ETA=0:05:10\n",
      "\u001b[32m[07/06 22:40:52 d2.evaluation.evaluator]: \u001b[0mInference done 3920/7914. Dataloading: 0.0022 s/iter. Inference: 0.0355 s/iter. Eval: 0.0387 s/iter. Total: 0.0766 s/iter. ETA=0:05:05\n",
      "\u001b[32m[07/06 22:40:57 d2.evaluation.evaluator]: \u001b[0mInference done 3986/7914. Dataloading: 0.0022 s/iter. Inference: 0.0356 s/iter. Eval: 0.0387 s/iter. Total: 0.0766 s/iter. ETA=0:05:00\n",
      "\u001b[32m[07/06 22:41:02 d2.evaluation.evaluator]: \u001b[0mInference done 4053/7914. Dataloading: 0.0022 s/iter. Inference: 0.0356 s/iter. Eval: 0.0387 s/iter. Total: 0.0765 s/iter. ETA=0:04:55\n",
      "\u001b[32m[07/06 22:41:07 d2.evaluation.evaluator]: \u001b[0mInference done 4120/7914. Dataloading: 0.0022 s/iter. Inference: 0.0356 s/iter. Eval: 0.0387 s/iter. Total: 0.0765 s/iter. ETA=0:04:50\n",
      "\u001b[32m[07/06 22:41:13 d2.evaluation.evaluator]: \u001b[0mInference done 4187/7914. Dataloading: 0.0022 s/iter. Inference: 0.0356 s/iter. Eval: 0.0387 s/iter. Total: 0.0765 s/iter. ETA=0:04:45\n",
      "\u001b[32m[07/06 22:41:18 d2.evaluation.evaluator]: \u001b[0mInference done 4254/7914. Dataloading: 0.0022 s/iter. Inference: 0.0356 s/iter. Eval: 0.0386 s/iter. Total: 0.0765 s/iter. ETA=0:04:39\n",
      "\u001b[32m[07/06 22:41:23 d2.evaluation.evaluator]: \u001b[0mInference done 4321/7914. Dataloading: 0.0022 s/iter. Inference: 0.0356 s/iter. Eval: 0.0386 s/iter. Total: 0.0764 s/iter. ETA=0:04:34\n",
      "\u001b[32m[07/06 22:41:28 d2.evaluation.evaluator]: \u001b[0mInference done 4388/7914. Dataloading: 0.0022 s/iter. Inference: 0.0356 s/iter. Eval: 0.0386 s/iter. Total: 0.0764 s/iter. ETA=0:04:29\n",
      "\u001b[32m[07/06 22:41:33 d2.evaluation.evaluator]: \u001b[0mInference done 4454/7914. Dataloading: 0.0022 s/iter. Inference: 0.0356 s/iter. Eval: 0.0386 s/iter. Total: 0.0764 s/iter. ETA=0:04:24\n",
      "\u001b[32m[07/06 22:41:38 d2.evaluation.evaluator]: \u001b[0mInference done 4520/7914. Dataloading: 0.0022 s/iter. Inference: 0.0356 s/iter. Eval: 0.0386 s/iter. Total: 0.0764 s/iter. ETA=0:04:19\n",
      "\u001b[32m[07/06 22:41:43 d2.evaluation.evaluator]: \u001b[0mInference done 4587/7914. Dataloading: 0.0022 s/iter. Inference: 0.0356 s/iter. Eval: 0.0386 s/iter. Total: 0.0764 s/iter. ETA=0:04:14\n",
      "\u001b[32m[07/06 22:41:48 d2.evaluation.evaluator]: \u001b[0mInference done 4653/7914. Dataloading: 0.0022 s/iter. Inference: 0.0356 s/iter. Eval: 0.0386 s/iter. Total: 0.0764 s/iter. ETA=0:04:09\n",
      "\u001b[32m[07/06 22:41:53 d2.evaluation.evaluator]: \u001b[0mInference done 4718/7914. Dataloading: 0.0022 s/iter. Inference: 0.0356 s/iter. Eval: 0.0386 s/iter. Total: 0.0764 s/iter. ETA=0:04:04\n",
      "\u001b[32m[07/06 22:41:58 d2.evaluation.evaluator]: \u001b[0mInference done 4784/7914. Dataloading: 0.0022 s/iter. Inference: 0.0356 s/iter. Eval: 0.0386 s/iter. Total: 0.0764 s/iter. ETA=0:03:59\n",
      "\u001b[32m[07/06 22:42:03 d2.evaluation.evaluator]: \u001b[0mInference done 4851/7914. Dataloading: 0.0022 s/iter. Inference: 0.0356 s/iter. Eval: 0.0386 s/iter. Total: 0.0764 s/iter. ETA=0:03:54\n",
      "\u001b[32m[07/06 22:42:08 d2.evaluation.evaluator]: \u001b[0mInference done 4916/7914. Dataloading: 0.0022 s/iter. Inference: 0.0356 s/iter. Eval: 0.0386 s/iter. Total: 0.0764 s/iter. ETA=0:03:49\n",
      "\u001b[32m[07/06 22:42:13 d2.evaluation.evaluator]: \u001b[0mInference done 4981/7914. Dataloading: 0.0022 s/iter. Inference: 0.0356 s/iter. Eval: 0.0386 s/iter. Total: 0.0764 s/iter. ETA=0:03:44\n",
      "\u001b[32m[07/06 22:42:18 d2.evaluation.evaluator]: \u001b[0mInference done 5046/7914. Dataloading: 0.0022 s/iter. Inference: 0.0356 s/iter. Eval: 0.0386 s/iter. Total: 0.0764 s/iter. ETA=0:03:39\n",
      "\u001b[32m[07/06 22:42:23 d2.evaluation.evaluator]: \u001b[0mInference done 5112/7914. Dataloading: 0.0022 s/iter. Inference: 0.0356 s/iter. Eval: 0.0386 s/iter. Total: 0.0765 s/iter. ETA=0:03:34\n",
      "\u001b[32m[07/06 22:42:28 d2.evaluation.evaluator]: \u001b[0mInference done 5178/7914. Dataloading: 0.0022 s/iter. Inference: 0.0356 s/iter. Eval: 0.0386 s/iter. Total: 0.0765 s/iter. ETA=0:03:29\n",
      "\u001b[32m[07/06 22:42:33 d2.evaluation.evaluator]: \u001b[0mInference done 5244/7914. Dataloading: 0.0022 s/iter. Inference: 0.0356 s/iter. Eval: 0.0386 s/iter. Total: 0.0765 s/iter. ETA=0:03:24\n",
      "\u001b[32m[07/06 22:42:38 d2.evaluation.evaluator]: \u001b[0mInference done 5310/7914. Dataloading: 0.0022 s/iter. Inference: 0.0355 s/iter. Eval: 0.0386 s/iter. Total: 0.0765 s/iter. ETA=0:03:19\n",
      "\u001b[32m[07/06 22:42:43 d2.evaluation.evaluator]: \u001b[0mInference done 5376/7914. Dataloading: 0.0022 s/iter. Inference: 0.0355 s/iter. Eval: 0.0386 s/iter. Total: 0.0765 s/iter. ETA=0:03:14\n",
      "\u001b[32m[07/06 22:42:48 d2.evaluation.evaluator]: \u001b[0mInference done 5442/7914. Dataloading: 0.0022 s/iter. Inference: 0.0355 s/iter. Eval: 0.0386 s/iter. Total: 0.0765 s/iter. ETA=0:03:09\n",
      "\u001b[32m[07/06 22:42:53 d2.evaluation.evaluator]: \u001b[0mInference done 5508/7914. Dataloading: 0.0022 s/iter. Inference: 0.0355 s/iter. Eval: 0.0386 s/iter. Total: 0.0765 s/iter. ETA=0:03:03\n",
      "\u001b[32m[07/06 22:42:58 d2.evaluation.evaluator]: \u001b[0mInference done 5574/7914. Dataloading: 0.0022 s/iter. Inference: 0.0355 s/iter. Eval: 0.0386 s/iter. Total: 0.0765 s/iter. ETA=0:02:58\n",
      "\u001b[32m[07/06 22:43:03 d2.evaluation.evaluator]: \u001b[0mInference done 5639/7914. Dataloading: 0.0022 s/iter. Inference: 0.0355 s/iter. Eval: 0.0386 s/iter. Total: 0.0765 s/iter. ETA=0:02:53\n",
      "\u001b[32m[07/06 22:43:08 d2.evaluation.evaluator]: \u001b[0mInference done 5705/7914. Dataloading: 0.0022 s/iter. Inference: 0.0355 s/iter. Eval: 0.0386 s/iter. Total: 0.0765 s/iter. ETA=0:02:48\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/06 22:43:14 d2.evaluation.evaluator]: \u001b[0mInference done 5771/7914. Dataloading: 0.0022 s/iter. Inference: 0.0355 s/iter. Eval: 0.0386 s/iter. Total: 0.0765 s/iter. ETA=0:02:43\n",
      "\u001b[32m[07/06 22:43:19 d2.evaluation.evaluator]: \u001b[0mInference done 5838/7914. Dataloading: 0.0022 s/iter. Inference: 0.0355 s/iter. Eval: 0.0386 s/iter. Total: 0.0765 s/iter. ETA=0:02:38\n",
      "\u001b[32m[07/06 22:43:24 d2.evaluation.evaluator]: \u001b[0mInference done 5903/7914. Dataloading: 0.0022 s/iter. Inference: 0.0356 s/iter. Eval: 0.0386 s/iter. Total: 0.0765 s/iter. ETA=0:02:33\n",
      "\u001b[32m[07/06 22:43:29 d2.evaluation.evaluator]: \u001b[0mInference done 5969/7914. Dataloading: 0.0022 s/iter. Inference: 0.0356 s/iter. Eval: 0.0386 s/iter. Total: 0.0765 s/iter. ETA=0:02:28\n",
      "\u001b[32m[07/06 22:43:34 d2.evaluation.evaluator]: \u001b[0mInference done 6035/7914. Dataloading: 0.0022 s/iter. Inference: 0.0356 s/iter. Eval: 0.0386 s/iter. Total: 0.0765 s/iter. ETA=0:02:23\n",
      "\u001b[32m[07/06 22:43:39 d2.evaluation.evaluator]: \u001b[0mInference done 6100/7914. Dataloading: 0.0022 s/iter. Inference: 0.0356 s/iter. Eval: 0.0386 s/iter. Total: 0.0765 s/iter. ETA=0:02:18\n",
      "\u001b[32m[07/06 22:43:44 d2.evaluation.evaluator]: \u001b[0mInference done 6166/7914. Dataloading: 0.0022 s/iter. Inference: 0.0356 s/iter. Eval: 0.0386 s/iter. Total: 0.0765 s/iter. ETA=0:02:13\n",
      "\u001b[32m[07/06 22:43:49 d2.evaluation.evaluator]: \u001b[0mInference done 6233/7914. Dataloading: 0.0022 s/iter. Inference: 0.0356 s/iter. Eval: 0.0386 s/iter. Total: 0.0764 s/iter. ETA=0:02:08\n",
      "\u001b[32m[07/06 22:43:54 d2.evaluation.evaluator]: \u001b[0mInference done 6300/7914. Dataloading: 0.0022 s/iter. Inference: 0.0356 s/iter. Eval: 0.0386 s/iter. Total: 0.0764 s/iter. ETA=0:02:03\n",
      "\u001b[32m[07/06 22:43:59 d2.evaluation.evaluator]: \u001b[0mInference done 6365/7914. Dataloading: 0.0022 s/iter. Inference: 0.0356 s/iter. Eval: 0.0386 s/iter. Total: 0.0764 s/iter. ETA=0:01:58\n",
      "\u001b[32m[07/06 22:44:04 d2.evaluation.evaluator]: \u001b[0mInference done 6432/7914. Dataloading: 0.0022 s/iter. Inference: 0.0356 s/iter. Eval: 0.0386 s/iter. Total: 0.0764 s/iter. ETA=0:01:53\n",
      "\u001b[32m[07/06 22:44:09 d2.evaluation.evaluator]: \u001b[0mInference done 6498/7914. Dataloading: 0.0022 s/iter. Inference: 0.0356 s/iter. Eval: 0.0386 s/iter. Total: 0.0764 s/iter. ETA=0:01:48\n",
      "\u001b[32m[07/06 22:44:14 d2.evaluation.evaluator]: \u001b[0mInference done 6534/7914. Dataloading: 0.0022 s/iter. Inference: 0.0356 s/iter. Eval: 0.0389 s/iter. Total: 0.0768 s/iter. ETA=0:01:45\n",
      "\u001b[32m[07/06 22:44:19 d2.evaluation.evaluator]: \u001b[0mInference done 6559/7914. Dataloading: 0.0022 s/iter. Inference: 0.0356 s/iter. Eval: 0.0393 s/iter. Total: 0.0773 s/iter. ETA=0:01:44\n",
      "\u001b[32m[07/06 22:44:24 d2.evaluation.evaluator]: \u001b[0mInference done 6584/7914. Dataloading: 0.0022 s/iter. Inference: 0.0357 s/iter. Eval: 0.0398 s/iter. Total: 0.0777 s/iter. ETA=0:01:43\n",
      "\u001b[32m[07/06 22:44:29 d2.evaluation.evaluator]: \u001b[0mInference done 6609/7914. Dataloading: 0.0022 s/iter. Inference: 0.0357 s/iter. Eval: 0.0402 s/iter. Total: 0.0782 s/iter. ETA=0:01:42\n",
      "\u001b[32m[07/06 22:44:34 d2.evaluation.evaluator]: \u001b[0mInference done 6634/7914. Dataloading: 0.0022 s/iter. Inference: 0.0358 s/iter. Eval: 0.0407 s/iter. Total: 0.0787 s/iter. ETA=0:01:40\n",
      "\u001b[32m[07/06 22:44:39 d2.evaluation.evaluator]: \u001b[0mInference done 6660/7914. Dataloading: 0.0022 s/iter. Inference: 0.0358 s/iter. Eval: 0.0411 s/iter. Total: 0.0791 s/iter. ETA=0:01:39\n",
      "\u001b[32m[07/06 22:44:44 d2.evaluation.evaluator]: \u001b[0mInference done 6687/7914. Dataloading: 0.0022 s/iter. Inference: 0.0358 s/iter. Eval: 0.0415 s/iter. Total: 0.0796 s/iter. ETA=0:01:37\n",
      "\u001b[32m[07/06 22:44:50 d2.evaluation.evaluator]: \u001b[0mInference done 6713/7914. Dataloading: 0.0022 s/iter. Inference: 0.0359 s/iter. Eval: 0.0419 s/iter. Total: 0.0800 s/iter. ETA=0:01:36\n",
      "\u001b[32m[07/06 22:44:55 d2.evaluation.evaluator]: \u001b[0mInference done 6740/7914. Dataloading: 0.0022 s/iter. Inference: 0.0359 s/iter. Eval: 0.0423 s/iter. Total: 0.0805 s/iter. ETA=0:01:34\n",
      "\u001b[32m[07/06 22:45:00 d2.evaluation.evaluator]: \u001b[0mInference done 6767/7914. Dataloading: 0.0022 s/iter. Inference: 0.0360 s/iter. Eval: 0.0427 s/iter. Total: 0.0809 s/iter. ETA=0:01:32\n",
      "\u001b[32m[07/06 22:45:05 d2.evaluation.evaluator]: \u001b[0mInference done 6794/7914. Dataloading: 0.0022 s/iter. Inference: 0.0360 s/iter. Eval: 0.0431 s/iter. Total: 0.0814 s/iter. ETA=0:01:31\n",
      "\u001b[32m[07/06 22:45:10 d2.evaluation.evaluator]: \u001b[0mInference done 6821/7914. Dataloading: 0.0022 s/iter. Inference: 0.0361 s/iter. Eval: 0.0435 s/iter. Total: 0.0818 s/iter. ETA=0:01:29\n",
      "\u001b[32m[07/06 22:45:15 d2.evaluation.evaluator]: \u001b[0mInference done 6847/7914. Dataloading: 0.0022 s/iter. Inference: 0.0361 s/iter. Eval: 0.0438 s/iter. Total: 0.0822 s/iter. ETA=0:01:27\n",
      "\u001b[32m[07/06 22:45:20 d2.evaluation.evaluator]: \u001b[0mInference done 6872/7914. Dataloading: 0.0022 s/iter. Inference: 0.0361 s/iter. Eval: 0.0443 s/iter. Total: 0.0827 s/iter. ETA=0:01:26\n",
      "\u001b[32m[07/06 22:45:25 d2.evaluation.evaluator]: \u001b[0mInference done 6897/7914. Dataloading: 0.0022 s/iter. Inference: 0.0362 s/iter. Eval: 0.0446 s/iter. Total: 0.0831 s/iter. ETA=0:01:24\n",
      "\u001b[32m[07/06 22:45:30 d2.evaluation.evaluator]: \u001b[0mInference done 6922/7914. Dataloading: 0.0022 s/iter. Inference: 0.0362 s/iter. Eval: 0.0450 s/iter. Total: 0.0835 s/iter. ETA=0:01:22\n",
      "\u001b[32m[07/06 22:45:35 d2.evaluation.evaluator]: \u001b[0mInference done 6947/7914. Dataloading: 0.0022 s/iter. Inference: 0.0363 s/iter. Eval: 0.0454 s/iter. Total: 0.0840 s/iter. ETA=0:01:21\n",
      "\u001b[32m[07/06 22:45:41 d2.evaluation.evaluator]: \u001b[0mInference done 6972/7914. Dataloading: 0.0022 s/iter. Inference: 0.0363 s/iter. Eval: 0.0458 s/iter. Total: 0.0844 s/iter. ETA=0:01:19\n",
      "\u001b[32m[07/06 22:45:46 d2.evaluation.evaluator]: \u001b[0mInference done 6998/7914. Dataloading: 0.0022 s/iter. Inference: 0.0363 s/iter. Eval: 0.0462 s/iter. Total: 0.0848 s/iter. ETA=0:01:17\n",
      "\u001b[32m[07/06 22:45:51 d2.evaluation.evaluator]: \u001b[0mInference done 7024/7914. Dataloading: 0.0022 s/iter. Inference: 0.0364 s/iter. Eval: 0.0466 s/iter. Total: 0.0852 s/iter. ETA=0:01:15\n",
      "\u001b[32m[07/06 22:45:56 d2.evaluation.evaluator]: \u001b[0mInference done 7050/7914. Dataloading: 0.0022 s/iter. Inference: 0.0364 s/iter. Eval: 0.0470 s/iter. Total: 0.0856 s/iter. ETA=0:01:13\n",
      "\u001b[32m[07/06 22:46:01 d2.evaluation.evaluator]: \u001b[0mInference done 7077/7914. Dataloading: 0.0022 s/iter. Inference: 0.0364 s/iter. Eval: 0.0473 s/iter. Total: 0.0860 s/iter. ETA=0:01:11\n",
      "\u001b[32m[07/06 22:46:06 d2.evaluation.evaluator]: \u001b[0mInference done 7103/7914. Dataloading: 0.0022 s/iter. Inference: 0.0365 s/iter. Eval: 0.0477 s/iter. Total: 0.0864 s/iter. ETA=0:01:10\n",
      "\u001b[32m[07/06 22:46:11 d2.evaluation.evaluator]: \u001b[0mInference done 7129/7914. Dataloading: 0.0022 s/iter. Inference: 0.0365 s/iter. Eval: 0.0480 s/iter. Total: 0.0868 s/iter. ETA=0:01:08\n",
      "\u001b[32m[07/06 22:46:16 d2.evaluation.evaluator]: \u001b[0mInference done 7154/7914. Dataloading: 0.0022 s/iter. Inference: 0.0366 s/iter. Eval: 0.0484 s/iter. Total: 0.0872 s/iter. ETA=0:01:06\n",
      "\u001b[32m[07/06 22:46:21 d2.evaluation.evaluator]: \u001b[0mInference done 7179/7914. Dataloading: 0.0022 s/iter. Inference: 0.0366 s/iter. Eval: 0.0488 s/iter. Total: 0.0876 s/iter. ETA=0:01:04\n",
      "\u001b[32m[07/06 22:46:26 d2.evaluation.evaluator]: \u001b[0mInference done 7204/7914. Dataloading: 0.0022 s/iter. Inference: 0.0366 s/iter. Eval: 0.0491 s/iter. Total: 0.0880 s/iter. ETA=0:01:02\n",
      "\u001b[32m[07/06 22:46:32 d2.evaluation.evaluator]: \u001b[0mInference done 7230/7914. Dataloading: 0.0022 s/iter. Inference: 0.0367 s/iter. Eval: 0.0495 s/iter. Total: 0.0884 s/iter. ETA=0:01:00\n",
      "\u001b[32m[07/06 22:46:37 d2.evaluation.evaluator]: \u001b[0mInference done 7255/7914. Dataloading: 0.0022 s/iter. Inference: 0.0367 s/iter. Eval: 0.0499 s/iter. Total: 0.0888 s/iter. ETA=0:00:58\n",
      "\u001b[32m[07/06 22:46:42 d2.evaluation.evaluator]: \u001b[0mInference done 7280/7914. Dataloading: 0.0022 s/iter. Inference: 0.0367 s/iter. Eval: 0.0502 s/iter. Total: 0.0892 s/iter. ETA=0:00:56\n",
      "\u001b[32m[07/06 22:46:47 d2.evaluation.evaluator]: \u001b[0mInference done 7304/7914. Dataloading: 0.0022 s/iter. Inference: 0.0368 s/iter. Eval: 0.0506 s/iter. Total: 0.0896 s/iter. ETA=0:00:54\n",
      "\u001b[32m[07/06 22:46:52 d2.evaluation.evaluator]: \u001b[0mInference done 7330/7914. Dataloading: 0.0022 s/iter. Inference: 0.0368 s/iter. Eval: 0.0509 s/iter. Total: 0.0900 s/iter. ETA=0:00:52\n",
      "\u001b[32m[07/06 22:46:57 d2.evaluation.evaluator]: \u001b[0mInference done 7355/7914. Dataloading: 0.0022 s/iter. Inference: 0.0368 s/iter. Eval: 0.0513 s/iter. Total: 0.0904 s/iter. ETA=0:00:50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/06 22:47:02 d2.evaluation.evaluator]: \u001b[0mInference done 7381/7914. Dataloading: 0.0022 s/iter. Inference: 0.0369 s/iter. Eval: 0.0516 s/iter. Total: 0.0908 s/iter. ETA=0:00:48\n",
      "\u001b[32m[07/06 22:47:07 d2.evaluation.evaluator]: \u001b[0mInference done 7407/7914. Dataloading: 0.0022 s/iter. Inference: 0.0369 s/iter. Eval: 0.0520 s/iter. Total: 0.0911 s/iter. ETA=0:00:46\n",
      "\u001b[32m[07/06 22:47:12 d2.evaluation.evaluator]: \u001b[0mInference done 7432/7914. Dataloading: 0.0022 s/iter. Inference: 0.0369 s/iter. Eval: 0.0523 s/iter. Total: 0.0915 s/iter. ETA=0:00:44\n",
      "\u001b[32m[07/06 22:47:17 d2.evaluation.evaluator]: \u001b[0mInference done 7459/7914. Dataloading: 0.0022 s/iter. Inference: 0.0370 s/iter. Eval: 0.0526 s/iter. Total: 0.0919 s/iter. ETA=0:00:41\n",
      "\u001b[32m[07/06 22:47:22 d2.evaluation.evaluator]: \u001b[0mInference done 7485/7914. Dataloading: 0.0022 s/iter. Inference: 0.0370 s/iter. Eval: 0.0530 s/iter. Total: 0.0922 s/iter. ETA=0:00:39\n",
      "\u001b[32m[07/06 22:47:28 d2.evaluation.evaluator]: \u001b[0mInference done 7510/7914. Dataloading: 0.0022 s/iter. Inference: 0.0370 s/iter. Eval: 0.0533 s/iter. Total: 0.0926 s/iter. ETA=0:00:37\n",
      "\u001b[32m[07/06 22:47:33 d2.evaluation.evaluator]: \u001b[0mInference done 7535/7914. Dataloading: 0.0022 s/iter. Inference: 0.0371 s/iter. Eval: 0.0536 s/iter. Total: 0.0930 s/iter. ETA=0:00:35\n",
      "\u001b[32m[07/06 22:47:38 d2.evaluation.evaluator]: \u001b[0mInference done 7561/7914. Dataloading: 0.0022 s/iter. Inference: 0.0371 s/iter. Eval: 0.0540 s/iter. Total: 0.0933 s/iter. ETA=0:00:32\n",
      "\u001b[32m[07/06 22:47:43 d2.evaluation.evaluator]: \u001b[0mInference done 7587/7914. Dataloading: 0.0022 s/iter. Inference: 0.0371 s/iter. Eval: 0.0543 s/iter. Total: 0.0937 s/iter. ETA=0:00:30\n",
      "\u001b[32m[07/06 22:47:48 d2.evaluation.evaluator]: \u001b[0mInference done 7612/7914. Dataloading: 0.0022 s/iter. Inference: 0.0372 s/iter. Eval: 0.0546 s/iter. Total: 0.0940 s/iter. ETA=0:00:28\n",
      "\u001b[32m[07/06 22:47:53 d2.evaluation.evaluator]: \u001b[0mInference done 7638/7914. Dataloading: 0.0022 s/iter. Inference: 0.0372 s/iter. Eval: 0.0549 s/iter. Total: 0.0944 s/iter. ETA=0:00:26\n",
      "\u001b[32m[07/06 22:47:58 d2.evaluation.evaluator]: \u001b[0mInference done 7663/7914. Dataloading: 0.0022 s/iter. Inference: 0.0372 s/iter. Eval: 0.0552 s/iter. Total: 0.0947 s/iter. ETA=0:00:23\n",
      "\u001b[32m[07/06 22:48:03 d2.evaluation.evaluator]: \u001b[0mInference done 7688/7914. Dataloading: 0.0022 s/iter. Inference: 0.0373 s/iter. Eval: 0.0556 s/iter. Total: 0.0951 s/iter. ETA=0:00:21\n",
      "\u001b[32m[07/06 22:48:08 d2.evaluation.evaluator]: \u001b[0mInference done 7714/7914. Dataloading: 0.0022 s/iter. Inference: 0.0373 s/iter. Eval: 0.0559 s/iter. Total: 0.0954 s/iter. ETA=0:00:19\n",
      "\u001b[32m[07/06 22:48:13 d2.evaluation.evaluator]: \u001b[0mInference done 7739/7914. Dataloading: 0.0022 s/iter. Inference: 0.0373 s/iter. Eval: 0.0562 s/iter. Total: 0.0958 s/iter. ETA=0:00:16\n",
      "\u001b[32m[07/06 22:48:18 d2.evaluation.evaluator]: \u001b[0mInference done 7765/7914. Dataloading: 0.0022 s/iter. Inference: 0.0374 s/iter. Eval: 0.0565 s/iter. Total: 0.0961 s/iter. ETA=0:00:14\n",
      "\u001b[32m[07/06 22:48:24 d2.evaluation.evaluator]: \u001b[0mInference done 7790/7914. Dataloading: 0.0022 s/iter. Inference: 0.0374 s/iter. Eval: 0.0568 s/iter. Total: 0.0965 s/iter. ETA=0:00:11\n",
      "\u001b[32m[07/06 22:48:29 d2.evaluation.evaluator]: \u001b[0mInference done 7816/7914. Dataloading: 0.0022 s/iter. Inference: 0.0374 s/iter. Eval: 0.0571 s/iter. Total: 0.0968 s/iter. ETA=0:00:09\n",
      "\u001b[32m[07/06 22:48:34 d2.evaluation.evaluator]: \u001b[0mInference done 7842/7914. Dataloading: 0.0022 s/iter. Inference: 0.0375 s/iter. Eval: 0.0574 s/iter. Total: 0.0971 s/iter. ETA=0:00:06\n",
      "\u001b[32m[07/06 22:48:39 d2.evaluation.evaluator]: \u001b[0mInference done 7868/7914. Dataloading: 0.0022 s/iter. Inference: 0.0375 s/iter. Eval: 0.0577 s/iter. Total: 0.0974 s/iter. ETA=0:00:04\n",
      "\u001b[32m[07/06 22:48:44 d2.evaluation.evaluator]: \u001b[0mInference done 7893/7914. Dataloading: 0.0022 s/iter. Inference: 0.0375 s/iter. Eval: 0.0580 s/iter. Total: 0.0978 s/iter. ETA=0:00:02\n",
      "\u001b[32m[07/06 22:48:48 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:12:55.613922 (0.098067 s / iter per device, on 1 devices)\n",
      "\u001b[32m[07/06 22:48:48 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:04:56 (0.037538 s / iter per device, on 1 devices)\n",
      "\u001b[32m[07/06 22:48:50 d2.evaluation.sem_seg_evaluation]: \u001b[0mOrderedDict([('sem_seg', {'mIoU': 69.87309081766043, 'fwIoU': 90.24667351862752, 'IoU-Unlabeled': nan, 'IoU-Building': 88.35488602431771, 'IoU-Fence': 38.42540074302701, 'IoU-Pedestrian': 71.4941594246607, 'IoU-Pole': 54.44341946061834, 'IoU-Road': 97.59438609101254, 'IoU-SideWalk': 81.12405118920721, 'IoU-Vegetation': 84.26401654811563, 'IoU-Vehicles': 87.97756866887792, 'IoU-Wall': 70.38147703812741, 'IoU-TrafficSign': 56.825284999155336, 'IoU-Sky': 93.15590787941332, 'IoU-TrafficLight': 64.36911178679198, 'IoU-Terrain': 62.69087072721832, 'IoU-ConstructionVehicle': 86.70663230100249, 'IoU-workzone_object': 73.20322930167164, 'IoU-Detour': 6.959050899349408, 'mACC': 77.25456930873688, 'pACC': 94.65888309231494, 'ACC-Unlabeled': nan, 'ACC-Building': 96.90644798131211, 'ACC-Fence': 46.8308589836729, 'ACC-Pedestrian': 86.519503270626, 'ACC-Pole': 64.30160653987379, 'ACC-Road': 98.6061365090828, 'ACC-SideWalk': 90.09802246144444, 'ACC-Vegetation': 90.87614421014945, 'ACC-Vehicles': 91.66744731084557, 'ACC-Wall': 82.58380200483901, 'ACC-TrafficSign': 65.31477518638796, 'ACC-Sky': 94.38207431040894, 'ACC-TrafficLight': 74.98568168992117, 'ACC-Terrain': 74.1172831421784, 'ACC-ConstructionVehicle': 91.48466258472604, 'ACC-workzone_object': 80.31678339240712, 'ACC-Detour': 7.0818793619142575})])\n",
      "\u001b[32m[07/06 22:48:50 d2.engine.defaults]: \u001b[0mEvaluation results for combined_all_val in csv format:\n",
      "\u001b[32m[07/06 22:48:50 d2.evaluation.testing]: \u001b[0mcopypaste: Task: sem_seg\n",
      "\u001b[32m[07/06 22:48:50 d2.evaluation.testing]: \u001b[0mcopypaste: mIoU,fwIoU,mACC,pACC\n",
      "\u001b[32m[07/06 22:48:50 d2.evaluation.testing]: \u001b[0mcopypaste: 69.8731,90.2467,77.2546,94.6589\n"
     ]
    }
   ],
   "source": [
    "trainer_day = Detectron2Trainer('combined_clear_train', 'combined_all_val', output_folder='./output_day_clear_40k')\n",
    "trainer_day.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1891d066",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/05 17:36:37 d2.engine.defaults]: \u001b[0mModel:\n",
      "SemanticSegmentor(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (sem_seg_head): SemSegFPNHead(\n",
      "    (p2): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "    )\n",
      "    (p3): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (1): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "    )\n",
      "    (p4): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (1): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      (2): Conv2d(\n",
      "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (3): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "    )\n",
      "    (p5): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (1): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      (2): Conv2d(\n",
      "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (3): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      (4): Conv2d(\n",
      "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (5): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "    )\n",
      "    (predictor): Conv2d(128, 17, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/05 17:36:37 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(720, 720), max_size=2048, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[07/05 17:36:37 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[07/05 17:36:37 d2.data.common]: \u001b[0mSerializing 22288 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[07/05 17:36:37 d2.data.common]: \u001b[0mSerialized dataset takes 6.80 MiB\n",
      "Last checkpoint: model_final.pth\n",
      "\u001b[32m[07/05 17:36:38 d2.checkpoint.c2_model_loading]: \u001b[0mFollowing weights matched with model:\n",
      "| Names in Model                       | Names in Checkpoint                                                                                  | Shapes                                          |\n",
      "|:-------------------------------------|:-----------------------------------------------------------------------------------------------------|:------------------------------------------------|\n",
      "| backbone.bottom_up.res2.0.conv1.*    | backbone.bottom_up.res2.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,1,1)             |\n",
      "| backbone.bottom_up.res2.0.conv2.*    | backbone.bottom_up.res2.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |\n",
      "| backbone.bottom_up.res2.0.conv3.*    | backbone.bottom_up.res2.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res2.0.shortcut.* | backbone.bottom_up.res2.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res2.1.conv1.*    | backbone.bottom_up.res2.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |\n",
      "| backbone.bottom_up.res2.1.conv2.*    | backbone.bottom_up.res2.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |\n",
      "| backbone.bottom_up.res2.1.conv3.*    | backbone.bottom_up.res2.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res2.2.conv1.*    | backbone.bottom_up.res2.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |\n",
      "| backbone.bottom_up.res2.2.conv2.*    | backbone.bottom_up.res2.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |\n",
      "| backbone.bottom_up.res2.2.conv3.*    | backbone.bottom_up.res2.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res3.0.conv1.*    | backbone.bottom_up.res3.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,256,1,1)       |\n",
      "| backbone.bottom_up.res3.0.conv2.*    | backbone.bottom_up.res3.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.0.conv3.*    | backbone.bottom_up.res3.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res3.0.shortcut.* | backbone.bottom_up.res3.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (512,) (512,) (512,) (512,) (512,256,1,1)       |\n",
      "| backbone.bottom_up.res3.1.conv1.*    | backbone.bottom_up.res3.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |\n",
      "| backbone.bottom_up.res3.1.conv2.*    | backbone.bottom_up.res3.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.1.conv3.*    | backbone.bottom_up.res3.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res3.2.conv1.*    | backbone.bottom_up.res3.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |\n",
      "| backbone.bottom_up.res3.2.conv2.*    | backbone.bottom_up.res3.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.2.conv3.*    | backbone.bottom_up.res3.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res3.3.conv1.*    | backbone.bottom_up.res3.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |\n",
      "| backbone.bottom_up.res3.3.conv2.*    | backbone.bottom_up.res3.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.3.conv3.*    | backbone.bottom_up.res3.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res4.0.conv1.*    | backbone.bottom_up.res4.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,512,1,1)       |\n",
      "| backbone.bottom_up.res4.0.conv2.*    | backbone.bottom_up.res4.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.0.conv3.*    | backbone.bottom_up.res4.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.0.shortcut.* | backbone.bottom_up.res4.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (1024,) (1024,) (1024,) (1024,) (1024,512,1,1)  |\n",
      "| backbone.bottom_up.res4.1.conv1.*    | backbone.bottom_up.res4.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.1.conv2.*    | backbone.bottom_up.res4.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.1.conv3.*    | backbone.bottom_up.res4.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.2.conv1.*    | backbone.bottom_up.res4.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.2.conv2.*    | backbone.bottom_up.res4.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.2.conv3.*    | backbone.bottom_up.res4.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.3.conv1.*    | backbone.bottom_up.res4.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.3.conv2.*    | backbone.bottom_up.res4.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.3.conv3.*    | backbone.bottom_up.res4.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.4.conv1.*    | backbone.bottom_up.res4.4.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.4.conv2.*    | backbone.bottom_up.res4.4.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.4.conv3.*    | backbone.bottom_up.res4.4.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.5.conv1.*    | backbone.bottom_up.res4.5.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.5.conv2.*    | backbone.bottom_up.res4.5.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.5.conv3.*    | backbone.bottom_up.res4.5.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res5.0.conv1.*    | backbone.bottom_up.res5.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,1024,1,1)      |\n",
      "| backbone.bottom_up.res5.0.conv2.*    | backbone.bottom_up.res5.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |\n",
      "| backbone.bottom_up.res5.0.conv3.*    | backbone.bottom_up.res5.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
      "| backbone.bottom_up.res5.0.shortcut.* | backbone.bottom_up.res5.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (2048,) (2048,) (2048,) (2048,) (2048,1024,1,1) |\n",
      "| backbone.bottom_up.res5.1.conv1.*    | backbone.bottom_up.res5.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |\n",
      "| backbone.bottom_up.res5.1.conv2.*    | backbone.bottom_up.res5.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |\n",
      "| backbone.bottom_up.res5.1.conv3.*    | backbone.bottom_up.res5.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
      "| backbone.bottom_up.res5.2.conv1.*    | backbone.bottom_up.res5.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |\n",
      "| backbone.bottom_up.res5.2.conv2.*    | backbone.bottom_up.res5.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |\n",
      "| backbone.bottom_up.res5.2.conv3.*    | backbone.bottom_up.res5.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
      "| backbone.bottom_up.stem.conv1.*      | backbone.bottom_up.stem.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}      | (64,) (64,) (64,) (64,) (64,3,7,7)              |\n",
      "| backbone.fpn_lateral2.*              | backbone.fpn_lateral2.{bias,weight}                                                                  | (256,) (256,256,1,1)                            |\n",
      "| backbone.fpn_lateral3.*              | backbone.fpn_lateral3.{bias,weight}                                                                  | (256,) (256,512,1,1)                            |\n",
      "| backbone.fpn_lateral4.*              | backbone.fpn_lateral4.{bias,weight}                                                                  | (256,) (256,1024,1,1)                           |\n",
      "| backbone.fpn_lateral5.*              | backbone.fpn_lateral5.{bias,weight}                                                                  | (256,) (256,2048,1,1)                           |\n",
      "| backbone.fpn_output2.*               | backbone.fpn_output2.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| backbone.fpn_output3.*               | backbone.fpn_output3.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| backbone.fpn_output4.*               | backbone.fpn_output4.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| backbone.fpn_output5.*               | backbone.fpn_output5.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| sem_seg_head.p2.0.*                  | sem_seg_head.p2.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p3.0.*                  | sem_seg_head.p3.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p4.0.*                  | sem_seg_head.p4.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p4.2.*                  | sem_seg_head.p4.2.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,128,3,3)                     |\n",
      "| sem_seg_head.p5.0.*                  | sem_seg_head.p5.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p5.2.*                  | sem_seg_head.p5.2.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,128,3,3)                     |\n",
      "| sem_seg_head.p5.4.*                  | sem_seg_head.p5.4.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,128,3,3)                     |\n",
      "| sem_seg_head.predictor.*             | sem_seg_head.predictor.{bias,weight}                                                                 | (17,) (17,128,1,1)                              |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/05 17:36:38 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(720, 720), max_size=2048, sample_style='choice')]\n",
      "\u001b[32m[07/05 17:36:38 d2.data.common]: \u001b[0mSerializing 3258 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[07/05 17:36:38 d2.data.common]: \u001b[0mSerialized dataset takes 0.99 MiB\n",
      "\u001b[32m[07/05 17:36:38 d2.evaluation.evaluator]: \u001b[0mStart inference on 3258 batches\n",
      "\u001b[32m[07/05 17:36:39 d2.evaluation.evaluator]: \u001b[0mInference done 11/3258. Dataloading: 0.0016 s/iter. Inference: 0.0355 s/iter. Eval: 0.0443 s/iter. Total: 0.0814 s/iter. ETA=0:04:24\n",
      "\u001b[32m[07/05 17:36:44 d2.evaluation.evaluator]: \u001b[0mInference done 76/3258. Dataloading: 0.0020 s/iter. Inference: 0.0351 s/iter. Eval: 0.0405 s/iter. Total: 0.0777 s/iter. ETA=0:04:07\n",
      "\u001b[32m[07/05 17:36:49 d2.evaluation.evaluator]: \u001b[0mInference done 143/3258. Dataloading: 0.0021 s/iter. Inference: 0.0351 s/iter. Eval: 0.0392 s/iter. Total: 0.0765 s/iter. ETA=0:03:58\n",
      "\u001b[32m[07/05 17:36:54 d2.evaluation.evaluator]: \u001b[0mInference done 211/3258. Dataloading: 0.0021 s/iter. Inference: 0.0352 s/iter. Eval: 0.0384 s/iter. Total: 0.0758 s/iter. ETA=0:03:50\n",
      "\u001b[32m[07/05 17:36:59 d2.evaluation.evaluator]: \u001b[0mInference done 278/3258. Dataloading: 0.0021 s/iter. Inference: 0.0352 s/iter. Eval: 0.0383 s/iter. Total: 0.0757 s/iter. ETA=0:03:45\n",
      "\u001b[32m[07/05 17:37:04 d2.evaluation.evaluator]: \u001b[0mInference done 345/3258. Dataloading: 0.0021 s/iter. Inference: 0.0352 s/iter. Eval: 0.0381 s/iter. Total: 0.0755 s/iter. ETA=0:03:39\n",
      "\u001b[32m[07/05 17:37:09 d2.evaluation.evaluator]: \u001b[0mInference done 412/3258. Dataloading: 0.0021 s/iter. Inference: 0.0352 s/iter. Eval: 0.0380 s/iter. Total: 0.0754 s/iter. ETA=0:03:34\n",
      "\u001b[32m[07/05 17:37:14 d2.evaluation.evaluator]: \u001b[0mInference done 478/3258. Dataloading: 0.0021 s/iter. Inference: 0.0353 s/iter. Eval: 0.0381 s/iter. Total: 0.0756 s/iter. ETA=0:03:30\n",
      "\u001b[32m[07/05 17:37:19 d2.evaluation.evaluator]: \u001b[0mInference done 545/3258. Dataloading: 0.0021 s/iter. Inference: 0.0353 s/iter. Eval: 0.0381 s/iter. Total: 0.0755 s/iter. ETA=0:03:24\n",
      "\u001b[32m[07/05 17:37:24 d2.evaluation.evaluator]: \u001b[0mInference done 611/3258. Dataloading: 0.0021 s/iter. Inference: 0.0353 s/iter. Eval: 0.0381 s/iter. Total: 0.0756 s/iter. ETA=0:03:20\n",
      "\u001b[32m[07/05 17:37:29 d2.evaluation.evaluator]: \u001b[0mInference done 676/3258. Dataloading: 0.0021 s/iter. Inference: 0.0353 s/iter. Eval: 0.0382 s/iter. Total: 0.0757 s/iter. ETA=0:03:15\n",
      "\u001b[32m[07/05 17:37:34 d2.evaluation.evaluator]: \u001b[0mInference done 740/3258. Dataloading: 0.0021 s/iter. Inference: 0.0353 s/iter. Eval: 0.0385 s/iter. Total: 0.0760 s/iter. ETA=0:03:11\n",
      "\u001b[32m[07/05 17:37:39 d2.evaluation.evaluator]: \u001b[0mInference done 805/3258. Dataloading: 0.0021 s/iter. Inference: 0.0353 s/iter. Eval: 0.0386 s/iter. Total: 0.0761 s/iter. ETA=0:03:06\n",
      "\u001b[32m[07/05 17:37:44 d2.evaluation.evaluator]: \u001b[0mInference done 870/3258. Dataloading: 0.0021 s/iter. Inference: 0.0353 s/iter. Eval: 0.0387 s/iter. Total: 0.0762 s/iter. ETA=0:03:01\n",
      "\u001b[32m[07/05 17:37:49 d2.evaluation.evaluator]: \u001b[0mInference done 935/3258. Dataloading: 0.0021 s/iter. Inference: 0.0353 s/iter. Eval: 0.0388 s/iter. Total: 0.0763 s/iter. ETA=0:02:57\n",
      "\u001b[32m[07/05 17:37:54 d2.evaluation.evaluator]: \u001b[0mInference done 1001/3258. Dataloading: 0.0021 s/iter. Inference: 0.0353 s/iter. Eval: 0.0388 s/iter. Total: 0.0763 s/iter. ETA=0:02:52\n",
      "\u001b[32m[07/05 17:37:59 d2.evaluation.evaluator]: \u001b[0mInference done 1067/3258. Dataloading: 0.0021 s/iter. Inference: 0.0353 s/iter. Eval: 0.0387 s/iter. Total: 0.0763 s/iter. ETA=0:02:47\n",
      "\u001b[32m[07/05 17:38:04 d2.evaluation.evaluator]: \u001b[0mInference done 1133/3258. Dataloading: 0.0021 s/iter. Inference: 0.0353 s/iter. Eval: 0.0388 s/iter. Total: 0.0763 s/iter. ETA=0:02:42\n",
      "\u001b[32m[07/05 17:38:09 d2.evaluation.evaluator]: \u001b[0mInference done 1198/3258. Dataloading: 0.0021 s/iter. Inference: 0.0353 s/iter. Eval: 0.0389 s/iter. Total: 0.0764 s/iter. ETA=0:02:37\n",
      "\u001b[32m[07/05 17:38:14 d2.evaluation.evaluator]: \u001b[0mInference done 1261/3258. Dataloading: 0.0021 s/iter. Inference: 0.0353 s/iter. Eval: 0.0390 s/iter. Total: 0.0765 s/iter. ETA=0:02:32\n",
      "\u001b[32m[07/05 17:38:19 d2.evaluation.evaluator]: \u001b[0mInference done 1324/3258. Dataloading: 0.0022 s/iter. Inference: 0.0353 s/iter. Eval: 0.0391 s/iter. Total: 0.0767 s/iter. ETA=0:02:28\n",
      "\u001b[32m[07/05 17:38:25 d2.evaluation.evaluator]: \u001b[0mInference done 1390/3258. Dataloading: 0.0022 s/iter. Inference: 0.0354 s/iter. Eval: 0.0391 s/iter. Total: 0.0767 s/iter. ETA=0:02:23\n",
      "\u001b[32m[07/05 17:38:30 d2.evaluation.evaluator]: \u001b[0mInference done 1455/3258. Dataloading: 0.0022 s/iter. Inference: 0.0354 s/iter. Eval: 0.0391 s/iter. Total: 0.0768 s/iter. ETA=0:02:18\n",
      "\u001b[32m[07/05 17:38:35 d2.evaluation.evaluator]: \u001b[0mInference done 1520/3258. Dataloading: 0.0022 s/iter. Inference: 0.0354 s/iter. Eval: 0.0391 s/iter. Total: 0.0768 s/iter. ETA=0:02:13\n",
      "\u001b[32m[07/05 17:38:40 d2.evaluation.evaluator]: \u001b[0mInference done 1585/3258. Dataloading: 0.0022 s/iter. Inference: 0.0354 s/iter. Eval: 0.0392 s/iter. Total: 0.0768 s/iter. ETA=0:02:08\n",
      "\u001b[32m[07/05 17:38:45 d2.evaluation.evaluator]: \u001b[0mInference done 1649/3258. Dataloading: 0.0022 s/iter. Inference: 0.0354 s/iter. Eval: 0.0392 s/iter. Total: 0.0769 s/iter. ETA=0:02:03\n",
      "\u001b[32m[07/05 17:38:50 d2.evaluation.evaluator]: \u001b[0mInference done 1712/3258. Dataloading: 0.0022 s/iter. Inference: 0.0354 s/iter. Eval: 0.0394 s/iter. Total: 0.0770 s/iter. ETA=0:01:59\n",
      "\u001b[32m[07/05 17:38:55 d2.evaluation.evaluator]: \u001b[0mInference done 1777/3258. Dataloading: 0.0022 s/iter. Inference: 0.0354 s/iter. Eval: 0.0394 s/iter. Total: 0.0770 s/iter. ETA=0:01:54\n",
      "\u001b[32m[07/05 17:39:00 d2.evaluation.evaluator]: \u001b[0mInference done 1840/3258. Dataloading: 0.0022 s/iter. Inference: 0.0354 s/iter. Eval: 0.0395 s/iter. Total: 0.0771 s/iter. ETA=0:01:49\n",
      "\u001b[32m[07/05 17:39:05 d2.evaluation.evaluator]: \u001b[0mInference done 1902/3258. Dataloading: 0.0022 s/iter. Inference: 0.0354 s/iter. Eval: 0.0396 s/iter. Total: 0.0772 s/iter. ETA=0:01:44\n",
      "\u001b[32m[07/05 17:39:10 d2.evaluation.evaluator]: \u001b[0mInference done 1966/3258. Dataloading: 0.0022 s/iter. Inference: 0.0354 s/iter. Eval: 0.0397 s/iter. Total: 0.0773 s/iter. ETA=0:01:39\n",
      "\u001b[32m[07/05 17:39:15 d2.evaluation.evaluator]: \u001b[0mInference done 2031/3258. Dataloading: 0.0022 s/iter. Inference: 0.0354 s/iter. Eval: 0.0396 s/iter. Total: 0.0773 s/iter. ETA=0:01:34\n",
      "\u001b[32m[07/05 17:39:20 d2.evaluation.evaluator]: \u001b[0mInference done 2096/3258. Dataloading: 0.0022 s/iter. Inference: 0.0354 s/iter. Eval: 0.0396 s/iter. Total: 0.0773 s/iter. ETA=0:01:29\n",
      "\u001b[32m[07/05 17:39:25 d2.evaluation.evaluator]: \u001b[0mInference done 2161/3258. Dataloading: 0.0022 s/iter. Inference: 0.0354 s/iter. Eval: 0.0396 s/iter. Total: 0.0773 s/iter. ETA=0:01:24\n",
      "\u001b[32m[07/05 17:39:30 d2.evaluation.evaluator]: \u001b[0mInference done 2226/3258. Dataloading: 0.0022 s/iter. Inference: 0.0354 s/iter. Eval: 0.0396 s/iter. Total: 0.0773 s/iter. ETA=0:01:19\n",
      "\u001b[32m[07/05 17:39:35 d2.evaluation.evaluator]: \u001b[0mInference done 2291/3258. Dataloading: 0.0022 s/iter. Inference: 0.0354 s/iter. Eval: 0.0396 s/iter. Total: 0.0773 s/iter. ETA=0:01:14\n",
      "\u001b[32m[07/05 17:39:40 d2.evaluation.evaluator]: \u001b[0mInference done 2356/3258. Dataloading: 0.0022 s/iter. Inference: 0.0354 s/iter. Eval: 0.0396 s/iter. Total: 0.0773 s/iter. ETA=0:01:09\n",
      "\u001b[32m[07/05 17:39:45 d2.evaluation.evaluator]: \u001b[0mInference done 2421/3258. Dataloading: 0.0022 s/iter. Inference: 0.0354 s/iter. Eval: 0.0396 s/iter. Total: 0.0773 s/iter. ETA=0:01:04\n",
      "\u001b[32m[07/05 17:39:50 d2.evaluation.evaluator]: \u001b[0mInference done 2486/3258. Dataloading: 0.0022 s/iter. Inference: 0.0354 s/iter. Eval: 0.0396 s/iter. Total: 0.0773 s/iter. ETA=0:00:59\n",
      "\u001b[32m[07/05 17:39:55 d2.evaluation.evaluator]: \u001b[0mInference done 2552/3258. Dataloading: 0.0022 s/iter. Inference: 0.0354 s/iter. Eval: 0.0396 s/iter. Total: 0.0773 s/iter. ETA=0:00:54\n",
      "\u001b[32m[07/05 17:40:00 d2.evaluation.evaluator]: \u001b[0mInference done 2618/3258. Dataloading: 0.0022 s/iter. Inference: 0.0354 s/iter. Eval: 0.0396 s/iter. Total: 0.0773 s/iter. ETA=0:00:49\n",
      "\u001b[32m[07/05 17:40:05 d2.evaluation.evaluator]: \u001b[0mInference done 2683/3258. Dataloading: 0.0022 s/iter. Inference: 0.0354 s/iter. Eval: 0.0396 s/iter. Total: 0.0773 s/iter. ETA=0:00:44\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/05 17:40:10 d2.evaluation.evaluator]: \u001b[0mInference done 2748/3258. Dataloading: 0.0022 s/iter. Inference: 0.0354 s/iter. Eval: 0.0396 s/iter. Total: 0.0773 s/iter. ETA=0:00:39\n",
      "\u001b[32m[07/05 17:40:15 d2.evaluation.evaluator]: \u001b[0mInference done 2814/3258. Dataloading: 0.0022 s/iter. Inference: 0.0354 s/iter. Eval: 0.0396 s/iter. Total: 0.0773 s/iter. ETA=0:00:34\n",
      "\u001b[32m[07/05 17:40:20 d2.evaluation.evaluator]: \u001b[0mInference done 2880/3258. Dataloading: 0.0022 s/iter. Inference: 0.0354 s/iter. Eval: 0.0395 s/iter. Total: 0.0772 s/iter. ETA=0:00:29\n",
      "\u001b[32m[07/05 17:40:25 d2.evaluation.evaluator]: \u001b[0mInference done 2946/3258. Dataloading: 0.0022 s/iter. Inference: 0.0354 s/iter. Eval: 0.0395 s/iter. Total: 0.0772 s/iter. ETA=0:00:24\n",
      "\u001b[32m[07/05 17:40:30 d2.evaluation.evaluator]: \u001b[0mInference done 3012/3258. Dataloading: 0.0022 s/iter. Inference: 0.0355 s/iter. Eval: 0.0395 s/iter. Total: 0.0772 s/iter. ETA=0:00:18\n",
      "\u001b[32m[07/05 17:40:35 d2.evaluation.evaluator]: \u001b[0mInference done 3077/3258. Dataloading: 0.0022 s/iter. Inference: 0.0355 s/iter. Eval: 0.0395 s/iter. Total: 0.0772 s/iter. ETA=0:00:13\n",
      "\u001b[32m[07/05 17:40:40 d2.evaluation.evaluator]: \u001b[0mInference done 3142/3258. Dataloading: 0.0022 s/iter. Inference: 0.0355 s/iter. Eval: 0.0395 s/iter. Total: 0.0772 s/iter. ETA=0:00:08\n",
      "\u001b[32m[07/05 17:40:45 d2.evaluation.evaluator]: \u001b[0mInference done 3207/3258. Dataloading: 0.0022 s/iter. Inference: 0.0355 s/iter. Eval: 0.0395 s/iter. Total: 0.0772 s/iter. ETA=0:00:03\n",
      "\u001b[32m[07/05 17:40:49 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:04:11.147082 (0.077205 s / iter per device, on 1 devices)\n",
      "\u001b[32m[07/05 17:40:49 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:01:55 (0.035462 s / iter per device, on 1 devices)\n",
      "\u001b[32m[07/05 17:40:50 d2.evaluation.sem_seg_evaluation]: \u001b[0mOrderedDict([('sem_seg', {'mIoU': 71.03922925818868, 'fwIoU': 93.73325204626296, 'IoU-Unlabeled': nan, 'IoU-Building': 92.49940279986562, 'IoU-Fence': 41.453715876827616, 'IoU-Pedestrian': 48.49854547543188, 'IoU-Pole': 61.3014188464904, 'IoU-Road': 99.01843298117558, 'IoU-SideWalk': 90.32541622930678, 'IoU-Vegetation': 83.21515521914513, 'IoU-Vehicles': 86.47836988613771, 'IoU-Wall': 84.90583915115401, 'IoU-TrafficSign': 52.30723615861417, 'IoU-Sky': 97.06189263766933, 'IoU-TrafficLight': 71.66785652514712, 'IoU-Terrain': 71.70257849053576, 'IoU-ConstructionVehicle': 65.61078712689216, 'IoU-workzone_object': 77.01264465824973, 'IoU-Detour': 13.568376068376068, 'mACC': 79.30941252939843, 'pACC': 96.60267471845296, 'ACC-Unlabeled': nan, 'ACC-Building': 96.82890919102732, 'ACC-Fence': 55.405025103908834, 'ACC-Pedestrian': 62.93895111248303, 'ACC-Pole': 70.73300770467569, 'ACC-Road': 99.45612764350264, 'ACC-SideWalk': 95.551640967667, 'ACC-Vegetation': 93.00764863151032, 'ACC-Vehicles': 88.80650680602523, 'ACC-Wall': 93.81941012057943, 'ACC-TrafficSign': 61.37672206683633, 'ACC-Sky': 98.35855339297365, 'ACC-TrafficLight': 81.32084874750845, 'ACC-Terrain': 76.47421368625287, 'ACC-ConstructionVehicle': 94.43896465772335, 'ACC-workzone_object': 86.1893049348093, 'ACC-Detour': 14.244765702891327})])\n",
      "\u001b[32m[07/05 17:40:50 d2.engine.defaults]: \u001b[0mEvaluation results for carla_clear_val in csv format:\n",
      "\u001b[32m[07/05 17:40:50 d2.evaluation.testing]: \u001b[0mcopypaste: Task: sem_seg\n",
      "\u001b[32m[07/05 17:40:50 d2.evaluation.testing]: \u001b[0mcopypaste: mIoU,fwIoU,mACC,pACC\n",
      "\u001b[32m[07/05 17:40:50 d2.evaluation.testing]: \u001b[0mcopypaste: 71.0392,93.7333,79.3094,96.6027\n"
     ]
    }
   ],
   "source": [
    "trainer_day = Detectron2Trainer('combined_all_train', 'carla_clear_val', output_folder='./output_day_40k')\n",
    "trainer_day.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6c49f665",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/05 17:40:50 d2.engine.defaults]: \u001b[0mModel:\n",
      "SemanticSegmentor(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (sem_seg_head): SemSegFPNHead(\n",
      "    (p2): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "    )\n",
      "    (p3): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (1): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "    )\n",
      "    (p4): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (1): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      (2): Conv2d(\n",
      "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (3): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "    )\n",
      "    (p5): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (1): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      (2): Conv2d(\n",
      "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (3): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      (4): Conv2d(\n",
      "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (5): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "    )\n",
      "    (predictor): Conv2d(128, 17, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/05 17:40:50 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(720, 720), max_size=2048, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[07/05 17:40:50 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[07/05 17:40:50 d2.data.common]: \u001b[0mSerializing 22288 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[07/05 17:40:50 d2.data.common]: \u001b[0mSerialized dataset takes 6.80 MiB\n",
      "Last checkpoint: model_final.pth\n",
      "\u001b[32m[07/05 17:40:51 d2.checkpoint.c2_model_loading]: \u001b[0mFollowing weights matched with model:\n",
      "| Names in Model                       | Names in Checkpoint                                                                                  | Shapes                                          |\n",
      "|:-------------------------------------|:-----------------------------------------------------------------------------------------------------|:------------------------------------------------|\n",
      "| backbone.bottom_up.res2.0.conv1.*    | backbone.bottom_up.res2.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,1,1)             |\n",
      "| backbone.bottom_up.res2.0.conv2.*    | backbone.bottom_up.res2.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |\n",
      "| backbone.bottom_up.res2.0.conv3.*    | backbone.bottom_up.res2.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res2.0.shortcut.* | backbone.bottom_up.res2.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res2.1.conv1.*    | backbone.bottom_up.res2.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |\n",
      "| backbone.bottom_up.res2.1.conv2.*    | backbone.bottom_up.res2.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |\n",
      "| backbone.bottom_up.res2.1.conv3.*    | backbone.bottom_up.res2.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res2.2.conv1.*    | backbone.bottom_up.res2.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |\n",
      "| backbone.bottom_up.res2.2.conv2.*    | backbone.bottom_up.res2.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |\n",
      "| backbone.bottom_up.res2.2.conv3.*    | backbone.bottom_up.res2.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res3.0.conv1.*    | backbone.bottom_up.res3.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,256,1,1)       |\n",
      "| backbone.bottom_up.res3.0.conv2.*    | backbone.bottom_up.res3.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.0.conv3.*    | backbone.bottom_up.res3.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res3.0.shortcut.* | backbone.bottom_up.res3.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (512,) (512,) (512,) (512,) (512,256,1,1)       |\n",
      "| backbone.bottom_up.res3.1.conv1.*    | backbone.bottom_up.res3.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |\n",
      "| backbone.bottom_up.res3.1.conv2.*    | backbone.bottom_up.res3.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.1.conv3.*    | backbone.bottom_up.res3.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res3.2.conv1.*    | backbone.bottom_up.res3.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |\n",
      "| backbone.bottom_up.res3.2.conv2.*    | backbone.bottom_up.res3.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.2.conv3.*    | backbone.bottom_up.res3.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res3.3.conv1.*    | backbone.bottom_up.res3.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |\n",
      "| backbone.bottom_up.res3.3.conv2.*    | backbone.bottom_up.res3.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.3.conv3.*    | backbone.bottom_up.res3.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res4.0.conv1.*    | backbone.bottom_up.res4.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,512,1,1)       |\n",
      "| backbone.bottom_up.res4.0.conv2.*    | backbone.bottom_up.res4.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.0.conv3.*    | backbone.bottom_up.res4.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.0.shortcut.* | backbone.bottom_up.res4.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (1024,) (1024,) (1024,) (1024,) (1024,512,1,1)  |\n",
      "| backbone.bottom_up.res4.1.conv1.*    | backbone.bottom_up.res4.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.1.conv2.*    | backbone.bottom_up.res4.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.1.conv3.*    | backbone.bottom_up.res4.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.2.conv1.*    | backbone.bottom_up.res4.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.2.conv2.*    | backbone.bottom_up.res4.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.2.conv3.*    | backbone.bottom_up.res4.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.3.conv1.*    | backbone.bottom_up.res4.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.3.conv2.*    | backbone.bottom_up.res4.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.3.conv3.*    | backbone.bottom_up.res4.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.4.conv1.*    | backbone.bottom_up.res4.4.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.4.conv2.*    | backbone.bottom_up.res4.4.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.4.conv3.*    | backbone.bottom_up.res4.4.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.5.conv1.*    | backbone.bottom_up.res4.5.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.5.conv2.*    | backbone.bottom_up.res4.5.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.5.conv3.*    | backbone.bottom_up.res4.5.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res5.0.conv1.*    | backbone.bottom_up.res5.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,1024,1,1)      |\n",
      "| backbone.bottom_up.res5.0.conv2.*    | backbone.bottom_up.res5.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |\n",
      "| backbone.bottom_up.res5.0.conv3.*    | backbone.bottom_up.res5.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
      "| backbone.bottom_up.res5.0.shortcut.* | backbone.bottom_up.res5.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (2048,) (2048,) (2048,) (2048,) (2048,1024,1,1) |\n",
      "| backbone.bottom_up.res5.1.conv1.*    | backbone.bottom_up.res5.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |\n",
      "| backbone.bottom_up.res5.1.conv2.*    | backbone.bottom_up.res5.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |\n",
      "| backbone.bottom_up.res5.1.conv3.*    | backbone.bottom_up.res5.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
      "| backbone.bottom_up.res5.2.conv1.*    | backbone.bottom_up.res5.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |\n",
      "| backbone.bottom_up.res5.2.conv2.*    | backbone.bottom_up.res5.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |\n",
      "| backbone.bottom_up.res5.2.conv3.*    | backbone.bottom_up.res5.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
      "| backbone.bottom_up.stem.conv1.*      | backbone.bottom_up.stem.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}      | (64,) (64,) (64,) (64,) (64,3,7,7)              |\n",
      "| backbone.fpn_lateral2.*              | backbone.fpn_lateral2.{bias,weight}                                                                  | (256,) (256,256,1,1)                            |\n",
      "| backbone.fpn_lateral3.*              | backbone.fpn_lateral3.{bias,weight}                                                                  | (256,) (256,512,1,1)                            |\n",
      "| backbone.fpn_lateral4.*              | backbone.fpn_lateral4.{bias,weight}                                                                  | (256,) (256,1024,1,1)                           |\n",
      "| backbone.fpn_lateral5.*              | backbone.fpn_lateral5.{bias,weight}                                                                  | (256,) (256,2048,1,1)                           |\n",
      "| backbone.fpn_output2.*               | backbone.fpn_output2.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| backbone.fpn_output3.*               | backbone.fpn_output3.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| backbone.fpn_output4.*               | backbone.fpn_output4.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| backbone.fpn_output5.*               | backbone.fpn_output5.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| sem_seg_head.p2.0.*                  | sem_seg_head.p2.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p3.0.*                  | sem_seg_head.p3.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p4.0.*                  | sem_seg_head.p4.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p4.2.*                  | sem_seg_head.p4.2.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,128,3,3)                     |\n",
      "| sem_seg_head.p5.0.*                  | sem_seg_head.p5.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p5.2.*                  | sem_seg_head.p5.2.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,128,3,3)                     |\n",
      "| sem_seg_head.p5.4.*                  | sem_seg_head.p5.4.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,128,3,3)                     |\n",
      "| sem_seg_head.predictor.*             | sem_seg_head.predictor.{bias,weight}                                                                 | (17,) (17,128,1,1)                              |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/05 17:40:51 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(720, 720), max_size=2048, sample_style='choice')]\n",
      "\u001b[32m[07/05 17:40:51 d2.data.common]: \u001b[0mSerializing 699 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[07/05 17:40:51 d2.data.common]: \u001b[0mSerialized dataset takes 0.22 MiB\n",
      "\u001b[32m[07/05 17:40:51 d2.evaluation.evaluator]: \u001b[0mStart inference on 699 batches\n",
      "\u001b[32m[07/05 17:40:53 d2.evaluation.evaluator]: \u001b[0mInference done 11/699. Dataloading: 0.0017 s/iter. Inference: 0.0468 s/iter. Eval: 0.1467 s/iter. Total: 0.1953 s/iter. ETA=0:02:14\n",
      "\u001b[32m[07/05 17:40:59 d2.evaluation.evaluator]: \u001b[0mInference done 37/699. Dataloading: 0.0020 s/iter. Inference: 0.0469 s/iter. Eval: 0.1477 s/iter. Total: 0.1967 s/iter. ETA=0:02:10\n",
      "\u001b[32m[07/05 17:41:04 d2.evaluation.evaluator]: \u001b[0mInference done 63/699. Dataloading: 0.0021 s/iter. Inference: 0.0468 s/iter. Eval: 0.1472 s/iter. Total: 0.1962 s/iter. ETA=0:02:04\n",
      "\u001b[32m[07/05 17:41:09 d2.evaluation.evaluator]: \u001b[0mInference done 88/699. Dataloading: 0.0020 s/iter. Inference: 0.0468 s/iter. Eval: 0.1485 s/iter. Total: 0.1975 s/iter. ETA=0:02:00\n",
      "\u001b[32m[07/05 17:41:14 d2.evaluation.evaluator]: \u001b[0mInference done 114/699. Dataloading: 0.0021 s/iter. Inference: 0.0468 s/iter. Eval: 0.1483 s/iter. Total: 0.1973 s/iter. ETA=0:01:55\n",
      "\u001b[32m[07/05 17:41:19 d2.evaluation.evaluator]: \u001b[0mInference done 141/699. Dataloading: 0.0021 s/iter. Inference: 0.0468 s/iter. Eval: 0.1471 s/iter. Total: 0.1960 s/iter. ETA=0:01:49\n",
      "\u001b[32m[07/05 17:41:24 d2.evaluation.evaluator]: \u001b[0mInference done 168/699. Dataloading: 0.0020 s/iter. Inference: 0.0468 s/iter. Eval: 0.1458 s/iter. Total: 0.1947 s/iter. ETA=0:01:43\n",
      "\u001b[32m[07/05 17:41:29 d2.evaluation.evaluator]: \u001b[0mInference done 193/699. Dataloading: 0.0020 s/iter. Inference: 0.0468 s/iter. Eval: 0.1470 s/iter. Total: 0.1960 s/iter. ETA=0:01:39\n",
      "\u001b[32m[07/05 17:41:34 d2.evaluation.evaluator]: \u001b[0mInference done 219/699. Dataloading: 0.0020 s/iter. Inference: 0.0468 s/iter. Eval: 0.1474 s/iter. Total: 0.1964 s/iter. ETA=0:01:34\n",
      "\u001b[32m[07/05 17:41:39 d2.evaluation.evaluator]: \u001b[0mInference done 245/699. Dataloading: 0.0020 s/iter. Inference: 0.0468 s/iter. Eval: 0.1476 s/iter. Total: 0.1966 s/iter. ETA=0:01:29\n",
      "\u001b[32m[07/05 17:41:45 d2.evaluation.evaluator]: \u001b[0mInference done 271/699. Dataloading: 0.0020 s/iter. Inference: 0.0468 s/iter. Eval: 0.1477 s/iter. Total: 0.1967 s/iter. ETA=0:01:24\n",
      "\u001b[32m[07/05 17:41:50 d2.evaluation.evaluator]: \u001b[0mInference done 297/699. Dataloading: 0.0020 s/iter. Inference: 0.0468 s/iter. Eval: 0.1475 s/iter. Total: 0.1965 s/iter. ETA=0:01:18\n",
      "\u001b[32m[07/05 17:41:55 d2.evaluation.evaluator]: \u001b[0mInference done 323/699. Dataloading: 0.0020 s/iter. Inference: 0.0468 s/iter. Eval: 0.1478 s/iter. Total: 0.1967 s/iter. ETA=0:01:13\n",
      "\u001b[32m[07/05 17:42:00 d2.evaluation.evaluator]: \u001b[0mInference done 349/699. Dataloading: 0.0020 s/iter. Inference: 0.0468 s/iter. Eval: 0.1479 s/iter. Total: 0.1968 s/iter. ETA=0:01:08\n",
      "\u001b[32m[07/05 17:42:05 d2.evaluation.evaluator]: \u001b[0mInference done 375/699. Dataloading: 0.0023 s/iter. Inference: 0.0468 s/iter. Eval: 0.1477 s/iter. Total: 0.1969 s/iter. ETA=0:01:03\n",
      "\u001b[32m[07/05 17:42:10 d2.evaluation.evaluator]: \u001b[0mInference done 401/699. Dataloading: 0.0023 s/iter. Inference: 0.0468 s/iter. Eval: 0.1476 s/iter. Total: 0.1968 s/iter. ETA=0:00:58\n",
      "\u001b[32m[07/05 17:42:15 d2.evaluation.evaluator]: \u001b[0mInference done 427/699. Dataloading: 0.0023 s/iter. Inference: 0.0468 s/iter. Eval: 0.1474 s/iter. Total: 0.1966 s/iter. ETA=0:00:53\n",
      "\u001b[32m[07/05 17:42:20 d2.evaluation.evaluator]: \u001b[0mInference done 454/699. Dataloading: 0.0023 s/iter. Inference: 0.0468 s/iter. Eval: 0.1469 s/iter. Total: 0.1961 s/iter. ETA=0:00:48\n",
      "\u001b[32m[07/05 17:42:25 d2.evaluation.evaluator]: \u001b[0mInference done 482/699. Dataloading: 0.0023 s/iter. Inference: 0.0468 s/iter. Eval: 0.1462 s/iter. Total: 0.1954 s/iter. ETA=0:00:42\n",
      "\u001b[32m[07/05 17:42:31 d2.evaluation.evaluator]: \u001b[0mInference done 509/699. Dataloading: 0.0023 s/iter. Inference: 0.0468 s/iter. Eval: 0.1459 s/iter. Total: 0.1951 s/iter. ETA=0:00:37\n",
      "\u001b[32m[07/05 17:42:36 d2.evaluation.evaluator]: \u001b[0mInference done 536/699. Dataloading: 0.0023 s/iter. Inference: 0.0468 s/iter. Eval: 0.1455 s/iter. Total: 0.1947 s/iter. ETA=0:00:31\n",
      "\u001b[32m[07/05 17:42:41 d2.evaluation.evaluator]: \u001b[0mInference done 563/699. Dataloading: 0.0023 s/iter. Inference: 0.0468 s/iter. Eval: 0.1452 s/iter. Total: 0.1943 s/iter. ETA=0:00:26\n",
      "\u001b[32m[07/05 17:42:46 d2.evaluation.evaluator]: \u001b[0mInference done 589/699. Dataloading: 0.0023 s/iter. Inference: 0.0468 s/iter. Eval: 0.1452 s/iter. Total: 0.1944 s/iter. ETA=0:00:21\n",
      "\u001b[32m[07/05 17:42:51 d2.evaluation.evaluator]: \u001b[0mInference done 616/699. Dataloading: 0.0023 s/iter. Inference: 0.0468 s/iter. Eval: 0.1451 s/iter. Total: 0.1943 s/iter. ETA=0:00:16\n",
      "\u001b[32m[07/05 17:42:56 d2.evaluation.evaluator]: \u001b[0mInference done 643/699. Dataloading: 0.0023 s/iter. Inference: 0.0468 s/iter. Eval: 0.1449 s/iter. Total: 0.1941 s/iter. ETA=0:00:10\n",
      "\u001b[32m[07/05 17:43:01 d2.evaluation.evaluator]: \u001b[0mInference done 670/699. Dataloading: 0.0023 s/iter. Inference: 0.0468 s/iter. Eval: 0.1447 s/iter. Total: 0.1938 s/iter. ETA=0:00:05\n",
      "\u001b[32m[07/05 17:43:06 d2.evaluation.evaluator]: \u001b[0mInference done 696/699. Dataloading: 0.0023 s/iter. Inference: 0.0468 s/iter. Eval: 0.1447 s/iter. Total: 0.1939 s/iter. ETA=0:00:00\n",
      "\u001b[32m[07/05 17:43:07 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:02:14.642123 (0.194009 s / iter per device, on 1 devices)\n",
      "\u001b[32m[07/05 17:43:07 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:32 (0.046795 s / iter per device, on 1 devices)\n",
      "\u001b[32m[07/05 17:43:07 d2.evaluation.sem_seg_evaluation]: \u001b[0mOrderedDict([('sem_seg', {'mIoU': 68.529418274466, 'fwIoU': 90.69049868692126, 'IoU-Unlabeled': nan, 'IoU-Building': 91.10228702258534, 'IoU-Fence': 54.35573416104956, 'IoU-Pedestrian': 78.77313467582354, 'IoU-Pole': 52.80074988476415, 'IoU-Road': 96.63979331968613, 'IoU-SideWalk': 78.77954228246024, 'IoU-Vegetation': 90.88674006180736, 'IoU-Vehicles': 90.80460054900887, 'IoU-Wall': 48.07296959547238, 'IoU-TrafficSign': 65.48880818212903, 'IoU-Sky': 94.54166706892254, 'IoU-TrafficLight': 55.61231363473173, 'IoU-Terrain': 61.55351540408319, 'IoU-ConstructionVehicle': nan, 'IoU-workzone_object': nan, 'IoU-Detour': nan, 'mACC': 81.86095252232727, 'pACC': 94.92112748797265, 'ACC-Unlabeled': nan, 'ACC-Building': 95.65641097366947, 'ACC-Fence': 70.48260238721106, 'ACC-Pedestrian': 87.97061896270598, 'ACC-Pole': 66.96038170400689, 'ACC-Road': 98.69609330946899, 'ACC-SideWalk': 85.8275246401359, 'ACC-Vegetation': 96.12540741217532, 'ACC-Vehicles': 95.11285655589876, 'ACC-Wall': 57.86831103626794, 'ACC-TrafficSign': 75.25261566553556, 'ACC-Sky': 97.2208490769573, 'ACC-TrafficLight': 64.56661457014451, 'ACC-Terrain': 72.45209649607666, 'ACC-ConstructionVehicle': nan, 'ACC-workzone_object': nan, 'ACC-Detour': nan})])\n",
      "\u001b[32m[07/05 17:43:07 d2.engine.defaults]: \u001b[0mEvaluation results for cityscapes_clear_val in csv format:\n",
      "\u001b[32m[07/05 17:43:07 d2.evaluation.testing]: \u001b[0mcopypaste: Task: sem_seg\n",
      "\u001b[32m[07/05 17:43:07 d2.evaluation.testing]: \u001b[0mcopypaste: mIoU,fwIoU,mACC,pACC\n",
      "\u001b[32m[07/05 17:43:07 d2.evaluation.testing]: \u001b[0mcopypaste: 68.5294,90.6905,81.8610,94.9211\n"
     ]
    }
   ],
   "source": [
    "trainer_day = Detectron2Trainer('combined_all_train', 'cityscapes_clear_val', output_folder='./output_day_40k')\n",
    "trainer_day.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "552c1d82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/05 17:43:07 d2.engine.defaults]: \u001b[0mModel:\n",
      "SemanticSegmentor(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (sem_seg_head): SemSegFPNHead(\n",
      "    (p2): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "    )\n",
      "    (p3): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (1): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "    )\n",
      "    (p4): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (1): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      (2): Conv2d(\n",
      "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (3): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "    )\n",
      "    (p5): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (1): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      (2): Conv2d(\n",
      "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (3): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      (4): Conv2d(\n",
      "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (5): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "    )\n",
      "    (predictor): Conv2d(128, 17, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/05 17:43:07 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(720, 720), max_size=2048, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[07/05 17:43:07 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[07/05 17:43:07 d2.data.common]: \u001b[0mSerializing 22288 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[07/05 17:43:07 d2.data.common]: \u001b[0mSerialized dataset takes 6.80 MiB\n",
      "Last checkpoint: model_final.pth\n",
      "\u001b[32m[07/05 17:43:08 d2.checkpoint.c2_model_loading]: \u001b[0mFollowing weights matched with model:\n",
      "| Names in Model                       | Names in Checkpoint                                                                                  | Shapes                                          |\n",
      "|:-------------------------------------|:-----------------------------------------------------------------------------------------------------|:------------------------------------------------|\n",
      "| backbone.bottom_up.res2.0.conv1.*    | backbone.bottom_up.res2.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,1,1)             |\n",
      "| backbone.bottom_up.res2.0.conv2.*    | backbone.bottom_up.res2.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |\n",
      "| backbone.bottom_up.res2.0.conv3.*    | backbone.bottom_up.res2.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res2.0.shortcut.* | backbone.bottom_up.res2.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res2.1.conv1.*    | backbone.bottom_up.res2.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |\n",
      "| backbone.bottom_up.res2.1.conv2.*    | backbone.bottom_up.res2.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |\n",
      "| backbone.bottom_up.res2.1.conv3.*    | backbone.bottom_up.res2.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res2.2.conv1.*    | backbone.bottom_up.res2.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |\n",
      "| backbone.bottom_up.res2.2.conv2.*    | backbone.bottom_up.res2.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |\n",
      "| backbone.bottom_up.res2.2.conv3.*    | backbone.bottom_up.res2.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res3.0.conv1.*    | backbone.bottom_up.res3.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,256,1,1)       |\n",
      "| backbone.bottom_up.res3.0.conv2.*    | backbone.bottom_up.res3.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.0.conv3.*    | backbone.bottom_up.res3.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res3.0.shortcut.* | backbone.bottom_up.res3.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (512,) (512,) (512,) (512,) (512,256,1,1)       |\n",
      "| backbone.bottom_up.res3.1.conv1.*    | backbone.bottom_up.res3.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |\n",
      "| backbone.bottom_up.res3.1.conv2.*    | backbone.bottom_up.res3.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.1.conv3.*    | backbone.bottom_up.res3.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res3.2.conv1.*    | backbone.bottom_up.res3.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |\n",
      "| backbone.bottom_up.res3.2.conv2.*    | backbone.bottom_up.res3.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.2.conv3.*    | backbone.bottom_up.res3.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res3.3.conv1.*    | backbone.bottom_up.res3.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |\n",
      "| backbone.bottom_up.res3.3.conv2.*    | backbone.bottom_up.res3.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.3.conv3.*    | backbone.bottom_up.res3.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res4.0.conv1.*    | backbone.bottom_up.res4.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,512,1,1)       |\n",
      "| backbone.bottom_up.res4.0.conv2.*    | backbone.bottom_up.res4.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.0.conv3.*    | backbone.bottom_up.res4.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.0.shortcut.* | backbone.bottom_up.res4.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (1024,) (1024,) (1024,) (1024,) (1024,512,1,1)  |\n",
      "| backbone.bottom_up.res4.1.conv1.*    | backbone.bottom_up.res4.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.1.conv2.*    | backbone.bottom_up.res4.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.1.conv3.*    | backbone.bottom_up.res4.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.2.conv1.*    | backbone.bottom_up.res4.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.2.conv2.*    | backbone.bottom_up.res4.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.2.conv3.*    | backbone.bottom_up.res4.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.3.conv1.*    | backbone.bottom_up.res4.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.3.conv2.*    | backbone.bottom_up.res4.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.3.conv3.*    | backbone.bottom_up.res4.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.4.conv1.*    | backbone.bottom_up.res4.4.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.4.conv2.*    | backbone.bottom_up.res4.4.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.4.conv3.*    | backbone.bottom_up.res4.4.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.5.conv1.*    | backbone.bottom_up.res4.5.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.5.conv2.*    | backbone.bottom_up.res4.5.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.5.conv3.*    | backbone.bottom_up.res4.5.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res5.0.conv1.*    | backbone.bottom_up.res5.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,1024,1,1)      |\n",
      "| backbone.bottom_up.res5.0.conv2.*    | backbone.bottom_up.res5.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |\n",
      "| backbone.bottom_up.res5.0.conv3.*    | backbone.bottom_up.res5.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
      "| backbone.bottom_up.res5.0.shortcut.* | backbone.bottom_up.res5.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (2048,) (2048,) (2048,) (2048,) (2048,1024,1,1) |\n",
      "| backbone.bottom_up.res5.1.conv1.*    | backbone.bottom_up.res5.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |\n",
      "| backbone.bottom_up.res5.1.conv2.*    | backbone.bottom_up.res5.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |\n",
      "| backbone.bottom_up.res5.1.conv3.*    | backbone.bottom_up.res5.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
      "| backbone.bottom_up.res5.2.conv1.*    | backbone.bottom_up.res5.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |\n",
      "| backbone.bottom_up.res5.2.conv2.*    | backbone.bottom_up.res5.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |\n",
      "| backbone.bottom_up.res5.2.conv3.*    | backbone.bottom_up.res5.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
      "| backbone.bottom_up.stem.conv1.*      | backbone.bottom_up.stem.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}      | (64,) (64,) (64,) (64,) (64,3,7,7)              |\n",
      "| backbone.fpn_lateral2.*              | backbone.fpn_lateral2.{bias,weight}                                                                  | (256,) (256,256,1,1)                            |\n",
      "| backbone.fpn_lateral3.*              | backbone.fpn_lateral3.{bias,weight}                                                                  | (256,) (256,512,1,1)                            |\n",
      "| backbone.fpn_lateral4.*              | backbone.fpn_lateral4.{bias,weight}                                                                  | (256,) (256,1024,1,1)                           |\n",
      "| backbone.fpn_lateral5.*              | backbone.fpn_lateral5.{bias,weight}                                                                  | (256,) (256,2048,1,1)                           |\n",
      "| backbone.fpn_output2.*               | backbone.fpn_output2.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| backbone.fpn_output3.*               | backbone.fpn_output3.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| backbone.fpn_output4.*               | backbone.fpn_output4.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| backbone.fpn_output5.*               | backbone.fpn_output5.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| sem_seg_head.p2.0.*                  | sem_seg_head.p2.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p3.0.*                  | sem_seg_head.p3.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p4.0.*                  | sem_seg_head.p4.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p4.2.*                  | sem_seg_head.p4.2.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,128,3,3)                     |\n",
      "| sem_seg_head.p5.0.*                  | sem_seg_head.p5.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p5.2.*                  | sem_seg_head.p5.2.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,128,3,3)                     |\n",
      "| sem_seg_head.p5.4.*                  | sem_seg_head.p5.4.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,128,3,3)                     |\n",
      "| sem_seg_head.predictor.*             | sem_seg_head.predictor.{bias,weight}                                                                 | (17,) (17,128,1,1)                              |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/05 17:43:08 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(720, 720), max_size=2048, sample_style='choice')]\n",
      "\u001b[32m[07/05 17:43:08 d2.data.common]: \u001b[0mSerializing 3957 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[07/05 17:43:08 d2.data.common]: \u001b[0mSerialized dataset takes 1.21 MiB\n",
      "\u001b[32m[07/05 17:43:08 d2.evaluation.evaluator]: \u001b[0mStart inference on 3957 batches\n",
      "\u001b[32m[07/05 17:43:11 d2.evaluation.evaluator]: \u001b[0mInference done 38/3957. Dataloading: 0.0020 s/iter. Inference: 0.0353 s/iter. Eval: 0.0427 s/iter. Total: 0.0801 s/iter. ETA=0:05:13\n",
      "\u001b[32m[07/05 17:43:16 d2.evaluation.evaluator]: \u001b[0mInference done 104/3957. Dataloading: 0.0021 s/iter. Inference: 0.0352 s/iter. Eval: 0.0402 s/iter. Total: 0.0775 s/iter. ETA=0:04:58\n",
      "\u001b[32m[07/05 17:43:21 d2.evaluation.evaluator]: \u001b[0mInference done 170/3957. Dataloading: 0.0021 s/iter. Inference: 0.0352 s/iter. Eval: 0.0395 s/iter. Total: 0.0769 s/iter. ETA=0:04:51\n",
      "\u001b[32m[07/05 17:43:26 d2.evaluation.evaluator]: \u001b[0mInference done 237/3957. Dataloading: 0.0022 s/iter. Inference: 0.0352 s/iter. Eval: 0.0390 s/iter. Total: 0.0764 s/iter. ETA=0:04:44\n",
      "\u001b[32m[07/05 17:43:31 d2.evaluation.evaluator]: \u001b[0mInference done 303/3957. Dataloading: 0.0022 s/iter. Inference: 0.0352 s/iter. Eval: 0.0388 s/iter. Total: 0.0763 s/iter. ETA=0:04:38\n",
      "\u001b[32m[07/05 17:43:36 d2.evaluation.evaluator]: \u001b[0mInference done 370/3957. Dataloading: 0.0022 s/iter. Inference: 0.0352 s/iter. Eval: 0.0386 s/iter. Total: 0.0761 s/iter. ETA=0:04:32\n",
      "\u001b[32m[07/05 17:43:41 d2.evaluation.evaluator]: \u001b[0mInference done 437/3957. Dataloading: 0.0022 s/iter. Inference: 0.0352 s/iter. Eval: 0.0385 s/iter. Total: 0.0760 s/iter. ETA=0:04:27\n",
      "\u001b[32m[07/05 17:43:46 d2.evaluation.evaluator]: \u001b[0mInference done 504/3957. Dataloading: 0.0022 s/iter. Inference: 0.0352 s/iter. Eval: 0.0383 s/iter. Total: 0.0759 s/iter. ETA=0:04:21\n",
      "\u001b[32m[07/05 17:43:51 d2.evaluation.evaluator]: \u001b[0mInference done 572/3957. Dataloading: 0.0022 s/iter. Inference: 0.0353 s/iter. Eval: 0.0381 s/iter. Total: 0.0756 s/iter. ETA=0:04:15\n",
      "\u001b[32m[07/05 17:43:57 d2.evaluation.evaluator]: \u001b[0mInference done 638/3957. Dataloading: 0.0022 s/iter. Inference: 0.0353 s/iter. Eval: 0.0381 s/iter. Total: 0.0757 s/iter. ETA=0:04:11\n",
      "\u001b[32m[07/05 17:44:02 d2.evaluation.evaluator]: \u001b[0mInference done 704/3957. Dataloading: 0.0022 s/iter. Inference: 0.0353 s/iter. Eval: 0.0382 s/iter. Total: 0.0757 s/iter. ETA=0:04:06\n",
      "\u001b[32m[07/05 17:44:07 d2.evaluation.evaluator]: \u001b[0mInference done 769/3957. Dataloading: 0.0022 s/iter. Inference: 0.0353 s/iter. Eval: 0.0383 s/iter. Total: 0.0759 s/iter. ETA=0:04:02\n",
      "\u001b[32m[07/05 17:44:12 d2.evaluation.evaluator]: \u001b[0mInference done 835/3957. Dataloading: 0.0022 s/iter. Inference: 0.0353 s/iter. Eval: 0.0384 s/iter. Total: 0.0760 s/iter. ETA=0:03:57\n",
      "\u001b[32m[07/05 17:44:17 d2.evaluation.evaluator]: \u001b[0mInference done 900/3957. Dataloading: 0.0022 s/iter. Inference: 0.0353 s/iter. Eval: 0.0385 s/iter. Total: 0.0761 s/iter. ETA=0:03:52\n",
      "\u001b[32m[07/05 17:44:22 d2.evaluation.evaluator]: \u001b[0mInference done 965/3957. Dataloading: 0.0022 s/iter. Inference: 0.0353 s/iter. Eval: 0.0386 s/iter. Total: 0.0762 s/iter. ETA=0:03:48\n",
      "\u001b[32m[07/05 17:44:27 d2.evaluation.evaluator]: \u001b[0mInference done 1030/3957. Dataloading: 0.0022 s/iter. Inference: 0.0353 s/iter. Eval: 0.0387 s/iter. Total: 0.0763 s/iter. ETA=0:03:43\n",
      "\u001b[32m[07/05 17:44:32 d2.evaluation.evaluator]: \u001b[0mInference done 1096/3957. Dataloading: 0.0022 s/iter. Inference: 0.0353 s/iter. Eval: 0.0387 s/iter. Total: 0.0764 s/iter. ETA=0:03:38\n",
      "\u001b[32m[07/05 17:44:37 d2.evaluation.evaluator]: \u001b[0mInference done 1161/3957. Dataloading: 0.0022 s/iter. Inference: 0.0353 s/iter. Eval: 0.0388 s/iter. Total: 0.0764 s/iter. ETA=0:03:33\n",
      "\u001b[32m[07/05 17:44:42 d2.evaluation.evaluator]: \u001b[0mInference done 1226/3957. Dataloading: 0.0022 s/iter. Inference: 0.0353 s/iter. Eval: 0.0389 s/iter. Total: 0.0765 s/iter. ETA=0:03:28\n",
      "\u001b[32m[07/05 17:44:47 d2.evaluation.evaluator]: \u001b[0mInference done 1291/3957. Dataloading: 0.0022 s/iter. Inference: 0.0354 s/iter. Eval: 0.0389 s/iter. Total: 0.0766 s/iter. ETA=0:03:24\n",
      "\u001b[32m[07/05 17:44:52 d2.evaluation.evaluator]: \u001b[0mInference done 1356/3957. Dataloading: 0.0022 s/iter. Inference: 0.0354 s/iter. Eval: 0.0390 s/iter. Total: 0.0767 s/iter. ETA=0:03:19\n",
      "\u001b[32m[07/05 17:44:57 d2.evaluation.evaluator]: \u001b[0mInference done 1422/3957. Dataloading: 0.0022 s/iter. Inference: 0.0354 s/iter. Eval: 0.0390 s/iter. Total: 0.0766 s/iter. ETA=0:03:14\n",
      "\u001b[32m[07/05 17:45:02 d2.evaluation.evaluator]: \u001b[0mInference done 1487/3957. Dataloading: 0.0022 s/iter. Inference: 0.0354 s/iter. Eval: 0.0390 s/iter. Total: 0.0767 s/iter. ETA=0:03:09\n",
      "\u001b[32m[07/05 17:45:07 d2.evaluation.evaluator]: \u001b[0mInference done 1551/3957. Dataloading: 0.0022 s/iter. Inference: 0.0354 s/iter. Eval: 0.0391 s/iter. Total: 0.0767 s/iter. ETA=0:03:04\n",
      "\u001b[32m[07/05 17:45:12 d2.evaluation.evaluator]: \u001b[0mInference done 1616/3957. Dataloading: 0.0022 s/iter. Inference: 0.0354 s/iter. Eval: 0.0391 s/iter. Total: 0.0768 s/iter. ETA=0:02:59\n",
      "\u001b[32m[07/05 17:45:17 d2.evaluation.evaluator]: \u001b[0mInference done 1680/3957. Dataloading: 0.0022 s/iter. Inference: 0.0354 s/iter. Eval: 0.0392 s/iter. Total: 0.0768 s/iter. ETA=0:02:54\n",
      "\u001b[32m[07/05 17:45:22 d2.evaluation.evaluator]: \u001b[0mInference done 1745/3957. Dataloading: 0.0022 s/iter. Inference: 0.0354 s/iter. Eval: 0.0392 s/iter. Total: 0.0768 s/iter. ETA=0:02:49\n",
      "\u001b[32m[07/05 17:45:27 d2.evaluation.evaluator]: \u001b[0mInference done 1809/3957. Dataloading: 0.0022 s/iter. Inference: 0.0354 s/iter. Eval: 0.0392 s/iter. Total: 0.0769 s/iter. ETA=0:02:45\n",
      "\u001b[32m[07/05 17:45:32 d2.evaluation.evaluator]: \u001b[0mInference done 1872/3957. Dataloading: 0.0022 s/iter. Inference: 0.0354 s/iter. Eval: 0.0393 s/iter. Total: 0.0770 s/iter. ETA=0:02:40\n",
      "\u001b[32m[07/05 17:45:37 d2.evaluation.evaluator]: \u001b[0mInference done 1937/3957. Dataloading: 0.0022 s/iter. Inference: 0.0354 s/iter. Eval: 0.0393 s/iter. Total: 0.0770 s/iter. ETA=0:02:35\n",
      "\u001b[32m[07/05 17:45:42 d2.evaluation.evaluator]: \u001b[0mInference done 2002/3957. Dataloading: 0.0022 s/iter. Inference: 0.0354 s/iter. Eval: 0.0393 s/iter. Total: 0.0770 s/iter. ETA=0:02:30\n",
      "\u001b[32m[07/05 17:45:48 d2.evaluation.evaluator]: \u001b[0mInference done 2068/3957. Dataloading: 0.0022 s/iter. Inference: 0.0354 s/iter. Eval: 0.0393 s/iter. Total: 0.0770 s/iter. ETA=0:02:25\n",
      "\u001b[32m[07/05 17:45:53 d2.evaluation.evaluator]: \u001b[0mInference done 2134/3957. Dataloading: 0.0022 s/iter. Inference: 0.0354 s/iter. Eval: 0.0393 s/iter. Total: 0.0770 s/iter. ETA=0:02:20\n",
      "\u001b[32m[07/05 17:45:58 d2.evaluation.evaluator]: \u001b[0mInference done 2200/3957. Dataloading: 0.0022 s/iter. Inference: 0.0354 s/iter. Eval: 0.0393 s/iter. Total: 0.0770 s/iter. ETA=0:02:15\n",
      "\u001b[32m[07/05 17:46:03 d2.evaluation.evaluator]: \u001b[0mInference done 2266/3957. Dataloading: 0.0022 s/iter. Inference: 0.0354 s/iter. Eval: 0.0392 s/iter. Total: 0.0770 s/iter. ETA=0:02:10\n",
      "\u001b[32m[07/05 17:46:08 d2.evaluation.evaluator]: \u001b[0mInference done 2332/3957. Dataloading: 0.0022 s/iter. Inference: 0.0354 s/iter. Eval: 0.0392 s/iter. Total: 0.0769 s/iter. ETA=0:02:05\n",
      "\u001b[32m[07/05 17:46:13 d2.evaluation.evaluator]: \u001b[0mInference done 2398/3957. Dataloading: 0.0022 s/iter. Inference: 0.0354 s/iter. Eval: 0.0392 s/iter. Total: 0.0769 s/iter. ETA=0:01:59\n",
      "\u001b[32m[07/05 17:46:18 d2.evaluation.evaluator]: \u001b[0mInference done 2464/3957. Dataloading: 0.0022 s/iter. Inference: 0.0354 s/iter. Eval: 0.0392 s/iter. Total: 0.0769 s/iter. ETA=0:01:54\n",
      "\u001b[32m[07/05 17:46:23 d2.evaluation.evaluator]: \u001b[0mInference done 2530/3957. Dataloading: 0.0022 s/iter. Inference: 0.0354 s/iter. Eval: 0.0391 s/iter. Total: 0.0769 s/iter. ETA=0:01:49\n",
      "\u001b[32m[07/05 17:46:28 d2.evaluation.evaluator]: \u001b[0mInference done 2597/3957. Dataloading: 0.0022 s/iter. Inference: 0.0354 s/iter. Eval: 0.0391 s/iter. Total: 0.0768 s/iter. ETA=0:01:44\n",
      "\u001b[32m[07/05 17:46:33 d2.evaluation.evaluator]: \u001b[0mInference done 2663/3957. Dataloading: 0.0022 s/iter. Inference: 0.0354 s/iter. Eval: 0.0391 s/iter. Total: 0.0768 s/iter. ETA=0:01:39\n",
      "\u001b[32m[07/05 17:46:38 d2.evaluation.evaluator]: \u001b[0mInference done 2729/3957. Dataloading: 0.0022 s/iter. Inference: 0.0355 s/iter. Eval: 0.0391 s/iter. Total: 0.0768 s/iter. ETA=0:01:34\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/05 17:46:43 d2.evaluation.evaluator]: \u001b[0mInference done 2795/3957. Dataloading: 0.0022 s/iter. Inference: 0.0355 s/iter. Eval: 0.0390 s/iter. Total: 0.0768 s/iter. ETA=0:01:29\n",
      "\u001b[32m[07/05 17:46:48 d2.evaluation.evaluator]: \u001b[0mInference done 2861/3957. Dataloading: 0.0022 s/iter. Inference: 0.0355 s/iter. Eval: 0.0390 s/iter. Total: 0.0768 s/iter. ETA=0:01:24\n",
      "\u001b[32m[07/05 17:46:53 d2.evaluation.evaluator]: \u001b[0mInference done 2927/3957. Dataloading: 0.0022 s/iter. Inference: 0.0355 s/iter. Eval: 0.0390 s/iter. Total: 0.0768 s/iter. ETA=0:01:19\n",
      "\u001b[32m[07/05 17:46:58 d2.evaluation.evaluator]: \u001b[0mInference done 2993/3957. Dataloading: 0.0022 s/iter. Inference: 0.0355 s/iter. Eval: 0.0390 s/iter. Total: 0.0768 s/iter. ETA=0:01:13\n",
      "\u001b[32m[07/05 17:47:03 d2.evaluation.evaluator]: \u001b[0mInference done 3059/3957. Dataloading: 0.0022 s/iter. Inference: 0.0355 s/iter. Eval: 0.0390 s/iter. Total: 0.0768 s/iter. ETA=0:01:08\n",
      "\u001b[32m[07/05 17:47:08 d2.evaluation.evaluator]: \u001b[0mInference done 3125/3957. Dataloading: 0.0022 s/iter. Inference: 0.0355 s/iter. Eval: 0.0390 s/iter. Total: 0.0767 s/iter. ETA=0:01:03\n",
      "\u001b[32m[07/05 17:47:13 d2.evaluation.evaluator]: \u001b[0mInference done 3191/3957. Dataloading: 0.0022 s/iter. Inference: 0.0355 s/iter. Eval: 0.0390 s/iter. Total: 0.0767 s/iter. ETA=0:00:58\n",
      "\u001b[32m[07/05 17:47:18 d2.evaluation.evaluator]: \u001b[0mInference done 3257/3957. Dataloading: 0.0022 s/iter. Inference: 0.0355 s/iter. Eval: 0.0389 s/iter. Total: 0.0767 s/iter. ETA=0:00:53\n",
      "\u001b[32m[07/05 17:47:23 d2.evaluation.evaluator]: \u001b[0mInference done 3285/3957. Dataloading: 0.0022 s/iter. Inference: 0.0356 s/iter. Eval: 0.0398 s/iter. Total: 0.0776 s/iter. ETA=0:00:52\n",
      "\u001b[32m[07/05 17:47:28 d2.evaluation.evaluator]: \u001b[0mInference done 3311/3957. Dataloading: 0.0022 s/iter. Inference: 0.0356 s/iter. Eval: 0.0406 s/iter. Total: 0.0785 s/iter. ETA=0:00:50\n",
      "\u001b[32m[07/05 17:47:33 d2.evaluation.evaluator]: \u001b[0mInference done 3337/3957. Dataloading: 0.0022 s/iter. Inference: 0.0357 s/iter. Eval: 0.0414 s/iter. Total: 0.0795 s/iter. ETA=0:00:49\n",
      "\u001b[32m[07/05 17:47:38 d2.evaluation.evaluator]: \u001b[0mInference done 3364/3957. Dataloading: 0.0022 s/iter. Inference: 0.0358 s/iter. Eval: 0.0422 s/iter. Total: 0.0803 s/iter. ETA=0:00:47\n",
      "\u001b[32m[07/05 17:47:43 d2.evaluation.evaluator]: \u001b[0mInference done 3391/3957. Dataloading: 0.0022 s/iter. Inference: 0.0359 s/iter. Eval: 0.0430 s/iter. Total: 0.0812 s/iter. ETA=0:00:45\n",
      "\u001b[32m[07/05 17:47:49 d2.evaluation.evaluator]: \u001b[0mInference done 3419/3957. Dataloading: 0.0022 s/iter. Inference: 0.0360 s/iter. Eval: 0.0437 s/iter. Total: 0.0820 s/iter. ETA=0:00:44\n",
      "\u001b[32m[07/05 17:47:54 d2.evaluation.evaluator]: \u001b[0mInference done 3444/3957. Dataloading: 0.0022 s/iter. Inference: 0.0361 s/iter. Eval: 0.0445 s/iter. Total: 0.0829 s/iter. ETA=0:00:42\n",
      "\u001b[32m[07/05 17:47:59 d2.evaluation.evaluator]: \u001b[0mInference done 3470/3957. Dataloading: 0.0022 s/iter. Inference: 0.0361 s/iter. Eval: 0.0453 s/iter. Total: 0.0837 s/iter. ETA=0:00:40\n",
      "\u001b[32m[07/05 17:48:04 d2.evaluation.evaluator]: \u001b[0mInference done 3495/3957. Dataloading: 0.0022 s/iter. Inference: 0.0362 s/iter. Eval: 0.0461 s/iter. Total: 0.0846 s/iter. ETA=0:00:39\n",
      "\u001b[32m[07/05 17:48:09 d2.evaluation.evaluator]: \u001b[0mInference done 3521/3957. Dataloading: 0.0022 s/iter. Inference: 0.0363 s/iter. Eval: 0.0468 s/iter. Total: 0.0854 s/iter. ETA=0:00:37\n",
      "\u001b[32m[07/05 17:48:14 d2.evaluation.evaluator]: \u001b[0mInference done 3548/3957. Dataloading: 0.0022 s/iter. Inference: 0.0364 s/iter. Eval: 0.0475 s/iter. Total: 0.0862 s/iter. ETA=0:00:35\n",
      "\u001b[32m[07/05 17:48:19 d2.evaluation.evaluator]: \u001b[0mInference done 3574/3957. Dataloading: 0.0022 s/iter. Inference: 0.0365 s/iter. Eval: 0.0482 s/iter. Total: 0.0870 s/iter. ETA=0:00:33\n",
      "\u001b[32m[07/05 17:48:24 d2.evaluation.evaluator]: \u001b[0mInference done 3600/3957. Dataloading: 0.0022 s/iter. Inference: 0.0365 s/iter. Eval: 0.0490 s/iter. Total: 0.0878 s/iter. ETA=0:00:31\n",
      "\u001b[32m[07/05 17:48:29 d2.evaluation.evaluator]: \u001b[0mInference done 3626/3957. Dataloading: 0.0022 s/iter. Inference: 0.0366 s/iter. Eval: 0.0497 s/iter. Total: 0.0886 s/iter. ETA=0:00:29\n",
      "\u001b[32m[07/05 17:48:34 d2.evaluation.evaluator]: \u001b[0mInference done 3652/3957. Dataloading: 0.0022 s/iter. Inference: 0.0367 s/iter. Eval: 0.0504 s/iter. Total: 0.0893 s/iter. ETA=0:00:27\n",
      "\u001b[32m[07/05 17:48:40 d2.evaluation.evaluator]: \u001b[0mInference done 3678/3957. Dataloading: 0.0022 s/iter. Inference: 0.0367 s/iter. Eval: 0.0510 s/iter. Total: 0.0901 s/iter. ETA=0:00:25\n",
      "\u001b[32m[07/05 17:48:45 d2.evaluation.evaluator]: \u001b[0mInference done 3704/3957. Dataloading: 0.0022 s/iter. Inference: 0.0368 s/iter. Eval: 0.0517 s/iter. Total: 0.0908 s/iter. ETA=0:00:22\n",
      "\u001b[32m[07/05 17:48:50 d2.evaluation.evaluator]: \u001b[0mInference done 3731/3957. Dataloading: 0.0022 s/iter. Inference: 0.0369 s/iter. Eval: 0.0523 s/iter. Total: 0.0915 s/iter. ETA=0:00:20\n",
      "\u001b[32m[07/05 17:48:55 d2.evaluation.evaluator]: \u001b[0mInference done 3757/3957. Dataloading: 0.0022 s/iter. Inference: 0.0370 s/iter. Eval: 0.0530 s/iter. Total: 0.0923 s/iter. ETA=0:00:18\n",
      "\u001b[32m[07/05 17:49:00 d2.evaluation.evaluator]: \u001b[0mInference done 3783/3957. Dataloading: 0.0022 s/iter. Inference: 0.0370 s/iter. Eval: 0.0536 s/iter. Total: 0.0930 s/iter. ETA=0:00:16\n",
      "\u001b[32m[07/05 17:49:05 d2.evaluation.evaluator]: \u001b[0mInference done 3809/3957. Dataloading: 0.0022 s/iter. Inference: 0.0371 s/iter. Eval: 0.0543 s/iter. Total: 0.0937 s/iter. ETA=0:00:13\n",
      "\u001b[32m[07/05 17:49:10 d2.evaluation.evaluator]: \u001b[0mInference done 3835/3957. Dataloading: 0.0022 s/iter. Inference: 0.0372 s/iter. Eval: 0.0549 s/iter. Total: 0.0944 s/iter. ETA=0:00:11\n",
      "\u001b[32m[07/05 17:49:15 d2.evaluation.evaluator]: \u001b[0mInference done 3861/3957. Dataloading: 0.0022 s/iter. Inference: 0.0372 s/iter. Eval: 0.0555 s/iter. Total: 0.0951 s/iter. ETA=0:00:09\n",
      "\u001b[32m[07/05 17:49:20 d2.evaluation.evaluator]: \u001b[0mInference done 3886/3957. Dataloading: 0.0022 s/iter. Inference: 0.0373 s/iter. Eval: 0.0561 s/iter. Total: 0.0957 s/iter. ETA=0:00:06\n",
      "\u001b[32m[07/05 17:49:25 d2.evaluation.evaluator]: \u001b[0mInference done 3912/3957. Dataloading: 0.0022 s/iter. Inference: 0.0373 s/iter. Eval: 0.0567 s/iter. Total: 0.0964 s/iter. ETA=0:00:04\n",
      "\u001b[32m[07/05 17:49:30 d2.evaluation.evaluator]: \u001b[0mInference done 3938/3957. Dataloading: 0.0022 s/iter. Inference: 0.0374 s/iter. Eval: 0.0573 s/iter. Total: 0.0970 s/iter. ETA=0:00:01\n",
      "\u001b[32m[07/05 17:49:34 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:06:25.545131 (0.097557 s / iter per device, on 1 devices)\n",
      "\u001b[32m[07/05 17:49:34 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:02:28 (0.037456 s / iter per device, on 1 devices)\n",
      "\u001b[32m[07/05 17:49:35 d2.evaluation.sem_seg_evaluation]: \u001b[0mOrderedDict([('sem_seg', {'mIoU': 72.57972531915358, 'fwIoU': 92.7333838200948, 'IoU-Unlabeled': nan, 'IoU-Building': 92.06390424741141, 'IoU-Fence': 47.42055436650479, 'IoU-Pedestrian': 76.68900555173201, 'IoU-Pole': 59.23608503519737, 'IoU-Road': 98.30211219507557, 'IoU-SideWalk': 85.70507861514373, 'IoU-Vegetation': 87.29143533600158, 'IoU-Vehicles': 88.81822039656282, 'IoU-Wall': 77.7281068699923, 'IoU-TrafficSign': 60.67508574301003, 'IoU-Sky': 96.81569389334732, 'IoU-TrafficLight': 66.27814052115258, 'IoU-Terrain': 68.22078651842654, 'IoU-ConstructionVehicle': 65.45037509027344, 'IoU-workzone_object': 77.01264465824973, 'IoU-Detour': 13.568376068376068, 'mACC': 80.92400545606152, 'pACC': 96.06777524309665, 'ACC-Unlabeled': nan, 'ACC-Building': 96.46419014655937, 'ACC-Fence': 62.491604855826175, 'ACC-Pedestrian': 86.47336789452001, 'ACC-Pole': 69.88035566920665, 'ACC-Road': 99.22989887121449, 'ACC-SideWalk': 91.72882675343462, 'ACC-Vegetation': 94.7070439547505, 'ACC-Vehicles': 92.1862944344426, 'ACC-Wall': 87.28389191462287, 'ACC-TrafficSign': 70.25245468654462, 'ACC-Sky': 98.24887489468561, 'ACC-TrafficLight': 75.78194464593034, 'ACC-Terrain': 75.18230327982245, 'ACC-ConstructionVehicle': 94.43896465772335, 'ACC-workzone_object': 86.1893049348093, 'ACC-Detour': 14.244765702891327})])\n",
      "\u001b[32m[07/05 17:49:35 d2.engine.defaults]: \u001b[0mEvaluation results for combined_clear_val in csv format:\n",
      "\u001b[32m[07/05 17:49:35 d2.evaluation.testing]: \u001b[0mcopypaste: Task: sem_seg\n",
      "\u001b[32m[07/05 17:49:35 d2.evaluation.testing]: \u001b[0mcopypaste: mIoU,fwIoU,mACC,pACC\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/05 17:49:35 d2.evaluation.testing]: \u001b[0mcopypaste: 72.5797,92.7334,80.9240,96.0678\n"
     ]
    }
   ],
   "source": [
    "trainer_day = Detectron2Trainer('combined_all_train', 'combined_clear_val', output_folder='./output_day_40k')\n",
    "trainer_day.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "28d7e655",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/06 01:42:29 d2.engine.defaults]: \u001b[0mModel:\n",
      "SemanticSegmentor(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (sem_seg_head): SemSegFPNHead(\n",
      "    (p2): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "    )\n",
      "    (p3): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (1): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "    )\n",
      "    (p4): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (1): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      (2): Conv2d(\n",
      "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (3): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "    )\n",
      "    (p5): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (1): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      (2): Conv2d(\n",
      "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (3): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      (4): Conv2d(\n",
      "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (5): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "    )\n",
      "    (predictor): Conv2d(128, 17, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/06 01:42:29 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(720, 720), max_size=2048, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[07/06 01:42:29 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[07/06 01:42:29 d2.data.common]: \u001b[0mSerializing 10470 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[07/06 01:42:30 d2.data.common]: \u001b[0mSerialized dataset takes 3.22 MiB\n",
      "Last checkpoint: model_final.pth\n",
      "\u001b[32m[07/06 01:42:30 d2.checkpoint.c2_model_loading]: \u001b[0mFollowing weights matched with model:\n",
      "| Names in Model                       | Names in Checkpoint                                                                                  | Shapes                                          |\n",
      "|:-------------------------------------|:-----------------------------------------------------------------------------------------------------|:------------------------------------------------|\n",
      "| backbone.bottom_up.res2.0.conv1.*    | backbone.bottom_up.res2.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,1,1)             |\n",
      "| backbone.bottom_up.res2.0.conv2.*    | backbone.bottom_up.res2.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |\n",
      "| backbone.bottom_up.res2.0.conv3.*    | backbone.bottom_up.res2.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res2.0.shortcut.* | backbone.bottom_up.res2.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res2.1.conv1.*    | backbone.bottom_up.res2.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |\n",
      "| backbone.bottom_up.res2.1.conv2.*    | backbone.bottom_up.res2.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |\n",
      "| backbone.bottom_up.res2.1.conv3.*    | backbone.bottom_up.res2.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res2.2.conv1.*    | backbone.bottom_up.res2.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |\n",
      "| backbone.bottom_up.res2.2.conv2.*    | backbone.bottom_up.res2.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |\n",
      "| backbone.bottom_up.res2.2.conv3.*    | backbone.bottom_up.res2.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res3.0.conv1.*    | backbone.bottom_up.res3.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,256,1,1)       |\n",
      "| backbone.bottom_up.res3.0.conv2.*    | backbone.bottom_up.res3.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.0.conv3.*    | backbone.bottom_up.res3.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res3.0.shortcut.* | backbone.bottom_up.res3.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (512,) (512,) (512,) (512,) (512,256,1,1)       |\n",
      "| backbone.bottom_up.res3.1.conv1.*    | backbone.bottom_up.res3.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |\n",
      "| backbone.bottom_up.res3.1.conv2.*    | backbone.bottom_up.res3.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.1.conv3.*    | backbone.bottom_up.res3.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res3.2.conv1.*    | backbone.bottom_up.res3.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |\n",
      "| backbone.bottom_up.res3.2.conv2.*    | backbone.bottom_up.res3.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.2.conv3.*    | backbone.bottom_up.res3.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res3.3.conv1.*    | backbone.bottom_up.res3.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |\n",
      "| backbone.bottom_up.res3.3.conv2.*    | backbone.bottom_up.res3.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.3.conv3.*    | backbone.bottom_up.res3.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res4.0.conv1.*    | backbone.bottom_up.res4.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,512,1,1)       |\n",
      "| backbone.bottom_up.res4.0.conv2.*    | backbone.bottom_up.res4.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.0.conv3.*    | backbone.bottom_up.res4.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.0.shortcut.* | backbone.bottom_up.res4.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (1024,) (1024,) (1024,) (1024,) (1024,512,1,1)  |\n",
      "| backbone.bottom_up.res4.1.conv1.*    | backbone.bottom_up.res4.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.1.conv2.*    | backbone.bottom_up.res4.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.1.conv3.*    | backbone.bottom_up.res4.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.2.conv1.*    | backbone.bottom_up.res4.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.2.conv2.*    | backbone.bottom_up.res4.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.2.conv3.*    | backbone.bottom_up.res4.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.3.conv1.*    | backbone.bottom_up.res4.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.3.conv2.*    | backbone.bottom_up.res4.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.3.conv3.*    | backbone.bottom_up.res4.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.4.conv1.*    | backbone.bottom_up.res4.4.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.4.conv2.*    | backbone.bottom_up.res4.4.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.4.conv3.*    | backbone.bottom_up.res4.4.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.5.conv1.*    | backbone.bottom_up.res4.5.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.5.conv2.*    | backbone.bottom_up.res4.5.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.5.conv3.*    | backbone.bottom_up.res4.5.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res5.0.conv1.*    | backbone.bottom_up.res5.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,1024,1,1)      |\n",
      "| backbone.bottom_up.res5.0.conv2.*    | backbone.bottom_up.res5.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |\n",
      "| backbone.bottom_up.res5.0.conv3.*    | backbone.bottom_up.res5.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
      "| backbone.bottom_up.res5.0.shortcut.* | backbone.bottom_up.res5.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (2048,) (2048,) (2048,) (2048,) (2048,1024,1,1) |\n",
      "| backbone.bottom_up.res5.1.conv1.*    | backbone.bottom_up.res5.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |\n",
      "| backbone.bottom_up.res5.1.conv2.*    | backbone.bottom_up.res5.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |\n",
      "| backbone.bottom_up.res5.1.conv3.*    | backbone.bottom_up.res5.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
      "| backbone.bottom_up.res5.2.conv1.*    | backbone.bottom_up.res5.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |\n",
      "| backbone.bottom_up.res5.2.conv2.*    | backbone.bottom_up.res5.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |\n",
      "| backbone.bottom_up.res5.2.conv3.*    | backbone.bottom_up.res5.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
      "| backbone.bottom_up.stem.conv1.*      | backbone.bottom_up.stem.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}      | (64,) (64,) (64,) (64,) (64,3,7,7)              |\n",
      "| backbone.fpn_lateral2.*              | backbone.fpn_lateral2.{bias,weight}                                                                  | (256,) (256,256,1,1)                            |\n",
      "| backbone.fpn_lateral3.*              | backbone.fpn_lateral3.{bias,weight}                                                                  | (256,) (256,512,1,1)                            |\n",
      "| backbone.fpn_lateral4.*              | backbone.fpn_lateral4.{bias,weight}                                                                  | (256,) (256,1024,1,1)                           |\n",
      "| backbone.fpn_lateral5.*              | backbone.fpn_lateral5.{bias,weight}                                                                  | (256,) (256,2048,1,1)                           |\n",
      "| backbone.fpn_output2.*               | backbone.fpn_output2.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| backbone.fpn_output3.*               | backbone.fpn_output3.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| backbone.fpn_output4.*               | backbone.fpn_output4.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| backbone.fpn_output5.*               | backbone.fpn_output5.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| sem_seg_head.p2.0.*                  | sem_seg_head.p2.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p3.0.*                  | sem_seg_head.p3.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p4.0.*                  | sem_seg_head.p4.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p4.2.*                  | sem_seg_head.p4.2.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,128,3,3)                     |\n",
      "| sem_seg_head.p5.0.*                  | sem_seg_head.p5.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p5.2.*                  | sem_seg_head.p5.2.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,128,3,3)                     |\n",
      "| sem_seg_head.p5.4.*                  | sem_seg_head.p5.4.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,128,3,3)                     |\n",
      "| sem_seg_head.predictor.*             | sem_seg_head.predictor.{bias,weight}                                                                 | (17,) (17,128,1,1)                              |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/06 01:42:30 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(720, 720), max_size=2048, sample_style='choice')]\n",
      "\u001b[32m[07/06 01:42:30 d2.data.common]: \u001b[0mSerializing 1089 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[07/06 01:42:30 d2.data.common]: \u001b[0mSerialized dataset takes 0.33 MiB\n",
      "\u001b[32m[07/06 01:42:30 d2.evaluation.evaluator]: \u001b[0mStart inference on 1089 batches\n",
      "\u001b[32m[07/06 01:42:31 d2.evaluation.evaluator]: \u001b[0mInference done 11/1089. Dataloading: 0.0017 s/iter. Inference: 0.0351 s/iter. Eval: 0.0435 s/iter. Total: 0.0802 s/iter. ETA=0:01:26\n",
      "\u001b[32m[07/06 01:42:36 d2.evaluation.evaluator]: \u001b[0mInference done 75/1089. Dataloading: 0.0020 s/iter. Inference: 0.0361 s/iter. Eval: 0.0405 s/iter. Total: 0.0787 s/iter. ETA=0:01:19\n",
      "\u001b[32m[07/06 01:42:41 d2.evaluation.evaluator]: \u001b[0mInference done 139/1089. Dataloading: 0.0021 s/iter. Inference: 0.0363 s/iter. Eval: 0.0402 s/iter. Total: 0.0787 s/iter. ETA=0:01:14\n",
      "\u001b[32m[07/06 01:42:46 d2.evaluation.evaluator]: \u001b[0mInference done 203/1089. Dataloading: 0.0021 s/iter. Inference: 0.0365 s/iter. Eval: 0.0402 s/iter. Total: 0.0788 s/iter. ETA=0:01:09\n",
      "\u001b[32m[07/06 01:42:51 d2.evaluation.evaluator]: \u001b[0mInference done 266/1089. Dataloading: 0.0021 s/iter. Inference: 0.0364 s/iter. Eval: 0.0404 s/iter. Total: 0.0790 s/iter. ETA=0:01:04\n",
      "\u001b[32m[07/06 01:42:56 d2.evaluation.evaluator]: \u001b[0mInference done 330/1089. Dataloading: 0.0021 s/iter. Inference: 0.0363 s/iter. Eval: 0.0405 s/iter. Total: 0.0790 s/iter. ETA=0:00:59\n",
      "\u001b[32m[07/06 01:43:01 d2.evaluation.evaluator]: \u001b[0mInference done 393/1089. Dataloading: 0.0021 s/iter. Inference: 0.0364 s/iter. Eval: 0.0406 s/iter. Total: 0.0792 s/iter. ETA=0:00:55\n",
      "\u001b[32m[07/06 01:43:06 d2.evaluation.evaluator]: \u001b[0mInference done 456/1089. Dataloading: 0.0021 s/iter. Inference: 0.0364 s/iter. Eval: 0.0407 s/iter. Total: 0.0793 s/iter. ETA=0:00:50\n",
      "\u001b[32m[07/06 01:43:12 d2.evaluation.evaluator]: \u001b[0mInference done 520/1089. Dataloading: 0.0021 s/iter. Inference: 0.0364 s/iter. Eval: 0.0407 s/iter. Total: 0.0792 s/iter. ETA=0:00:45\n",
      "\u001b[32m[07/06 01:43:17 d2.evaluation.evaluator]: \u001b[0mInference done 583/1089. Dataloading: 0.0021 s/iter. Inference: 0.0364 s/iter. Eval: 0.0407 s/iter. Total: 0.0792 s/iter. ETA=0:00:40\n",
      "\u001b[32m[07/06 01:43:22 d2.evaluation.evaluator]: \u001b[0mInference done 645/1089. Dataloading: 0.0021 s/iter. Inference: 0.0364 s/iter. Eval: 0.0409 s/iter. Total: 0.0795 s/iter. ETA=0:00:35\n",
      "\u001b[32m[07/06 01:43:27 d2.evaluation.evaluator]: \u001b[0mInference done 709/1089. Dataloading: 0.0021 s/iter. Inference: 0.0364 s/iter. Eval: 0.0409 s/iter. Total: 0.0795 s/iter. ETA=0:00:30\n",
      "\u001b[32m[07/06 01:43:32 d2.evaluation.evaluator]: \u001b[0mInference done 773/1089. Dataloading: 0.0020 s/iter. Inference: 0.0364 s/iter. Eval: 0.0408 s/iter. Total: 0.0794 s/iter. ETA=0:00:25\n",
      "\u001b[32m[07/06 01:43:37 d2.evaluation.evaluator]: \u001b[0mInference done 837/1089. Dataloading: 0.0020 s/iter. Inference: 0.0365 s/iter. Eval: 0.0408 s/iter. Total: 0.0794 s/iter. ETA=0:00:19\n",
      "\u001b[32m[07/06 01:43:42 d2.evaluation.evaluator]: \u001b[0mInference done 902/1089. Dataloading: 0.0020 s/iter. Inference: 0.0365 s/iter. Eval: 0.0406 s/iter. Total: 0.0793 s/iter. ETA=0:00:14\n",
      "\u001b[32m[07/06 01:43:47 d2.evaluation.evaluator]: \u001b[0mInference done 966/1089. Dataloading: 0.0021 s/iter. Inference: 0.0365 s/iter. Eval: 0.0406 s/iter. Total: 0.0793 s/iter. ETA=0:00:09\n",
      "\u001b[32m[07/06 01:43:52 d2.evaluation.evaluator]: \u001b[0mInference done 1030/1089. Dataloading: 0.0021 s/iter. Inference: 0.0366 s/iter. Eval: 0.0406 s/iter. Total: 0.0792 s/iter. ETA=0:00:04\n",
      "\u001b[32m[07/06 01:43:57 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:01:26.035069 (0.079368 s / iter per device, on 1 devices)\n",
      "\u001b[32m[07/06 01:43:57 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:39 (0.036675 s / iter per device, on 1 devices)\n",
      "\u001b[32m[07/06 01:43:57 d2.evaluation.sem_seg_evaluation]: \u001b[0mOrderedDict([('sem_seg', {'mIoU': 70.65658340267612, 'fwIoU': 93.54253892076585, 'IoU-Unlabeled': nan, 'IoU-Building': 92.4357085713673, 'IoU-Fence': 39.99942544110861, 'IoU-Pedestrian': 49.89213396217993, 'IoU-Pole': 61.516318832051034, 'IoU-Road': 98.88607168328124, 'IoU-SideWalk': 89.29194464860377, 'IoU-Vegetation': 83.21684144309901, 'IoU-Vehicles': 86.16347341846715, 'IoU-Wall': 84.09272622073654, 'IoU-TrafficSign': 53.843796424944316, 'IoU-Sky': 96.94860158286586, 'IoU-TrafficLight': 72.18548471337229, 'IoU-Terrain': 70.67398365952097, 'IoU-ConstructionVehicle': 64.96856470717715, 'IoU-workzone_object': 73.30708101202389, 'IoU-Detour': 13.083178122018808, 'mACC': 79.26460120384327, 'pACC': 96.49941194264972, 'ACC-Unlabeled': nan, 'ACC-Building': 96.83793347377258, 'ACC-Fence': 53.834599112069995, 'ACC-Pedestrian': 66.33317581898305, 'ACC-Pole': 70.6898275679801, 'ACC-Road': 99.44627792703365, 'ACC-SideWalk': 94.43222149028806, 'ACC-Vegetation': 92.87118443061, 'ACC-Vehicles': 88.72898950370795, 'ACC-Wall': 93.70766240230967, 'ACC-TrafficSign': 63.35189604879342, 'ACC-Sky': 98.31288212814388, 'ACC-TrafficLight': 81.69657773715385, 'ACC-Terrain': 75.32256494142827, 'ACC-ConstructionVehicle': 94.22109815565713, 'ACC-workzone_object': 84.93004386593653, 'ACC-Detour': 13.516684657624257})])\n",
      "\u001b[32m[07/06 01:43:57 d2.engine.defaults]: \u001b[0mEvaluation results for carla_rain_val in csv format:\n",
      "\u001b[32m[07/06 01:43:57 d2.evaluation.testing]: \u001b[0mcopypaste: Task: sem_seg\n",
      "\u001b[32m[07/06 01:43:57 d2.evaluation.testing]: \u001b[0mcopypaste: mIoU,fwIoU,mACC,pACC\n",
      "\u001b[32m[07/06 01:43:57 d2.evaluation.testing]: \u001b[0mcopypaste: 70.6566,93.5425,79.2646,96.4994\n"
     ]
    }
   ],
   "source": [
    "trainer_day = Detectron2Trainer('combined_all_train', 'carla_rain_val', output_folder='./output_day_40k')\n",
    "trainer_day.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "50275fac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/06 01:43:57 d2.engine.defaults]: \u001b[0mModel:\n",
      "SemanticSegmentor(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (sem_seg_head): SemSegFPNHead(\n",
      "    (p2): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "    )\n",
      "    (p3): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (1): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "    )\n",
      "    (p4): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (1): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      (2): Conv2d(\n",
      "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (3): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "    )\n",
      "    (p5): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (1): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      (2): Conv2d(\n",
      "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (3): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      (4): Conv2d(\n",
      "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (5): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "    )\n",
      "    (predictor): Conv2d(128, 17, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/06 01:43:57 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(720, 720), max_size=2048, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[07/06 01:43:57 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[07/06 01:43:57 d2.data.common]: \u001b[0mSerializing 10470 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[07/06 01:43:57 d2.data.common]: \u001b[0mSerialized dataset takes 3.22 MiB\n",
      "Last checkpoint: model_final.pth\n",
      "\u001b[32m[07/06 01:43:58 d2.checkpoint.c2_model_loading]: \u001b[0mFollowing weights matched with model:\n",
      "| Names in Model                       | Names in Checkpoint                                                                                  | Shapes                                          |\n",
      "|:-------------------------------------|:-----------------------------------------------------------------------------------------------------|:------------------------------------------------|\n",
      "| backbone.bottom_up.res2.0.conv1.*    | backbone.bottom_up.res2.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,1,1)             |\n",
      "| backbone.bottom_up.res2.0.conv2.*    | backbone.bottom_up.res2.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |\n",
      "| backbone.bottom_up.res2.0.conv3.*    | backbone.bottom_up.res2.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res2.0.shortcut.* | backbone.bottom_up.res2.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res2.1.conv1.*    | backbone.bottom_up.res2.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |\n",
      "| backbone.bottom_up.res2.1.conv2.*    | backbone.bottom_up.res2.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |\n",
      "| backbone.bottom_up.res2.1.conv3.*    | backbone.bottom_up.res2.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res2.2.conv1.*    | backbone.bottom_up.res2.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |\n",
      "| backbone.bottom_up.res2.2.conv2.*    | backbone.bottom_up.res2.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |\n",
      "| backbone.bottom_up.res2.2.conv3.*    | backbone.bottom_up.res2.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res3.0.conv1.*    | backbone.bottom_up.res3.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,256,1,1)       |\n",
      "| backbone.bottom_up.res3.0.conv2.*    | backbone.bottom_up.res3.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.0.conv3.*    | backbone.bottom_up.res3.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res3.0.shortcut.* | backbone.bottom_up.res3.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (512,) (512,) (512,) (512,) (512,256,1,1)       |\n",
      "| backbone.bottom_up.res3.1.conv1.*    | backbone.bottom_up.res3.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |\n",
      "| backbone.bottom_up.res3.1.conv2.*    | backbone.bottom_up.res3.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.1.conv3.*    | backbone.bottom_up.res3.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res3.2.conv1.*    | backbone.bottom_up.res3.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |\n",
      "| backbone.bottom_up.res3.2.conv2.*    | backbone.bottom_up.res3.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.2.conv3.*    | backbone.bottom_up.res3.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res3.3.conv1.*    | backbone.bottom_up.res3.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |\n",
      "| backbone.bottom_up.res3.3.conv2.*    | backbone.bottom_up.res3.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.3.conv3.*    | backbone.bottom_up.res3.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res4.0.conv1.*    | backbone.bottom_up.res4.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,512,1,1)       |\n",
      "| backbone.bottom_up.res4.0.conv2.*    | backbone.bottom_up.res4.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.0.conv3.*    | backbone.bottom_up.res4.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.0.shortcut.* | backbone.bottom_up.res4.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (1024,) (1024,) (1024,) (1024,) (1024,512,1,1)  |\n",
      "| backbone.bottom_up.res4.1.conv1.*    | backbone.bottom_up.res4.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.1.conv2.*    | backbone.bottom_up.res4.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.1.conv3.*    | backbone.bottom_up.res4.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.2.conv1.*    | backbone.bottom_up.res4.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.2.conv2.*    | backbone.bottom_up.res4.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.2.conv3.*    | backbone.bottom_up.res4.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.3.conv1.*    | backbone.bottom_up.res4.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.3.conv2.*    | backbone.bottom_up.res4.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.3.conv3.*    | backbone.bottom_up.res4.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.4.conv1.*    | backbone.bottom_up.res4.4.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.4.conv2.*    | backbone.bottom_up.res4.4.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.4.conv3.*    | backbone.bottom_up.res4.4.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.5.conv1.*    | backbone.bottom_up.res4.5.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.5.conv2.*    | backbone.bottom_up.res4.5.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.5.conv3.*    | backbone.bottom_up.res4.5.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res5.0.conv1.*    | backbone.bottom_up.res5.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,1024,1,1)      |\n",
      "| backbone.bottom_up.res5.0.conv2.*    | backbone.bottom_up.res5.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |\n",
      "| backbone.bottom_up.res5.0.conv3.*    | backbone.bottom_up.res5.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
      "| backbone.bottom_up.res5.0.shortcut.* | backbone.bottom_up.res5.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (2048,) (2048,) (2048,) (2048,) (2048,1024,1,1) |\n",
      "| backbone.bottom_up.res5.1.conv1.*    | backbone.bottom_up.res5.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |\n",
      "| backbone.bottom_up.res5.1.conv2.*    | backbone.bottom_up.res5.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |\n",
      "| backbone.bottom_up.res5.1.conv3.*    | backbone.bottom_up.res5.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
      "| backbone.bottom_up.res5.2.conv1.*    | backbone.bottom_up.res5.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |\n",
      "| backbone.bottom_up.res5.2.conv2.*    | backbone.bottom_up.res5.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |\n",
      "| backbone.bottom_up.res5.2.conv3.*    | backbone.bottom_up.res5.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
      "| backbone.bottom_up.stem.conv1.*      | backbone.bottom_up.stem.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}      | (64,) (64,) (64,) (64,) (64,3,7,7)              |\n",
      "| backbone.fpn_lateral2.*              | backbone.fpn_lateral2.{bias,weight}                                                                  | (256,) (256,256,1,1)                            |\n",
      "| backbone.fpn_lateral3.*              | backbone.fpn_lateral3.{bias,weight}                                                                  | (256,) (256,512,1,1)                            |\n",
      "| backbone.fpn_lateral4.*              | backbone.fpn_lateral4.{bias,weight}                                                                  | (256,) (256,1024,1,1)                           |\n",
      "| backbone.fpn_lateral5.*              | backbone.fpn_lateral5.{bias,weight}                                                                  | (256,) (256,2048,1,1)                           |\n",
      "| backbone.fpn_output2.*               | backbone.fpn_output2.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| backbone.fpn_output3.*               | backbone.fpn_output3.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| backbone.fpn_output4.*               | backbone.fpn_output4.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| backbone.fpn_output5.*               | backbone.fpn_output5.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| sem_seg_head.p2.0.*                  | sem_seg_head.p2.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p3.0.*                  | sem_seg_head.p3.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p4.0.*                  | sem_seg_head.p4.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p4.2.*                  | sem_seg_head.p4.2.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,128,3,3)                     |\n",
      "| sem_seg_head.p5.0.*                  | sem_seg_head.p5.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p5.2.*                  | sem_seg_head.p5.2.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,128,3,3)                     |\n",
      "| sem_seg_head.p5.4.*                  | sem_seg_head.p5.4.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,128,3,3)                     |\n",
      "| sem_seg_head.predictor.*             | sem_seg_head.predictor.{bias,weight}                                                                 | (17,) (17,128,1,1)                              |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/06 01:43:58 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(720, 720), max_size=2048, sample_style='choice')]\n",
      "\u001b[32m[07/06 01:43:58 d2.data.common]: \u001b[0mSerializing 699 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[07/06 01:43:58 d2.data.common]: \u001b[0mSerialized dataset takes 0.21 MiB\n",
      "\u001b[32m[07/06 01:43:58 d2.evaluation.evaluator]: \u001b[0mStart inference on 699 batches\n",
      "\u001b[32m[07/06 01:44:00 d2.evaluation.evaluator]: \u001b[0mInference done 11/699. Dataloading: 0.0018 s/iter. Inference: 0.0408 s/iter. Eval: 0.1416 s/iter. Total: 0.1841 s/iter. ETA=0:02:06\n",
      "\u001b[32m[07/06 01:44:05 d2.evaluation.evaluator]: \u001b[0mInference done 38/699. Dataloading: 0.0021 s/iter. Inference: 0.0410 s/iter. Eval: 0.1432 s/iter. Total: 0.1865 s/iter. ETA=0:02:03\n",
      "\u001b[32m[07/06 01:44:10 d2.evaluation.evaluator]: \u001b[0mInference done 66/699. Dataloading: 0.0021 s/iter. Inference: 0.0416 s/iter. Eval: 0.1412 s/iter. Total: 0.1850 s/iter. ETA=0:01:57\n",
      "\u001b[32m[07/06 01:44:16 d2.evaluation.evaluator]: \u001b[0mInference done 93/699. Dataloading: 0.0021 s/iter. Inference: 0.0428 s/iter. Eval: 0.1418 s/iter. Total: 0.1868 s/iter. ETA=0:01:53\n",
      "\u001b[32m[07/06 01:44:21 d2.evaluation.evaluator]: \u001b[0mInference done 122/699. Dataloading: 0.0022 s/iter. Inference: 0.0426 s/iter. Eval: 0.1397 s/iter. Total: 0.1845 s/iter. ETA=0:01:46\n",
      "\u001b[32m[07/06 01:44:26 d2.evaluation.evaluator]: \u001b[0mInference done 151/699. Dataloading: 0.0022 s/iter. Inference: 0.0431 s/iter. Eval: 0.1371 s/iter. Total: 0.1825 s/iter. ETA=0:01:40\n",
      "\u001b[32m[07/06 01:44:31 d2.evaluation.evaluator]: \u001b[0mInference done 178/699. Dataloading: 0.0022 s/iter. Inference: 0.0434 s/iter. Eval: 0.1383 s/iter. Total: 0.1840 s/iter. ETA=0:01:35\n",
      "\u001b[32m[07/06 01:44:36 d2.evaluation.evaluator]: \u001b[0mInference done 204/699. Dataloading: 0.0022 s/iter. Inference: 0.0435 s/iter. Eval: 0.1395 s/iter. Total: 0.1853 s/iter. ETA=0:01:31\n",
      "\u001b[32m[07/06 01:44:41 d2.evaluation.evaluator]: \u001b[0mInference done 230/699. Dataloading: 0.0022 s/iter. Inference: 0.0435 s/iter. Eval: 0.1407 s/iter. Total: 0.1865 s/iter. ETA=0:01:27\n",
      "\u001b[32m[07/06 01:44:46 d2.evaluation.evaluator]: \u001b[0mInference done 257/699. Dataloading: 0.0021 s/iter. Inference: 0.0432 s/iter. Eval: 0.1409 s/iter. Total: 0.1864 s/iter. ETA=0:01:22\n",
      "\u001b[32m[07/06 01:44:51 d2.evaluation.evaluator]: \u001b[0mInference done 285/699. Dataloading: 0.0021 s/iter. Inference: 0.0431 s/iter. Eval: 0.1407 s/iter. Total: 0.1860 s/iter. ETA=0:01:17\n",
      "\u001b[32m[07/06 01:44:56 d2.evaluation.evaluator]: \u001b[0mInference done 312/699. Dataloading: 0.0021 s/iter. Inference: 0.0433 s/iter. Eval: 0.1410 s/iter. Total: 0.1865 s/iter. ETA=0:01:12\n",
      "\u001b[32m[07/06 01:45:01 d2.evaluation.evaluator]: \u001b[0mInference done 339/699. Dataloading: 0.0021 s/iter. Inference: 0.0431 s/iter. Eval: 0.1412 s/iter. Total: 0.1865 s/iter. ETA=0:01:07\n",
      "\u001b[32m[07/06 01:45:07 d2.evaluation.evaluator]: \u001b[0mInference done 366/699. Dataloading: 0.0021 s/iter. Inference: 0.0433 s/iter. Eval: 0.1415 s/iter. Total: 0.1870 s/iter. ETA=0:01:02\n",
      "\u001b[32m[07/06 01:45:12 d2.evaluation.evaluator]: \u001b[0mInference done 393/699. Dataloading: 0.0021 s/iter. Inference: 0.0433 s/iter. Eval: 0.1418 s/iter. Total: 0.1874 s/iter. ETA=0:00:57\n",
      "\u001b[32m[07/06 01:45:17 d2.evaluation.evaluator]: \u001b[0mInference done 420/699. Dataloading: 0.0021 s/iter. Inference: 0.0433 s/iter. Eval: 0.1419 s/iter. Total: 0.1875 s/iter. ETA=0:00:52\n",
      "\u001b[32m[07/06 01:45:22 d2.evaluation.evaluator]: \u001b[0mInference done 447/699. Dataloading: 0.0021 s/iter. Inference: 0.0434 s/iter. Eval: 0.1419 s/iter. Total: 0.1875 s/iter. ETA=0:00:47\n",
      "\u001b[32m[07/06 01:45:27 d2.evaluation.evaluator]: \u001b[0mInference done 475/699. Dataloading: 0.0021 s/iter. Inference: 0.0434 s/iter. Eval: 0.1417 s/iter. Total: 0.1873 s/iter. ETA=0:00:41\n",
      "\u001b[32m[07/06 01:45:32 d2.evaluation.evaluator]: \u001b[0mInference done 502/699. Dataloading: 0.0021 s/iter. Inference: 0.0433 s/iter. Eval: 0.1420 s/iter. Total: 0.1876 s/iter. ETA=0:00:36\n",
      "\u001b[32m[07/06 01:45:38 d2.evaluation.evaluator]: \u001b[0mInference done 529/699. Dataloading: 0.0021 s/iter. Inference: 0.0434 s/iter. Eval: 0.1421 s/iter. Total: 0.1877 s/iter. ETA=0:00:31\n",
      "\u001b[32m[07/06 01:45:43 d2.evaluation.evaluator]: \u001b[0mInference done 556/699. Dataloading: 0.0021 s/iter. Inference: 0.0434 s/iter. Eval: 0.1422 s/iter. Total: 0.1878 s/iter. ETA=0:00:26\n",
      "\u001b[32m[07/06 01:45:48 d2.evaluation.evaluator]: \u001b[0mInference done 583/699. Dataloading: 0.0021 s/iter. Inference: 0.0434 s/iter. Eval: 0.1422 s/iter. Total: 0.1878 s/iter. ETA=0:00:21\n",
      "\u001b[32m[07/06 01:45:53 d2.evaluation.evaluator]: \u001b[0mInference done 610/699. Dataloading: 0.0021 s/iter. Inference: 0.0433 s/iter. Eval: 0.1422 s/iter. Total: 0.1878 s/iter. ETA=0:00:16\n",
      "\u001b[32m[07/06 01:45:58 d2.evaluation.evaluator]: \u001b[0mInference done 637/699. Dataloading: 0.0021 s/iter. Inference: 0.0433 s/iter. Eval: 0.1423 s/iter. Total: 0.1878 s/iter. ETA=0:00:11\n",
      "\u001b[32m[07/06 01:46:03 d2.evaluation.evaluator]: \u001b[0mInference done 665/699. Dataloading: 0.0021 s/iter. Inference: 0.0433 s/iter. Eval: 0.1421 s/iter. Total: 0.1876 s/iter. ETA=0:00:06\n",
      "\u001b[32m[07/06 01:46:08 d2.evaluation.evaluator]: \u001b[0mInference done 692/699. Dataloading: 0.0021 s/iter. Inference: 0.0434 s/iter. Eval: 0.1420 s/iter. Total: 0.1876 s/iter. ETA=0:00:01\n",
      "\u001b[32m[07/06 01:46:09 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:02:10.314104 (0.187772 s / iter per device, on 1 devices)\n",
      "\u001b[32m[07/06 01:46:09 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:30 (0.043382 s / iter per device, on 1 devices)\n",
      "\u001b[32m[07/06 01:46:10 d2.evaluation.sem_seg_evaluation]: \u001b[0mOrderedDict([('sem_seg', {'mIoU': 68.27497496156779, 'fwIoU': 90.54222469653251, 'IoU-Unlabeled': nan, 'IoU-Building': 90.95151887105693, 'IoU-Fence': 53.88990981542023, 'IoU-Pedestrian': 78.59215957143144, 'IoU-Pole': 52.34811183560251, 'IoU-Road': 96.59802986516829, 'IoU-SideWalk': 78.45267701614065, 'IoU-Vegetation': 90.63849078184234, 'IoU-Vehicles': 90.63397594364459, 'IoU-Wall': 47.886202117233964, 'IoU-TrafficSign': 65.16298754425989, 'IoU-Sky': 94.42793136159932, 'IoU-TrafficLight': 54.94849511378834, 'IoU-Terrain': 61.31915962476071, 'IoU-ConstructionVehicle': nan, 'IoU-workzone_object': nan, 'IoU-Detour': nan, 'mACC': 81.66100922476338, 'pACC': 94.83526786813839, 'ACC-Unlabeled': nan, 'ACC-Building': 95.52912243347846, 'ACC-Fence': 69.97655961658118, 'ACC-Pedestrian': 87.89507311171357, 'ACC-Pole': 66.67424607134652, 'ACC-Road': 98.66681995539273, 'ACC-SideWalk': 85.5500166377243, 'ACC-Vegetation': 95.99024507250238, 'ACC-Vehicles': 95.08266646671878, 'ACC-Wall': 57.816199795229764, 'ACC-TrafficSign': 74.81764880542683, 'ACC-Sky': 97.46374173792567, 'ACC-TrafficLight': 63.813659885663846, 'ACC-Terrain': 72.31712033221986, 'ACC-ConstructionVehicle': nan, 'ACC-workzone_object': nan, 'ACC-Detour': nan})])\n",
      "\u001b[32m[07/06 01:46:10 d2.engine.defaults]: \u001b[0mEvaluation results for cityscapes_rain_val in csv format:\n",
      "\u001b[32m[07/06 01:46:10 d2.evaluation.testing]: \u001b[0mcopypaste: Task: sem_seg\n",
      "\u001b[32m[07/06 01:46:10 d2.evaluation.testing]: \u001b[0mcopypaste: mIoU,fwIoU,mACC,pACC\n",
      "\u001b[32m[07/06 01:46:10 d2.evaluation.testing]: \u001b[0mcopypaste: 68.2750,90.5422,81.6610,94.8353\n"
     ]
    }
   ],
   "source": [
    "trainer_day = Detectron2Trainer('combined_all_train', 'cityscapes_rain_val', output_folder='./output_day_40k')\n",
    "trainer_day.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c69f032f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/06 01:46:10 d2.engine.defaults]: \u001b[0mModel:\n",
      "SemanticSegmentor(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (sem_seg_head): SemSegFPNHead(\n",
      "    (p2): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "    )\n",
      "    (p3): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (1): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "    )\n",
      "    (p4): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (1): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      (2): Conv2d(\n",
      "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (3): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "    )\n",
      "    (p5): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (1): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      (2): Conv2d(\n",
      "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (3): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      (4): Conv2d(\n",
      "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (5): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "    )\n",
      "    (predictor): Conv2d(128, 17, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/06 01:46:10 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(720, 720), max_size=2048, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[07/06 01:46:10 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[07/06 01:46:10 d2.data.common]: \u001b[0mSerializing 10470 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[07/06 01:46:10 d2.data.common]: \u001b[0mSerialized dataset takes 3.22 MiB\n",
      "Last checkpoint: model_final.pth\n",
      "\u001b[32m[07/06 01:46:10 d2.checkpoint.c2_model_loading]: \u001b[0mFollowing weights matched with model:\n",
      "| Names in Model                       | Names in Checkpoint                                                                                  | Shapes                                          |\n",
      "|:-------------------------------------|:-----------------------------------------------------------------------------------------------------|:------------------------------------------------|\n",
      "| backbone.bottom_up.res2.0.conv1.*    | backbone.bottom_up.res2.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,1,1)             |\n",
      "| backbone.bottom_up.res2.0.conv2.*    | backbone.bottom_up.res2.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |\n",
      "| backbone.bottom_up.res2.0.conv3.*    | backbone.bottom_up.res2.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res2.0.shortcut.* | backbone.bottom_up.res2.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res2.1.conv1.*    | backbone.bottom_up.res2.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |\n",
      "| backbone.bottom_up.res2.1.conv2.*    | backbone.bottom_up.res2.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |\n",
      "| backbone.bottom_up.res2.1.conv3.*    | backbone.bottom_up.res2.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res2.2.conv1.*    | backbone.bottom_up.res2.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |\n",
      "| backbone.bottom_up.res2.2.conv2.*    | backbone.bottom_up.res2.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |\n",
      "| backbone.bottom_up.res2.2.conv3.*    | backbone.bottom_up.res2.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res3.0.conv1.*    | backbone.bottom_up.res3.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,256,1,1)       |\n",
      "| backbone.bottom_up.res3.0.conv2.*    | backbone.bottom_up.res3.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.0.conv3.*    | backbone.bottom_up.res3.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res3.0.shortcut.* | backbone.bottom_up.res3.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (512,) (512,) (512,) (512,) (512,256,1,1)       |\n",
      "| backbone.bottom_up.res3.1.conv1.*    | backbone.bottom_up.res3.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |\n",
      "| backbone.bottom_up.res3.1.conv2.*    | backbone.bottom_up.res3.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.1.conv3.*    | backbone.bottom_up.res3.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res3.2.conv1.*    | backbone.bottom_up.res3.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |\n",
      "| backbone.bottom_up.res3.2.conv2.*    | backbone.bottom_up.res3.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.2.conv3.*    | backbone.bottom_up.res3.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res3.3.conv1.*    | backbone.bottom_up.res3.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |\n",
      "| backbone.bottom_up.res3.3.conv2.*    | backbone.bottom_up.res3.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.3.conv3.*    | backbone.bottom_up.res3.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res4.0.conv1.*    | backbone.bottom_up.res4.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,512,1,1)       |\n",
      "| backbone.bottom_up.res4.0.conv2.*    | backbone.bottom_up.res4.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.0.conv3.*    | backbone.bottom_up.res4.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.0.shortcut.* | backbone.bottom_up.res4.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (1024,) (1024,) (1024,) (1024,) (1024,512,1,1)  |\n",
      "| backbone.bottom_up.res4.1.conv1.*    | backbone.bottom_up.res4.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.1.conv2.*    | backbone.bottom_up.res4.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.1.conv3.*    | backbone.bottom_up.res4.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.2.conv1.*    | backbone.bottom_up.res4.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.2.conv2.*    | backbone.bottom_up.res4.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.2.conv3.*    | backbone.bottom_up.res4.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.3.conv1.*    | backbone.bottom_up.res4.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.3.conv2.*    | backbone.bottom_up.res4.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.3.conv3.*    | backbone.bottom_up.res4.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.4.conv1.*    | backbone.bottom_up.res4.4.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.4.conv2.*    | backbone.bottom_up.res4.4.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.4.conv3.*    | backbone.bottom_up.res4.4.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.5.conv1.*    | backbone.bottom_up.res4.5.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.5.conv2.*    | backbone.bottom_up.res4.5.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.5.conv3.*    | backbone.bottom_up.res4.5.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res5.0.conv1.*    | backbone.bottom_up.res5.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,1024,1,1)      |\n",
      "| backbone.bottom_up.res5.0.conv2.*    | backbone.bottom_up.res5.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |\n",
      "| backbone.bottom_up.res5.0.conv3.*    | backbone.bottom_up.res5.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
      "| backbone.bottom_up.res5.0.shortcut.* | backbone.bottom_up.res5.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (2048,) (2048,) (2048,) (2048,) (2048,1024,1,1) |\n",
      "| backbone.bottom_up.res5.1.conv1.*    | backbone.bottom_up.res5.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |\n",
      "| backbone.bottom_up.res5.1.conv2.*    | backbone.bottom_up.res5.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |\n",
      "| backbone.bottom_up.res5.1.conv3.*    | backbone.bottom_up.res5.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
      "| backbone.bottom_up.res5.2.conv1.*    | backbone.bottom_up.res5.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |\n",
      "| backbone.bottom_up.res5.2.conv2.*    | backbone.bottom_up.res5.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |\n",
      "| backbone.bottom_up.res5.2.conv3.*    | backbone.bottom_up.res5.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
      "| backbone.bottom_up.stem.conv1.*      | backbone.bottom_up.stem.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}      | (64,) (64,) (64,) (64,) (64,3,7,7)              |\n",
      "| backbone.fpn_lateral2.*              | backbone.fpn_lateral2.{bias,weight}                                                                  | (256,) (256,256,1,1)                            |\n",
      "| backbone.fpn_lateral3.*              | backbone.fpn_lateral3.{bias,weight}                                                                  | (256,) (256,512,1,1)                            |\n",
      "| backbone.fpn_lateral4.*              | backbone.fpn_lateral4.{bias,weight}                                                                  | (256,) (256,1024,1,1)                           |\n",
      "| backbone.fpn_lateral5.*              | backbone.fpn_lateral5.{bias,weight}                                                                  | (256,) (256,2048,1,1)                           |\n",
      "| backbone.fpn_output2.*               | backbone.fpn_output2.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| backbone.fpn_output3.*               | backbone.fpn_output3.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| backbone.fpn_output4.*               | backbone.fpn_output4.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| backbone.fpn_output5.*               | backbone.fpn_output5.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| sem_seg_head.p2.0.*                  | sem_seg_head.p2.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p3.0.*                  | sem_seg_head.p3.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p4.0.*                  | sem_seg_head.p4.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p4.2.*                  | sem_seg_head.p4.2.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,128,3,3)                     |\n",
      "| sem_seg_head.p5.0.*                  | sem_seg_head.p5.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p5.2.*                  | sem_seg_head.p5.2.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,128,3,3)                     |\n",
      "| sem_seg_head.p5.4.*                  | sem_seg_head.p5.4.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,128,3,3)                     |\n",
      "| sem_seg_head.predictor.*             | sem_seg_head.predictor.{bias,weight}                                                                 | (17,) (17,128,1,1)                              |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/06 01:46:11 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(720, 720), max_size=2048, sample_style='choice')]\n",
      "\u001b[32m[07/06 01:46:11 d2.data.common]: \u001b[0mSerializing 1788 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[07/06 01:46:11 d2.data.common]: \u001b[0mSerialized dataset takes 0.54 MiB\n",
      "\u001b[32m[07/06 01:46:11 d2.evaluation.evaluator]: \u001b[0mStart inference on 1788 batches\n",
      "\u001b[32m[07/06 01:46:13 d2.evaluation.evaluator]: \u001b[0mInference done 28/1788. Dataloading: 0.0019 s/iter. Inference: 0.0367 s/iter. Eval: 0.0429 s/iter. Total: 0.0816 s/iter. ETA=0:02:23\n",
      "\u001b[32m[07/06 01:46:18 d2.evaluation.evaluator]: \u001b[0mInference done 92/1788. Dataloading: 0.0020 s/iter. Inference: 0.0368 s/iter. Eval: 0.0404 s/iter. Total: 0.0793 s/iter. ETA=0:02:14\n",
      "\u001b[32m[07/06 01:46:23 d2.evaluation.evaluator]: \u001b[0mInference done 156/1788. Dataloading: 0.0020 s/iter. Inference: 0.0368 s/iter. Eval: 0.0401 s/iter. Total: 0.0790 s/iter. ETA=0:02:08\n",
      "\u001b[32m[07/06 01:46:28 d2.evaluation.evaluator]: \u001b[0mInference done 219/1788. Dataloading: 0.0020 s/iter. Inference: 0.0367 s/iter. Eval: 0.0403 s/iter. Total: 0.0792 s/iter. ETA=0:02:04\n",
      "\u001b[32m[07/06 01:46:33 d2.evaluation.evaluator]: \u001b[0mInference done 281/1788. Dataloading: 0.0021 s/iter. Inference: 0.0368 s/iter. Eval: 0.0406 s/iter. Total: 0.0796 s/iter. ETA=0:01:59\n",
      "\u001b[32m[07/06 01:46:38 d2.evaluation.evaluator]: \u001b[0mInference done 343/1788. Dataloading: 0.0021 s/iter. Inference: 0.0368 s/iter. Eval: 0.0409 s/iter. Total: 0.0799 s/iter. ETA=0:01:55\n",
      "\u001b[32m[07/06 01:46:43 d2.evaluation.evaluator]: \u001b[0mInference done 405/1788. Dataloading: 0.0021 s/iter. Inference: 0.0369 s/iter. Eval: 0.0411 s/iter. Total: 0.0801 s/iter. ETA=0:01:50\n",
      "\u001b[32m[07/06 01:46:48 d2.evaluation.evaluator]: \u001b[0mInference done 467/1788. Dataloading: 0.0021 s/iter. Inference: 0.0368 s/iter. Eval: 0.0412 s/iter. Total: 0.0802 s/iter. ETA=0:01:45\n",
      "\u001b[32m[07/06 01:46:53 d2.evaluation.evaluator]: \u001b[0mInference done 529/1788. Dataloading: 0.0021 s/iter. Inference: 0.0369 s/iter. Eval: 0.0413 s/iter. Total: 0.0803 s/iter. ETA=0:01:41\n",
      "\u001b[32m[07/06 01:46:58 d2.evaluation.evaluator]: \u001b[0mInference done 592/1788. Dataloading: 0.0021 s/iter. Inference: 0.0368 s/iter. Eval: 0.0413 s/iter. Total: 0.0803 s/iter. ETA=0:01:36\n",
      "\u001b[32m[07/06 01:47:03 d2.evaluation.evaluator]: \u001b[0mInference done 653/1788. Dataloading: 0.0021 s/iter. Inference: 0.0369 s/iter. Eval: 0.0415 s/iter. Total: 0.0805 s/iter. ETA=0:01:31\n",
      "\u001b[32m[07/06 01:47:09 d2.evaluation.evaluator]: \u001b[0mInference done 717/1788. Dataloading: 0.0021 s/iter. Inference: 0.0368 s/iter. Eval: 0.0414 s/iter. Total: 0.0804 s/iter. ETA=0:01:26\n",
      "\u001b[32m[07/06 01:47:14 d2.evaluation.evaluator]: \u001b[0mInference done 781/1788. Dataloading: 0.0021 s/iter. Inference: 0.0368 s/iter. Eval: 0.0413 s/iter. Total: 0.0803 s/iter. ETA=0:01:20\n",
      "\u001b[32m[07/06 01:47:19 d2.evaluation.evaluator]: \u001b[0mInference done 846/1788. Dataloading: 0.0021 s/iter. Inference: 0.0368 s/iter. Eval: 0.0411 s/iter. Total: 0.0801 s/iter. ETA=0:01:15\n",
      "\u001b[32m[07/06 01:47:24 d2.evaluation.evaluator]: \u001b[0mInference done 911/1788. Dataloading: 0.0021 s/iter. Inference: 0.0368 s/iter. Eval: 0.0409 s/iter. Total: 0.0799 s/iter. ETA=0:01:10\n",
      "\u001b[32m[07/06 01:47:29 d2.evaluation.evaluator]: \u001b[0mInference done 976/1788. Dataloading: 0.0020 s/iter. Inference: 0.0368 s/iter. Eval: 0.0407 s/iter. Total: 0.0797 s/iter. ETA=0:01:04\n",
      "\u001b[32m[07/06 01:47:34 d2.evaluation.evaluator]: \u001b[0mInference done 1042/1788. Dataloading: 0.0021 s/iter. Inference: 0.0368 s/iter. Eval: 0.0406 s/iter. Total: 0.0795 s/iter. ETA=0:00:59\n",
      "\u001b[32m[07/06 01:47:39 d2.evaluation.evaluator]: \u001b[0mInference done 1096/1788. Dataloading: 0.0020 s/iter. Inference: 0.0369 s/iter. Eval: 0.0412 s/iter. Total: 0.0802 s/iter. ETA=0:00:55\n",
      "\u001b[32m[07/06 01:47:44 d2.evaluation.evaluator]: \u001b[0mInference done 1122/1788. Dataloading: 0.0021 s/iter. Inference: 0.0371 s/iter. Eval: 0.0436 s/iter. Total: 0.0828 s/iter. ETA=0:00:55\n",
      "\u001b[32m[07/06 01:47:49 d2.evaluation.evaluator]: \u001b[0mInference done 1148/1788. Dataloading: 0.0021 s/iter. Inference: 0.0373 s/iter. Eval: 0.0459 s/iter. Total: 0.0854 s/iter. ETA=0:00:54\n",
      "\u001b[32m[07/06 01:47:54 d2.evaluation.evaluator]: \u001b[0mInference done 1175/1788. Dataloading: 0.0021 s/iter. Inference: 0.0375 s/iter. Eval: 0.0482 s/iter. Total: 0.0878 s/iter. ETA=0:00:53\n",
      "\u001b[32m[07/06 01:47:59 d2.evaluation.evaluator]: \u001b[0mInference done 1203/1788. Dataloading: 0.0021 s/iter. Inference: 0.0376 s/iter. Eval: 0.0503 s/iter. Total: 0.0900 s/iter. ETA=0:00:52\n",
      "\u001b[32m[07/06 01:48:04 d2.evaluation.evaluator]: \u001b[0mInference done 1232/1788. Dataloading: 0.0021 s/iter. Inference: 0.0377 s/iter. Eval: 0.0522 s/iter. Total: 0.0921 s/iter. ETA=0:00:51\n",
      "\u001b[32m[07/06 01:48:09 d2.evaluation.evaluator]: \u001b[0mInference done 1260/1788. Dataloading: 0.0021 s/iter. Inference: 0.0378 s/iter. Eval: 0.0541 s/iter. Total: 0.0941 s/iter. ETA=0:00:49\n",
      "\u001b[32m[07/06 01:48:14 d2.evaluation.evaluator]: \u001b[0mInference done 1287/1788. Dataloading: 0.0021 s/iter. Inference: 0.0380 s/iter. Eval: 0.0560 s/iter. Total: 0.0961 s/iter. ETA=0:00:48\n",
      "\u001b[32m[07/06 01:48:20 d2.evaluation.evaluator]: \u001b[0mInference done 1312/1788. Dataloading: 0.0022 s/iter. Inference: 0.0381 s/iter. Eval: 0.0577 s/iter. Total: 0.0981 s/iter. ETA=0:00:46\n",
      "\u001b[32m[07/06 01:48:25 d2.evaluation.evaluator]: \u001b[0mInference done 1338/1788. Dataloading: 0.0022 s/iter. Inference: 0.0382 s/iter. Eval: 0.0595 s/iter. Total: 0.1000 s/iter. ETA=0:00:44\n",
      "\u001b[32m[07/06 01:48:30 d2.evaluation.evaluator]: \u001b[0mInference done 1364/1788. Dataloading: 0.0022 s/iter. Inference: 0.0383 s/iter. Eval: 0.0612 s/iter. Total: 0.1018 s/iter. ETA=0:00:43\n",
      "\u001b[32m[07/06 01:48:35 d2.evaluation.evaluator]: \u001b[0mInference done 1391/1788. Dataloading: 0.0022 s/iter. Inference: 0.0384 s/iter. Eval: 0.0628 s/iter. Total: 0.1035 s/iter. ETA=0:00:41\n",
      "\u001b[32m[07/06 01:48:40 d2.evaluation.evaluator]: \u001b[0mInference done 1417/1788. Dataloading: 0.0022 s/iter. Inference: 0.0385 s/iter. Eval: 0.0644 s/iter. Total: 0.1052 s/iter. ETA=0:00:39\n",
      "\u001b[32m[07/06 01:48:45 d2.evaluation.evaluator]: \u001b[0mInference done 1443/1788. Dataloading: 0.0022 s/iter. Inference: 0.0386 s/iter. Eval: 0.0659 s/iter. Total: 0.1068 s/iter. ETA=0:00:36\n",
      "\u001b[32m[07/06 01:48:50 d2.evaluation.evaluator]: \u001b[0mInference done 1469/1788. Dataloading: 0.0022 s/iter. Inference: 0.0387 s/iter. Eval: 0.0674 s/iter. Total: 0.1084 s/iter. ETA=0:00:34\n",
      "\u001b[32m[07/06 01:48:55 d2.evaluation.evaluator]: \u001b[0mInference done 1495/1788. Dataloading: 0.0022 s/iter. Inference: 0.0388 s/iter. Eval: 0.0688 s/iter. Total: 0.1099 s/iter. ETA=0:00:32\n",
      "\u001b[32m[07/06 01:49:00 d2.evaluation.evaluator]: \u001b[0mInference done 1522/1788. Dataloading: 0.0022 s/iter. Inference: 0.0389 s/iter. Eval: 0.0702 s/iter. Total: 0.1114 s/iter. ETA=0:00:29\n",
      "\u001b[32m[07/06 01:49:05 d2.evaluation.evaluator]: \u001b[0mInference done 1549/1788. Dataloading: 0.0022 s/iter. Inference: 0.0390 s/iter. Eval: 0.0714 s/iter. Total: 0.1127 s/iter. ETA=0:00:26\n",
      "\u001b[32m[07/06 01:49:10 d2.evaluation.evaluator]: \u001b[0mInference done 1576/1788. Dataloading: 0.0022 s/iter. Inference: 0.0391 s/iter. Eval: 0.0727 s/iter. Total: 0.1141 s/iter. ETA=0:00:24\n",
      "\u001b[32m[07/06 01:49:16 d2.evaluation.evaluator]: \u001b[0mInference done 1603/1788. Dataloading: 0.0022 s/iter. Inference: 0.0392 s/iter. Eval: 0.0739 s/iter. Total: 0.1154 s/iter. ETA=0:00:21\n",
      "\u001b[32m[07/06 01:49:21 d2.evaluation.evaluator]: \u001b[0mInference done 1630/1788. Dataloading: 0.0022 s/iter. Inference: 0.0393 s/iter. Eval: 0.0750 s/iter. Total: 0.1166 s/iter. ETA=0:00:18\n",
      "\u001b[32m[07/06 01:49:26 d2.evaluation.evaluator]: \u001b[0mInference done 1656/1788. Dataloading: 0.0022 s/iter. Inference: 0.0394 s/iter. Eval: 0.0762 s/iter. Total: 0.1178 s/iter. ETA=0:00:15\n",
      "\u001b[32m[07/06 01:49:31 d2.evaluation.evaluator]: \u001b[0mInference done 1682/1788. Dataloading: 0.0022 s/iter. Inference: 0.0394 s/iter. Eval: 0.0773 s/iter. Total: 0.1190 s/iter. ETA=0:00:12\n",
      "\u001b[32m[07/06 01:49:36 d2.evaluation.evaluator]: \u001b[0mInference done 1708/1788. Dataloading: 0.0022 s/iter. Inference: 0.0395 s/iter. Eval: 0.0784 s/iter. Total: 0.1201 s/iter. ETA=0:00:09\n",
      "\u001b[32m[07/06 01:49:41 d2.evaluation.evaluator]: \u001b[0mInference done 1735/1788. Dataloading: 0.0022 s/iter. Inference: 0.0395 s/iter. Eval: 0.0794 s/iter. Total: 0.1212 s/iter. ETA=0:00:06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/06 01:49:46 d2.evaluation.evaluator]: \u001b[0mInference done 1762/1788. Dataloading: 0.0022 s/iter. Inference: 0.0396 s/iter. Eval: 0.0804 s/iter. Total: 0.1222 s/iter. ETA=0:00:03\n",
      "\u001b[32m[07/06 01:49:51 d2.evaluation.evaluator]: \u001b[0mInference done 1788/1788. Dataloading: 0.0022 s/iter. Inference: 0.0397 s/iter. Eval: 0.0814 s/iter. Total: 0.1233 s/iter. ETA=0:00:00\n",
      "\u001b[32m[07/06 01:49:51 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:03:39.953208 (0.123361 s / iter per device, on 1 devices)\n",
      "\u001b[32m[07/06 01:49:51 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:01:10 (0.039664 s / iter per device, on 1 devices)\n",
      "\u001b[32m[07/06 01:49:52 d2.evaluation.sem_seg_evaluation]: \u001b[0mOrderedDict([('sem_seg', {'mIoU': 71.31689084175994, 'fwIoU': 91.76156662378858, 'IoU-Unlabeled': nan, 'IoU-Building': 91.57833519727593, 'IoU-Fence': 49.99255167142559, 'IoU-Pedestrian': 77.75145973685973, 'IoU-Pole': 57.0295706008061, 'IoU-Road': 97.59723285476997, 'IoU-SideWalk': 82.1070664544052, 'IoU-Vegetation': 88.92481603512218, 'IoU-Vehicles': 89.67159035902603, 'IoU-Wall': 68.99875864592364, 'IoU-TrafficSign': 63.31109616916778, 'IoU-Sky': 96.3353623946222, 'IoU-TrafficLight': 61.81497353936507, 'IoU-Terrain': 65.06749561168473, 'IoU-ConstructionVehicle': 64.49968506366213, 'IoU-workzone_object': 73.30708101202389, 'IoU-Detour': 13.083178122018808, 'mACC': 80.14276231271798, 'pACC': 95.53010194175157, 'ACC-Unlabeled': nan, 'ACC-Building': 96.0826949613917, 'ACC-Fence': 65.56332379329052, 'ACC-Pedestrian': 87.36129904246643, 'ACC-Pole': 68.82773185995748, 'ACC-Road': 99.01019717729143, 'ACC-SideWalk': 88.60570381247574, 'ACC-Vegetation': 95.29865962680674, 'ACC-Vehicles': 93.69483624135428, 'ACC-Wall': 79.43961786686, 'ACC-TrafficSign': 72.97983384590184, 'ACC-Sky': 98.10904931628095, 'ACC-TrafficLight': 71.0483019578446, 'ACC-Terrain': 73.59512082234788, 'ACC-ConstructionVehicle': 94.22109815565713, 'ACC-workzone_object': 84.93004386593653, 'ACC-Detour': 13.516684657624257})])\n",
      "\u001b[32m[07/06 01:49:52 d2.engine.defaults]: \u001b[0mEvaluation results for combined_rain_val in csv format:\n",
      "\u001b[32m[07/06 01:49:52 d2.evaluation.testing]: \u001b[0mcopypaste: Task: sem_seg\n",
      "\u001b[32m[07/06 01:49:52 d2.evaluation.testing]: \u001b[0mcopypaste: mIoU,fwIoU,mACC,pACC\n",
      "\u001b[32m[07/06 01:49:52 d2.evaluation.testing]: \u001b[0mcopypaste: 71.3169,91.7616,80.1428,95.5301\n"
     ]
    }
   ],
   "source": [
    "trainer_day = Detectron2Trainer('combined_all_train', 'combined_rain_val', output_folder='./output_day_40k')\n",
    "trainer_day.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0027de9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/05 18:02:26 d2.engine.defaults]: \u001b[0mModel:\n",
      "SemanticSegmentor(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (sem_seg_head): SemSegFPNHead(\n",
      "    (p2): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "    )\n",
      "    (p3): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (1): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "    )\n",
      "    (p4): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (1): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      (2): Conv2d(\n",
      "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (3): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "    )\n",
      "    (p5): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (1): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      (2): Conv2d(\n",
      "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (3): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      (4): Conv2d(\n",
      "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (5): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "    )\n",
      "    (predictor): Conv2d(128, 17, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/05 18:02:26 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(720, 720), max_size=2048, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[07/05 18:02:26 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[07/05 18:02:26 d2.data.common]: \u001b[0mSerializing 22288 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[07/05 18:02:26 d2.data.common]: \u001b[0mSerialized dataset takes 6.80 MiB\n",
      "Last checkpoint: model_final.pth\n",
      "\u001b[32m[07/05 18:02:27 d2.checkpoint.c2_model_loading]: \u001b[0mFollowing weights matched with model:\n",
      "| Names in Model                       | Names in Checkpoint                                                                                  | Shapes                                          |\n",
      "|:-------------------------------------|:-----------------------------------------------------------------------------------------------------|:------------------------------------------------|\n",
      "| backbone.bottom_up.res2.0.conv1.*    | backbone.bottom_up.res2.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,1,1)             |\n",
      "| backbone.bottom_up.res2.0.conv2.*    | backbone.bottom_up.res2.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |\n",
      "| backbone.bottom_up.res2.0.conv3.*    | backbone.bottom_up.res2.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res2.0.shortcut.* | backbone.bottom_up.res2.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res2.1.conv1.*    | backbone.bottom_up.res2.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |\n",
      "| backbone.bottom_up.res2.1.conv2.*    | backbone.bottom_up.res2.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |\n",
      "| backbone.bottom_up.res2.1.conv3.*    | backbone.bottom_up.res2.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res2.2.conv1.*    | backbone.bottom_up.res2.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |\n",
      "| backbone.bottom_up.res2.2.conv2.*    | backbone.bottom_up.res2.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |\n",
      "| backbone.bottom_up.res2.2.conv3.*    | backbone.bottom_up.res2.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res3.0.conv1.*    | backbone.bottom_up.res3.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,256,1,1)       |\n",
      "| backbone.bottom_up.res3.0.conv2.*    | backbone.bottom_up.res3.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.0.conv3.*    | backbone.bottom_up.res3.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res3.0.shortcut.* | backbone.bottom_up.res3.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (512,) (512,) (512,) (512,) (512,256,1,1)       |\n",
      "| backbone.bottom_up.res3.1.conv1.*    | backbone.bottom_up.res3.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |\n",
      "| backbone.bottom_up.res3.1.conv2.*    | backbone.bottom_up.res3.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.1.conv3.*    | backbone.bottom_up.res3.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res3.2.conv1.*    | backbone.bottom_up.res3.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |\n",
      "| backbone.bottom_up.res3.2.conv2.*    | backbone.bottom_up.res3.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.2.conv3.*    | backbone.bottom_up.res3.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res3.3.conv1.*    | backbone.bottom_up.res3.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |\n",
      "| backbone.bottom_up.res3.3.conv2.*    | backbone.bottom_up.res3.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.3.conv3.*    | backbone.bottom_up.res3.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res4.0.conv1.*    | backbone.bottom_up.res4.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,512,1,1)       |\n",
      "| backbone.bottom_up.res4.0.conv2.*    | backbone.bottom_up.res4.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.0.conv3.*    | backbone.bottom_up.res4.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.0.shortcut.* | backbone.bottom_up.res4.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (1024,) (1024,) (1024,) (1024,) (1024,512,1,1)  |\n",
      "| backbone.bottom_up.res4.1.conv1.*    | backbone.bottom_up.res4.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.1.conv2.*    | backbone.bottom_up.res4.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.1.conv3.*    | backbone.bottom_up.res4.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.2.conv1.*    | backbone.bottom_up.res4.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.2.conv2.*    | backbone.bottom_up.res4.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.2.conv3.*    | backbone.bottom_up.res4.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.3.conv1.*    | backbone.bottom_up.res4.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.3.conv2.*    | backbone.bottom_up.res4.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.3.conv3.*    | backbone.bottom_up.res4.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.4.conv1.*    | backbone.bottom_up.res4.4.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.4.conv2.*    | backbone.bottom_up.res4.4.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.4.conv3.*    | backbone.bottom_up.res4.4.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.5.conv1.*    | backbone.bottom_up.res4.5.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.5.conv2.*    | backbone.bottom_up.res4.5.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.5.conv3.*    | backbone.bottom_up.res4.5.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res5.0.conv1.*    | backbone.bottom_up.res5.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,1024,1,1)      |\n",
      "| backbone.bottom_up.res5.0.conv2.*    | backbone.bottom_up.res5.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |\n",
      "| backbone.bottom_up.res5.0.conv3.*    | backbone.bottom_up.res5.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
      "| backbone.bottom_up.res5.0.shortcut.* | backbone.bottom_up.res5.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (2048,) (2048,) (2048,) (2048,) (2048,1024,1,1) |\n",
      "| backbone.bottom_up.res5.1.conv1.*    | backbone.bottom_up.res5.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |\n",
      "| backbone.bottom_up.res5.1.conv2.*    | backbone.bottom_up.res5.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |\n",
      "| backbone.bottom_up.res5.1.conv3.*    | backbone.bottom_up.res5.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
      "| backbone.bottom_up.res5.2.conv1.*    | backbone.bottom_up.res5.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |\n",
      "| backbone.bottom_up.res5.2.conv2.*    | backbone.bottom_up.res5.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |\n",
      "| backbone.bottom_up.res5.2.conv3.*    | backbone.bottom_up.res5.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
      "| backbone.bottom_up.stem.conv1.*      | backbone.bottom_up.stem.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}      | (64,) (64,) (64,) (64,) (64,3,7,7)              |\n",
      "| backbone.fpn_lateral2.*              | backbone.fpn_lateral2.{bias,weight}                                                                  | (256,) (256,256,1,1)                            |\n",
      "| backbone.fpn_lateral3.*              | backbone.fpn_lateral3.{bias,weight}                                                                  | (256,) (256,512,1,1)                            |\n",
      "| backbone.fpn_lateral4.*              | backbone.fpn_lateral4.{bias,weight}                                                                  | (256,) (256,1024,1,1)                           |\n",
      "| backbone.fpn_lateral5.*              | backbone.fpn_lateral5.{bias,weight}                                                                  | (256,) (256,2048,1,1)                           |\n",
      "| backbone.fpn_output2.*               | backbone.fpn_output2.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| backbone.fpn_output3.*               | backbone.fpn_output3.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| backbone.fpn_output4.*               | backbone.fpn_output4.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| backbone.fpn_output5.*               | backbone.fpn_output5.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| sem_seg_head.p2.0.*                  | sem_seg_head.p2.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p3.0.*                  | sem_seg_head.p3.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p4.0.*                  | sem_seg_head.p4.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p4.2.*                  | sem_seg_head.p4.2.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,128,3,3)                     |\n",
      "| sem_seg_head.p5.0.*                  | sem_seg_head.p5.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p5.2.*                  | sem_seg_head.p5.2.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,128,3,3)                     |\n",
      "| sem_seg_head.p5.4.*                  | sem_seg_head.p5.4.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,128,3,3)                     |\n",
      "| sem_seg_head.predictor.*             | sem_seg_head.predictor.{bias,weight}                                                                 | (17,) (17,128,1,1)                              |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/05 18:02:27 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(720, 720), max_size=2048, sample_style='choice')]\n",
      "\u001b[32m[07/05 18:02:27 d2.data.common]: \u001b[0mSerializing 7914 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[07/05 18:02:27 d2.data.common]: \u001b[0mSerialized dataset takes 2.41 MiB\n",
      "\u001b[32m[07/05 18:02:27 d2.evaluation.evaluator]: \u001b[0mStart inference on 7914 batches\n",
      "\u001b[32m[07/05 18:02:28 d2.evaluation.evaluator]: \u001b[0mInference done 11/7914. Dataloading: 0.0018 s/iter. Inference: 0.0348 s/iter. Eval: 0.0445 s/iter. Total: 0.0811 s/iter. ETA=0:10:40\n",
      "\u001b[32m[07/05 18:02:33 d2.evaluation.evaluator]: \u001b[0mInference done 74/7914. Dataloading: 0.0022 s/iter. Inference: 0.0351 s/iter. Eval: 0.0430 s/iter. Total: 0.0803 s/iter. ETA=0:10:29\n",
      "\u001b[32m[07/05 18:02:38 d2.evaluation.evaluator]: \u001b[0mInference done 139/7914. Dataloading: 0.0022 s/iter. Inference: 0.0351 s/iter. Eval: 0.0415 s/iter. Total: 0.0789 s/iter. ETA=0:10:13\n",
      "\u001b[32m[07/05 18:02:43 d2.evaluation.evaluator]: \u001b[0mInference done 206/7914. Dataloading: 0.0022 s/iter. Inference: 0.0352 s/iter. Eval: 0.0403 s/iter. Total: 0.0778 s/iter. ETA=0:09:59\n",
      "\u001b[32m[07/05 18:02:48 d2.evaluation.evaluator]: \u001b[0mInference done 273/7914. Dataloading: 0.0022 s/iter. Inference: 0.0352 s/iter. Eval: 0.0397 s/iter. Total: 0.0773 s/iter. ETA=0:09:50\n",
      "\u001b[32m[07/05 18:02:53 d2.evaluation.evaluator]: \u001b[0mInference done 339/7914. Dataloading: 0.0022 s/iter. Inference: 0.0352 s/iter. Eval: 0.0394 s/iter. Total: 0.0770 s/iter. ETA=0:09:43\n",
      "\u001b[32m[07/05 18:02:58 d2.evaluation.evaluator]: \u001b[0mInference done 406/7914. Dataloading: 0.0022 s/iter. Inference: 0.0353 s/iter. Eval: 0.0391 s/iter. Total: 0.0767 s/iter. ETA=0:09:35\n",
      "\u001b[32m[07/05 18:03:03 d2.evaluation.evaluator]: \u001b[0mInference done 472/7914. Dataloading: 0.0022 s/iter. Inference: 0.0353 s/iter. Eval: 0.0390 s/iter. Total: 0.0766 s/iter. ETA=0:09:29\n",
      "\u001b[32m[07/05 18:03:08 d2.evaluation.evaluator]: \u001b[0mInference done 539/7914. Dataloading: 0.0022 s/iter. Inference: 0.0353 s/iter. Eval: 0.0388 s/iter. Total: 0.0764 s/iter. ETA=0:09:23\n",
      "\u001b[32m[07/05 18:03:13 d2.evaluation.evaluator]: \u001b[0mInference done 605/7914. Dataloading: 0.0022 s/iter. Inference: 0.0353 s/iter. Eval: 0.0388 s/iter. Total: 0.0764 s/iter. ETA=0:09:18\n",
      "\u001b[32m[07/05 18:03:18 d2.evaluation.evaluator]: \u001b[0mInference done 673/7914. Dataloading: 0.0022 s/iter. Inference: 0.0353 s/iter. Eval: 0.0386 s/iter. Total: 0.0762 s/iter. ETA=0:09:11\n",
      "\u001b[32m[07/05 18:03:23 d2.evaluation.evaluator]: \u001b[0mInference done 740/7914. Dataloading: 0.0022 s/iter. Inference: 0.0353 s/iter. Eval: 0.0385 s/iter. Total: 0.0762 s/iter. ETA=0:09:06\n",
      "\u001b[32m[07/05 18:03:28 d2.evaluation.evaluator]: \u001b[0mInference done 806/7914. Dataloading: 0.0022 s/iter. Inference: 0.0354 s/iter. Eval: 0.0385 s/iter. Total: 0.0761 s/iter. ETA=0:09:01\n",
      "\u001b[32m[07/05 18:03:33 d2.evaluation.evaluator]: \u001b[0mInference done 872/7914. Dataloading: 0.0022 s/iter. Inference: 0.0354 s/iter. Eval: 0.0384 s/iter. Total: 0.0761 s/iter. ETA=0:08:56\n",
      "\u001b[32m[07/05 18:03:38 d2.evaluation.evaluator]: \u001b[0mInference done 938/7914. Dataloading: 0.0022 s/iter. Inference: 0.0354 s/iter. Eval: 0.0384 s/iter. Total: 0.0761 s/iter. ETA=0:08:51\n",
      "\u001b[32m[07/05 18:03:43 d2.evaluation.evaluator]: \u001b[0mInference done 1004/7914. Dataloading: 0.0022 s/iter. Inference: 0.0354 s/iter. Eval: 0.0384 s/iter. Total: 0.0761 s/iter. ETA=0:08:46\n",
      "\u001b[32m[07/05 18:03:49 d2.evaluation.evaluator]: \u001b[0mInference done 1071/7914. Dataloading: 0.0022 s/iter. Inference: 0.0354 s/iter. Eval: 0.0384 s/iter. Total: 0.0761 s/iter. ETA=0:08:40\n",
      "\u001b[32m[07/05 18:03:54 d2.evaluation.evaluator]: \u001b[0mInference done 1138/7914. Dataloading: 0.0023 s/iter. Inference: 0.0354 s/iter. Eval: 0.0383 s/iter. Total: 0.0761 s/iter. ETA=0:08:35\n",
      "\u001b[32m[07/05 18:03:59 d2.evaluation.evaluator]: \u001b[0mInference done 1204/7914. Dataloading: 0.0023 s/iter. Inference: 0.0354 s/iter. Eval: 0.0384 s/iter. Total: 0.0761 s/iter. ETA=0:08:30\n",
      "\u001b[32m[07/05 18:04:04 d2.evaluation.evaluator]: \u001b[0mInference done 1268/7914. Dataloading: 0.0023 s/iter. Inference: 0.0354 s/iter. Eval: 0.0385 s/iter. Total: 0.0762 s/iter. ETA=0:08:26\n",
      "\u001b[32m[07/05 18:04:09 d2.evaluation.evaluator]: \u001b[0mInference done 1334/7914. Dataloading: 0.0023 s/iter. Inference: 0.0354 s/iter. Eval: 0.0385 s/iter. Total: 0.0763 s/iter. ETA=0:08:21\n",
      "\u001b[32m[07/05 18:04:14 d2.evaluation.evaluator]: \u001b[0mInference done 1399/7914. Dataloading: 0.0023 s/iter. Inference: 0.0354 s/iter. Eval: 0.0386 s/iter. Total: 0.0763 s/iter. ETA=0:08:17\n",
      "\u001b[32m[07/05 18:04:19 d2.evaluation.evaluator]: \u001b[0mInference done 1463/7914. Dataloading: 0.0023 s/iter. Inference: 0.0354 s/iter. Eval: 0.0387 s/iter. Total: 0.0764 s/iter. ETA=0:08:13\n",
      "\u001b[32m[07/05 18:04:24 d2.evaluation.evaluator]: \u001b[0mInference done 1528/7914. Dataloading: 0.0023 s/iter. Inference: 0.0354 s/iter. Eval: 0.0387 s/iter. Total: 0.0765 s/iter. ETA=0:08:08\n",
      "\u001b[32m[07/05 18:04:29 d2.evaluation.evaluator]: \u001b[0mInference done 1593/7914. Dataloading: 0.0023 s/iter. Inference: 0.0354 s/iter. Eval: 0.0388 s/iter. Total: 0.0766 s/iter. ETA=0:08:03\n",
      "\u001b[32m[07/05 18:04:34 d2.evaluation.evaluator]: \u001b[0mInference done 1658/7914. Dataloading: 0.0023 s/iter. Inference: 0.0354 s/iter. Eval: 0.0388 s/iter. Total: 0.0766 s/iter. ETA=0:07:59\n",
      "\u001b[32m[07/05 18:04:39 d2.evaluation.evaluator]: \u001b[0mInference done 1723/7914. Dataloading: 0.0023 s/iter. Inference: 0.0354 s/iter. Eval: 0.0389 s/iter. Total: 0.0767 s/iter. ETA=0:07:54\n",
      "\u001b[32m[07/05 18:04:44 d2.evaluation.evaluator]: \u001b[0mInference done 1788/7914. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0389 s/iter. Total: 0.0767 s/iter. ETA=0:07:49\n",
      "\u001b[32m[07/05 18:04:49 d2.evaluation.evaluator]: \u001b[0mInference done 1851/7914. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0390 s/iter. Total: 0.0768 s/iter. ETA=0:07:45\n",
      "\u001b[32m[07/05 18:04:54 d2.evaluation.evaluator]: \u001b[0mInference done 1915/7914. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0391 s/iter. Total: 0.0769 s/iter. ETA=0:07:41\n",
      "\u001b[32m[07/05 18:04:59 d2.evaluation.evaluator]: \u001b[0mInference done 1979/7914. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0391 s/iter. Total: 0.0769 s/iter. ETA=0:07:36\n",
      "\u001b[32m[07/05 18:05:04 d2.evaluation.evaluator]: \u001b[0mInference done 2044/7914. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0392 s/iter. Total: 0.0770 s/iter. ETA=0:07:31\n",
      "\u001b[32m[07/05 18:05:09 d2.evaluation.evaluator]: \u001b[0mInference done 2108/7914. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0392 s/iter. Total: 0.0770 s/iter. ETA=0:07:27\n",
      "\u001b[32m[07/05 18:05:14 d2.evaluation.evaluator]: \u001b[0mInference done 2173/7914. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0392 s/iter. Total: 0.0770 s/iter. ETA=0:07:22\n",
      "\u001b[32m[07/05 18:05:19 d2.evaluation.evaluator]: \u001b[0mInference done 2237/7914. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0393 s/iter. Total: 0.0771 s/iter. ETA=0:07:17\n",
      "\u001b[32m[07/05 18:05:24 d2.evaluation.evaluator]: \u001b[0mInference done 2301/7914. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0393 s/iter. Total: 0.0771 s/iter. ETA=0:07:12\n",
      "\u001b[32m[07/05 18:05:30 d2.evaluation.evaluator]: \u001b[0mInference done 2366/7914. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0393 s/iter. Total: 0.0771 s/iter. ETA=0:07:07\n",
      "\u001b[32m[07/05 18:05:35 d2.evaluation.evaluator]: \u001b[0mInference done 2429/7914. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0394 s/iter. Total: 0.0772 s/iter. ETA=0:07:03\n",
      "\u001b[32m[07/05 18:05:40 d2.evaluation.evaluator]: \u001b[0mInference done 2493/7914. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0394 s/iter. Total: 0.0772 s/iter. ETA=0:06:58\n",
      "\u001b[32m[07/05 18:05:45 d2.evaluation.evaluator]: \u001b[0mInference done 2556/7914. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0395 s/iter. Total: 0.0773 s/iter. ETA=0:06:54\n",
      "\u001b[32m[07/05 18:05:50 d2.evaluation.evaluator]: \u001b[0mInference done 2619/7914. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0396 s/iter. Total: 0.0774 s/iter. ETA=0:06:49\n",
      "\u001b[32m[07/05 18:05:55 d2.evaluation.evaluator]: \u001b[0mInference done 2683/7914. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0396 s/iter. Total: 0.0774 s/iter. ETA=0:06:44\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/05 18:06:00 d2.evaluation.evaluator]: \u001b[0mInference done 2748/7914. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0396 s/iter. Total: 0.0774 s/iter. ETA=0:06:39\n",
      "\u001b[32m[07/05 18:06:05 d2.evaluation.evaluator]: \u001b[0mInference done 2815/7914. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0395 s/iter. Total: 0.0774 s/iter. ETA=0:06:34\n",
      "\u001b[32m[07/05 18:06:10 d2.evaluation.evaluator]: \u001b[0mInference done 2879/7914. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0396 s/iter. Total: 0.0774 s/iter. ETA=0:06:29\n",
      "\u001b[32m[07/05 18:06:15 d2.evaluation.evaluator]: \u001b[0mInference done 2944/7914. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0396 s/iter. Total: 0.0774 s/iter. ETA=0:06:24\n",
      "\u001b[32m[07/05 18:06:20 d2.evaluation.evaluator]: \u001b[0mInference done 3008/7914. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0396 s/iter. Total: 0.0774 s/iter. ETA=0:06:19\n",
      "\u001b[32m[07/05 18:06:25 d2.evaluation.evaluator]: \u001b[0mInference done 3072/7914. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0397 s/iter. Total: 0.0775 s/iter. ETA=0:06:15\n",
      "\u001b[32m[07/05 18:06:30 d2.evaluation.evaluator]: \u001b[0mInference done 3135/7914. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0397 s/iter. Total: 0.0775 s/iter. ETA=0:06:10\n",
      "\u001b[32m[07/05 18:06:35 d2.evaluation.evaluator]: \u001b[0mInference done 3203/7914. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0396 s/iter. Total: 0.0775 s/iter. ETA=0:06:04\n",
      "\u001b[32m[07/05 18:06:40 d2.evaluation.evaluator]: \u001b[0mInference done 3268/7914. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0396 s/iter. Total: 0.0775 s/iter. ETA=0:05:59\n",
      "\u001b[32m[07/05 18:06:45 d2.evaluation.evaluator]: \u001b[0mInference done 3331/7914. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0397 s/iter. Total: 0.0775 s/iter. ETA=0:05:55\n",
      "\u001b[32m[07/05 18:06:50 d2.evaluation.evaluator]: \u001b[0mInference done 3395/7914. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0397 s/iter. Total: 0.0775 s/iter. ETA=0:05:50\n",
      "\u001b[32m[07/05 18:06:55 d2.evaluation.evaluator]: \u001b[0mInference done 3460/7914. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0397 s/iter. Total: 0.0775 s/iter. ETA=0:05:45\n",
      "\u001b[32m[07/05 18:07:00 d2.evaluation.evaluator]: \u001b[0mInference done 3526/7914. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0397 s/iter. Total: 0.0775 s/iter. ETA=0:05:40\n",
      "\u001b[32m[07/05 18:07:05 d2.evaluation.evaluator]: \u001b[0mInference done 3590/7914. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0397 s/iter. Total: 0.0775 s/iter. ETA=0:05:35\n",
      "\u001b[32m[07/05 18:07:10 d2.evaluation.evaluator]: \u001b[0mInference done 3655/7914. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0397 s/iter. Total: 0.0775 s/iter. ETA=0:05:30\n",
      "\u001b[32m[07/05 18:07:15 d2.evaluation.evaluator]: \u001b[0mInference done 3716/7914. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0398 s/iter. Total: 0.0776 s/iter. ETA=0:05:25\n",
      "\u001b[32m[07/05 18:07:21 d2.evaluation.evaluator]: \u001b[0mInference done 3780/7914. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0398 s/iter. Total: 0.0776 s/iter. ETA=0:05:20\n",
      "\u001b[32m[07/05 18:07:26 d2.evaluation.evaluator]: \u001b[0mInference done 3844/7914. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0398 s/iter. Total: 0.0777 s/iter. ETA=0:05:16\n",
      "\u001b[32m[07/05 18:07:31 d2.evaluation.evaluator]: \u001b[0mInference done 3908/7914. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0398 s/iter. Total: 0.0777 s/iter. ETA=0:05:11\n",
      "\u001b[32m[07/05 18:07:36 d2.evaluation.evaluator]: \u001b[0mInference done 3973/7914. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0399 s/iter. Total: 0.0777 s/iter. ETA=0:05:06\n",
      "\u001b[32m[07/05 18:07:41 d2.evaluation.evaluator]: \u001b[0mInference done 4039/7914. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0398 s/iter. Total: 0.0777 s/iter. ETA=0:05:00\n",
      "\u001b[32m[07/05 18:07:46 d2.evaluation.evaluator]: \u001b[0mInference done 4105/7914. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0398 s/iter. Total: 0.0776 s/iter. ETA=0:04:55\n",
      "\u001b[32m[07/05 18:07:51 d2.evaluation.evaluator]: \u001b[0mInference done 4171/7914. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0398 s/iter. Total: 0.0776 s/iter. ETA=0:04:50\n",
      "\u001b[32m[07/05 18:07:56 d2.evaluation.evaluator]: \u001b[0mInference done 4236/7914. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0398 s/iter. Total: 0.0776 s/iter. ETA=0:04:45\n",
      "\u001b[32m[07/05 18:08:01 d2.evaluation.evaluator]: \u001b[0mInference done 4302/7914. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0398 s/iter. Total: 0.0776 s/iter. ETA=0:04:40\n",
      "\u001b[32m[07/05 18:08:06 d2.evaluation.evaluator]: \u001b[0mInference done 4369/7914. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0397 s/iter. Total: 0.0776 s/iter. ETA=0:04:34\n",
      "\u001b[32m[07/05 18:08:11 d2.evaluation.evaluator]: \u001b[0mInference done 4435/7914. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0397 s/iter. Total: 0.0775 s/iter. ETA=0:04:29\n",
      "\u001b[32m[07/05 18:08:16 d2.evaluation.evaluator]: \u001b[0mInference done 4502/7914. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0397 s/iter. Total: 0.0775 s/iter. ETA=0:04:24\n",
      "\u001b[32m[07/05 18:08:21 d2.evaluation.evaluator]: \u001b[0mInference done 4568/7914. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0397 s/iter. Total: 0.0775 s/iter. ETA=0:04:19\n",
      "\u001b[32m[07/05 18:08:26 d2.evaluation.evaluator]: \u001b[0mInference done 4635/7914. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0396 s/iter. Total: 0.0775 s/iter. ETA=0:04:14\n",
      "\u001b[32m[07/05 18:08:31 d2.evaluation.evaluator]: \u001b[0mInference done 4701/7914. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0396 s/iter. Total: 0.0775 s/iter. ETA=0:04:08\n",
      "\u001b[32m[07/05 18:08:36 d2.evaluation.evaluator]: \u001b[0mInference done 4767/7914. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0396 s/iter. Total: 0.0774 s/iter. ETA=0:04:03\n",
      "\u001b[32m[07/05 18:08:41 d2.evaluation.evaluator]: \u001b[0mInference done 4834/7914. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0396 s/iter. Total: 0.0774 s/iter. ETA=0:03:58\n",
      "\u001b[32m[07/05 18:08:46 d2.evaluation.evaluator]: \u001b[0mInference done 4901/7914. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0396 s/iter. Total: 0.0774 s/iter. ETA=0:03:53\n",
      "\u001b[32m[07/05 18:08:51 d2.evaluation.evaluator]: \u001b[0mInference done 4967/7914. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0395 s/iter. Total: 0.0774 s/iter. ETA=0:03:48\n",
      "\u001b[32m[07/05 18:08:56 d2.evaluation.evaluator]: \u001b[0mInference done 5034/7914. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0395 s/iter. Total: 0.0773 s/iter. ETA=0:03:42\n",
      "\u001b[32m[07/05 18:09:01 d2.evaluation.evaluator]: \u001b[0mInference done 5101/7914. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0395 s/iter. Total: 0.0773 s/iter. ETA=0:03:37\n",
      "\u001b[32m[07/05 18:09:06 d2.evaluation.evaluator]: \u001b[0mInference done 5167/7914. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0395 s/iter. Total: 0.0773 s/iter. ETA=0:03:32\n",
      "\u001b[32m[07/05 18:09:12 d2.evaluation.evaluator]: \u001b[0mInference done 5233/7914. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0395 s/iter. Total: 0.0773 s/iter. ETA=0:03:27\n",
      "\u001b[32m[07/05 18:09:17 d2.evaluation.evaluator]: \u001b[0mInference done 5299/7914. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0394 s/iter. Total: 0.0773 s/iter. ETA=0:03:22\n",
      "\u001b[32m[07/05 18:09:22 d2.evaluation.evaluator]: \u001b[0mInference done 5366/7914. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0394 s/iter. Total: 0.0773 s/iter. ETA=0:03:16\n",
      "\u001b[32m[07/05 18:09:27 d2.evaluation.evaluator]: \u001b[0mInference done 5432/7914. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0394 s/iter. Total: 0.0772 s/iter. ETA=0:03:11\n",
      "\u001b[32m[07/05 18:09:32 d2.evaluation.evaluator]: \u001b[0mInference done 5497/7914. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0394 s/iter. Total: 0.0772 s/iter. ETA=0:03:06\n",
      "\u001b[32m[07/05 18:09:37 d2.evaluation.evaluator]: \u001b[0mInference done 5562/7914. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0394 s/iter. Total: 0.0772 s/iter. ETA=0:03:01\n",
      "\u001b[32m[07/05 18:09:42 d2.evaluation.evaluator]: \u001b[0mInference done 5628/7914. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0394 s/iter. Total: 0.0772 s/iter. ETA=0:02:56\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/05 18:09:47 d2.evaluation.evaluator]: \u001b[0mInference done 5694/7914. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0394 s/iter. Total: 0.0772 s/iter. ETA=0:02:51\n",
      "\u001b[32m[07/05 18:09:52 d2.evaluation.evaluator]: \u001b[0mInference done 5760/7914. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0394 s/iter. Total: 0.0772 s/iter. ETA=0:02:46\n",
      "\u001b[32m[07/05 18:09:57 d2.evaluation.evaluator]: \u001b[0mInference done 5827/7914. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0394 s/iter. Total: 0.0772 s/iter. ETA=0:02:41\n",
      "\u001b[32m[07/05 18:10:02 d2.evaluation.evaluator]: \u001b[0mInference done 5893/7914. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0393 s/iter. Total: 0.0772 s/iter. ETA=0:02:35\n",
      "\u001b[32m[07/05 18:10:07 d2.evaluation.evaluator]: \u001b[0mInference done 5959/7914. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0393 s/iter. Total: 0.0772 s/iter. ETA=0:02:30\n",
      "\u001b[32m[07/05 18:10:12 d2.evaluation.evaluator]: \u001b[0mInference done 6026/7914. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0393 s/iter. Total: 0.0771 s/iter. ETA=0:02:25\n",
      "\u001b[32m[07/05 18:10:17 d2.evaluation.evaluator]: \u001b[0mInference done 6093/7914. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0393 s/iter. Total: 0.0771 s/iter. ETA=0:02:20\n",
      "\u001b[32m[07/05 18:10:22 d2.evaluation.evaluator]: \u001b[0mInference done 6158/7914. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0393 s/iter. Total: 0.0771 s/iter. ETA=0:02:15\n",
      "\u001b[32m[07/05 18:10:27 d2.evaluation.evaluator]: \u001b[0mInference done 6224/7914. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0393 s/iter. Total: 0.0771 s/iter. ETA=0:02:10\n",
      "\u001b[32m[07/05 18:10:32 d2.evaluation.evaluator]: \u001b[0mInference done 6291/7914. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0392 s/iter. Total: 0.0771 s/iter. ETA=0:02:05\n",
      "\u001b[32m[07/05 18:10:37 d2.evaluation.evaluator]: \u001b[0mInference done 6358/7914. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0392 s/iter. Total: 0.0771 s/iter. ETA=0:01:59\n",
      "\u001b[32m[07/05 18:10:42 d2.evaluation.evaluator]: \u001b[0mInference done 6425/7914. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0392 s/iter. Total: 0.0771 s/iter. ETA=0:01:54\n",
      "\u001b[32m[07/05 18:10:47 d2.evaluation.evaluator]: \u001b[0mInference done 6491/7914. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0392 s/iter. Total: 0.0771 s/iter. ETA=0:01:49\n",
      "\u001b[32m[07/05 18:10:52 d2.evaluation.evaluator]: \u001b[0mInference done 6533/7914. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0395 s/iter. Total: 0.0773 s/iter. ETA=0:01:46\n",
      "\u001b[32m[07/05 18:10:57 d2.evaluation.evaluator]: \u001b[0mInference done 6560/7914. Dataloading: 0.0023 s/iter. Inference: 0.0356 s/iter. Eval: 0.0399 s/iter. Total: 0.0778 s/iter. ETA=0:01:45\n",
      "\u001b[32m[07/05 18:11:03 d2.evaluation.evaluator]: \u001b[0mInference done 6587/7914. Dataloading: 0.0023 s/iter. Inference: 0.0356 s/iter. Eval: 0.0403 s/iter. Total: 0.0783 s/iter. ETA=0:01:43\n",
      "\u001b[32m[07/05 18:11:08 d2.evaluation.evaluator]: \u001b[0mInference done 6614/7914. Dataloading: 0.0023 s/iter. Inference: 0.0357 s/iter. Eval: 0.0407 s/iter. Total: 0.0787 s/iter. ETA=0:01:42\n",
      "\u001b[32m[07/05 18:11:13 d2.evaluation.evaluator]: \u001b[0mInference done 6641/7914. Dataloading: 0.0023 s/iter. Inference: 0.0357 s/iter. Eval: 0.0411 s/iter. Total: 0.0791 s/iter. ETA=0:01:40\n",
      "\u001b[32m[07/05 18:11:18 d2.evaluation.evaluator]: \u001b[0mInference done 6667/7914. Dataloading: 0.0023 s/iter. Inference: 0.0358 s/iter. Eval: 0.0415 s/iter. Total: 0.0796 s/iter. ETA=0:01:39\n",
      "\u001b[32m[07/05 18:11:23 d2.evaluation.evaluator]: \u001b[0mInference done 6694/7914. Dataloading: 0.0023 s/iter. Inference: 0.0358 s/iter. Eval: 0.0419 s/iter. Total: 0.0800 s/iter. ETA=0:01:37\n",
      "\u001b[32m[07/05 18:11:28 d2.evaluation.evaluator]: \u001b[0mInference done 6721/7914. Dataloading: 0.0023 s/iter. Inference: 0.0358 s/iter. Eval: 0.0423 s/iter. Total: 0.0805 s/iter. ETA=0:01:35\n",
      "\u001b[32m[07/05 18:11:33 d2.evaluation.evaluator]: \u001b[0mInference done 6748/7914. Dataloading: 0.0023 s/iter. Inference: 0.0359 s/iter. Eval: 0.0427 s/iter. Total: 0.0809 s/iter. ETA=0:01:34\n",
      "\u001b[32m[07/05 18:11:38 d2.evaluation.evaluator]: \u001b[0mInference done 6776/7914. Dataloading: 0.0023 s/iter. Inference: 0.0359 s/iter. Eval: 0.0430 s/iter. Total: 0.0813 s/iter. ETA=0:01:32\n",
      "\u001b[32m[07/05 18:11:43 d2.evaluation.evaluator]: \u001b[0mInference done 6803/7914. Dataloading: 0.0023 s/iter. Inference: 0.0360 s/iter. Eval: 0.0434 s/iter. Total: 0.0817 s/iter. ETA=0:01:30\n",
      "\u001b[32m[07/05 18:11:48 d2.evaluation.evaluator]: \u001b[0mInference done 6831/7914. Dataloading: 0.0023 s/iter. Inference: 0.0360 s/iter. Eval: 0.0438 s/iter. Total: 0.0821 s/iter. ETA=0:01:28\n",
      "\u001b[32m[07/05 18:11:53 d2.evaluation.evaluator]: \u001b[0mInference done 6857/7914. Dataloading: 0.0023 s/iter. Inference: 0.0361 s/iter. Eval: 0.0441 s/iter. Total: 0.0825 s/iter. ETA=0:01:27\n",
      "\u001b[32m[07/05 18:11:58 d2.evaluation.evaluator]: \u001b[0mInference done 6883/7914. Dataloading: 0.0023 s/iter. Inference: 0.0361 s/iter. Eval: 0.0445 s/iter. Total: 0.0830 s/iter. ETA=0:01:25\n",
      "\u001b[32m[07/05 18:12:03 d2.evaluation.evaluator]: \u001b[0mInference done 6909/7914. Dataloading: 0.0023 s/iter. Inference: 0.0361 s/iter. Eval: 0.0449 s/iter. Total: 0.0834 s/iter. ETA=0:01:23\n",
      "\u001b[32m[07/05 18:12:08 d2.evaluation.evaluator]: \u001b[0mInference done 6935/7914. Dataloading: 0.0023 s/iter. Inference: 0.0362 s/iter. Eval: 0.0453 s/iter. Total: 0.0838 s/iter. ETA=0:01:22\n",
      "\u001b[32m[07/05 18:12:13 d2.evaluation.evaluator]: \u001b[0mInference done 6960/7914. Dataloading: 0.0023 s/iter. Inference: 0.0362 s/iter. Eval: 0.0457 s/iter. Total: 0.0843 s/iter. ETA=0:01:20\n",
      "\u001b[32m[07/05 18:12:19 d2.evaluation.evaluator]: \u001b[0mInference done 6986/7914. Dataloading: 0.0023 s/iter. Inference: 0.0363 s/iter. Eval: 0.0461 s/iter. Total: 0.0847 s/iter. ETA=0:01:18\n",
      "\u001b[32m[07/05 18:12:24 d2.evaluation.evaluator]: \u001b[0mInference done 7013/7914. Dataloading: 0.0023 s/iter. Inference: 0.0363 s/iter. Eval: 0.0464 s/iter. Total: 0.0851 s/iter. ETA=0:01:16\n",
      "\u001b[32m[07/05 18:12:29 d2.evaluation.evaluator]: \u001b[0mInference done 7039/7914. Dataloading: 0.0023 s/iter. Inference: 0.0363 s/iter. Eval: 0.0468 s/iter. Total: 0.0855 s/iter. ETA=0:01:14\n",
      "\u001b[32m[07/05 18:12:34 d2.evaluation.evaluator]: \u001b[0mInference done 7066/7914. Dataloading: 0.0023 s/iter. Inference: 0.0364 s/iter. Eval: 0.0472 s/iter. Total: 0.0859 s/iter. ETA=0:01:12\n",
      "\u001b[32m[07/05 18:12:39 d2.evaluation.evaluator]: \u001b[0mInference done 7093/7914. Dataloading: 0.0023 s/iter. Inference: 0.0364 s/iter. Eval: 0.0475 s/iter. Total: 0.0863 s/iter. ETA=0:01:10\n",
      "\u001b[32m[07/05 18:12:44 d2.evaluation.evaluator]: \u001b[0mInference done 7119/7914. Dataloading: 0.0023 s/iter. Inference: 0.0365 s/iter. Eval: 0.0479 s/iter. Total: 0.0867 s/iter. ETA=0:01:08\n",
      "\u001b[32m[07/05 18:12:49 d2.evaluation.evaluator]: \u001b[0mInference done 7145/7914. Dataloading: 0.0023 s/iter. Inference: 0.0365 s/iter. Eval: 0.0483 s/iter. Total: 0.0871 s/iter. ETA=0:01:06\n",
      "\u001b[32m[07/05 18:12:54 d2.evaluation.evaluator]: \u001b[0mInference done 7171/7914. Dataloading: 0.0023 s/iter. Inference: 0.0365 s/iter. Eval: 0.0486 s/iter. Total: 0.0875 s/iter. ETA=0:01:04\n",
      "\u001b[32m[07/05 18:12:59 d2.evaluation.evaluator]: \u001b[0mInference done 7197/7914. Dataloading: 0.0023 s/iter. Inference: 0.0366 s/iter. Eval: 0.0490 s/iter. Total: 0.0879 s/iter. ETA=0:01:02\n",
      "\u001b[32m[07/05 18:13:04 d2.evaluation.evaluator]: \u001b[0mInference done 7224/7914. Dataloading: 0.0023 s/iter. Inference: 0.0366 s/iter. Eval: 0.0493 s/iter. Total: 0.0882 s/iter. ETA=0:01:00\n",
      "\u001b[32m[07/05 18:13:09 d2.evaluation.evaluator]: \u001b[0mInference done 7249/7914. Dataloading: 0.0023 s/iter. Inference: 0.0366 s/iter. Eval: 0.0496 s/iter. Total: 0.0886 s/iter. ETA=0:00:58\n",
      "\u001b[32m[07/05 18:13:15 d2.evaluation.evaluator]: \u001b[0mInference done 7275/7914. Dataloading: 0.0023 s/iter. Inference: 0.0367 s/iter. Eval: 0.0500 s/iter. Total: 0.0890 s/iter. ETA=0:00:56\n",
      "\u001b[32m[07/05 18:13:20 d2.evaluation.evaluator]: \u001b[0mInference done 7301/7914. Dataloading: 0.0023 s/iter. Inference: 0.0367 s/iter. Eval: 0.0503 s/iter. Total: 0.0894 s/iter. ETA=0:00:54\n",
      "\u001b[32m[07/05 18:13:25 d2.evaluation.evaluator]: \u001b[0mInference done 7327/7914. Dataloading: 0.0023 s/iter. Inference: 0.0367 s/iter. Eval: 0.0507 s/iter. Total: 0.0898 s/iter. ETA=0:00:52\n",
      "\u001b[32m[07/05 18:13:30 d2.evaluation.evaluator]: \u001b[0mInference done 7354/7914. Dataloading: 0.0023 s/iter. Inference: 0.0368 s/iter. Eval: 0.0510 s/iter. Total: 0.0901 s/iter. ETA=0:00:50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/05 18:13:35 d2.evaluation.evaluator]: \u001b[0mInference done 7381/7914. Dataloading: 0.0023 s/iter. Inference: 0.0368 s/iter. Eval: 0.0513 s/iter. Total: 0.0905 s/iter. ETA=0:00:48\n",
      "\u001b[32m[07/05 18:13:40 d2.evaluation.evaluator]: \u001b[0mInference done 7407/7914. Dataloading: 0.0023 s/iter. Inference: 0.0369 s/iter. Eval: 0.0517 s/iter. Total: 0.0909 s/iter. ETA=0:00:46\n",
      "\u001b[32m[07/05 18:13:45 d2.evaluation.evaluator]: \u001b[0mInference done 7434/7914. Dataloading: 0.0023 s/iter. Inference: 0.0369 s/iter. Eval: 0.0520 s/iter. Total: 0.0912 s/iter. ETA=0:00:43\n",
      "\u001b[32m[07/05 18:13:50 d2.evaluation.evaluator]: \u001b[0mInference done 7462/7914. Dataloading: 0.0023 s/iter. Inference: 0.0369 s/iter. Eval: 0.0523 s/iter. Total: 0.0916 s/iter. ETA=0:00:41\n",
      "\u001b[32m[07/05 18:13:55 d2.evaluation.evaluator]: \u001b[0mInference done 7488/7914. Dataloading: 0.0023 s/iter. Inference: 0.0370 s/iter. Eval: 0.0526 s/iter. Total: 0.0919 s/iter. ETA=0:00:39\n",
      "\u001b[32m[07/05 18:14:00 d2.evaluation.evaluator]: \u001b[0mInference done 7514/7914. Dataloading: 0.0023 s/iter. Inference: 0.0370 s/iter. Eval: 0.0529 s/iter. Total: 0.0923 s/iter. ETA=0:00:36\n",
      "\u001b[32m[07/05 18:14:06 d2.evaluation.evaluator]: \u001b[0mInference done 7540/7914. Dataloading: 0.0023 s/iter. Inference: 0.0370 s/iter. Eval: 0.0533 s/iter. Total: 0.0926 s/iter. ETA=0:00:34\n",
      "\u001b[32m[07/05 18:14:11 d2.evaluation.evaluator]: \u001b[0mInference done 7567/7914. Dataloading: 0.0023 s/iter. Inference: 0.0371 s/iter. Eval: 0.0536 s/iter. Total: 0.0930 s/iter. ETA=0:00:32\n",
      "\u001b[32m[07/05 18:14:16 d2.evaluation.evaluator]: \u001b[0mInference done 7594/7914. Dataloading: 0.0023 s/iter. Inference: 0.0371 s/iter. Eval: 0.0539 s/iter. Total: 0.0933 s/iter. ETA=0:00:29\n",
      "\u001b[32m[07/05 18:14:21 d2.evaluation.evaluator]: \u001b[0mInference done 7619/7914. Dataloading: 0.0023 s/iter. Inference: 0.0371 s/iter. Eval: 0.0542 s/iter. Total: 0.0937 s/iter. ETA=0:00:27\n",
      "\u001b[32m[07/05 18:14:26 d2.evaluation.evaluator]: \u001b[0mInference done 7645/7914. Dataloading: 0.0023 s/iter. Inference: 0.0372 s/iter. Eval: 0.0545 s/iter. Total: 0.0940 s/iter. ETA=0:00:25\n",
      "\u001b[32m[07/05 18:14:31 d2.evaluation.evaluator]: \u001b[0mInference done 7671/7914. Dataloading: 0.0023 s/iter. Inference: 0.0372 s/iter. Eval: 0.0548 s/iter. Total: 0.0944 s/iter. ETA=0:00:22\n",
      "\u001b[32m[07/05 18:14:36 d2.evaluation.evaluator]: \u001b[0mInference done 7697/7914. Dataloading: 0.0023 s/iter. Inference: 0.0372 s/iter. Eval: 0.0552 s/iter. Total: 0.0947 s/iter. ETA=0:00:20\n",
      "\u001b[32m[07/05 18:14:41 d2.evaluation.evaluator]: \u001b[0mInference done 7723/7914. Dataloading: 0.0023 s/iter. Inference: 0.0373 s/iter. Eval: 0.0555 s/iter. Total: 0.0951 s/iter. ETA=0:00:18\n",
      "\u001b[32m[07/05 18:14:46 d2.evaluation.evaluator]: \u001b[0mInference done 7749/7914. Dataloading: 0.0023 s/iter. Inference: 0.0373 s/iter. Eval: 0.0558 s/iter. Total: 0.0954 s/iter. ETA=0:00:15\n",
      "\u001b[32m[07/05 18:14:52 d2.evaluation.evaluator]: \u001b[0mInference done 7776/7914. Dataloading: 0.0023 s/iter. Inference: 0.0373 s/iter. Eval: 0.0561 s/iter. Total: 0.0958 s/iter. ETA=0:00:13\n",
      "\u001b[32m[07/05 18:14:57 d2.evaluation.evaluator]: \u001b[0mInference done 7803/7914. Dataloading: 0.0023 s/iter. Inference: 0.0374 s/iter. Eval: 0.0564 s/iter. Total: 0.0961 s/iter. ETA=0:00:10\n",
      "\u001b[32m[07/05 18:15:02 d2.evaluation.evaluator]: \u001b[0mInference done 7830/7914. Dataloading: 0.0023 s/iter. Inference: 0.0374 s/iter. Eval: 0.0567 s/iter. Total: 0.0964 s/iter. ETA=0:00:08\n",
      "\u001b[32m[07/05 18:15:07 d2.evaluation.evaluator]: \u001b[0mInference done 7857/7914. Dataloading: 0.0023 s/iter. Inference: 0.0374 s/iter. Eval: 0.0569 s/iter. Total: 0.0967 s/iter. ETA=0:00:05\n",
      "\u001b[32m[07/05 18:15:12 d2.evaluation.evaluator]: \u001b[0mInference done 7883/7914. Dataloading: 0.0023 s/iter. Inference: 0.0375 s/iter. Eval: 0.0572 s/iter. Total: 0.0970 s/iter. ETA=0:00:03\n",
      "\u001b[32m[07/05 18:15:17 d2.evaluation.evaluator]: \u001b[0mInference done 7908/7914. Dataloading: 0.0023 s/iter. Inference: 0.0375 s/iter. Eval: 0.0575 s/iter. Total: 0.0974 s/iter. ETA=0:00:00\n",
      "\u001b[32m[07/05 18:15:18 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:12:50.836179 (0.097463 s / iter per device, on 1 devices)\n",
      "\u001b[32m[07/05 18:15:18 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:04:56 (0.037496 s / iter per device, on 1 devices)\n",
      "\u001b[32m[07/05 18:15:20 d2.evaluation.sem_seg_evaluation]: \u001b[0mOrderedDict([('sem_seg', {'mIoU': 72.43304415052386, 'fwIoU': 92.52849231265388, 'IoU-Unlabeled': nan, 'IoU-Building': 91.90459570680758, 'IoU-Fence': 46.79569494838163, 'IoU-Pedestrian': 76.24525963940823, 'IoU-Pole': 58.70663750941727, 'IoU-Road': 98.22941083286521, 'IoU-SideWalk': 85.19446207890357, 'IoU-Vegetation': 86.86909488332823, 'IoU-Vehicles': 88.61590095596779, 'IoU-Wall': 77.83580968952141, 'IoU-TrafficSign': 60.723513804175255, 'IoU-Sky': 96.42183407619287, 'IoU-TrafficLight': 66.65270924900886, 'IoU-Terrain': 68.09993350403279, 'IoU-ConstructionVehicle': 66.10137975487578, 'IoU-workzone_object': 76.64384827134481, 'IoU-Detour': 13.888621504150223, 'mACC': 80.8067411540824, 'pACC': 95.95531918362096, 'ACC-Unlabeled': nan, 'ACC-Building': 96.40956850934708, 'ACC-Fence': 61.7709547820173, 'ACC-Pedestrian': 86.27786100964586, 'ACC-Pole': 69.32571881859263, 'ACC-Road': 99.22567198863564, 'ACC-SideWalk': 91.12339033779179, 'ACC-Vegetation': 94.49647359510611, 'ACC-Vehicles': 92.11292180313777, 'ACC-Wall': 87.19848751941598, 'ACC-TrafficSign': 70.28239482403826, 'ACC-Sky': 98.00665854637131, 'ACC-TrafficLight': 76.24043803826433, 'ACC-Terrain': 75.21980658454828, 'ACC-ConstructionVehicle': 94.61841629832345, 'ACC-workzone_object': 85.98901978814854, 'ACC-Detour': 14.610076021934198})])\n",
      "\u001b[32m[07/05 18:15:20 d2.engine.defaults]: \u001b[0mEvaluation results for combined_all_val in csv format:\n",
      "\u001b[32m[07/05 18:15:20 d2.evaluation.testing]: \u001b[0mcopypaste: Task: sem_seg\n",
      "\u001b[32m[07/05 18:15:20 d2.evaluation.testing]: \u001b[0mcopypaste: mIoU,fwIoU,mACC,pACC\n",
      "\u001b[32m[07/05 18:15:20 d2.evaluation.testing]: \u001b[0mcopypaste: 72.4330,92.5285,80.8067,95.9553\n"
     ]
    }
   ],
   "source": [
    "trainer_day = Detectron2Trainer('combined_all_train', 'combined_all_val', output_folder='./output_day_40k')\n",
    "trainer_day.test()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b97272",
   "metadata": {},
   "source": [
    "### 2. Night"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d07ed4e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainer_night = Detectron2Trainer('carla_night_all_train', 'carla_night_clear_val', output_folder='./output_night_clear_40k')\n",
    "#trainer_night.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "47945f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainer_day = Detectron2Trainer('carla_night_clear_train', 'cityscapes_clear_val', output_folder='./output_night_clear_40k')\n",
    "#trainer_day.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "809ef47b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/12 15:38:49 d2.engine.defaults]: \u001b[0mModel:\n",
      "SemanticSegmentor(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (sem_seg_head): SemSegFPNHead(\n",
      "    (p2): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "    )\n",
      "    (p3): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (1): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "    )\n",
      "    (p4): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (1): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      (2): Conv2d(\n",
      "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (3): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "    )\n",
      "    (p5): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (1): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      (2): Conv2d(\n",
      "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (3): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      (4): Conv2d(\n",
      "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (5): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "    )\n",
      "    (predictor): Conv2d(128, 17, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/12 15:38:49 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(720, 720), max_size=2048, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[07/12 15:38:49 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[07/12 15:38:49 d2.data.common]: \u001b[0mSerializing 7723 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[07/12 15:38:49 d2.data.common]: \u001b[0mSerialized dataset takes 2.52 MiB\n",
      "Last checkpoint: model_final.pth\n",
      "\u001b[32m[07/12 15:38:50 d2.checkpoint.c2_model_loading]: \u001b[0mFollowing weights matched with model:\n",
      "| Names in Model                       | Names in Checkpoint                                                                                  | Shapes                                          |\n",
      "|:-------------------------------------|:-----------------------------------------------------------------------------------------------------|:------------------------------------------------|\n",
      "| backbone.bottom_up.res2.0.conv1.*    | backbone.bottom_up.res2.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,1,1)             |\n",
      "| backbone.bottom_up.res2.0.conv2.*    | backbone.bottom_up.res2.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |\n",
      "| backbone.bottom_up.res2.0.conv3.*    | backbone.bottom_up.res2.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res2.0.shortcut.* | backbone.bottom_up.res2.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res2.1.conv1.*    | backbone.bottom_up.res2.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |\n",
      "| backbone.bottom_up.res2.1.conv2.*    | backbone.bottom_up.res2.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |\n",
      "| backbone.bottom_up.res2.1.conv3.*    | backbone.bottom_up.res2.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res2.2.conv1.*    | backbone.bottom_up.res2.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |\n",
      "| backbone.bottom_up.res2.2.conv2.*    | backbone.bottom_up.res2.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |\n",
      "| backbone.bottom_up.res2.2.conv3.*    | backbone.bottom_up.res2.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res3.0.conv1.*    | backbone.bottom_up.res3.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,256,1,1)       |\n",
      "| backbone.bottom_up.res3.0.conv2.*    | backbone.bottom_up.res3.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.0.conv3.*    | backbone.bottom_up.res3.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res3.0.shortcut.* | backbone.bottom_up.res3.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (512,) (512,) (512,) (512,) (512,256,1,1)       |\n",
      "| backbone.bottom_up.res3.1.conv1.*    | backbone.bottom_up.res3.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |\n",
      "| backbone.bottom_up.res3.1.conv2.*    | backbone.bottom_up.res3.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.1.conv3.*    | backbone.bottom_up.res3.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res3.2.conv1.*    | backbone.bottom_up.res3.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |\n",
      "| backbone.bottom_up.res3.2.conv2.*    | backbone.bottom_up.res3.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.2.conv3.*    | backbone.bottom_up.res3.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res3.3.conv1.*    | backbone.bottom_up.res3.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |\n",
      "| backbone.bottom_up.res3.3.conv2.*    | backbone.bottom_up.res3.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.3.conv3.*    | backbone.bottom_up.res3.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res4.0.conv1.*    | backbone.bottom_up.res4.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,512,1,1)       |\n",
      "| backbone.bottom_up.res4.0.conv2.*    | backbone.bottom_up.res4.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.0.conv3.*    | backbone.bottom_up.res4.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.0.shortcut.* | backbone.bottom_up.res4.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (1024,) (1024,) (1024,) (1024,) (1024,512,1,1)  |\n",
      "| backbone.bottom_up.res4.1.conv1.*    | backbone.bottom_up.res4.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.1.conv2.*    | backbone.bottom_up.res4.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.1.conv3.*    | backbone.bottom_up.res4.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.2.conv1.*    | backbone.bottom_up.res4.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.2.conv2.*    | backbone.bottom_up.res4.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.2.conv3.*    | backbone.bottom_up.res4.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.3.conv1.*    | backbone.bottom_up.res4.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.3.conv2.*    | backbone.bottom_up.res4.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.3.conv3.*    | backbone.bottom_up.res4.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.4.conv1.*    | backbone.bottom_up.res4.4.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.4.conv2.*    | backbone.bottom_up.res4.4.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.4.conv3.*    | backbone.bottom_up.res4.4.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.5.conv1.*    | backbone.bottom_up.res4.5.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.5.conv2.*    | backbone.bottom_up.res4.5.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.5.conv3.*    | backbone.bottom_up.res4.5.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res5.0.conv1.*    | backbone.bottom_up.res5.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,1024,1,1)      |\n",
      "| backbone.bottom_up.res5.0.conv2.*    | backbone.bottom_up.res5.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |\n",
      "| backbone.bottom_up.res5.0.conv3.*    | backbone.bottom_up.res5.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
      "| backbone.bottom_up.res5.0.shortcut.* | backbone.bottom_up.res5.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (2048,) (2048,) (2048,) (2048,) (2048,1024,1,1) |\n",
      "| backbone.bottom_up.res5.1.conv1.*    | backbone.bottom_up.res5.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |\n",
      "| backbone.bottom_up.res5.1.conv2.*    | backbone.bottom_up.res5.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |\n",
      "| backbone.bottom_up.res5.1.conv3.*    | backbone.bottom_up.res5.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
      "| backbone.bottom_up.res5.2.conv1.*    | backbone.bottom_up.res5.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |\n",
      "| backbone.bottom_up.res5.2.conv2.*    | backbone.bottom_up.res5.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |\n",
      "| backbone.bottom_up.res5.2.conv3.*    | backbone.bottom_up.res5.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
      "| backbone.bottom_up.stem.conv1.*      | backbone.bottom_up.stem.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}      | (64,) (64,) (64,) (64,) (64,3,7,7)              |\n",
      "| backbone.fpn_lateral2.*              | backbone.fpn_lateral2.{bias,weight}                                                                  | (256,) (256,256,1,1)                            |\n",
      "| backbone.fpn_lateral3.*              | backbone.fpn_lateral3.{bias,weight}                                                                  | (256,) (256,512,1,1)                            |\n",
      "| backbone.fpn_lateral4.*              | backbone.fpn_lateral4.{bias,weight}                                                                  | (256,) (256,1024,1,1)                           |\n",
      "| backbone.fpn_lateral5.*              | backbone.fpn_lateral5.{bias,weight}                                                                  | (256,) (256,2048,1,1)                           |\n",
      "| backbone.fpn_output2.*               | backbone.fpn_output2.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| backbone.fpn_output3.*               | backbone.fpn_output3.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| backbone.fpn_output4.*               | backbone.fpn_output4.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| backbone.fpn_output5.*               | backbone.fpn_output5.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| sem_seg_head.p2.0.*                  | sem_seg_head.p2.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p3.0.*                  | sem_seg_head.p3.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p4.0.*                  | sem_seg_head.p4.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p4.2.*                  | sem_seg_head.p4.2.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,128,3,3)                     |\n",
      "| sem_seg_head.p5.0.*                  | sem_seg_head.p5.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p5.2.*                  | sem_seg_head.p5.2.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,128,3,3)                     |\n",
      "| sem_seg_head.p5.4.*                  | sem_seg_head.p5.4.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,128,3,3)                     |\n",
      "| sem_seg_head.predictor.*             | sem_seg_head.predictor.{bias,weight}                                                                 | (17,) (17,128,1,1)                              |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/12 15:38:50 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(720, 720), max_size=2048, sample_style='choice')]\n",
      "\u001b[32m[07/12 15:38:50 d2.data.common]: \u001b[0mSerializing 3273 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[07/12 15:38:50 d2.data.common]: \u001b[0mSerialized dataset takes 1.04 MiB\n",
      "\u001b[32m[07/12 15:38:50 d2.evaluation.evaluator]: \u001b[0mStart inference on 3273 batches\n",
      "\u001b[32m[07/12 15:38:51 d2.evaluation.evaluator]: \u001b[0mInference done 11/3273. Dataloading: 0.0016 s/iter. Inference: 0.0373 s/iter. Eval: 0.0410 s/iter. Total: 0.0799 s/iter. ETA=0:04:20\n",
      "\u001b[32m[07/12 15:38:56 d2.evaluation.evaluator]: \u001b[0mInference done 76/3273. Dataloading: 0.0020 s/iter. Inference: 0.0348 s/iter. Eval: 0.0406 s/iter. Total: 0.0775 s/iter. ETA=0:04:07\n",
      "\u001b[32m[07/12 15:39:01 d2.evaluation.evaluator]: \u001b[0mInference done 140/3273. Dataloading: 0.0021 s/iter. Inference: 0.0348 s/iter. Eval: 0.0412 s/iter. Total: 0.0782 s/iter. ETA=0:04:04\n",
      "\u001b[32m[07/12 15:39:06 d2.evaluation.evaluator]: \u001b[0mInference done 204/3273. Dataloading: 0.0021 s/iter. Inference: 0.0348 s/iter. Eval: 0.0415 s/iter. Total: 0.0785 s/iter. ETA=0:04:00\n",
      "\u001b[32m[07/12 15:39:11 d2.evaluation.evaluator]: \u001b[0mInference done 268/3273. Dataloading: 0.0021 s/iter. Inference: 0.0348 s/iter. Eval: 0.0417 s/iter. Total: 0.0787 s/iter. ETA=0:03:56\n",
      "\u001b[32m[07/12 15:39:16 d2.evaluation.evaluator]: \u001b[0mInference done 331/3273. Dataloading: 0.0021 s/iter. Inference: 0.0348 s/iter. Eval: 0.0419 s/iter. Total: 0.0789 s/iter. ETA=0:03:52\n",
      "\u001b[32m[07/12 15:39:21 d2.evaluation.evaluator]: \u001b[0mInference done 394/3273. Dataloading: 0.0021 s/iter. Inference: 0.0349 s/iter. Eval: 0.0420 s/iter. Total: 0.0791 s/iter. ETA=0:03:47\n",
      "\u001b[32m[07/12 15:39:26 d2.evaluation.evaluator]: \u001b[0mInference done 456/3273. Dataloading: 0.0021 s/iter. Inference: 0.0349 s/iter. Eval: 0.0423 s/iter. Total: 0.0793 s/iter. ETA=0:03:43\n",
      "\u001b[32m[07/12 15:39:31 d2.evaluation.evaluator]: \u001b[0mInference done 517/3273. Dataloading: 0.0023 s/iter. Inference: 0.0349 s/iter. Eval: 0.0424 s/iter. Total: 0.0797 s/iter. ETA=0:03:39\n",
      "\u001b[32m[07/12 15:39:36 d2.evaluation.evaluator]: \u001b[0mInference done 581/3273. Dataloading: 0.0023 s/iter. Inference: 0.0349 s/iter. Eval: 0.0422 s/iter. Total: 0.0795 s/iter. ETA=0:03:34\n",
      "\u001b[32m[07/12 15:39:41 d2.evaluation.evaluator]: \u001b[0mInference done 645/3273. Dataloading: 0.0023 s/iter. Inference: 0.0350 s/iter. Eval: 0.0422 s/iter. Total: 0.0795 s/iter. ETA=0:03:28\n",
      "\u001b[32m[07/12 15:39:46 d2.evaluation.evaluator]: \u001b[0mInference done 708/3273. Dataloading: 0.0022 s/iter. Inference: 0.0350 s/iter. Eval: 0.0422 s/iter. Total: 0.0795 s/iter. ETA=0:03:23\n",
      "\u001b[32m[07/12 15:39:51 d2.evaluation.evaluator]: \u001b[0mInference done 771/3273. Dataloading: 0.0022 s/iter. Inference: 0.0350 s/iter. Eval: 0.0422 s/iter. Total: 0.0795 s/iter. ETA=0:03:18\n",
      "\u001b[32m[07/12 15:39:56 d2.evaluation.evaluator]: \u001b[0mInference done 838/3273. Dataloading: 0.0022 s/iter. Inference: 0.0350 s/iter. Eval: 0.0418 s/iter. Total: 0.0792 s/iter. ETA=0:03:12\n",
      "\u001b[32m[07/12 15:40:01 d2.evaluation.evaluator]: \u001b[0mInference done 904/3273. Dataloading: 0.0022 s/iter. Inference: 0.0350 s/iter. Eval: 0.0416 s/iter. Total: 0.0790 s/iter. ETA=0:03:07\n",
      "\u001b[32m[07/12 15:40:06 d2.evaluation.evaluator]: \u001b[0mInference done 970/3273. Dataloading: 0.0022 s/iter. Inference: 0.0351 s/iter. Eval: 0.0414 s/iter. Total: 0.0788 s/iter. ETA=0:03:01\n",
      "\u001b[32m[07/12 15:40:11 d2.evaluation.evaluator]: \u001b[0mInference done 1035/3273. Dataloading: 0.0022 s/iter. Inference: 0.0351 s/iter. Eval: 0.0413 s/iter. Total: 0.0787 s/iter. ETA=0:02:56\n",
      "\u001b[32m[07/12 15:40:16 d2.evaluation.evaluator]: \u001b[0mInference done 1100/3273. Dataloading: 0.0022 s/iter. Inference: 0.0351 s/iter. Eval: 0.0412 s/iter. Total: 0.0786 s/iter. ETA=0:02:50\n",
      "\u001b[32m[07/12 15:40:21 d2.evaluation.evaluator]: \u001b[0mInference done 1166/3273. Dataloading: 0.0022 s/iter. Inference: 0.0351 s/iter. Eval: 0.0411 s/iter. Total: 0.0785 s/iter. ETA=0:02:45\n",
      "\u001b[32m[07/12 15:40:26 d2.evaluation.evaluator]: \u001b[0mInference done 1230/3273. Dataloading: 0.0022 s/iter. Inference: 0.0351 s/iter. Eval: 0.0411 s/iter. Total: 0.0785 s/iter. ETA=0:02:40\n",
      "\u001b[32m[07/12 15:40:31 d2.evaluation.evaluator]: \u001b[0mInference done 1295/3273. Dataloading: 0.0022 s/iter. Inference: 0.0351 s/iter. Eval: 0.0410 s/iter. Total: 0.0784 s/iter. ETA=0:02:35\n",
      "\u001b[32m[07/12 15:40:37 d2.evaluation.evaluator]: \u001b[0mInference done 1359/3273. Dataloading: 0.0022 s/iter. Inference: 0.0352 s/iter. Eval: 0.0410 s/iter. Total: 0.0784 s/iter. ETA=0:02:30\n",
      "\u001b[32m[07/12 15:40:42 d2.evaluation.evaluator]: \u001b[0mInference done 1425/3273. Dataloading: 0.0022 s/iter. Inference: 0.0352 s/iter. Eval: 0.0409 s/iter. Total: 0.0784 s/iter. ETA=0:02:24\n",
      "\u001b[32m[07/12 15:40:47 d2.evaluation.evaluator]: \u001b[0mInference done 1491/3273. Dataloading: 0.0022 s/iter. Inference: 0.0352 s/iter. Eval: 0.0408 s/iter. Total: 0.0783 s/iter. ETA=0:02:19\n",
      "\u001b[32m[07/12 15:40:52 d2.evaluation.evaluator]: \u001b[0mInference done 1557/3273. Dataloading: 0.0022 s/iter. Inference: 0.0352 s/iter. Eval: 0.0407 s/iter. Total: 0.0782 s/iter. ETA=0:02:14\n",
      "\u001b[32m[07/12 15:40:57 d2.evaluation.evaluator]: \u001b[0mInference done 1622/3273. Dataloading: 0.0022 s/iter. Inference: 0.0352 s/iter. Eval: 0.0407 s/iter. Total: 0.0781 s/iter. ETA=0:02:08\n",
      "\u001b[32m[07/12 15:41:02 d2.evaluation.evaluator]: \u001b[0mInference done 1689/3273. Dataloading: 0.0022 s/iter. Inference: 0.0352 s/iter. Eval: 0.0405 s/iter. Total: 0.0780 s/iter. ETA=0:02:03\n",
      "\u001b[32m[07/12 15:41:07 d2.evaluation.evaluator]: \u001b[0mInference done 1756/3273. Dataloading: 0.0022 s/iter. Inference: 0.0352 s/iter. Eval: 0.0404 s/iter. Total: 0.0779 s/iter. ETA=0:01:58\n",
      "\u001b[32m[07/12 15:41:12 d2.evaluation.evaluator]: \u001b[0mInference done 1822/3273. Dataloading: 0.0022 s/iter. Inference: 0.0352 s/iter. Eval: 0.0404 s/iter. Total: 0.0779 s/iter. ETA=0:01:52\n",
      "\u001b[32m[07/12 15:41:17 d2.evaluation.evaluator]: \u001b[0mInference done 1888/3273. Dataloading: 0.0022 s/iter. Inference: 0.0352 s/iter. Eval: 0.0403 s/iter. Total: 0.0778 s/iter. ETA=0:01:47\n",
      "\u001b[32m[07/12 15:41:22 d2.evaluation.evaluator]: \u001b[0mInference done 1954/3273. Dataloading: 0.0022 s/iter. Inference: 0.0353 s/iter. Eval: 0.0403 s/iter. Total: 0.0778 s/iter. ETA=0:01:42\n",
      "\u001b[32m[07/12 15:41:27 d2.evaluation.evaluator]: \u001b[0mInference done 2020/3273. Dataloading: 0.0022 s/iter. Inference: 0.0353 s/iter. Eval: 0.0402 s/iter. Total: 0.0777 s/iter. ETA=0:01:37\n",
      "\u001b[32m[07/12 15:41:32 d2.evaluation.evaluator]: \u001b[0mInference done 2086/3273. Dataloading: 0.0022 s/iter. Inference: 0.0353 s/iter. Eval: 0.0402 s/iter. Total: 0.0777 s/iter. ETA=0:01:32\n",
      "\u001b[32m[07/12 15:41:37 d2.evaluation.evaluator]: \u001b[0mInference done 2151/3273. Dataloading: 0.0022 s/iter. Inference: 0.0353 s/iter. Eval: 0.0401 s/iter. Total: 0.0777 s/iter. ETA=0:01:27\n",
      "\u001b[32m[07/12 15:41:42 d2.evaluation.evaluator]: \u001b[0mInference done 2217/3273. Dataloading: 0.0022 s/iter. Inference: 0.0353 s/iter. Eval: 0.0401 s/iter. Total: 0.0776 s/iter. ETA=0:01:21\n",
      "\u001b[32m[07/12 15:41:47 d2.evaluation.evaluator]: \u001b[0mInference done 2283/3273. Dataloading: 0.0022 s/iter. Inference: 0.0353 s/iter. Eval: 0.0400 s/iter. Total: 0.0776 s/iter. ETA=0:01:16\n",
      "\u001b[32m[07/12 15:41:52 d2.evaluation.evaluator]: \u001b[0mInference done 2349/3273. Dataloading: 0.0022 s/iter. Inference: 0.0353 s/iter. Eval: 0.0400 s/iter. Total: 0.0776 s/iter. ETA=0:01:11\n",
      "\u001b[32m[07/12 15:41:57 d2.evaluation.evaluator]: \u001b[0mInference done 2413/3273. Dataloading: 0.0022 s/iter. Inference: 0.0353 s/iter. Eval: 0.0400 s/iter. Total: 0.0776 s/iter. ETA=0:01:06\n",
      "\u001b[32m[07/12 15:42:02 d2.evaluation.evaluator]: \u001b[0mInference done 2477/3273. Dataloading: 0.0022 s/iter. Inference: 0.0353 s/iter. Eval: 0.0400 s/iter. Total: 0.0776 s/iter. ETA=0:01:01\n",
      "\u001b[32m[07/12 15:42:07 d2.evaluation.evaluator]: \u001b[0mInference done 2542/3273. Dataloading: 0.0022 s/iter. Inference: 0.0353 s/iter. Eval: 0.0400 s/iter. Total: 0.0776 s/iter. ETA=0:00:56\n",
      "\u001b[32m[07/12 15:42:12 d2.evaluation.evaluator]: \u001b[0mInference done 2607/3273. Dataloading: 0.0022 s/iter. Inference: 0.0353 s/iter. Eval: 0.0400 s/iter. Total: 0.0776 s/iter. ETA=0:00:51\n",
      "\u001b[32m[07/12 15:42:17 d2.evaluation.evaluator]: \u001b[0mInference done 2672/3273. Dataloading: 0.0022 s/iter. Inference: 0.0354 s/iter. Eval: 0.0400 s/iter. Total: 0.0776 s/iter. ETA=0:00:46\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/12 15:42:22 d2.evaluation.evaluator]: \u001b[0mInference done 2736/3273. Dataloading: 0.0022 s/iter. Inference: 0.0354 s/iter. Eval: 0.0400 s/iter. Total: 0.0776 s/iter. ETA=0:00:41\n",
      "\u001b[32m[07/12 15:42:27 d2.evaluation.evaluator]: \u001b[0mInference done 2799/3273. Dataloading: 0.0022 s/iter. Inference: 0.0354 s/iter. Eval: 0.0401 s/iter. Total: 0.0777 s/iter. ETA=0:00:36\n",
      "\u001b[32m[07/12 15:42:32 d2.evaluation.evaluator]: \u001b[0mInference done 2862/3273. Dataloading: 0.0022 s/iter. Inference: 0.0354 s/iter. Eval: 0.0401 s/iter. Total: 0.0777 s/iter. ETA=0:00:31\n",
      "\u001b[32m[07/12 15:42:37 d2.evaluation.evaluator]: \u001b[0mInference done 2926/3273. Dataloading: 0.0022 s/iter. Inference: 0.0354 s/iter. Eval: 0.0401 s/iter. Total: 0.0778 s/iter. ETA=0:00:26\n",
      "\u001b[32m[07/12 15:42:43 d2.evaluation.evaluator]: \u001b[0mInference done 2990/3273. Dataloading: 0.0022 s/iter. Inference: 0.0354 s/iter. Eval: 0.0402 s/iter. Total: 0.0778 s/iter. ETA=0:00:22\n",
      "\u001b[32m[07/12 15:42:48 d2.evaluation.evaluator]: \u001b[0mInference done 3056/3273. Dataloading: 0.0022 s/iter. Inference: 0.0354 s/iter. Eval: 0.0401 s/iter. Total: 0.0778 s/iter. ETA=0:00:16\n",
      "\u001b[32m[07/12 15:42:53 d2.evaluation.evaluator]: \u001b[0mInference done 3120/3273. Dataloading: 0.0022 s/iter. Inference: 0.0354 s/iter. Eval: 0.0401 s/iter. Total: 0.0778 s/iter. ETA=0:00:11\n",
      "\u001b[32m[07/12 15:42:58 d2.evaluation.evaluator]: \u001b[0mInference done 3185/3273. Dataloading: 0.0022 s/iter. Inference: 0.0354 s/iter. Eval: 0.0401 s/iter. Total: 0.0778 s/iter. ETA=0:00:06\n",
      "\u001b[32m[07/12 15:43:03 d2.evaluation.evaluator]: \u001b[0mInference done 3251/3273. Dataloading: 0.0022 s/iter. Inference: 0.0354 s/iter. Eval: 0.0401 s/iter. Total: 0.0777 s/iter. ETA=0:00:01\n",
      "\u001b[32m[07/12 15:43:04 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:04:14.135892 (0.077765 s / iter per device, on 1 devices)\n",
      "\u001b[32m[07/12 15:43:04 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:01:55 (0.035405 s / iter per device, on 1 devices)\n",
      "\u001b[32m[07/12 15:43:05 d2.evaluation.sem_seg_evaluation]: \u001b[0mOrderedDict([('sem_seg', {'mIoU': 30.33838480332871, 'fwIoU': 64.27690314161804, 'IoU-Unlabeled': nan, 'IoU-Building': 41.529102286714995, 'IoU-Fence': 9.597897149210844, 'IoU-Pedestrian': 12.124291890726614, 'IoU-Pole': 34.84247405796961, 'IoU-Road': 88.92367581588125, 'IoU-SideWalk': 40.88859697483544, 'IoU-Vegetation': 36.76587457114645, 'IoU-Vehicles': 39.71596215651606, 'IoU-Wall': 6.578766100847694, 'IoU-TrafficSign': 28.557978878792973, 'IoU-Sky': 75.04021359235155, 'IoU-TrafficLight': 18.619451804657544, 'IoU-Terrain': 0.15599804891794627, 'IoU-ConstructionVehicle': 59.07309914559728, 'IoU-workzone_object': 10.020722169447017, 'IoU-Detour': 13.31843701297482, 'mACC': 53.35032371448555, 'pACC': 75.67358055314442, 'ACC-Unlabeled': nan, 'ACC-Building': 91.65319913406496, 'ACC-Fence': 15.524745551127204, 'ACC-Pedestrian': 65.5039968527292, 'ACC-Pole': 41.605264779125406, 'ACC-Road': 94.22307761962607, 'ACC-SideWalk': 55.790892820188795, 'ACC-Vegetation': 44.03692050905064, 'ACC-Vehicles': 80.83342044336858, 'ACC-Wall': 6.804041823856115, 'ACC-TrafficSign': 39.99537875648272, 'ACC-Sky': 80.40319611634804, 'ACC-TrafficLight': 20.87312560301422, 'ACC-Terrain': 0.1567082824592334, 'ACC-ConstructionVehicle': 93.46265996656982, 'ACC-workzone_object': 76.51803768490072, 'ACC-Detour': 46.22051348885703})])\n",
      "\u001b[32m[07/12 15:43:05 d2.engine.defaults]: \u001b[0mEvaluation results for carla_night_clear_val in csv format:\n",
      "\u001b[32m[07/12 15:43:05 d2.evaluation.testing]: \u001b[0mcopypaste: Task: sem_seg\n",
      "\u001b[32m[07/12 15:43:05 d2.evaluation.testing]: \u001b[0mcopypaste: mIoU,fwIoU,mACC,pACC\n",
      "\u001b[32m[07/12 15:43:05 d2.evaluation.testing]: \u001b[0mcopypaste: 30.3384,64.2769,53.3503,75.6736\n"
     ]
    }
   ],
   "source": [
    "trainer_day = Detectron2Trainer('carla_night_clear_train', 'carla_night_clear_val', output_folder='./output_night_clear_40k')\n",
    "trainer_day.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f9a6ccde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/12 15:43:05 d2.engine.defaults]: \u001b[0mModel:\n",
      "SemanticSegmentor(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (sem_seg_head): SemSegFPNHead(\n",
      "    (p2): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "    )\n",
      "    (p3): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (1): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "    )\n",
      "    (p4): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (1): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      (2): Conv2d(\n",
      "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (3): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "    )\n",
      "    (p5): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (1): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      (2): Conv2d(\n",
      "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (3): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      (4): Conv2d(\n",
      "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (5): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "    )\n",
      "    (predictor): Conv2d(128, 17, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/12 15:43:06 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(720, 720), max_size=2048, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[07/12 15:43:06 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[07/12 15:43:06 d2.data.common]: \u001b[0mSerializing 7723 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[07/12 15:43:06 d2.data.common]: \u001b[0mSerialized dataset takes 2.52 MiB\n",
      "Last checkpoint: model_final.pth\n",
      "\u001b[32m[07/12 15:43:06 d2.checkpoint.c2_model_loading]: \u001b[0mFollowing weights matched with model:\n",
      "| Names in Model                       | Names in Checkpoint                                                                                  | Shapes                                          |\n",
      "|:-------------------------------------|:-----------------------------------------------------------------------------------------------------|:------------------------------------------------|\n",
      "| backbone.bottom_up.res2.0.conv1.*    | backbone.bottom_up.res2.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,1,1)             |\n",
      "| backbone.bottom_up.res2.0.conv2.*    | backbone.bottom_up.res2.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |\n",
      "| backbone.bottom_up.res2.0.conv3.*    | backbone.bottom_up.res2.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res2.0.shortcut.* | backbone.bottom_up.res2.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res2.1.conv1.*    | backbone.bottom_up.res2.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |\n",
      "| backbone.bottom_up.res2.1.conv2.*    | backbone.bottom_up.res2.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |\n",
      "| backbone.bottom_up.res2.1.conv3.*    | backbone.bottom_up.res2.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res2.2.conv1.*    | backbone.bottom_up.res2.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |\n",
      "| backbone.bottom_up.res2.2.conv2.*    | backbone.bottom_up.res2.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |\n",
      "| backbone.bottom_up.res2.2.conv3.*    | backbone.bottom_up.res2.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res3.0.conv1.*    | backbone.bottom_up.res3.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,256,1,1)       |\n",
      "| backbone.bottom_up.res3.0.conv2.*    | backbone.bottom_up.res3.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.0.conv3.*    | backbone.bottom_up.res3.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res3.0.shortcut.* | backbone.bottom_up.res3.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (512,) (512,) (512,) (512,) (512,256,1,1)       |\n",
      "| backbone.bottom_up.res3.1.conv1.*    | backbone.bottom_up.res3.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |\n",
      "| backbone.bottom_up.res3.1.conv2.*    | backbone.bottom_up.res3.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.1.conv3.*    | backbone.bottom_up.res3.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res3.2.conv1.*    | backbone.bottom_up.res3.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |\n",
      "| backbone.bottom_up.res3.2.conv2.*    | backbone.bottom_up.res3.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.2.conv3.*    | backbone.bottom_up.res3.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res3.3.conv1.*    | backbone.bottom_up.res3.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |\n",
      "| backbone.bottom_up.res3.3.conv2.*    | backbone.bottom_up.res3.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.3.conv3.*    | backbone.bottom_up.res3.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res4.0.conv1.*    | backbone.bottom_up.res4.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,512,1,1)       |\n",
      "| backbone.bottom_up.res4.0.conv2.*    | backbone.bottom_up.res4.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.0.conv3.*    | backbone.bottom_up.res4.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.0.shortcut.* | backbone.bottom_up.res4.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (1024,) (1024,) (1024,) (1024,) (1024,512,1,1)  |\n",
      "| backbone.bottom_up.res4.1.conv1.*    | backbone.bottom_up.res4.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.1.conv2.*    | backbone.bottom_up.res4.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.1.conv3.*    | backbone.bottom_up.res4.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.2.conv1.*    | backbone.bottom_up.res4.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.2.conv2.*    | backbone.bottom_up.res4.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.2.conv3.*    | backbone.bottom_up.res4.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.3.conv1.*    | backbone.bottom_up.res4.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.3.conv2.*    | backbone.bottom_up.res4.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.3.conv3.*    | backbone.bottom_up.res4.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.4.conv1.*    | backbone.bottom_up.res4.4.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.4.conv2.*    | backbone.bottom_up.res4.4.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.4.conv3.*    | backbone.bottom_up.res4.4.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.5.conv1.*    | backbone.bottom_up.res4.5.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.5.conv2.*    | backbone.bottom_up.res4.5.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.5.conv3.*    | backbone.bottom_up.res4.5.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res5.0.conv1.*    | backbone.bottom_up.res5.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,1024,1,1)      |\n",
      "| backbone.bottom_up.res5.0.conv2.*    | backbone.bottom_up.res5.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |\n",
      "| backbone.bottom_up.res5.0.conv3.*    | backbone.bottom_up.res5.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
      "| backbone.bottom_up.res5.0.shortcut.* | backbone.bottom_up.res5.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (2048,) (2048,) (2048,) (2048,) (2048,1024,1,1) |\n",
      "| backbone.bottom_up.res5.1.conv1.*    | backbone.bottom_up.res5.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |\n",
      "| backbone.bottom_up.res5.1.conv2.*    | backbone.bottom_up.res5.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |\n",
      "| backbone.bottom_up.res5.1.conv3.*    | backbone.bottom_up.res5.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
      "| backbone.bottom_up.res5.2.conv1.*    | backbone.bottom_up.res5.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |\n",
      "| backbone.bottom_up.res5.2.conv2.*    | backbone.bottom_up.res5.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |\n",
      "| backbone.bottom_up.res5.2.conv3.*    | backbone.bottom_up.res5.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
      "| backbone.bottom_up.stem.conv1.*      | backbone.bottom_up.stem.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}      | (64,) (64,) (64,) (64,) (64,3,7,7)              |\n",
      "| backbone.fpn_lateral2.*              | backbone.fpn_lateral2.{bias,weight}                                                                  | (256,) (256,256,1,1)                            |\n",
      "| backbone.fpn_lateral3.*              | backbone.fpn_lateral3.{bias,weight}                                                                  | (256,) (256,512,1,1)                            |\n",
      "| backbone.fpn_lateral4.*              | backbone.fpn_lateral4.{bias,weight}                                                                  | (256,) (256,1024,1,1)                           |\n",
      "| backbone.fpn_lateral5.*              | backbone.fpn_lateral5.{bias,weight}                                                                  | (256,) (256,2048,1,1)                           |\n",
      "| backbone.fpn_output2.*               | backbone.fpn_output2.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| backbone.fpn_output3.*               | backbone.fpn_output3.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| backbone.fpn_output4.*               | backbone.fpn_output4.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| backbone.fpn_output5.*               | backbone.fpn_output5.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| sem_seg_head.p2.0.*                  | sem_seg_head.p2.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p3.0.*                  | sem_seg_head.p3.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p4.0.*                  | sem_seg_head.p4.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p4.2.*                  | sem_seg_head.p4.2.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,128,3,3)                     |\n",
      "| sem_seg_head.p5.0.*                  | sem_seg_head.p5.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p5.2.*                  | sem_seg_head.p5.2.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,128,3,3)                     |\n",
      "| sem_seg_head.p5.4.*                  | sem_seg_head.p5.4.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,128,3,3)                     |\n",
      "| sem_seg_head.predictor.*             | sem_seg_head.predictor.{bias,weight}                                                                 | (17,) (17,128,1,1)                              |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/12 15:43:06 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(720, 720), max_size=2048, sample_style='choice')]\n",
      "\u001b[32m[07/12 15:43:06 d2.data.common]: \u001b[0mSerializing 3273 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[07/12 15:43:06 d2.data.common]: \u001b[0mSerialized dataset takes 1.04 MiB\n",
      "\u001b[32m[07/12 15:43:06 d2.evaluation.evaluator]: \u001b[0mStart inference on 3273 batches\n",
      "\u001b[32m[07/12 15:43:08 d2.evaluation.evaluator]: \u001b[0mInference done 18/3273. Dataloading: 0.0018 s/iter. Inference: 0.0356 s/iter. Eval: 0.0420 s/iter. Total: 0.0794 s/iter. ETA=0:04:18\n",
      "\u001b[32m[07/12 15:43:13 d2.evaluation.evaluator]: \u001b[0mInference done 81/3273. Dataloading: 0.0020 s/iter. Inference: 0.0355 s/iter. Eval: 0.0419 s/iter. Total: 0.0795 s/iter. ETA=0:04:13\n",
      "\u001b[32m[07/12 15:43:18 d2.evaluation.evaluator]: \u001b[0mInference done 143/3273. Dataloading: 0.0020 s/iter. Inference: 0.0356 s/iter. Eval: 0.0426 s/iter. Total: 0.0802 s/iter. ETA=0:04:11\n",
      "\u001b[32m[07/12 15:43:23 d2.evaluation.evaluator]: \u001b[0mInference done 206/3273. Dataloading: 0.0020 s/iter. Inference: 0.0356 s/iter. Eval: 0.0425 s/iter. Total: 0.0801 s/iter. ETA=0:04:05\n",
      "\u001b[32m[07/12 15:43:28 d2.evaluation.evaluator]: \u001b[0mInference done 270/3273. Dataloading: 0.0020 s/iter. Inference: 0.0356 s/iter. Eval: 0.0423 s/iter. Total: 0.0799 s/iter. ETA=0:04:00\n",
      "\u001b[32m[07/12 15:43:33 d2.evaluation.evaluator]: \u001b[0mInference done 332/3273. Dataloading: 0.0019 s/iter. Inference: 0.0356 s/iter. Eval: 0.0425 s/iter. Total: 0.0801 s/iter. ETA=0:03:55\n",
      "\u001b[32m[07/12 15:43:38 d2.evaluation.evaluator]: \u001b[0mInference done 394/3273. Dataloading: 0.0019 s/iter. Inference: 0.0356 s/iter. Eval: 0.0427 s/iter. Total: 0.0803 s/iter. ETA=0:03:51\n",
      "\u001b[32m[07/12 15:43:43 d2.evaluation.evaluator]: \u001b[0mInference done 456/3273. Dataloading: 0.0020 s/iter. Inference: 0.0356 s/iter. Eval: 0.0429 s/iter. Total: 0.0805 s/iter. ETA=0:03:46\n",
      "\u001b[32m[07/12 15:43:48 d2.evaluation.evaluator]: \u001b[0mInference done 518/3273. Dataloading: 0.0020 s/iter. Inference: 0.0356 s/iter. Eval: 0.0430 s/iter. Total: 0.0806 s/iter. ETA=0:03:41\n",
      "\u001b[32m[07/12 15:43:53 d2.evaluation.evaluator]: \u001b[0mInference done 580/3273. Dataloading: 0.0020 s/iter. Inference: 0.0356 s/iter. Eval: 0.0430 s/iter. Total: 0.0806 s/iter. ETA=0:03:37\n",
      "\u001b[32m[07/12 15:43:58 d2.evaluation.evaluator]: \u001b[0mInference done 642/3273. Dataloading: 0.0020 s/iter. Inference: 0.0356 s/iter. Eval: 0.0431 s/iter. Total: 0.0807 s/iter. ETA=0:03:32\n",
      "\u001b[32m[07/12 15:44:03 d2.evaluation.evaluator]: \u001b[0mInference done 703/3273. Dataloading: 0.0020 s/iter. Inference: 0.0356 s/iter. Eval: 0.0432 s/iter. Total: 0.0808 s/iter. ETA=0:03:27\n",
      "\u001b[32m[07/12 15:44:08 d2.evaluation.evaluator]: \u001b[0mInference done 765/3273. Dataloading: 0.0020 s/iter. Inference: 0.0356 s/iter. Eval: 0.0432 s/iter. Total: 0.0808 s/iter. ETA=0:03:22\n",
      "\u001b[32m[07/12 15:44:13 d2.evaluation.evaluator]: \u001b[0mInference done 831/3273. Dataloading: 0.0020 s/iter. Inference: 0.0356 s/iter. Eval: 0.0428 s/iter. Total: 0.0805 s/iter. ETA=0:03:16\n",
      "\u001b[32m[07/12 15:44:18 d2.evaluation.evaluator]: \u001b[0mInference done 896/3273. Dataloading: 0.0020 s/iter. Inference: 0.0356 s/iter. Eval: 0.0426 s/iter. Total: 0.0802 s/iter. ETA=0:03:10\n",
      "\u001b[32m[07/12 15:44:23 d2.evaluation.evaluator]: \u001b[0mInference done 961/3273. Dataloading: 0.0020 s/iter. Inference: 0.0356 s/iter. Eval: 0.0423 s/iter. Total: 0.0800 s/iter. ETA=0:03:04\n",
      "\u001b[32m[07/12 15:44:28 d2.evaluation.evaluator]: \u001b[0mInference done 1026/3273. Dataloading: 0.0020 s/iter. Inference: 0.0356 s/iter. Eval: 0.0422 s/iter. Total: 0.0798 s/iter. ETA=0:02:59\n",
      "\u001b[32m[07/12 15:44:33 d2.evaluation.evaluator]: \u001b[0mInference done 1091/3273. Dataloading: 0.0020 s/iter. Inference: 0.0356 s/iter. Eval: 0.0420 s/iter. Total: 0.0797 s/iter. ETA=0:02:53\n",
      "\u001b[32m[07/12 15:44:38 d2.evaluation.evaluator]: \u001b[0mInference done 1157/3273. Dataloading: 0.0020 s/iter. Inference: 0.0356 s/iter. Eval: 0.0418 s/iter. Total: 0.0795 s/iter. ETA=0:02:48\n",
      "\u001b[32m[07/12 15:44:43 d2.evaluation.evaluator]: \u001b[0mInference done 1222/3273. Dataloading: 0.0020 s/iter. Inference: 0.0356 s/iter. Eval: 0.0417 s/iter. Total: 0.0794 s/iter. ETA=0:02:42\n",
      "\u001b[32m[07/12 15:44:48 d2.evaluation.evaluator]: \u001b[0mInference done 1288/3273. Dataloading: 0.0020 s/iter. Inference: 0.0356 s/iter. Eval: 0.0416 s/iter. Total: 0.0793 s/iter. ETA=0:02:37\n",
      "\u001b[32m[07/12 15:44:54 d2.evaluation.evaluator]: \u001b[0mInference done 1352/3273. Dataloading: 0.0020 s/iter. Inference: 0.0356 s/iter. Eval: 0.0416 s/iter. Total: 0.0793 s/iter. ETA=0:02:32\n",
      "\u001b[32m[07/12 15:44:59 d2.evaluation.evaluator]: \u001b[0mInference done 1416/3273. Dataloading: 0.0020 s/iter. Inference: 0.0356 s/iter. Eval: 0.0415 s/iter. Total: 0.0792 s/iter. ETA=0:02:27\n",
      "\u001b[32m[07/12 15:45:04 d2.evaluation.evaluator]: \u001b[0mInference done 1481/3273. Dataloading: 0.0020 s/iter. Inference: 0.0356 s/iter. Eval: 0.0415 s/iter. Total: 0.0792 s/iter. ETA=0:02:21\n",
      "\u001b[32m[07/12 15:45:09 d2.evaluation.evaluator]: \u001b[0mInference done 1545/3273. Dataloading: 0.0020 s/iter. Inference: 0.0356 s/iter. Eval: 0.0414 s/iter. Total: 0.0791 s/iter. ETA=0:02:16\n",
      "\u001b[32m[07/12 15:45:14 d2.evaluation.evaluator]: \u001b[0mInference done 1609/3273. Dataloading: 0.0020 s/iter. Inference: 0.0356 s/iter. Eval: 0.0414 s/iter. Total: 0.0791 s/iter. ETA=0:02:11\n",
      "\u001b[32m[07/12 15:45:19 d2.evaluation.evaluator]: \u001b[0mInference done 1673/3273. Dataloading: 0.0020 s/iter. Inference: 0.0356 s/iter. Eval: 0.0414 s/iter. Total: 0.0791 s/iter. ETA=0:02:06\n",
      "\u001b[32m[07/12 15:45:24 d2.evaluation.evaluator]: \u001b[0mInference done 1737/3273. Dataloading: 0.0020 s/iter. Inference: 0.0356 s/iter. Eval: 0.0414 s/iter. Total: 0.0791 s/iter. ETA=0:02:01\n",
      "\u001b[32m[07/12 15:45:29 d2.evaluation.evaluator]: \u001b[0mInference done 1802/3273. Dataloading: 0.0020 s/iter. Inference: 0.0356 s/iter. Eval: 0.0413 s/iter. Total: 0.0790 s/iter. ETA=0:01:56\n",
      "\u001b[32m[07/12 15:45:34 d2.evaluation.evaluator]: \u001b[0mInference done 1866/3273. Dataloading: 0.0020 s/iter. Inference: 0.0356 s/iter. Eval: 0.0413 s/iter. Total: 0.0790 s/iter. ETA=0:01:51\n",
      "\u001b[32m[07/12 15:45:39 d2.evaluation.evaluator]: \u001b[0mInference done 1931/3273. Dataloading: 0.0020 s/iter. Inference: 0.0356 s/iter. Eval: 0.0412 s/iter. Total: 0.0790 s/iter. ETA=0:01:45\n",
      "\u001b[32m[07/12 15:45:44 d2.evaluation.evaluator]: \u001b[0mInference done 1996/3273. Dataloading: 0.0020 s/iter. Inference: 0.0357 s/iter. Eval: 0.0412 s/iter. Total: 0.0789 s/iter. ETA=0:01:40\n",
      "\u001b[32m[07/12 15:45:49 d2.evaluation.evaluator]: \u001b[0mInference done 2060/3273. Dataloading: 0.0020 s/iter. Inference: 0.0357 s/iter. Eval: 0.0412 s/iter. Total: 0.0789 s/iter. ETA=0:01:35\n",
      "\u001b[32m[07/12 15:45:54 d2.evaluation.evaluator]: \u001b[0mInference done 2125/3273. Dataloading: 0.0020 s/iter. Inference: 0.0357 s/iter. Eval: 0.0411 s/iter. Total: 0.0789 s/iter. ETA=0:01:30\n",
      "\u001b[32m[07/12 15:45:59 d2.evaluation.evaluator]: \u001b[0mInference done 2191/3273. Dataloading: 0.0020 s/iter. Inference: 0.0357 s/iter. Eval: 0.0411 s/iter. Total: 0.0788 s/iter. ETA=0:01:25\n",
      "\u001b[32m[07/12 15:46:04 d2.evaluation.evaluator]: \u001b[0mInference done 2255/3273. Dataloading: 0.0020 s/iter. Inference: 0.0357 s/iter. Eval: 0.0410 s/iter. Total: 0.0788 s/iter. ETA=0:01:20\n",
      "\u001b[32m[07/12 15:46:09 d2.evaluation.evaluator]: \u001b[0mInference done 2318/3273. Dataloading: 0.0021 s/iter. Inference: 0.0357 s/iter. Eval: 0.0410 s/iter. Total: 0.0788 s/iter. ETA=0:01:15\n",
      "\u001b[32m[07/12 15:46:14 d2.evaluation.evaluator]: \u001b[0mInference done 2382/3273. Dataloading: 0.0021 s/iter. Inference: 0.0357 s/iter. Eval: 0.0410 s/iter. Total: 0.0788 s/iter. ETA=0:01:10\n",
      "\u001b[32m[07/12 15:46:19 d2.evaluation.evaluator]: \u001b[0mInference done 2446/3273. Dataloading: 0.0021 s/iter. Inference: 0.0357 s/iter. Eval: 0.0410 s/iter. Total: 0.0788 s/iter. ETA=0:01:05\n",
      "\u001b[32m[07/12 15:46:24 d2.evaluation.evaluator]: \u001b[0mInference done 2511/3273. Dataloading: 0.0021 s/iter. Inference: 0.0357 s/iter. Eval: 0.0410 s/iter. Total: 0.0788 s/iter. ETA=0:01:00\n",
      "\u001b[32m[07/12 15:46:29 d2.evaluation.evaluator]: \u001b[0mInference done 2575/3273. Dataloading: 0.0021 s/iter. Inference: 0.0357 s/iter. Eval: 0.0410 s/iter. Total: 0.0788 s/iter. ETA=0:00:54\n",
      "\u001b[32m[07/12 15:46:34 d2.evaluation.evaluator]: \u001b[0mInference done 2639/3273. Dataloading: 0.0021 s/iter. Inference: 0.0357 s/iter. Eval: 0.0410 s/iter. Total: 0.0788 s/iter. ETA=0:00:49\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/12 15:46:39 d2.evaluation.evaluator]: \u001b[0mInference done 2703/3273. Dataloading: 0.0021 s/iter. Inference: 0.0357 s/iter. Eval: 0.0410 s/iter. Total: 0.0788 s/iter. ETA=0:00:44\n",
      "\u001b[32m[07/12 15:46:44 d2.evaluation.evaluator]: \u001b[0mInference done 2767/3273. Dataloading: 0.0021 s/iter. Inference: 0.0357 s/iter. Eval: 0.0410 s/iter. Total: 0.0788 s/iter. ETA=0:00:39\n",
      "\u001b[32m[07/12 15:46:49 d2.evaluation.evaluator]: \u001b[0mInference done 2830/3273. Dataloading: 0.0021 s/iter. Inference: 0.0357 s/iter. Eval: 0.0410 s/iter. Total: 0.0788 s/iter. ETA=0:00:34\n",
      "\u001b[32m[07/12 15:46:54 d2.evaluation.evaluator]: \u001b[0mInference done 2893/3273. Dataloading: 0.0021 s/iter. Inference: 0.0357 s/iter. Eval: 0.0410 s/iter. Total: 0.0788 s/iter. ETA=0:00:29\n",
      "\u001b[32m[07/12 15:46:59 d2.evaluation.evaluator]: \u001b[0mInference done 2956/3273. Dataloading: 0.0021 s/iter. Inference: 0.0357 s/iter. Eval: 0.0411 s/iter. Total: 0.0789 s/iter. ETA=0:00:25\n",
      "\u001b[32m[07/12 15:47:05 d2.evaluation.evaluator]: \u001b[0mInference done 3019/3273. Dataloading: 0.0021 s/iter. Inference: 0.0357 s/iter. Eval: 0.0411 s/iter. Total: 0.0789 s/iter. ETA=0:00:20\n",
      "\u001b[32m[07/12 15:47:10 d2.evaluation.evaluator]: \u001b[0mInference done 3082/3273. Dataloading: 0.0021 s/iter. Inference: 0.0357 s/iter. Eval: 0.0411 s/iter. Total: 0.0789 s/iter. ETA=0:00:15\n",
      "\u001b[32m[07/12 15:47:15 d2.evaluation.evaluator]: \u001b[0mInference done 3146/3273. Dataloading: 0.0021 s/iter. Inference: 0.0357 s/iter. Eval: 0.0411 s/iter. Total: 0.0789 s/iter. ETA=0:00:10\n",
      "\u001b[32m[07/12 15:47:20 d2.evaluation.evaluator]: \u001b[0mInference done 3209/3273. Dataloading: 0.0021 s/iter. Inference: 0.0357 s/iter. Eval: 0.0411 s/iter. Total: 0.0789 s/iter. ETA=0:00:05\n",
      "\u001b[32m[07/12 15:47:25 d2.evaluation.evaluator]: \u001b[0mInference done 3273/3273. Dataloading: 0.0021 s/iter. Inference: 0.0357 s/iter. Eval: 0.0411 s/iter. Total: 0.0789 s/iter. ETA=0:00:00\n",
      "\u001b[32m[07/12 15:47:25 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:04:18.025663 (0.078955 s / iter per device, on 1 devices)\n",
      "\u001b[32m[07/12 15:47:25 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:01:56 (0.035680 s / iter per device, on 1 devices)\n",
      "\u001b[32m[07/12 15:47:25 d2.evaluation.sem_seg_evaluation]: \u001b[0mOrderedDict([('sem_seg', {'mIoU': 25.169839061663808, 'fwIoU': 50.69599850590151, 'IoU-Unlabeled': nan, 'IoU-Building': 30.872204660894987, 'IoU-Fence': 6.542131499579246, 'IoU-Pedestrian': 17.868739215076797, 'IoU-Pole': 31.437818473583768, 'IoU-Road': 78.49653442231137, 'IoU-SideWalk': 30.257083913288756, 'IoU-Vegetation': 27.46547850582467, 'IoU-Vehicles': 27.816749540571518, 'IoU-Wall': 2.2392908386781087, 'IoU-TrafficSign': 27.880217815701158, 'IoU-Sky': 50.8315852937754, 'IoU-TrafficLight': 25.537709497206706, 'IoU-Terrain': 0.05066111618336585, 'IoU-ConstructionVehicle': 27.771536748720017, 'IoU-workzone_object': 10.872537452906212, 'IoU-Detour': 6.777145992318818, 'mACC': 48.56442599180475, 'pACC': 63.349585201865864, 'ACC-Unlabeled': nan, 'ACC-Building': 93.27550808115808, 'ACC-Fence': 10.132657001995511, 'ACC-Pedestrian': 58.54764841154707, 'ACC-Pole': 40.00508444832758, 'ACC-Road': 83.45580584421639, 'ACC-SideWalk': 40.59253915694445, 'ACC-Vegetation': 35.62148709641815, 'ACC-Vehicles': 76.32327139121432, 'ACC-Wall': 2.2780680353750555, 'ACC-TrafficSign': 43.11005449039661, 'ACC-Sky': 56.20484793420548, 'ACC-TrafficLight': 30.466032780991803, 'ACC-Terrain': 0.050886648884106635, 'ACC-ConstructionVehicle': 94.6796450284473, 'ACC-workzone_object': 76.87088436692304, 'ACC-Detour': 35.4163951518311})])\n",
      "\u001b[32m[07/12 15:47:25 d2.engine.defaults]: \u001b[0mEvaluation results for carla_night_rain_val in csv format:\n",
      "\u001b[32m[07/12 15:47:25 d2.evaluation.testing]: \u001b[0mcopypaste: Task: sem_seg\n",
      "\u001b[32m[07/12 15:47:25 d2.evaluation.testing]: \u001b[0mcopypaste: mIoU,fwIoU,mACC,pACC\n",
      "\u001b[32m[07/12 15:47:25 d2.evaluation.testing]: \u001b[0mcopypaste: 25.1698,50.6960,48.5644,63.3496\n"
     ]
    }
   ],
   "source": [
    "trainer_day = Detectron2Trainer('carla_night_clear_train', 'carla_night_rain_val', output_folder='./output_night_clear_40k')\n",
    "trainer_day.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "12253421",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/12 15:47:26 d2.engine.defaults]: \u001b[0mModel:\n",
      "SemanticSegmentor(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (sem_seg_head): SemSegFPNHead(\n",
      "    (p2): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "    )\n",
      "    (p3): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (1): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "    )\n",
      "    (p4): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (1): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      (2): Conv2d(\n",
      "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (3): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "    )\n",
      "    (p5): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (1): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      (2): Conv2d(\n",
      "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (3): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      (4): Conv2d(\n",
      "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (5): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "    )\n",
      "    (predictor): Conv2d(128, 17, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/12 15:47:26 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(720, 720), max_size=2048, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[07/12 15:47:26 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[07/12 15:47:26 d2.data.common]: \u001b[0mSerializing 7723 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[07/12 15:47:26 d2.data.common]: \u001b[0mSerialized dataset takes 2.52 MiB\n",
      "Last checkpoint: model_final.pth\n",
      "\u001b[32m[07/12 15:47:26 d2.checkpoint.c2_model_loading]: \u001b[0mFollowing weights matched with model:\n",
      "| Names in Model                       | Names in Checkpoint                                                                                  | Shapes                                          |\n",
      "|:-------------------------------------|:-----------------------------------------------------------------------------------------------------|:------------------------------------------------|\n",
      "| backbone.bottom_up.res2.0.conv1.*    | backbone.bottom_up.res2.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,1,1)             |\n",
      "| backbone.bottom_up.res2.0.conv2.*    | backbone.bottom_up.res2.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |\n",
      "| backbone.bottom_up.res2.0.conv3.*    | backbone.bottom_up.res2.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res2.0.shortcut.* | backbone.bottom_up.res2.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res2.1.conv1.*    | backbone.bottom_up.res2.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |\n",
      "| backbone.bottom_up.res2.1.conv2.*    | backbone.bottom_up.res2.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |\n",
      "| backbone.bottom_up.res2.1.conv3.*    | backbone.bottom_up.res2.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res2.2.conv1.*    | backbone.bottom_up.res2.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |\n",
      "| backbone.bottom_up.res2.2.conv2.*    | backbone.bottom_up.res2.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |\n",
      "| backbone.bottom_up.res2.2.conv3.*    | backbone.bottom_up.res2.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res3.0.conv1.*    | backbone.bottom_up.res3.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,256,1,1)       |\n",
      "| backbone.bottom_up.res3.0.conv2.*    | backbone.bottom_up.res3.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.0.conv3.*    | backbone.bottom_up.res3.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res3.0.shortcut.* | backbone.bottom_up.res3.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (512,) (512,) (512,) (512,) (512,256,1,1)       |\n",
      "| backbone.bottom_up.res3.1.conv1.*    | backbone.bottom_up.res3.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |\n",
      "| backbone.bottom_up.res3.1.conv2.*    | backbone.bottom_up.res3.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.1.conv3.*    | backbone.bottom_up.res3.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res3.2.conv1.*    | backbone.bottom_up.res3.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |\n",
      "| backbone.bottom_up.res3.2.conv2.*    | backbone.bottom_up.res3.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.2.conv3.*    | backbone.bottom_up.res3.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res3.3.conv1.*    | backbone.bottom_up.res3.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |\n",
      "| backbone.bottom_up.res3.3.conv2.*    | backbone.bottom_up.res3.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.3.conv3.*    | backbone.bottom_up.res3.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res4.0.conv1.*    | backbone.bottom_up.res4.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,512,1,1)       |\n",
      "| backbone.bottom_up.res4.0.conv2.*    | backbone.bottom_up.res4.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.0.conv3.*    | backbone.bottom_up.res4.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.0.shortcut.* | backbone.bottom_up.res4.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (1024,) (1024,) (1024,) (1024,) (1024,512,1,1)  |\n",
      "| backbone.bottom_up.res4.1.conv1.*    | backbone.bottom_up.res4.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.1.conv2.*    | backbone.bottom_up.res4.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.1.conv3.*    | backbone.bottom_up.res4.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.2.conv1.*    | backbone.bottom_up.res4.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.2.conv2.*    | backbone.bottom_up.res4.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.2.conv3.*    | backbone.bottom_up.res4.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.3.conv1.*    | backbone.bottom_up.res4.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.3.conv2.*    | backbone.bottom_up.res4.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.3.conv3.*    | backbone.bottom_up.res4.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.4.conv1.*    | backbone.bottom_up.res4.4.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.4.conv2.*    | backbone.bottom_up.res4.4.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.4.conv3.*    | backbone.bottom_up.res4.4.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.5.conv1.*    | backbone.bottom_up.res4.5.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.5.conv2.*    | backbone.bottom_up.res4.5.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.5.conv3.*    | backbone.bottom_up.res4.5.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res5.0.conv1.*    | backbone.bottom_up.res5.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,1024,1,1)      |\n",
      "| backbone.bottom_up.res5.0.conv2.*    | backbone.bottom_up.res5.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |\n",
      "| backbone.bottom_up.res5.0.conv3.*    | backbone.bottom_up.res5.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
      "| backbone.bottom_up.res5.0.shortcut.* | backbone.bottom_up.res5.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (2048,) (2048,) (2048,) (2048,) (2048,1024,1,1) |\n",
      "| backbone.bottom_up.res5.1.conv1.*    | backbone.bottom_up.res5.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |\n",
      "| backbone.bottom_up.res5.1.conv2.*    | backbone.bottom_up.res5.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |\n",
      "| backbone.bottom_up.res5.1.conv3.*    | backbone.bottom_up.res5.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
      "| backbone.bottom_up.res5.2.conv1.*    | backbone.bottom_up.res5.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |\n",
      "| backbone.bottom_up.res5.2.conv2.*    | backbone.bottom_up.res5.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |\n",
      "| backbone.bottom_up.res5.2.conv3.*    | backbone.bottom_up.res5.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
      "| backbone.bottom_up.stem.conv1.*      | backbone.bottom_up.stem.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}      | (64,) (64,) (64,) (64,) (64,3,7,7)              |\n",
      "| backbone.fpn_lateral2.*              | backbone.fpn_lateral2.{bias,weight}                                                                  | (256,) (256,256,1,1)                            |\n",
      "| backbone.fpn_lateral3.*              | backbone.fpn_lateral3.{bias,weight}                                                                  | (256,) (256,512,1,1)                            |\n",
      "| backbone.fpn_lateral4.*              | backbone.fpn_lateral4.{bias,weight}                                                                  | (256,) (256,1024,1,1)                           |\n",
      "| backbone.fpn_lateral5.*              | backbone.fpn_lateral5.{bias,weight}                                                                  | (256,) (256,2048,1,1)                           |\n",
      "| backbone.fpn_output2.*               | backbone.fpn_output2.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| backbone.fpn_output3.*               | backbone.fpn_output3.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| backbone.fpn_output4.*               | backbone.fpn_output4.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| backbone.fpn_output5.*               | backbone.fpn_output5.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| sem_seg_head.p2.0.*                  | sem_seg_head.p2.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p3.0.*                  | sem_seg_head.p3.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p4.0.*                  | sem_seg_head.p4.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p4.2.*                  | sem_seg_head.p4.2.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,128,3,3)                     |\n",
      "| sem_seg_head.p5.0.*                  | sem_seg_head.p5.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p5.2.*                  | sem_seg_head.p5.2.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,128,3,3)                     |\n",
      "| sem_seg_head.p5.4.*                  | sem_seg_head.p5.4.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,128,3,3)                     |\n",
      "| sem_seg_head.predictor.*             | sem_seg_head.predictor.{bias,weight}                                                                 | (17,) (17,128,1,1)                              |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/12 15:47:26 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(720, 720), max_size=2048, sample_style='choice')]\n",
      "\u001b[32m[07/12 15:47:26 d2.data.common]: \u001b[0mSerializing 6546 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[07/12 15:47:26 d2.data.common]: \u001b[0mSerialized dataset takes 2.08 MiB\n",
      "\u001b[32m[07/12 15:47:26 d2.evaluation.evaluator]: \u001b[0mStart inference on 6546 batches\n",
      "\u001b[32m[07/12 15:47:30 d2.evaluation.evaluator]: \u001b[0mInference done 38/6546. Dataloading: 0.0020 s/iter. Inference: 0.0356 s/iter. Eval: 0.0438 s/iter. Total: 0.0814 s/iter. ETA=0:08:49\n",
      "\u001b[32m[07/12 15:47:35 d2.evaluation.evaluator]: \u001b[0mInference done 101/6546. Dataloading: 0.0020 s/iter. Inference: 0.0356 s/iter. Eval: 0.0430 s/iter. Total: 0.0806 s/iter. ETA=0:08:39\n",
      "\u001b[32m[07/12 15:47:40 d2.evaluation.evaluator]: \u001b[0mInference done 165/6546. Dataloading: 0.0020 s/iter. Inference: 0.0356 s/iter. Eval: 0.0422 s/iter. Total: 0.0799 s/iter. ETA=0:08:29\n",
      "\u001b[32m[07/12 15:47:45 d2.evaluation.evaluator]: \u001b[0mInference done 228/6546. Dataloading: 0.0020 s/iter. Inference: 0.0356 s/iter. Eval: 0.0423 s/iter. Total: 0.0801 s/iter. ETA=0:08:25\n",
      "\u001b[32m[07/12 15:47:50 d2.evaluation.evaluator]: \u001b[0mInference done 292/6546. Dataloading: 0.0020 s/iter. Inference: 0.0356 s/iter. Eval: 0.0421 s/iter. Total: 0.0798 s/iter. ETA=0:08:19\n",
      "\u001b[32m[07/12 15:47:55 d2.evaluation.evaluator]: \u001b[0mInference done 356/6546. Dataloading: 0.0020 s/iter. Inference: 0.0357 s/iter. Eval: 0.0419 s/iter. Total: 0.0797 s/iter. ETA=0:08:13\n",
      "\u001b[32m[07/12 15:48:00 d2.evaluation.evaluator]: \u001b[0mInference done 418/6546. Dataloading: 0.0021 s/iter. Inference: 0.0357 s/iter. Eval: 0.0421 s/iter. Total: 0.0799 s/iter. ETA=0:08:09\n",
      "\u001b[32m[07/12 15:48:05 d2.evaluation.evaluator]: \u001b[0mInference done 482/6546. Dataloading: 0.0021 s/iter. Inference: 0.0357 s/iter. Eval: 0.0420 s/iter. Total: 0.0798 s/iter. ETA=0:08:03\n",
      "\u001b[32m[07/12 15:48:10 d2.evaluation.evaluator]: \u001b[0mInference done 546/6546. Dataloading: 0.0021 s/iter. Inference: 0.0357 s/iter. Eval: 0.0419 s/iter. Total: 0.0797 s/iter. ETA=0:07:58\n",
      "\u001b[32m[07/12 15:48:15 d2.evaluation.evaluator]: \u001b[0mInference done 609/6546. Dataloading: 0.0021 s/iter. Inference: 0.0357 s/iter. Eval: 0.0419 s/iter. Total: 0.0797 s/iter. ETA=0:07:53\n",
      "\u001b[32m[07/12 15:48:20 d2.evaluation.evaluator]: \u001b[0mInference done 671/6546. Dataloading: 0.0021 s/iter. Inference: 0.0357 s/iter. Eval: 0.0420 s/iter. Total: 0.0799 s/iter. ETA=0:07:49\n",
      "\u001b[32m[07/12 15:48:25 d2.evaluation.evaluator]: \u001b[0mInference done 732/6546. Dataloading: 0.0021 s/iter. Inference: 0.0357 s/iter. Eval: 0.0422 s/iter. Total: 0.0801 s/iter. ETA=0:07:45\n",
      "\u001b[32m[07/12 15:48:30 d2.evaluation.evaluator]: \u001b[0mInference done 794/6546. Dataloading: 0.0021 s/iter. Inference: 0.0357 s/iter. Eval: 0.0424 s/iter. Total: 0.0803 s/iter. ETA=0:07:41\n",
      "\u001b[32m[07/12 15:48:35 d2.evaluation.evaluator]: \u001b[0mInference done 855/6546. Dataloading: 0.0021 s/iter. Inference: 0.0357 s/iter. Eval: 0.0426 s/iter. Total: 0.0805 s/iter. ETA=0:07:37\n",
      "\u001b[32m[07/12 15:48:41 d2.evaluation.evaluator]: \u001b[0mInference done 917/6546. Dataloading: 0.0021 s/iter. Inference: 0.0357 s/iter. Eval: 0.0427 s/iter. Total: 0.0806 s/iter. ETA=0:07:33\n",
      "\u001b[32m[07/12 15:48:46 d2.evaluation.evaluator]: \u001b[0mInference done 979/6546. Dataloading: 0.0021 s/iter. Inference: 0.0357 s/iter. Eval: 0.0427 s/iter. Total: 0.0806 s/iter. ETA=0:07:28\n",
      "\u001b[32m[07/12 15:48:51 d2.evaluation.evaluator]: \u001b[0mInference done 1040/6546. Dataloading: 0.0021 s/iter. Inference: 0.0357 s/iter. Eval: 0.0428 s/iter. Total: 0.0807 s/iter. ETA=0:07:24\n",
      "\u001b[32m[07/12 15:48:56 d2.evaluation.evaluator]: \u001b[0mInference done 1101/6546. Dataloading: 0.0021 s/iter. Inference: 0.0357 s/iter. Eval: 0.0429 s/iter. Total: 0.0808 s/iter. ETA=0:07:20\n",
      "\u001b[32m[07/12 15:49:01 d2.evaluation.evaluator]: \u001b[0mInference done 1163/6546. Dataloading: 0.0021 s/iter. Inference: 0.0357 s/iter. Eval: 0.0429 s/iter. Total: 0.0808 s/iter. ETA=0:07:15\n",
      "\u001b[32m[07/12 15:49:06 d2.evaluation.evaluator]: \u001b[0mInference done 1224/6546. Dataloading: 0.0021 s/iter. Inference: 0.0358 s/iter. Eval: 0.0429 s/iter. Total: 0.0809 s/iter. ETA=0:07:10\n",
      "\u001b[32m[07/12 15:49:11 d2.evaluation.evaluator]: \u001b[0mInference done 1286/6546. Dataloading: 0.0021 s/iter. Inference: 0.0358 s/iter. Eval: 0.0429 s/iter. Total: 0.0810 s/iter. ETA=0:07:05\n",
      "\u001b[32m[07/12 15:49:16 d2.evaluation.evaluator]: \u001b[0mInference done 1346/6546. Dataloading: 0.0022 s/iter. Inference: 0.0358 s/iter. Eval: 0.0431 s/iter. Total: 0.0811 s/iter. ETA=0:07:01\n",
      "\u001b[32m[07/12 15:49:21 d2.evaluation.evaluator]: \u001b[0mInference done 1408/6546. Dataloading: 0.0022 s/iter. Inference: 0.0358 s/iter. Eval: 0.0431 s/iter. Total: 0.0812 s/iter. ETA=0:06:56\n",
      "\u001b[32m[07/12 15:49:26 d2.evaluation.evaluator]: \u001b[0mInference done 1470/6546. Dataloading: 0.0022 s/iter. Inference: 0.0358 s/iter. Eval: 0.0431 s/iter. Total: 0.0812 s/iter. ETA=0:06:52\n",
      "\u001b[32m[07/12 15:49:31 d2.evaluation.evaluator]: \u001b[0mInference done 1532/6546. Dataloading: 0.0022 s/iter. Inference: 0.0358 s/iter. Eval: 0.0431 s/iter. Total: 0.0812 s/iter. ETA=0:06:47\n",
      "\u001b[32m[07/12 15:49:36 d2.evaluation.evaluator]: \u001b[0mInference done 1597/6546. Dataloading: 0.0022 s/iter. Inference: 0.0358 s/iter. Eval: 0.0430 s/iter. Total: 0.0810 s/iter. ETA=0:06:41\n",
      "\u001b[32m[07/12 15:49:41 d2.evaluation.evaluator]: \u001b[0mInference done 1662/6546. Dataloading: 0.0022 s/iter. Inference: 0.0358 s/iter. Eval: 0.0428 s/iter. Total: 0.0809 s/iter. ETA=0:06:35\n",
      "\u001b[32m[07/12 15:49:46 d2.evaluation.evaluator]: \u001b[0mInference done 1727/6546. Dataloading: 0.0022 s/iter. Inference: 0.0358 s/iter. Eval: 0.0427 s/iter. Total: 0.0808 s/iter. ETA=0:06:29\n",
      "\u001b[32m[07/12 15:49:51 d2.evaluation.evaluator]: \u001b[0mInference done 1793/6546. Dataloading: 0.0022 s/iter. Inference: 0.0358 s/iter. Eval: 0.0425 s/iter. Total: 0.0806 s/iter. ETA=0:06:23\n",
      "\u001b[32m[07/12 15:49:56 d2.evaluation.evaluator]: \u001b[0mInference done 1859/6546. Dataloading: 0.0022 s/iter. Inference: 0.0358 s/iter. Eval: 0.0424 s/iter. Total: 0.0805 s/iter. ETA=0:06:17\n",
      "\u001b[32m[07/12 15:50:01 d2.evaluation.evaluator]: \u001b[0mInference done 1924/6546. Dataloading: 0.0022 s/iter. Inference: 0.0358 s/iter. Eval: 0.0422 s/iter. Total: 0.0804 s/iter. ETA=0:06:11\n",
      "\u001b[32m[07/12 15:50:06 d2.evaluation.evaluator]: \u001b[0mInference done 1990/6546. Dataloading: 0.0022 s/iter. Inference: 0.0358 s/iter. Eval: 0.0421 s/iter. Total: 0.0802 s/iter. ETA=0:06:05\n",
      "\u001b[32m[07/12 15:50:11 d2.evaluation.evaluator]: \u001b[0mInference done 2056/6546. Dataloading: 0.0022 s/iter. Inference: 0.0358 s/iter. Eval: 0.0420 s/iter. Total: 0.0801 s/iter. ETA=0:05:59\n",
      "\u001b[32m[07/12 15:50:16 d2.evaluation.evaluator]: \u001b[0mInference done 2121/6546. Dataloading: 0.0022 s/iter. Inference: 0.0359 s/iter. Eval: 0.0419 s/iter. Total: 0.0801 s/iter. ETA=0:05:54\n",
      "\u001b[32m[07/12 15:50:22 d2.evaluation.evaluator]: \u001b[0mInference done 2184/6546. Dataloading: 0.0022 s/iter. Inference: 0.0359 s/iter. Eval: 0.0419 s/iter. Total: 0.0801 s/iter. ETA=0:05:49\n",
      "\u001b[32m[07/12 15:50:27 d2.evaluation.evaluator]: \u001b[0mInference done 2248/6546. Dataloading: 0.0022 s/iter. Inference: 0.0359 s/iter. Eval: 0.0419 s/iter. Total: 0.0800 s/iter. ETA=0:05:43\n",
      "\u001b[32m[07/12 15:50:32 d2.evaluation.evaluator]: \u001b[0mInference done 2313/6546. Dataloading: 0.0022 s/iter. Inference: 0.0359 s/iter. Eval: 0.0418 s/iter. Total: 0.0799 s/iter. ETA=0:05:38\n",
      "\u001b[32m[07/12 15:50:37 d2.evaluation.evaluator]: \u001b[0mInference done 2377/6546. Dataloading: 0.0022 s/iter. Inference: 0.0359 s/iter. Eval: 0.0417 s/iter. Total: 0.0799 s/iter. ETA=0:05:33\n",
      "\u001b[32m[07/12 15:50:42 d2.evaluation.evaluator]: \u001b[0mInference done 2441/6546. Dataloading: 0.0022 s/iter. Inference: 0.0359 s/iter. Eval: 0.0417 s/iter. Total: 0.0799 s/iter. ETA=0:05:27\n",
      "\u001b[32m[07/12 15:50:47 d2.evaluation.evaluator]: \u001b[0mInference done 2506/6546. Dataloading: 0.0022 s/iter. Inference: 0.0359 s/iter. Eval: 0.0416 s/iter. Total: 0.0798 s/iter. ETA=0:05:22\n",
      "\u001b[32m[07/12 15:50:52 d2.evaluation.evaluator]: \u001b[0mInference done 2571/6546. Dataloading: 0.0022 s/iter. Inference: 0.0359 s/iter. Eval: 0.0415 s/iter. Total: 0.0797 s/iter. ETA=0:05:16\n",
      "\u001b[32m[07/12 15:50:57 d2.evaluation.evaluator]: \u001b[0mInference done 2634/6546. Dataloading: 0.0022 s/iter. Inference: 0.0359 s/iter. Eval: 0.0415 s/iter. Total: 0.0797 s/iter. ETA=0:05:11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/12 15:51:02 d2.evaluation.evaluator]: \u001b[0mInference done 2697/6546. Dataloading: 0.0022 s/iter. Inference: 0.0359 s/iter. Eval: 0.0415 s/iter. Total: 0.0797 s/iter. ETA=0:05:06\n",
      "\u001b[32m[07/12 15:51:07 d2.evaluation.evaluator]: \u001b[0mInference done 2760/6546. Dataloading: 0.0022 s/iter. Inference: 0.0359 s/iter. Eval: 0.0416 s/iter. Total: 0.0797 s/iter. ETA=0:05:01\n",
      "\u001b[32m[07/12 15:51:12 d2.evaluation.evaluator]: \u001b[0mInference done 2824/6546. Dataloading: 0.0022 s/iter. Inference: 0.0359 s/iter. Eval: 0.0415 s/iter. Total: 0.0797 s/iter. ETA=0:04:56\n",
      "\u001b[32m[07/12 15:51:17 d2.evaluation.evaluator]: \u001b[0mInference done 2889/6546. Dataloading: 0.0022 s/iter. Inference: 0.0359 s/iter. Eval: 0.0415 s/iter. Total: 0.0797 s/iter. ETA=0:04:51\n",
      "\u001b[32m[07/12 15:51:22 d2.evaluation.evaluator]: \u001b[0mInference done 2954/6546. Dataloading: 0.0022 s/iter. Inference: 0.0359 s/iter. Eval: 0.0414 s/iter. Total: 0.0796 s/iter. ETA=0:04:46\n",
      "\u001b[32m[07/12 15:51:27 d2.evaluation.evaluator]: \u001b[0mInference done 3018/6546. Dataloading: 0.0022 s/iter. Inference: 0.0359 s/iter. Eval: 0.0414 s/iter. Total: 0.0796 s/iter. ETA=0:04:40\n",
      "\u001b[32m[07/12 15:51:32 d2.evaluation.evaluator]: \u001b[0mInference done 3083/6546. Dataloading: 0.0023 s/iter. Inference: 0.0359 s/iter. Eval: 0.0414 s/iter. Total: 0.0796 s/iter. ETA=0:04:35\n",
      "\u001b[32m[07/12 15:51:37 d2.evaluation.evaluator]: \u001b[0mInference done 3148/6546. Dataloading: 0.0023 s/iter. Inference: 0.0359 s/iter. Eval: 0.0413 s/iter. Total: 0.0795 s/iter. ETA=0:04:30\n",
      "\u001b[32m[07/12 15:51:42 d2.evaluation.evaluator]: \u001b[0mInference done 3212/6546. Dataloading: 0.0023 s/iter. Inference: 0.0359 s/iter. Eval: 0.0413 s/iter. Total: 0.0795 s/iter. ETA=0:04:24\n",
      "\u001b[32m[07/12 15:51:47 d2.evaluation.evaluator]: \u001b[0mInference done 3276/6546. Dataloading: 0.0023 s/iter. Inference: 0.0359 s/iter. Eval: 0.0412 s/iter. Total: 0.0795 s/iter. ETA=0:04:19\n",
      "\u001b[32m[07/12 15:51:52 d2.evaluation.evaluator]: \u001b[0mInference done 3341/6546. Dataloading: 0.0023 s/iter. Inference: 0.0359 s/iter. Eval: 0.0412 s/iter. Total: 0.0794 s/iter. ETA=0:04:14\n",
      "\u001b[32m[07/12 15:51:57 d2.evaluation.evaluator]: \u001b[0mInference done 3406/6546. Dataloading: 0.0023 s/iter. Inference: 0.0359 s/iter. Eval: 0.0412 s/iter. Total: 0.0794 s/iter. ETA=0:04:09\n",
      "\u001b[32m[07/12 15:52:02 d2.evaluation.evaluator]: \u001b[0mInference done 3471/6546. Dataloading: 0.0023 s/iter. Inference: 0.0359 s/iter. Eval: 0.0411 s/iter. Total: 0.0794 s/iter. ETA=0:04:04\n",
      "\u001b[32m[07/12 15:52:07 d2.evaluation.evaluator]: \u001b[0mInference done 3537/6546. Dataloading: 0.0023 s/iter. Inference: 0.0359 s/iter. Eval: 0.0411 s/iter. Total: 0.0793 s/iter. ETA=0:03:58\n",
      "\u001b[32m[07/12 15:52:12 d2.evaluation.evaluator]: \u001b[0mInference done 3603/6546. Dataloading: 0.0023 s/iter. Inference: 0.0359 s/iter. Eval: 0.0410 s/iter. Total: 0.0793 s/iter. ETA=0:03:53\n",
      "\u001b[32m[07/12 15:52:17 d2.evaluation.evaluator]: \u001b[0mInference done 3669/6546. Dataloading: 0.0023 s/iter. Inference: 0.0359 s/iter. Eval: 0.0410 s/iter. Total: 0.0792 s/iter. ETA=0:03:47\n",
      "\u001b[32m[07/12 15:52:22 d2.evaluation.evaluator]: \u001b[0mInference done 3735/6546. Dataloading: 0.0023 s/iter. Inference: 0.0359 s/iter. Eval: 0.0409 s/iter. Total: 0.0792 s/iter. ETA=0:03:42\n",
      "\u001b[32m[07/12 15:52:27 d2.evaluation.evaluator]: \u001b[0mInference done 3801/6546. Dataloading: 0.0023 s/iter. Inference: 0.0359 s/iter. Eval: 0.0409 s/iter. Total: 0.0791 s/iter. ETA=0:03:37\n",
      "\u001b[32m[07/12 15:52:32 d2.evaluation.evaluator]: \u001b[0mInference done 3867/6546. Dataloading: 0.0023 s/iter. Inference: 0.0359 s/iter. Eval: 0.0408 s/iter. Total: 0.0791 s/iter. ETA=0:03:31\n",
      "\u001b[32m[07/12 15:52:37 d2.evaluation.evaluator]: \u001b[0mInference done 3933/6546. Dataloading: 0.0023 s/iter. Inference: 0.0359 s/iter. Eval: 0.0408 s/iter. Total: 0.0790 s/iter. ETA=0:03:26\n",
      "\u001b[32m[07/12 15:52:42 d2.evaluation.evaluator]: \u001b[0mInference done 3999/6546. Dataloading: 0.0023 s/iter. Inference: 0.0359 s/iter. Eval: 0.0407 s/iter. Total: 0.0790 s/iter. ETA=0:03:21\n",
      "\u001b[32m[07/12 15:52:47 d2.evaluation.evaluator]: \u001b[0mInference done 4064/6546. Dataloading: 0.0023 s/iter. Inference: 0.0359 s/iter. Eval: 0.0407 s/iter. Total: 0.0789 s/iter. ETA=0:03:15\n",
      "\u001b[32m[07/12 15:52:53 d2.evaluation.evaluator]: \u001b[0mInference done 4129/6546. Dataloading: 0.0023 s/iter. Inference: 0.0359 s/iter. Eval: 0.0407 s/iter. Total: 0.0789 s/iter. ETA=0:03:10\n",
      "\u001b[32m[07/12 15:52:58 d2.evaluation.evaluator]: \u001b[0mInference done 4194/6546. Dataloading: 0.0023 s/iter. Inference: 0.0359 s/iter. Eval: 0.0406 s/iter. Total: 0.0789 s/iter. ETA=0:03:05\n",
      "\u001b[32m[07/12 15:53:03 d2.evaluation.evaluator]: \u001b[0mInference done 4258/6546. Dataloading: 0.0023 s/iter. Inference: 0.0359 s/iter. Eval: 0.0406 s/iter. Total: 0.0789 s/iter. ETA=0:03:00\n",
      "\u001b[32m[07/12 15:53:08 d2.evaluation.evaluator]: \u001b[0mInference done 4323/6546. Dataloading: 0.0023 s/iter. Inference: 0.0359 s/iter. Eval: 0.0406 s/iter. Total: 0.0789 s/iter. ETA=0:02:55\n",
      "\u001b[32m[07/12 15:53:13 d2.evaluation.evaluator]: \u001b[0mInference done 4388/6546. Dataloading: 0.0023 s/iter. Inference: 0.0359 s/iter. Eval: 0.0406 s/iter. Total: 0.0788 s/iter. ETA=0:02:50\n",
      "\u001b[32m[07/12 15:53:18 d2.evaluation.evaluator]: \u001b[0mInference done 4453/6546. Dataloading: 0.0023 s/iter. Inference: 0.0359 s/iter. Eval: 0.0405 s/iter. Total: 0.0788 s/iter. ETA=0:02:44\n",
      "\u001b[32m[07/12 15:53:23 d2.evaluation.evaluator]: \u001b[0mInference done 4515/6546. Dataloading: 0.0023 s/iter. Inference: 0.0359 s/iter. Eval: 0.0405 s/iter. Total: 0.0789 s/iter. ETA=0:02:40\n",
      "\u001b[32m[07/12 15:53:28 d2.evaluation.evaluator]: \u001b[0mInference done 4580/6546. Dataloading: 0.0023 s/iter. Inference: 0.0359 s/iter. Eval: 0.0405 s/iter. Total: 0.0788 s/iter. ETA=0:02:34\n",
      "\u001b[32m[07/12 15:53:33 d2.evaluation.evaluator]: \u001b[0mInference done 4644/6546. Dataloading: 0.0023 s/iter. Inference: 0.0359 s/iter. Eval: 0.0405 s/iter. Total: 0.0788 s/iter. ETA=0:02:29\n",
      "\u001b[32m[07/12 15:53:38 d2.evaluation.evaluator]: \u001b[0mInference done 4708/6546. Dataloading: 0.0023 s/iter. Inference: 0.0359 s/iter. Eval: 0.0405 s/iter. Total: 0.0788 s/iter. ETA=0:02:24\n",
      "\u001b[32m[07/12 15:53:43 d2.evaluation.evaluator]: \u001b[0mInference done 4772/6546. Dataloading: 0.0023 s/iter. Inference: 0.0359 s/iter. Eval: 0.0405 s/iter. Total: 0.0788 s/iter. ETA=0:02:19\n",
      "\u001b[32m[07/12 15:53:48 d2.evaluation.evaluator]: \u001b[0mInference done 4836/6546. Dataloading: 0.0023 s/iter. Inference: 0.0359 s/iter. Eval: 0.0405 s/iter. Total: 0.0788 s/iter. ETA=0:02:14\n",
      "\u001b[32m[07/12 15:53:53 d2.evaluation.evaluator]: \u001b[0mInference done 4900/6546. Dataloading: 0.0023 s/iter. Inference: 0.0359 s/iter. Eval: 0.0405 s/iter. Total: 0.0788 s/iter. ETA=0:02:09\n",
      "\u001b[32m[07/12 15:53:58 d2.evaluation.evaluator]: \u001b[0mInference done 4964/6546. Dataloading: 0.0023 s/iter. Inference: 0.0359 s/iter. Eval: 0.0405 s/iter. Total: 0.0788 s/iter. ETA=0:02:04\n",
      "\u001b[32m[07/12 15:54:03 d2.evaluation.evaluator]: \u001b[0mInference done 5028/6546. Dataloading: 0.0023 s/iter. Inference: 0.0359 s/iter. Eval: 0.0405 s/iter. Total: 0.0788 s/iter. ETA=0:01:59\n",
      "\u001b[32m[07/12 15:54:08 d2.evaluation.evaluator]: \u001b[0mInference done 5092/6546. Dataloading: 0.0023 s/iter. Inference: 0.0359 s/iter. Eval: 0.0405 s/iter. Total: 0.0788 s/iter. ETA=0:01:54\n",
      "\u001b[32m[07/12 15:54:13 d2.evaluation.evaluator]: \u001b[0mInference done 5156/6546. Dataloading: 0.0023 s/iter. Inference: 0.0359 s/iter. Eval: 0.0405 s/iter. Total: 0.0788 s/iter. ETA=0:01:49\n",
      "\u001b[32m[07/12 15:54:18 d2.evaluation.evaluator]: \u001b[0mInference done 5219/6546. Dataloading: 0.0023 s/iter. Inference: 0.0359 s/iter. Eval: 0.0405 s/iter. Total: 0.0788 s/iter. ETA=0:01:44\n",
      "\u001b[32m[07/12 15:54:23 d2.evaluation.evaluator]: \u001b[0mInference done 5283/6546. Dataloading: 0.0023 s/iter. Inference: 0.0359 s/iter. Eval: 0.0405 s/iter. Total: 0.0788 s/iter. ETA=0:01:39\n",
      "\u001b[32m[07/12 15:54:28 d2.evaluation.evaluator]: \u001b[0mInference done 5347/6546. Dataloading: 0.0023 s/iter. Inference: 0.0359 s/iter. Eval: 0.0405 s/iter. Total: 0.0788 s/iter. ETA=0:01:34\n",
      "\u001b[32m[07/12 15:54:33 d2.evaluation.evaluator]: \u001b[0mInference done 5412/6546. Dataloading: 0.0023 s/iter. Inference: 0.0359 s/iter. Eval: 0.0405 s/iter. Total: 0.0788 s/iter. ETA=0:01:29\n",
      "\u001b[32m[07/12 15:54:38 d2.evaluation.evaluator]: \u001b[0mInference done 5477/6546. Dataloading: 0.0023 s/iter. Inference: 0.0359 s/iter. Eval: 0.0404 s/iter. Total: 0.0788 s/iter. ETA=0:01:24\n",
      "\u001b[32m[07/12 15:54:43 d2.evaluation.evaluator]: \u001b[0mInference done 5540/6546. Dataloading: 0.0023 s/iter. Inference: 0.0359 s/iter. Eval: 0.0404 s/iter. Total: 0.0788 s/iter. ETA=0:01:19\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/12 15:54:48 d2.evaluation.evaluator]: \u001b[0mInference done 5603/6546. Dataloading: 0.0023 s/iter. Inference: 0.0359 s/iter. Eval: 0.0405 s/iter. Total: 0.0788 s/iter. ETA=0:01:14\n",
      "\u001b[32m[07/12 15:54:53 d2.evaluation.evaluator]: \u001b[0mInference done 5666/6546. Dataloading: 0.0023 s/iter. Inference: 0.0359 s/iter. Eval: 0.0405 s/iter. Total: 0.0788 s/iter. ETA=0:01:09\n",
      "\u001b[32m[07/12 15:54:58 d2.evaluation.evaluator]: \u001b[0mInference done 5729/6546. Dataloading: 0.0023 s/iter. Inference: 0.0359 s/iter. Eval: 0.0405 s/iter. Total: 0.0788 s/iter. ETA=0:01:04\n",
      "\u001b[32m[07/12 15:55:03 d2.evaluation.evaluator]: \u001b[0mInference done 5794/6546. Dataloading: 0.0023 s/iter. Inference: 0.0359 s/iter. Eval: 0.0405 s/iter. Total: 0.0788 s/iter. ETA=0:00:59\n",
      "\u001b[32m[07/12 15:55:08 d2.evaluation.evaluator]: \u001b[0mInference done 5858/6546. Dataloading: 0.0023 s/iter. Inference: 0.0359 s/iter. Eval: 0.0405 s/iter. Total: 0.0788 s/iter. ETA=0:00:54\n",
      "\u001b[32m[07/12 15:55:13 d2.evaluation.evaluator]: \u001b[0mInference done 5920/6546. Dataloading: 0.0023 s/iter. Inference: 0.0359 s/iter. Eval: 0.0405 s/iter. Total: 0.0788 s/iter. ETA=0:00:49\n",
      "\u001b[32m[07/12 15:55:18 d2.evaluation.evaluator]: \u001b[0mInference done 5981/6546. Dataloading: 0.0023 s/iter. Inference: 0.0359 s/iter. Eval: 0.0405 s/iter. Total: 0.0789 s/iter. ETA=0:00:44\n",
      "\u001b[32m[07/12 15:55:23 d2.evaluation.evaluator]: \u001b[0mInference done 6046/6546. Dataloading: 0.0023 s/iter. Inference: 0.0359 s/iter. Eval: 0.0405 s/iter. Total: 0.0789 s/iter. ETA=0:00:39\n",
      "\u001b[32m[07/12 15:55:28 d2.evaluation.evaluator]: \u001b[0mInference done 6110/6546. Dataloading: 0.0023 s/iter. Inference: 0.0359 s/iter. Eval: 0.0405 s/iter. Total: 0.0789 s/iter. ETA=0:00:34\n",
      "\u001b[32m[07/12 15:55:33 d2.evaluation.evaluator]: \u001b[0mInference done 6173/6546. Dataloading: 0.0023 s/iter. Inference: 0.0359 s/iter. Eval: 0.0405 s/iter. Total: 0.0789 s/iter. ETA=0:00:29\n",
      "\u001b[32m[07/12 15:55:39 d2.evaluation.evaluator]: \u001b[0mInference done 6237/6546. Dataloading: 0.0023 s/iter. Inference: 0.0359 s/iter. Eval: 0.0405 s/iter. Total: 0.0789 s/iter. ETA=0:00:24\n",
      "\u001b[32m[07/12 15:55:44 d2.evaluation.evaluator]: \u001b[0mInference done 6300/6546. Dataloading: 0.0023 s/iter. Inference: 0.0359 s/iter. Eval: 0.0405 s/iter. Total: 0.0789 s/iter. ETA=0:00:19\n",
      "\u001b[32m[07/12 15:55:49 d2.evaluation.evaluator]: \u001b[0mInference done 6362/6546. Dataloading: 0.0023 s/iter. Inference: 0.0359 s/iter. Eval: 0.0405 s/iter. Total: 0.0789 s/iter. ETA=0:00:14\n",
      "\u001b[32m[07/12 15:55:54 d2.evaluation.evaluator]: \u001b[0mInference done 6426/6546. Dataloading: 0.0023 s/iter. Inference: 0.0359 s/iter. Eval: 0.0405 s/iter. Total: 0.0789 s/iter. ETA=0:00:09\n",
      "\u001b[32m[07/12 15:55:59 d2.evaluation.evaluator]: \u001b[0mInference done 6491/6546. Dataloading: 0.0023 s/iter. Inference: 0.0359 s/iter. Eval: 0.0405 s/iter. Total: 0.0789 s/iter. ETA=0:00:04\n",
      "\u001b[32m[07/12 15:56:03 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:08:36.048862 (0.078894 s / iter per device, on 1 devices)\n",
      "\u001b[32m[07/12 15:56:03 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:03:55 (0.035935 s / iter per device, on 1 devices)\n",
      "\u001b[32m[07/12 15:56:04 d2.evaluation.sem_seg_evaluation]: \u001b[0mOrderedDict([('sem_seg', {'mIoU': 26.480143174004766, 'fwIoU': 57.30425593876954, 'IoU-Unlabeled': nan, 'IoU-Building': 35.370675378523146, 'IoU-Fence': 8.103157051260972, 'IoU-Pedestrian': 14.292903214840113, 'IoU-Pole': 33.086025869994536, 'IoU-Road': 83.7013045318367, 'IoU-SideWalk': 35.617772066549, 'IoU-Vegetation': 31.930787211807072, 'IoU-Vehicles': 32.88432392053875, 'IoU-Wall': 4.426929604749544, 'IoU-TrafficSign': 28.202335537272127, 'IoU-Sky': 62.74554260557854, 'IoU-TrafficLight': 22.186125881289268, 'IoU-Terrain': 0.1033322315681064, 'IoU-ConstructionVehicle': 37.69340038889597, 'IoU-workzone_object': 10.430243811627115, 'IoU-Detour': 9.387574651750054, 'mACC': 50.957374853145154, 'pACC': 69.51158287750513, 'ACC-Unlabeled': nan, 'ACC-Building': 92.46435360761151, 'ACC-Fence': 12.828701276561358, 'ACC-Pedestrian': 62.02582263213814, 'ACC-Pole': 40.80517461372649, 'ACC-Road': 88.83944173192123, 'ACC-SideWalk': 48.19171598856663, 'ACC-Vegetation': 39.82920380273439, 'ACC-Vehicles': 78.57834591729144, 'ACC-Wall': 4.541054929615585, 'ACC-TrafficSign': 41.552716623439665, 'ACC-Sky': 68.30402202527677, 'ACC-TrafficLight': 25.669579192003013, 'ACC-Terrain': 0.10379746567167002, 'ACC-ConstructionVehicle': 94.07115249750856, 'ACC-workzone_object': 76.69446102591189, 'ACC-Detour': 40.81845432034406})])\n",
      "\u001b[32m[07/12 15:56:04 d2.engine.defaults]: \u001b[0mEvaluation results for carla_night_all_val in csv format:\n",
      "\u001b[32m[07/12 15:56:04 d2.evaluation.testing]: \u001b[0mcopypaste: Task: sem_seg\n",
      "\u001b[32m[07/12 15:56:04 d2.evaluation.testing]: \u001b[0mcopypaste: mIoU,fwIoU,mACC,pACC\n",
      "\u001b[32m[07/12 15:56:04 d2.evaluation.testing]: \u001b[0mcopypaste: 26.4801,57.3043,50.9574,69.5116\n"
     ]
    }
   ],
   "source": [
    "trainer_night = Detectron2Trainer('carla_night_clear_train', 'carla_night_all_val', output_folder='./output_night_clear_40k')\n",
    "trainer_night.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d33ad3ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainer_day = Detectron2Trainer('carla_night_clear_train', 'combined_clear_val', output_folder='./output_night_clear_40k')\n",
    "#trainer_day.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6012a3f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainer_day = Detectron2Trainer('carla_night_clear_train', 'cityscapes_rain_val', output_folder='./output_night_clear_40k')\n",
    "#trainer_day.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2bd18a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainer_day = Detectron2Trainer('carla_night_clear_train', 'combined_rain_val', output_folder='./output_night_clear_40k')\n",
    "#trainer_day.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f7ea7056",
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainer_day = Detectron2Trainer('carla_night_all_train', 'cityscapes_clear_val', output_folder='./output_night_40k')\n",
    "#trainer_day.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f2087e85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/12 15:56:05 d2.engine.defaults]: \u001b[0mModel:\n",
      "SemanticSegmentor(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (sem_seg_head): SemSegFPNHead(\n",
      "    (p2): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "    )\n",
      "    (p3): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (1): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "    )\n",
      "    (p4): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (1): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      (2): Conv2d(\n",
      "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (3): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "    )\n",
      "    (p5): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (1): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      (2): Conv2d(\n",
      "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (3): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      (4): Conv2d(\n",
      "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (5): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "    )\n",
      "    (predictor): Conv2d(128, 17, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/12 15:56:05 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(720, 720), max_size=2048, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[07/12 15:56:05 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[07/12 15:56:05 d2.data.common]: \u001b[0mSerializing 15446 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[07/12 15:56:05 d2.data.common]: \u001b[0mSerialized dataset takes 5.05 MiB\n",
      "Last checkpoint: model_final.pth\n",
      "\u001b[32m[07/12 15:56:06 d2.checkpoint.c2_model_loading]: \u001b[0mFollowing weights matched with model:\n",
      "| Names in Model                       | Names in Checkpoint                                                                                  | Shapes                                          |\n",
      "|:-------------------------------------|:-----------------------------------------------------------------------------------------------------|:------------------------------------------------|\n",
      "| backbone.bottom_up.res2.0.conv1.*    | backbone.bottom_up.res2.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,1,1)             |\n",
      "| backbone.bottom_up.res2.0.conv2.*    | backbone.bottom_up.res2.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |\n",
      "| backbone.bottom_up.res2.0.conv3.*    | backbone.bottom_up.res2.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res2.0.shortcut.* | backbone.bottom_up.res2.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res2.1.conv1.*    | backbone.bottom_up.res2.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |\n",
      "| backbone.bottom_up.res2.1.conv2.*    | backbone.bottom_up.res2.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |\n",
      "| backbone.bottom_up.res2.1.conv3.*    | backbone.bottom_up.res2.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res2.2.conv1.*    | backbone.bottom_up.res2.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |\n",
      "| backbone.bottom_up.res2.2.conv2.*    | backbone.bottom_up.res2.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |\n",
      "| backbone.bottom_up.res2.2.conv3.*    | backbone.bottom_up.res2.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res3.0.conv1.*    | backbone.bottom_up.res3.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,256,1,1)       |\n",
      "| backbone.bottom_up.res3.0.conv2.*    | backbone.bottom_up.res3.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.0.conv3.*    | backbone.bottom_up.res3.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res3.0.shortcut.* | backbone.bottom_up.res3.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (512,) (512,) (512,) (512,) (512,256,1,1)       |\n",
      "| backbone.bottom_up.res3.1.conv1.*    | backbone.bottom_up.res3.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |\n",
      "| backbone.bottom_up.res3.1.conv2.*    | backbone.bottom_up.res3.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.1.conv3.*    | backbone.bottom_up.res3.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res3.2.conv1.*    | backbone.bottom_up.res3.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |\n",
      "| backbone.bottom_up.res3.2.conv2.*    | backbone.bottom_up.res3.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.2.conv3.*    | backbone.bottom_up.res3.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res3.3.conv1.*    | backbone.bottom_up.res3.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |\n",
      "| backbone.bottom_up.res3.3.conv2.*    | backbone.bottom_up.res3.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.3.conv3.*    | backbone.bottom_up.res3.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res4.0.conv1.*    | backbone.bottom_up.res4.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,512,1,1)       |\n",
      "| backbone.bottom_up.res4.0.conv2.*    | backbone.bottom_up.res4.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.0.conv3.*    | backbone.bottom_up.res4.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.0.shortcut.* | backbone.bottom_up.res4.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (1024,) (1024,) (1024,) (1024,) (1024,512,1,1)  |\n",
      "| backbone.bottom_up.res4.1.conv1.*    | backbone.bottom_up.res4.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.1.conv2.*    | backbone.bottom_up.res4.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.1.conv3.*    | backbone.bottom_up.res4.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.2.conv1.*    | backbone.bottom_up.res4.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.2.conv2.*    | backbone.bottom_up.res4.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.2.conv3.*    | backbone.bottom_up.res4.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.3.conv1.*    | backbone.bottom_up.res4.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.3.conv2.*    | backbone.bottom_up.res4.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.3.conv3.*    | backbone.bottom_up.res4.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.4.conv1.*    | backbone.bottom_up.res4.4.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.4.conv2.*    | backbone.bottom_up.res4.4.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.4.conv3.*    | backbone.bottom_up.res4.4.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.5.conv1.*    | backbone.bottom_up.res4.5.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.5.conv2.*    | backbone.bottom_up.res4.5.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.5.conv3.*    | backbone.bottom_up.res4.5.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res5.0.conv1.*    | backbone.bottom_up.res5.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,1024,1,1)      |\n",
      "| backbone.bottom_up.res5.0.conv2.*    | backbone.bottom_up.res5.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |\n",
      "| backbone.bottom_up.res5.0.conv3.*    | backbone.bottom_up.res5.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
      "| backbone.bottom_up.res5.0.shortcut.* | backbone.bottom_up.res5.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (2048,) (2048,) (2048,) (2048,) (2048,1024,1,1) |\n",
      "| backbone.bottom_up.res5.1.conv1.*    | backbone.bottom_up.res5.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |\n",
      "| backbone.bottom_up.res5.1.conv2.*    | backbone.bottom_up.res5.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |\n",
      "| backbone.bottom_up.res5.1.conv3.*    | backbone.bottom_up.res5.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
      "| backbone.bottom_up.res5.2.conv1.*    | backbone.bottom_up.res5.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |\n",
      "| backbone.bottom_up.res5.2.conv2.*    | backbone.bottom_up.res5.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |\n",
      "| backbone.bottom_up.res5.2.conv3.*    | backbone.bottom_up.res5.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
      "| backbone.bottom_up.stem.conv1.*      | backbone.bottom_up.stem.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}      | (64,) (64,) (64,) (64,) (64,3,7,7)              |\n",
      "| backbone.fpn_lateral2.*              | backbone.fpn_lateral2.{bias,weight}                                                                  | (256,) (256,256,1,1)                            |\n",
      "| backbone.fpn_lateral3.*              | backbone.fpn_lateral3.{bias,weight}                                                                  | (256,) (256,512,1,1)                            |\n",
      "| backbone.fpn_lateral4.*              | backbone.fpn_lateral4.{bias,weight}                                                                  | (256,) (256,1024,1,1)                           |\n",
      "| backbone.fpn_lateral5.*              | backbone.fpn_lateral5.{bias,weight}                                                                  | (256,) (256,2048,1,1)                           |\n",
      "| backbone.fpn_output2.*               | backbone.fpn_output2.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| backbone.fpn_output3.*               | backbone.fpn_output3.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| backbone.fpn_output4.*               | backbone.fpn_output4.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| backbone.fpn_output5.*               | backbone.fpn_output5.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| sem_seg_head.p2.0.*                  | sem_seg_head.p2.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p3.0.*                  | sem_seg_head.p3.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p4.0.*                  | sem_seg_head.p4.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p4.2.*                  | sem_seg_head.p4.2.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,128,3,3)                     |\n",
      "| sem_seg_head.p5.0.*                  | sem_seg_head.p5.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p5.2.*                  | sem_seg_head.p5.2.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,128,3,3)                     |\n",
      "| sem_seg_head.p5.4.*                  | sem_seg_head.p5.4.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,128,3,3)                     |\n",
      "| sem_seg_head.predictor.*             | sem_seg_head.predictor.{bias,weight}                                                                 | (17,) (17,128,1,1)                              |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/12 15:56:06 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(720, 720), max_size=2048, sample_style='choice')]\n",
      "\u001b[32m[07/12 15:56:06 d2.data.common]: \u001b[0mSerializing 3273 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[07/12 15:56:06 d2.data.common]: \u001b[0mSerialized dataset takes 1.04 MiB\n",
      "\u001b[32m[07/12 15:56:06 d2.evaluation.evaluator]: \u001b[0mStart inference on 3273 batches\n",
      "\u001b[32m[07/12 15:56:07 d2.evaluation.evaluator]: \u001b[0mInference done 11/3273. Dataloading: 0.0016 s/iter. Inference: 0.0364 s/iter. Eval: 0.0414 s/iter. Total: 0.0794 s/iter. ETA=0:04:19\n",
      "\u001b[32m[07/12 15:56:12 d2.evaluation.evaluator]: \u001b[0mInference done 75/3273. Dataloading: 0.0019 s/iter. Inference: 0.0357 s/iter. Eval: 0.0413 s/iter. Total: 0.0790 s/iter. ETA=0:04:12\n",
      "\u001b[32m[07/12 15:56:17 d2.evaluation.evaluator]: \u001b[0mInference done 138/3273. Dataloading: 0.0019 s/iter. Inference: 0.0357 s/iter. Eval: 0.0417 s/iter. Total: 0.0794 s/iter. ETA=0:04:08\n",
      "\u001b[32m[07/12 15:56:22 d2.evaluation.evaluator]: \u001b[0mInference done 200/3273. Dataloading: 0.0020 s/iter. Inference: 0.0357 s/iter. Eval: 0.0422 s/iter. Total: 0.0800 s/iter. ETA=0:04:05\n",
      "\u001b[32m[07/12 15:56:27 d2.evaluation.evaluator]: \u001b[0mInference done 263/3273. Dataloading: 0.0020 s/iter. Inference: 0.0357 s/iter. Eval: 0.0421 s/iter. Total: 0.0799 s/iter. ETA=0:04:00\n",
      "\u001b[32m[07/12 15:56:32 d2.evaluation.evaluator]: \u001b[0mInference done 326/3273. Dataloading: 0.0020 s/iter. Inference: 0.0357 s/iter. Eval: 0.0421 s/iter. Total: 0.0799 s/iter. ETA=0:03:55\n",
      "\u001b[32m[07/12 15:56:37 d2.evaluation.evaluator]: \u001b[0mInference done 388/3273. Dataloading: 0.0020 s/iter. Inference: 0.0357 s/iter. Eval: 0.0423 s/iter. Total: 0.0801 s/iter. ETA=0:03:51\n",
      "\u001b[32m[07/12 15:56:42 d2.evaluation.evaluator]: \u001b[0mInference done 450/3273. Dataloading: 0.0021 s/iter. Inference: 0.0357 s/iter. Eval: 0.0425 s/iter. Total: 0.0803 s/iter. ETA=0:03:46\n",
      "\u001b[32m[07/12 15:56:47 d2.evaluation.evaluator]: \u001b[0mInference done 511/3273. Dataloading: 0.0021 s/iter. Inference: 0.0357 s/iter. Eval: 0.0428 s/iter. Total: 0.0806 s/iter. ETA=0:03:42\n",
      "\u001b[32m[07/12 15:56:52 d2.evaluation.evaluator]: \u001b[0mInference done 573/3273. Dataloading: 0.0021 s/iter. Inference: 0.0357 s/iter. Eval: 0.0429 s/iter. Total: 0.0807 s/iter. ETA=0:03:37\n",
      "\u001b[32m[07/12 15:56:57 d2.evaluation.evaluator]: \u001b[0mInference done 635/3273. Dataloading: 0.0021 s/iter. Inference: 0.0357 s/iter. Eval: 0.0429 s/iter. Total: 0.0807 s/iter. ETA=0:03:32\n",
      "\u001b[32m[07/12 15:57:02 d2.evaluation.evaluator]: \u001b[0mInference done 696/3273. Dataloading: 0.0021 s/iter. Inference: 0.0357 s/iter. Eval: 0.0430 s/iter. Total: 0.0809 s/iter. ETA=0:03:28\n",
      "\u001b[32m[07/12 15:57:07 d2.evaluation.evaluator]: \u001b[0mInference done 759/3273. Dataloading: 0.0021 s/iter. Inference: 0.0357 s/iter. Eval: 0.0430 s/iter. Total: 0.0809 s/iter. ETA=0:03:23\n",
      "\u001b[32m[07/12 15:57:12 d2.evaluation.evaluator]: \u001b[0mInference done 825/3273. Dataloading: 0.0021 s/iter. Inference: 0.0357 s/iter. Eval: 0.0426 s/iter. Total: 0.0805 s/iter. ETA=0:03:17\n",
      "\u001b[32m[07/12 15:57:17 d2.evaluation.evaluator]: \u001b[0mInference done 891/3273. Dataloading: 0.0021 s/iter. Inference: 0.0357 s/iter. Eval: 0.0423 s/iter. Total: 0.0802 s/iter. ETA=0:03:11\n",
      "\u001b[32m[07/12 15:57:22 d2.evaluation.evaluator]: \u001b[0mInference done 954/3273. Dataloading: 0.0021 s/iter. Inference: 0.0357 s/iter. Eval: 0.0422 s/iter. Total: 0.0802 s/iter. ETA=0:03:05\n",
      "\u001b[32m[07/12 15:57:27 d2.evaluation.evaluator]: \u001b[0mInference done 1019/3273. Dataloading: 0.0021 s/iter. Inference: 0.0358 s/iter. Eval: 0.0420 s/iter. Total: 0.0800 s/iter. ETA=0:03:00\n",
      "\u001b[32m[07/12 15:57:32 d2.evaluation.evaluator]: \u001b[0mInference done 1083/3273. Dataloading: 0.0021 s/iter. Inference: 0.0358 s/iter. Eval: 0.0419 s/iter. Total: 0.0799 s/iter. ETA=0:02:55\n",
      "\u001b[32m[07/12 15:57:37 d2.evaluation.evaluator]: \u001b[0mInference done 1147/3273. Dataloading: 0.0022 s/iter. Inference: 0.0358 s/iter. Eval: 0.0418 s/iter. Total: 0.0799 s/iter. ETA=0:02:49\n",
      "\u001b[32m[07/12 15:57:43 d2.evaluation.evaluator]: \u001b[0mInference done 1211/3273. Dataloading: 0.0022 s/iter. Inference: 0.0358 s/iter. Eval: 0.0418 s/iter. Total: 0.0798 s/iter. ETA=0:02:44\n",
      "\u001b[32m[07/12 15:57:48 d2.evaluation.evaluator]: \u001b[0mInference done 1275/3273. Dataloading: 0.0022 s/iter. Inference: 0.0358 s/iter. Eval: 0.0417 s/iter. Total: 0.0798 s/iter. ETA=0:02:39\n",
      "\u001b[32m[07/12 15:57:53 d2.evaluation.evaluator]: \u001b[0mInference done 1339/3273. Dataloading: 0.0022 s/iter. Inference: 0.0358 s/iter. Eval: 0.0417 s/iter. Total: 0.0797 s/iter. ETA=0:02:34\n",
      "\u001b[32m[07/12 15:57:58 d2.evaluation.evaluator]: \u001b[0mInference done 1403/3273. Dataloading: 0.0022 s/iter. Inference: 0.0358 s/iter. Eval: 0.0416 s/iter. Total: 0.0797 s/iter. ETA=0:02:29\n",
      "\u001b[32m[07/12 15:58:03 d2.evaluation.evaluator]: \u001b[0mInference done 1469/3273. Dataloading: 0.0022 s/iter. Inference: 0.0358 s/iter. Eval: 0.0415 s/iter. Total: 0.0796 s/iter. ETA=0:02:23\n",
      "\u001b[32m[07/12 15:58:08 d2.evaluation.evaluator]: \u001b[0mInference done 1535/3273. Dataloading: 0.0022 s/iter. Inference: 0.0358 s/iter. Eval: 0.0413 s/iter. Total: 0.0794 s/iter. ETA=0:02:18\n",
      "\u001b[32m[07/12 15:58:13 d2.evaluation.evaluator]: \u001b[0mInference done 1598/3273. Dataloading: 0.0022 s/iter. Inference: 0.0360 s/iter. Eval: 0.0412 s/iter. Total: 0.0795 s/iter. ETA=0:02:13\n",
      "\u001b[32m[07/12 15:58:18 d2.evaluation.evaluator]: \u001b[0mInference done 1664/3273. Dataloading: 0.0022 s/iter. Inference: 0.0360 s/iter. Eval: 0.0411 s/iter. Total: 0.0793 s/iter. ETA=0:02:07\n",
      "\u001b[32m[07/12 15:58:23 d2.evaluation.evaluator]: \u001b[0mInference done 1731/3273. Dataloading: 0.0022 s/iter. Inference: 0.0360 s/iter. Eval: 0.0409 s/iter. Total: 0.0792 s/iter. ETA=0:02:02\n",
      "\u001b[32m[07/12 15:58:28 d2.evaluation.evaluator]: \u001b[0mInference done 1796/3273. Dataloading: 0.0022 s/iter. Inference: 0.0360 s/iter. Eval: 0.0409 s/iter. Total: 0.0791 s/iter. ETA=0:01:56\n",
      "\u001b[32m[07/12 15:58:33 d2.evaluation.evaluator]: \u001b[0mInference done 1862/3273. Dataloading: 0.0022 s/iter. Inference: 0.0360 s/iter. Eval: 0.0408 s/iter. Total: 0.0790 s/iter. ETA=0:01:51\n",
      "\u001b[32m[07/12 15:58:38 d2.evaluation.evaluator]: \u001b[0mInference done 1928/3273. Dataloading: 0.0022 s/iter. Inference: 0.0360 s/iter. Eval: 0.0407 s/iter. Total: 0.0789 s/iter. ETA=0:01:46\n",
      "\u001b[32m[07/12 15:58:43 d2.evaluation.evaluator]: \u001b[0mInference done 1994/3273. Dataloading: 0.0022 s/iter. Inference: 0.0360 s/iter. Eval: 0.0406 s/iter. Total: 0.0788 s/iter. ETA=0:01:40\n",
      "\u001b[32m[07/12 15:58:48 d2.evaluation.evaluator]: \u001b[0mInference done 2060/3273. Dataloading: 0.0022 s/iter. Inference: 0.0360 s/iter. Eval: 0.0405 s/iter. Total: 0.0787 s/iter. ETA=0:01:35\n",
      "\u001b[32m[07/12 15:58:53 d2.evaluation.evaluator]: \u001b[0mInference done 2126/3273. Dataloading: 0.0022 s/iter. Inference: 0.0360 s/iter. Eval: 0.0404 s/iter. Total: 0.0787 s/iter. ETA=0:01:30\n",
      "\u001b[32m[07/12 15:58:58 d2.evaluation.evaluator]: \u001b[0mInference done 2192/3273. Dataloading: 0.0022 s/iter. Inference: 0.0360 s/iter. Eval: 0.0404 s/iter. Total: 0.0786 s/iter. ETA=0:01:24\n",
      "\u001b[32m[07/12 15:59:03 d2.evaluation.evaluator]: \u001b[0mInference done 2258/3273. Dataloading: 0.0022 s/iter. Inference: 0.0360 s/iter. Eval: 0.0403 s/iter. Total: 0.0785 s/iter. ETA=0:01:19\n",
      "\u001b[32m[07/12 15:59:08 d2.evaluation.evaluator]: \u001b[0mInference done 2324/3273. Dataloading: 0.0021 s/iter. Inference: 0.0360 s/iter. Eval: 0.0402 s/iter. Total: 0.0785 s/iter. ETA=0:01:14\n",
      "\u001b[32m[07/12 15:59:13 d2.evaluation.evaluator]: \u001b[0mInference done 2389/3273. Dataloading: 0.0021 s/iter. Inference: 0.0360 s/iter. Eval: 0.0402 s/iter. Total: 0.0784 s/iter. ETA=0:01:09\n",
      "\u001b[32m[07/12 15:59:18 d2.evaluation.evaluator]: \u001b[0mInference done 2452/3273. Dataloading: 0.0021 s/iter. Inference: 0.0360 s/iter. Eval: 0.0403 s/iter. Total: 0.0785 s/iter. ETA=0:01:04\n",
      "\u001b[32m[07/12 15:59:23 d2.evaluation.evaluator]: \u001b[0mInference done 2516/3273. Dataloading: 0.0021 s/iter. Inference: 0.0360 s/iter. Eval: 0.0402 s/iter. Total: 0.0785 s/iter. ETA=0:00:59\n",
      "\u001b[32m[07/12 15:59:28 d2.evaluation.evaluator]: \u001b[0mInference done 2582/3273. Dataloading: 0.0021 s/iter. Inference: 0.0360 s/iter. Eval: 0.0402 s/iter. Total: 0.0784 s/iter. ETA=0:00:54\n",
      "\u001b[32m[07/12 15:59:33 d2.evaluation.evaluator]: \u001b[0mInference done 2646/3273. Dataloading: 0.0021 s/iter. Inference: 0.0360 s/iter. Eval: 0.0402 s/iter. Total: 0.0784 s/iter. ETA=0:00:49\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/12 15:59:38 d2.evaluation.evaluator]: \u001b[0mInference done 2710/3273. Dataloading: 0.0021 s/iter. Inference: 0.0360 s/iter. Eval: 0.0402 s/iter. Total: 0.0784 s/iter. ETA=0:00:44\n",
      "\u001b[32m[07/12 15:59:43 d2.evaluation.evaluator]: \u001b[0mInference done 2773/3273. Dataloading: 0.0021 s/iter. Inference: 0.0360 s/iter. Eval: 0.0402 s/iter. Total: 0.0785 s/iter. ETA=0:00:39\n",
      "\u001b[32m[07/12 15:59:49 d2.evaluation.evaluator]: \u001b[0mInference done 2836/3273. Dataloading: 0.0021 s/iter. Inference: 0.0360 s/iter. Eval: 0.0403 s/iter. Total: 0.0785 s/iter. ETA=0:00:34\n",
      "\u001b[32m[07/12 15:59:54 d2.evaluation.evaluator]: \u001b[0mInference done 2898/3273. Dataloading: 0.0021 s/iter. Inference: 0.0360 s/iter. Eval: 0.0403 s/iter. Total: 0.0785 s/iter. ETA=0:00:29\n",
      "\u001b[32m[07/12 15:59:59 d2.evaluation.evaluator]: \u001b[0mInference done 2961/3273. Dataloading: 0.0021 s/iter. Inference: 0.0360 s/iter. Eval: 0.0404 s/iter. Total: 0.0786 s/iter. ETA=0:00:24\n",
      "\u001b[32m[07/12 16:00:04 d2.evaluation.evaluator]: \u001b[0mInference done 3026/3273. Dataloading: 0.0021 s/iter. Inference: 0.0360 s/iter. Eval: 0.0404 s/iter. Total: 0.0786 s/iter. ETA=0:00:19\n",
      "\u001b[32m[07/12 16:00:09 d2.evaluation.evaluator]: \u001b[0mInference done 3091/3273. Dataloading: 0.0021 s/iter. Inference: 0.0360 s/iter. Eval: 0.0403 s/iter. Total: 0.0785 s/iter. ETA=0:00:14\n",
      "\u001b[32m[07/12 16:00:14 d2.evaluation.evaluator]: \u001b[0mInference done 3157/3273. Dataloading: 0.0021 s/iter. Inference: 0.0360 s/iter. Eval: 0.0403 s/iter. Total: 0.0785 s/iter. ETA=0:00:09\n",
      "\u001b[32m[07/12 16:00:19 d2.evaluation.evaluator]: \u001b[0mInference done 3223/3273. Dataloading: 0.0021 s/iter. Inference: 0.0360 s/iter. Eval: 0.0403 s/iter. Total: 0.0785 s/iter. ETA=0:00:03\n",
      "\u001b[32m[07/12 16:00:23 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:04:16.330253 (0.078436 s / iter per device, on 1 devices)\n",
      "\u001b[32m[07/12 16:00:23 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:01:57 (0.036003 s / iter per device, on 1 devices)\n",
      "\u001b[32m[07/12 16:00:23 d2.evaluation.sem_seg_evaluation]: \u001b[0mOrderedDict([('sem_seg', {'mIoU': 34.343154655918454, 'fwIoU': 64.35547858501232, 'IoU-Unlabeled': nan, 'IoU-Building': 40.73502565740994, 'IoU-Fence': 9.849757158839095, 'IoU-Pedestrian': 16.986205996257777, 'IoU-Pole': 36.0469404035407, 'IoU-Road': 88.9909087124007, 'IoU-SideWalk': 44.71469021501791, 'IoU-Vegetation': 42.823580416753074, 'IoU-Vehicles': 48.413161974074534, 'IoU-Wall': 5.04779115161456, 'IoU-TrafficSign': 26.545266340183744, 'IoU-Sky': 72.58558106425821, 'IoU-TrafficLight': 21.682471909946013, 'IoU-Terrain': 0.02940711339612508, 'IoU-ConstructionVehicle': 60.93245946189917, 'IoU-workzone_object': 11.259352012674304, 'IoU-Detour': 22.847874906429343, 'mACC': 53.846516472316516, 'pACC': 75.70491550491715, 'ACC-Unlabeled': nan, 'ACC-Building': 93.23670764048997, 'ACC-Fence': 14.027367654774203, 'ACC-Pedestrian': 65.67184266751906, 'ACC-Pole': 43.24493027550687, 'ACC-Road': 94.40703098727313, 'ACC-SideWalk': 66.4187549786729, 'ACC-Vegetation': 51.56290320787002, 'ACC-Vehicles': 78.53971014215777, 'ACC-Wall': 5.185516676947391, 'ACC-TrafficSign': 45.174775217839695, 'ACC-Sky': 75.62992201133487, 'ACC-TrafficLight': 24.041651123212095, 'ACC-Terrain': 0.029433098414326384, 'ACC-ConstructionVehicle': 90.1674496921506, 'ACC-workzone_object': 78.40540802390231, 'ACC-Detour': 35.800860158999086})])\n",
      "\u001b[32m[07/12 16:00:23 d2.engine.defaults]: \u001b[0mEvaluation results for carla_night_clear_val in csv format:\n",
      "\u001b[32m[07/12 16:00:23 d2.evaluation.testing]: \u001b[0mcopypaste: Task: sem_seg\n",
      "\u001b[32m[07/12 16:00:23 d2.evaluation.testing]: \u001b[0mcopypaste: mIoU,fwIoU,mACC,pACC\n",
      "\u001b[32m[07/12 16:00:23 d2.evaluation.testing]: \u001b[0mcopypaste: 34.3432,64.3555,53.8465,75.7049\n"
     ]
    }
   ],
   "source": [
    "trainer_day = Detectron2Trainer('carla_night_all_train', 'carla_night_clear_val', output_folder='./output_night_40k')\n",
    "trainer_day.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "46e19df5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/12 16:00:24 d2.engine.defaults]: \u001b[0mModel:\n",
      "SemanticSegmentor(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (sem_seg_head): SemSegFPNHead(\n",
      "    (p2): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "    )\n",
      "    (p3): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (1): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "    )\n",
      "    (p4): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (1): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      (2): Conv2d(\n",
      "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (3): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "    )\n",
      "    (p5): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (1): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      (2): Conv2d(\n",
      "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (3): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      (4): Conv2d(\n",
      "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (5): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "    )\n",
      "    (predictor): Conv2d(128, 17, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/12 16:00:24 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(720, 720), max_size=2048, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[07/12 16:00:24 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[07/12 16:00:24 d2.data.common]: \u001b[0mSerializing 15446 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[07/12 16:00:24 d2.data.common]: \u001b[0mSerialized dataset takes 5.05 MiB\n",
      "Last checkpoint: model_final.pth\n",
      "\u001b[32m[07/12 16:00:24 d2.checkpoint.c2_model_loading]: \u001b[0mFollowing weights matched with model:\n",
      "| Names in Model                       | Names in Checkpoint                                                                                  | Shapes                                          |\n",
      "|:-------------------------------------|:-----------------------------------------------------------------------------------------------------|:------------------------------------------------|\n",
      "| backbone.bottom_up.res2.0.conv1.*    | backbone.bottom_up.res2.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,1,1)             |\n",
      "| backbone.bottom_up.res2.0.conv2.*    | backbone.bottom_up.res2.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |\n",
      "| backbone.bottom_up.res2.0.conv3.*    | backbone.bottom_up.res2.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res2.0.shortcut.* | backbone.bottom_up.res2.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res2.1.conv1.*    | backbone.bottom_up.res2.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |\n",
      "| backbone.bottom_up.res2.1.conv2.*    | backbone.bottom_up.res2.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |\n",
      "| backbone.bottom_up.res2.1.conv3.*    | backbone.bottom_up.res2.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res2.2.conv1.*    | backbone.bottom_up.res2.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |\n",
      "| backbone.bottom_up.res2.2.conv2.*    | backbone.bottom_up.res2.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |\n",
      "| backbone.bottom_up.res2.2.conv3.*    | backbone.bottom_up.res2.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res3.0.conv1.*    | backbone.bottom_up.res3.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,256,1,1)       |\n",
      "| backbone.bottom_up.res3.0.conv2.*    | backbone.bottom_up.res3.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.0.conv3.*    | backbone.bottom_up.res3.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res3.0.shortcut.* | backbone.bottom_up.res3.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (512,) (512,) (512,) (512,) (512,256,1,1)       |\n",
      "| backbone.bottom_up.res3.1.conv1.*    | backbone.bottom_up.res3.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |\n",
      "| backbone.bottom_up.res3.1.conv2.*    | backbone.bottom_up.res3.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.1.conv3.*    | backbone.bottom_up.res3.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res3.2.conv1.*    | backbone.bottom_up.res3.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |\n",
      "| backbone.bottom_up.res3.2.conv2.*    | backbone.bottom_up.res3.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.2.conv3.*    | backbone.bottom_up.res3.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res3.3.conv1.*    | backbone.bottom_up.res3.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |\n",
      "| backbone.bottom_up.res3.3.conv2.*    | backbone.bottom_up.res3.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.3.conv3.*    | backbone.bottom_up.res3.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res4.0.conv1.*    | backbone.bottom_up.res4.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,512,1,1)       |\n",
      "| backbone.bottom_up.res4.0.conv2.*    | backbone.bottom_up.res4.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.0.conv3.*    | backbone.bottom_up.res4.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.0.shortcut.* | backbone.bottom_up.res4.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (1024,) (1024,) (1024,) (1024,) (1024,512,1,1)  |\n",
      "| backbone.bottom_up.res4.1.conv1.*    | backbone.bottom_up.res4.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.1.conv2.*    | backbone.bottom_up.res4.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.1.conv3.*    | backbone.bottom_up.res4.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.2.conv1.*    | backbone.bottom_up.res4.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.2.conv2.*    | backbone.bottom_up.res4.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.2.conv3.*    | backbone.bottom_up.res4.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.3.conv1.*    | backbone.bottom_up.res4.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.3.conv2.*    | backbone.bottom_up.res4.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.3.conv3.*    | backbone.bottom_up.res4.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.4.conv1.*    | backbone.bottom_up.res4.4.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.4.conv2.*    | backbone.bottom_up.res4.4.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.4.conv3.*    | backbone.bottom_up.res4.4.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.5.conv1.*    | backbone.bottom_up.res4.5.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.5.conv2.*    | backbone.bottom_up.res4.5.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.5.conv3.*    | backbone.bottom_up.res4.5.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res5.0.conv1.*    | backbone.bottom_up.res5.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,1024,1,1)      |\n",
      "| backbone.bottom_up.res5.0.conv2.*    | backbone.bottom_up.res5.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |\n",
      "| backbone.bottom_up.res5.0.conv3.*    | backbone.bottom_up.res5.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
      "| backbone.bottom_up.res5.0.shortcut.* | backbone.bottom_up.res5.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (2048,) (2048,) (2048,) (2048,) (2048,1024,1,1) |\n",
      "| backbone.bottom_up.res5.1.conv1.*    | backbone.bottom_up.res5.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |\n",
      "| backbone.bottom_up.res5.1.conv2.*    | backbone.bottom_up.res5.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |\n",
      "| backbone.bottom_up.res5.1.conv3.*    | backbone.bottom_up.res5.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
      "| backbone.bottom_up.res5.2.conv1.*    | backbone.bottom_up.res5.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |\n",
      "| backbone.bottom_up.res5.2.conv2.*    | backbone.bottom_up.res5.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |\n",
      "| backbone.bottom_up.res5.2.conv3.*    | backbone.bottom_up.res5.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
      "| backbone.bottom_up.stem.conv1.*      | backbone.bottom_up.stem.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}      | (64,) (64,) (64,) (64,) (64,3,7,7)              |\n",
      "| backbone.fpn_lateral2.*              | backbone.fpn_lateral2.{bias,weight}                                                                  | (256,) (256,256,1,1)                            |\n",
      "| backbone.fpn_lateral3.*              | backbone.fpn_lateral3.{bias,weight}                                                                  | (256,) (256,512,1,1)                            |\n",
      "| backbone.fpn_lateral4.*              | backbone.fpn_lateral4.{bias,weight}                                                                  | (256,) (256,1024,1,1)                           |\n",
      "| backbone.fpn_lateral5.*              | backbone.fpn_lateral5.{bias,weight}                                                                  | (256,) (256,2048,1,1)                           |\n",
      "| backbone.fpn_output2.*               | backbone.fpn_output2.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| backbone.fpn_output3.*               | backbone.fpn_output3.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| backbone.fpn_output4.*               | backbone.fpn_output4.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| backbone.fpn_output5.*               | backbone.fpn_output5.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| sem_seg_head.p2.0.*                  | sem_seg_head.p2.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p3.0.*                  | sem_seg_head.p3.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p4.0.*                  | sem_seg_head.p4.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p4.2.*                  | sem_seg_head.p4.2.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,128,3,3)                     |\n",
      "| sem_seg_head.p5.0.*                  | sem_seg_head.p5.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p5.2.*                  | sem_seg_head.p5.2.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,128,3,3)                     |\n",
      "| sem_seg_head.p5.4.*                  | sem_seg_head.p5.4.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,128,3,3)                     |\n",
      "| sem_seg_head.predictor.*             | sem_seg_head.predictor.{bias,weight}                                                                 | (17,) (17,128,1,1)                              |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/12 16:00:24 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(720, 720), max_size=2048, sample_style='choice')]\n",
      "\u001b[32m[07/12 16:00:24 d2.data.common]: \u001b[0mSerializing 3273 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[07/12 16:00:24 d2.data.common]: \u001b[0mSerialized dataset takes 1.04 MiB\n",
      "\u001b[32m[07/12 16:00:24 d2.evaluation.evaluator]: \u001b[0mStart inference on 3273 batches\n",
      "\u001b[32m[07/12 16:00:25 d2.evaluation.evaluator]: \u001b[0mInference done 11/3273. Dataloading: 0.0017 s/iter. Inference: 0.0368 s/iter. Eval: 0.0419 s/iter. Total: 0.0804 s/iter. ETA=0:04:22\n",
      "\u001b[32m[07/12 16:00:30 d2.evaluation.evaluator]: \u001b[0mInference done 76/3273. Dataloading: 0.0021 s/iter. Inference: 0.0358 s/iter. Eval: 0.0402 s/iter. Total: 0.0782 s/iter. ETA=0:04:09\n",
      "\u001b[32m[07/12 16:00:35 d2.evaluation.evaluator]: \u001b[0mInference done 139/3273. Dataloading: 0.0021 s/iter. Inference: 0.0358 s/iter. Eval: 0.0409 s/iter. Total: 0.0788 s/iter. ETA=0:04:07\n",
      "\u001b[32m[07/12 16:00:40 d2.evaluation.evaluator]: \u001b[0mInference done 203/3273. Dataloading: 0.0021 s/iter. Inference: 0.0358 s/iter. Eval: 0.0407 s/iter. Total: 0.0787 s/iter. ETA=0:04:01\n",
      "\u001b[32m[07/12 16:00:46 d2.evaluation.evaluator]: \u001b[0mInference done 267/3273. Dataloading: 0.0021 s/iter. Inference: 0.0358 s/iter. Eval: 0.0408 s/iter. Total: 0.0788 s/iter. ETA=0:03:56\n",
      "\u001b[32m[07/12 16:00:51 d2.evaluation.evaluator]: \u001b[0mInference done 329/3273. Dataloading: 0.0021 s/iter. Inference: 0.0358 s/iter. Eval: 0.0411 s/iter. Total: 0.0792 s/iter. ETA=0:03:53\n",
      "\u001b[32m[07/12 16:00:56 d2.evaluation.evaluator]: \u001b[0mInference done 392/3273. Dataloading: 0.0021 s/iter. Inference: 0.0358 s/iter. Eval: 0.0412 s/iter. Total: 0.0793 s/iter. ETA=0:03:48\n",
      "\u001b[32m[07/12 16:01:01 d2.evaluation.evaluator]: \u001b[0mInference done 455/3273. Dataloading: 0.0021 s/iter. Inference: 0.0358 s/iter. Eval: 0.0414 s/iter. Total: 0.0794 s/iter. ETA=0:03:43\n",
      "\u001b[32m[07/12 16:01:06 d2.evaluation.evaluator]: \u001b[0mInference done 518/3273. Dataloading: 0.0021 s/iter. Inference: 0.0358 s/iter. Eval: 0.0415 s/iter. Total: 0.0795 s/iter. ETA=0:03:38\n",
      "\u001b[32m[07/12 16:01:11 d2.evaluation.evaluator]: \u001b[0mInference done 582/3273. Dataloading: 0.0021 s/iter. Inference: 0.0358 s/iter. Eval: 0.0414 s/iter. Total: 0.0794 s/iter. ETA=0:03:33\n",
      "\u001b[32m[07/12 16:01:16 d2.evaluation.evaluator]: \u001b[0mInference done 646/3273. Dataloading: 0.0020 s/iter. Inference: 0.0358 s/iter. Eval: 0.0414 s/iter. Total: 0.0794 s/iter. ETA=0:03:28\n",
      "\u001b[32m[07/12 16:01:21 d2.evaluation.evaluator]: \u001b[0mInference done 709/3273. Dataloading: 0.0020 s/iter. Inference: 0.0359 s/iter. Eval: 0.0415 s/iter. Total: 0.0794 s/iter. ETA=0:03:23\n",
      "\u001b[32m[07/12 16:01:26 d2.evaluation.evaluator]: \u001b[0mInference done 773/3273. Dataloading: 0.0020 s/iter. Inference: 0.0359 s/iter. Eval: 0.0414 s/iter. Total: 0.0794 s/iter. ETA=0:03:18\n",
      "\u001b[32m[07/12 16:01:31 d2.evaluation.evaluator]: \u001b[0mInference done 840/3273. Dataloading: 0.0020 s/iter. Inference: 0.0359 s/iter. Eval: 0.0411 s/iter. Total: 0.0790 s/iter. ETA=0:03:12\n",
      "\u001b[32m[07/12 16:01:36 d2.evaluation.evaluator]: \u001b[0mInference done 907/3273. Dataloading: 0.0020 s/iter. Inference: 0.0359 s/iter. Eval: 0.0408 s/iter. Total: 0.0788 s/iter. ETA=0:03:06\n",
      "\u001b[32m[07/12 16:01:41 d2.evaluation.evaluator]: \u001b[0mInference done 973/3273. Dataloading: 0.0020 s/iter. Inference: 0.0359 s/iter. Eval: 0.0407 s/iter. Total: 0.0786 s/iter. ETA=0:03:00\n",
      "\u001b[32m[07/12 16:01:46 d2.evaluation.evaluator]: \u001b[0mInference done 1039/3273. Dataloading: 0.0020 s/iter. Inference: 0.0359 s/iter. Eval: 0.0405 s/iter. Total: 0.0785 s/iter. ETA=0:02:55\n",
      "\u001b[32m[07/12 16:01:51 d2.evaluation.evaluator]: \u001b[0mInference done 1104/3273. Dataloading: 0.0020 s/iter. Inference: 0.0359 s/iter. Eval: 0.0405 s/iter. Total: 0.0785 s/iter. ETA=0:02:50\n",
      "\u001b[32m[07/12 16:01:56 d2.evaluation.evaluator]: \u001b[0mInference done 1170/3273. Dataloading: 0.0020 s/iter. Inference: 0.0359 s/iter. Eval: 0.0403 s/iter. Total: 0.0783 s/iter. ETA=0:02:44\n",
      "\u001b[32m[07/12 16:02:01 d2.evaluation.evaluator]: \u001b[0mInference done 1236/3273. Dataloading: 0.0020 s/iter. Inference: 0.0359 s/iter. Eval: 0.0402 s/iter. Total: 0.0783 s/iter. ETA=0:02:39\n",
      "\u001b[32m[07/12 16:02:06 d2.evaluation.evaluator]: \u001b[0mInference done 1301/3273. Dataloading: 0.0020 s/iter. Inference: 0.0360 s/iter. Eval: 0.0401 s/iter. Total: 0.0782 s/iter. ETA=0:02:34\n",
      "\u001b[32m[07/12 16:02:11 d2.evaluation.evaluator]: \u001b[0mInference done 1365/3273. Dataloading: 0.0020 s/iter. Inference: 0.0360 s/iter. Eval: 0.0401 s/iter. Total: 0.0782 s/iter. ETA=0:02:29\n",
      "\u001b[32m[07/12 16:02:16 d2.evaluation.evaluator]: \u001b[0mInference done 1431/3273. Dataloading: 0.0020 s/iter. Inference: 0.0360 s/iter. Eval: 0.0400 s/iter. Total: 0.0781 s/iter. ETA=0:02:23\n",
      "\u001b[32m[07/12 16:02:21 d2.evaluation.evaluator]: \u001b[0mInference done 1497/3273. Dataloading: 0.0020 s/iter. Inference: 0.0360 s/iter. Eval: 0.0399 s/iter. Total: 0.0780 s/iter. ETA=0:02:18\n",
      "\u001b[32m[07/12 16:02:26 d2.evaluation.evaluator]: \u001b[0mInference done 1564/3273. Dataloading: 0.0020 s/iter. Inference: 0.0360 s/iter. Eval: 0.0398 s/iter. Total: 0.0779 s/iter. ETA=0:02:13\n",
      "\u001b[32m[07/12 16:02:31 d2.evaluation.evaluator]: \u001b[0mInference done 1632/3273. Dataloading: 0.0020 s/iter. Inference: 0.0360 s/iter. Eval: 0.0396 s/iter. Total: 0.0777 s/iter. ETA=0:02:07\n",
      "\u001b[32m[07/12 16:02:36 d2.evaluation.evaluator]: \u001b[0mInference done 1700/3273. Dataloading: 0.0020 s/iter. Inference: 0.0360 s/iter. Eval: 0.0395 s/iter. Total: 0.0776 s/iter. ETA=0:02:02\n",
      "\u001b[32m[07/12 16:02:41 d2.evaluation.evaluator]: \u001b[0mInference done 1768/3273. Dataloading: 0.0020 s/iter. Inference: 0.0360 s/iter. Eval: 0.0393 s/iter. Total: 0.0775 s/iter. ETA=0:01:56\n",
      "\u001b[32m[07/12 16:02:47 d2.evaluation.evaluator]: \u001b[0mInference done 1836/3273. Dataloading: 0.0020 s/iter. Inference: 0.0360 s/iter. Eval: 0.0392 s/iter. Total: 0.0773 s/iter. ETA=0:01:51\n",
      "\u001b[32m[07/12 16:02:52 d2.evaluation.evaluator]: \u001b[0mInference done 1904/3273. Dataloading: 0.0020 s/iter. Inference: 0.0360 s/iter. Eval: 0.0391 s/iter. Total: 0.0772 s/iter. ETA=0:01:45\n",
      "\u001b[32m[07/12 16:02:57 d2.evaluation.evaluator]: \u001b[0mInference done 1972/3273. Dataloading: 0.0020 s/iter. Inference: 0.0360 s/iter. Eval: 0.0390 s/iter. Total: 0.0771 s/iter. ETA=0:01:40\n",
      "\u001b[32m[07/12 16:03:02 d2.evaluation.evaluator]: \u001b[0mInference done 2040/3273. Dataloading: 0.0020 s/iter. Inference: 0.0360 s/iter. Eval: 0.0388 s/iter. Total: 0.0770 s/iter. ETA=0:01:34\n",
      "\u001b[32m[07/12 16:03:07 d2.evaluation.evaluator]: \u001b[0mInference done 2108/3273. Dataloading: 0.0020 s/iter. Inference: 0.0360 s/iter. Eval: 0.0387 s/iter. Total: 0.0769 s/iter. ETA=0:01:29\n",
      "\u001b[32m[07/12 16:03:12 d2.evaluation.evaluator]: \u001b[0mInference done 2175/3273. Dataloading: 0.0021 s/iter. Inference: 0.0361 s/iter. Eval: 0.0386 s/iter. Total: 0.0768 s/iter. ETA=0:01:24\n",
      "\u001b[32m[07/12 16:03:17 d2.evaluation.evaluator]: \u001b[0mInference done 2242/3273. Dataloading: 0.0021 s/iter. Inference: 0.0361 s/iter. Eval: 0.0386 s/iter. Total: 0.0768 s/iter. ETA=0:01:19\n",
      "\u001b[32m[07/12 16:03:22 d2.evaluation.evaluator]: \u001b[0mInference done 2310/3273. Dataloading: 0.0021 s/iter. Inference: 0.0361 s/iter. Eval: 0.0385 s/iter. Total: 0.0767 s/iter. ETA=0:01:13\n",
      "\u001b[32m[07/12 16:03:27 d2.evaluation.evaluator]: \u001b[0mInference done 2377/3273. Dataloading: 0.0021 s/iter. Inference: 0.0361 s/iter. Eval: 0.0385 s/iter. Total: 0.0767 s/iter. ETA=0:01:08\n",
      "\u001b[32m[07/12 16:03:32 d2.evaluation.evaluator]: \u001b[0mInference done 2443/3273. Dataloading: 0.0021 s/iter. Inference: 0.0361 s/iter. Eval: 0.0384 s/iter. Total: 0.0767 s/iter. ETA=0:01:03\n",
      "\u001b[32m[07/12 16:03:37 d2.evaluation.evaluator]: \u001b[0mInference done 2508/3273. Dataloading: 0.0021 s/iter. Inference: 0.0361 s/iter. Eval: 0.0384 s/iter. Total: 0.0767 s/iter. ETA=0:00:58\n",
      "\u001b[32m[07/12 16:03:42 d2.evaluation.evaluator]: \u001b[0mInference done 2574/3273. Dataloading: 0.0021 s/iter. Inference: 0.0361 s/iter. Eval: 0.0384 s/iter. Total: 0.0767 s/iter. ETA=0:00:53\n",
      "\u001b[32m[07/12 16:03:47 d2.evaluation.evaluator]: \u001b[0mInference done 2640/3273. Dataloading: 0.0021 s/iter. Inference: 0.0361 s/iter. Eval: 0.0384 s/iter. Total: 0.0766 s/iter. ETA=0:00:48\n",
      "\u001b[32m[07/12 16:03:52 d2.evaluation.evaluator]: \u001b[0mInference done 2702/3273. Dataloading: 0.0021 s/iter. Inference: 0.0362 s/iter. Eval: 0.0384 s/iter. Total: 0.0767 s/iter. ETA=0:00:43\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/12 16:03:57 d2.evaluation.evaluator]: \u001b[0mInference done 2767/3273. Dataloading: 0.0021 s/iter. Inference: 0.0362 s/iter. Eval: 0.0384 s/iter. Total: 0.0768 s/iter. ETA=0:00:38\n",
      "\u001b[32m[07/12 16:04:02 d2.evaluation.evaluator]: \u001b[0mInference done 2831/3273. Dataloading: 0.0021 s/iter. Inference: 0.0362 s/iter. Eval: 0.0385 s/iter. Total: 0.0768 s/iter. ETA=0:00:33\n",
      "\u001b[32m[07/12 16:04:07 d2.evaluation.evaluator]: \u001b[0mInference done 2893/3273. Dataloading: 0.0021 s/iter. Inference: 0.0362 s/iter. Eval: 0.0386 s/iter. Total: 0.0769 s/iter. ETA=0:00:29\n",
      "\u001b[32m[07/12 16:04:12 d2.evaluation.evaluator]: \u001b[0mInference done 2956/3273. Dataloading: 0.0021 s/iter. Inference: 0.0362 s/iter. Eval: 0.0387 s/iter. Total: 0.0770 s/iter. ETA=0:00:24\n",
      "\u001b[32m[07/12 16:04:17 d2.evaluation.evaluator]: \u001b[0mInference done 3019/3273. Dataloading: 0.0021 s/iter. Inference: 0.0362 s/iter. Eval: 0.0387 s/iter. Total: 0.0770 s/iter. ETA=0:00:19\n",
      "\u001b[32m[07/12 16:04:22 d2.evaluation.evaluator]: \u001b[0mInference done 3083/3273. Dataloading: 0.0021 s/iter. Inference: 0.0362 s/iter. Eval: 0.0388 s/iter. Total: 0.0771 s/iter. ETA=0:00:14\n",
      "\u001b[32m[07/12 16:04:27 d2.evaluation.evaluator]: \u001b[0mInference done 3148/3273. Dataloading: 0.0021 s/iter. Inference: 0.0362 s/iter. Eval: 0.0388 s/iter. Total: 0.0771 s/iter. ETA=0:00:09\n",
      "\u001b[32m[07/12 16:04:32 d2.evaluation.evaluator]: \u001b[0mInference done 3213/3273. Dataloading: 0.0021 s/iter. Inference: 0.0362 s/iter. Eval: 0.0388 s/iter. Total: 0.0771 s/iter. ETA=0:00:04\n",
      "\u001b[32m[07/12 16:04:37 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:04:11.958593 (0.077099 s / iter per device, on 1 devices)\n",
      "\u001b[32m[07/12 16:04:37 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:01:58 (0.036157 s / iter per device, on 1 devices)\n",
      "\u001b[32m[07/12 16:04:37 d2.evaluation.sem_seg_evaluation]: \u001b[0mOrderedDict([('sem_seg', {'mIoU': 37.93074505894021, 'fwIoU': 68.91408011858411, 'IoU-Unlabeled': nan, 'IoU-Building': 52.81014975866283, 'IoU-Fence': 13.75249388615733, 'IoU-Pedestrian': 25.420566459875086, 'IoU-Pole': 37.047604473605425, 'IoU-Road': 89.09768657727466, 'IoU-SideWalk': 43.16117195331247, 'IoU-Vegetation': 44.09117434175347, 'IoU-Vehicles': 55.585622087899154, 'IoU-Wall': 4.92595016433666, 'IoU-TrafficSign': 26.287961933368955, 'IoU-Sky': 82.83931163213028, 'IoU-TrafficLight': 25.714149089256495, 'IoU-Terrain': 0.016884172980880238, 'IoU-ConstructionVehicle': 59.80557967678204, 'IoU-workzone_object': 17.15774576720283, 'IoU-Detour': 29.177868968444887, 'mACC': 55.1940468412812, 'pACC': 80.56896793372756, 'ACC-Unlabeled': nan, 'ACC-Building': 90.53236209445586, 'ACC-Fence': 19.036870306032814, 'ACC-Pedestrian': 61.35819228633953, 'ACC-Pole': 43.431807606894715, 'ACC-Road': 95.36688589651489, 'ACC-SideWalk': 60.56618189379754, 'ACC-Vegetation': 53.1739170061447, 'ACC-Vehicles': 78.067969672044, 'ACC-Wall': 5.039768679441585, 'ACC-TrafficSign': 46.30644992045313, 'ACC-Sky': 92.92647999597082, 'ACC-TrafficLight': 28.46809867538988, 'ACC-Terrain': 0.01689528848368455, 'ACC-ConstructionVehicle': 90.18291686220333, 'ACC-workzone_object': 78.3197747281768, 'ACC-Detour': 40.310178548155875})])\n",
      "\u001b[32m[07/12 16:04:37 d2.engine.defaults]: \u001b[0mEvaluation results for carla_night_rain_val in csv format:\n",
      "\u001b[32m[07/12 16:04:37 d2.evaluation.testing]: \u001b[0mcopypaste: Task: sem_seg\n",
      "\u001b[32m[07/12 16:04:37 d2.evaluation.testing]: \u001b[0mcopypaste: mIoU,fwIoU,mACC,pACC\n",
      "\u001b[32m[07/12 16:04:37 d2.evaluation.testing]: \u001b[0mcopypaste: 37.9307,68.9141,55.1940,80.5690\n"
     ]
    }
   ],
   "source": [
    "trainer_day = Detectron2Trainer('carla_night_all_train', 'carla_night_rain_val', output_folder='./output_night_40k')\n",
    "trainer_day.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "21570888",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/12 16:04:38 d2.engine.defaults]: \u001b[0mModel:\n",
      "SemanticSegmentor(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (sem_seg_head): SemSegFPNHead(\n",
      "    (p2): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "    )\n",
      "    (p3): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (1): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "    )\n",
      "    (p4): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (1): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      (2): Conv2d(\n",
      "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (3): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "    )\n",
      "    (p5): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (1): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      (2): Conv2d(\n",
      "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (3): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      (4): Conv2d(\n",
      "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (5): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "    )\n",
      "    (predictor): Conv2d(128, 17, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/12 16:04:38 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(720, 720), max_size=2048, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[07/12 16:04:38 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[07/12 16:04:38 d2.data.common]: \u001b[0mSerializing 15446 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[07/12 16:04:38 d2.data.common]: \u001b[0mSerialized dataset takes 5.05 MiB\n",
      "Last checkpoint: model_final.pth\n",
      "\u001b[32m[07/12 16:04:38 d2.checkpoint.c2_model_loading]: \u001b[0mFollowing weights matched with model:\n",
      "| Names in Model                       | Names in Checkpoint                                                                                  | Shapes                                          |\n",
      "|:-------------------------------------|:-----------------------------------------------------------------------------------------------------|:------------------------------------------------|\n",
      "| backbone.bottom_up.res2.0.conv1.*    | backbone.bottom_up.res2.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,1,1)             |\n",
      "| backbone.bottom_up.res2.0.conv2.*    | backbone.bottom_up.res2.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |\n",
      "| backbone.bottom_up.res2.0.conv3.*    | backbone.bottom_up.res2.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res2.0.shortcut.* | backbone.bottom_up.res2.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res2.1.conv1.*    | backbone.bottom_up.res2.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |\n",
      "| backbone.bottom_up.res2.1.conv2.*    | backbone.bottom_up.res2.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |\n",
      "| backbone.bottom_up.res2.1.conv3.*    | backbone.bottom_up.res2.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res2.2.conv1.*    | backbone.bottom_up.res2.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |\n",
      "| backbone.bottom_up.res2.2.conv2.*    | backbone.bottom_up.res2.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |\n",
      "| backbone.bottom_up.res2.2.conv3.*    | backbone.bottom_up.res2.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res3.0.conv1.*    | backbone.bottom_up.res3.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,256,1,1)       |\n",
      "| backbone.bottom_up.res3.0.conv2.*    | backbone.bottom_up.res3.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.0.conv3.*    | backbone.bottom_up.res3.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res3.0.shortcut.* | backbone.bottom_up.res3.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (512,) (512,) (512,) (512,) (512,256,1,1)       |\n",
      "| backbone.bottom_up.res3.1.conv1.*    | backbone.bottom_up.res3.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |\n",
      "| backbone.bottom_up.res3.1.conv2.*    | backbone.bottom_up.res3.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.1.conv3.*    | backbone.bottom_up.res3.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res3.2.conv1.*    | backbone.bottom_up.res3.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |\n",
      "| backbone.bottom_up.res3.2.conv2.*    | backbone.bottom_up.res3.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.2.conv3.*    | backbone.bottom_up.res3.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res3.3.conv1.*    | backbone.bottom_up.res3.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |\n",
      "| backbone.bottom_up.res3.3.conv2.*    | backbone.bottom_up.res3.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.3.conv3.*    | backbone.bottom_up.res3.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res4.0.conv1.*    | backbone.bottom_up.res4.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,512,1,1)       |\n",
      "| backbone.bottom_up.res4.0.conv2.*    | backbone.bottom_up.res4.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.0.conv3.*    | backbone.bottom_up.res4.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.0.shortcut.* | backbone.bottom_up.res4.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (1024,) (1024,) (1024,) (1024,) (1024,512,1,1)  |\n",
      "| backbone.bottom_up.res4.1.conv1.*    | backbone.bottom_up.res4.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.1.conv2.*    | backbone.bottom_up.res4.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.1.conv3.*    | backbone.bottom_up.res4.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.2.conv1.*    | backbone.bottom_up.res4.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.2.conv2.*    | backbone.bottom_up.res4.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.2.conv3.*    | backbone.bottom_up.res4.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.3.conv1.*    | backbone.bottom_up.res4.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.3.conv2.*    | backbone.bottom_up.res4.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.3.conv3.*    | backbone.bottom_up.res4.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.4.conv1.*    | backbone.bottom_up.res4.4.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.4.conv2.*    | backbone.bottom_up.res4.4.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.4.conv3.*    | backbone.bottom_up.res4.4.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.5.conv1.*    | backbone.bottom_up.res4.5.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.5.conv2.*    | backbone.bottom_up.res4.5.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.5.conv3.*    | backbone.bottom_up.res4.5.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res5.0.conv1.*    | backbone.bottom_up.res5.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,1024,1,1)      |\n",
      "| backbone.bottom_up.res5.0.conv2.*    | backbone.bottom_up.res5.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |\n",
      "| backbone.bottom_up.res5.0.conv3.*    | backbone.bottom_up.res5.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
      "| backbone.bottom_up.res5.0.shortcut.* | backbone.bottom_up.res5.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (2048,) (2048,) (2048,) (2048,) (2048,1024,1,1) |\n",
      "| backbone.bottom_up.res5.1.conv1.*    | backbone.bottom_up.res5.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |\n",
      "| backbone.bottom_up.res5.1.conv2.*    | backbone.bottom_up.res5.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |\n",
      "| backbone.bottom_up.res5.1.conv3.*    | backbone.bottom_up.res5.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
      "| backbone.bottom_up.res5.2.conv1.*    | backbone.bottom_up.res5.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |\n",
      "| backbone.bottom_up.res5.2.conv2.*    | backbone.bottom_up.res5.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |\n",
      "| backbone.bottom_up.res5.2.conv3.*    | backbone.bottom_up.res5.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
      "| backbone.bottom_up.stem.conv1.*      | backbone.bottom_up.stem.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}      | (64,) (64,) (64,) (64,) (64,3,7,7)              |\n",
      "| backbone.fpn_lateral2.*              | backbone.fpn_lateral2.{bias,weight}                                                                  | (256,) (256,256,1,1)                            |\n",
      "| backbone.fpn_lateral3.*              | backbone.fpn_lateral3.{bias,weight}                                                                  | (256,) (256,512,1,1)                            |\n",
      "| backbone.fpn_lateral4.*              | backbone.fpn_lateral4.{bias,weight}                                                                  | (256,) (256,1024,1,1)                           |\n",
      "| backbone.fpn_lateral5.*              | backbone.fpn_lateral5.{bias,weight}                                                                  | (256,) (256,2048,1,1)                           |\n",
      "| backbone.fpn_output2.*               | backbone.fpn_output2.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| backbone.fpn_output3.*               | backbone.fpn_output3.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| backbone.fpn_output4.*               | backbone.fpn_output4.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| backbone.fpn_output5.*               | backbone.fpn_output5.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| sem_seg_head.p2.0.*                  | sem_seg_head.p2.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p3.0.*                  | sem_seg_head.p3.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p4.0.*                  | sem_seg_head.p4.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p4.2.*                  | sem_seg_head.p4.2.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,128,3,3)                     |\n",
      "| sem_seg_head.p5.0.*                  | sem_seg_head.p5.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p5.2.*                  | sem_seg_head.p5.2.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,128,3,3)                     |\n",
      "| sem_seg_head.p5.4.*                  | sem_seg_head.p5.4.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,128,3,3)                     |\n",
      "| sem_seg_head.predictor.*             | sem_seg_head.predictor.{bias,weight}                                                                 | (17,) (17,128,1,1)                              |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/12 16:04:38 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(720, 720), max_size=2048, sample_style='choice')]\n",
      "\u001b[32m[07/12 16:04:38 d2.data.common]: \u001b[0mSerializing 6546 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[07/12 16:04:38 d2.data.common]: \u001b[0mSerialized dataset takes 2.08 MiB\n",
      "\u001b[32m[07/12 16:04:38 d2.evaluation.evaluator]: \u001b[0mStart inference on 6546 batches\n",
      "\u001b[32m[07/12 16:04:40 d2.evaluation.evaluator]: \u001b[0mInference done 11/6546. Dataloading: 0.0018 s/iter. Inference: 0.0369 s/iter. Eval: 0.0420 s/iter. Total: 0.0807 s/iter. ETA=0:08:47\n",
      "\u001b[32m[07/12 16:04:45 d2.evaluation.evaluator]: \u001b[0mInference done 73/6546. Dataloading: 0.0021 s/iter. Inference: 0.0356 s/iter. Eval: 0.0435 s/iter. Total: 0.0814 s/iter. ETA=0:08:46\n",
      "\u001b[32m[07/12 16:04:50 d2.evaluation.evaluator]: \u001b[0mInference done 137/6546. Dataloading: 0.0021 s/iter. Inference: 0.0357 s/iter. Eval: 0.0424 s/iter. Total: 0.0803 s/iter. ETA=0:08:34\n",
      "\u001b[32m[07/12 16:04:55 d2.evaluation.evaluator]: \u001b[0mInference done 199/6546. Dataloading: 0.0021 s/iter. Inference: 0.0357 s/iter. Eval: 0.0428 s/iter. Total: 0.0807 s/iter. ETA=0:08:32\n",
      "\u001b[32m[07/12 16:05:00 d2.evaluation.evaluator]: \u001b[0mInference done 261/6546. Dataloading: 0.0021 s/iter. Inference: 0.0357 s/iter. Eval: 0.0431 s/iter. Total: 0.0809 s/iter. ETA=0:08:28\n",
      "\u001b[32m[07/12 16:05:05 d2.evaluation.evaluator]: \u001b[0mInference done 324/6546. Dataloading: 0.0021 s/iter. Inference: 0.0357 s/iter. Eval: 0.0429 s/iter. Total: 0.0807 s/iter. ETA=0:08:22\n",
      "\u001b[32m[07/12 16:05:10 d2.evaluation.evaluator]: \u001b[0mInference done 387/6546. Dataloading: 0.0020 s/iter. Inference: 0.0358 s/iter. Eval: 0.0427 s/iter. Total: 0.0806 s/iter. ETA=0:08:16\n",
      "\u001b[32m[07/12 16:05:15 d2.evaluation.evaluator]: \u001b[0mInference done 450/6546. Dataloading: 0.0020 s/iter. Inference: 0.0358 s/iter. Eval: 0.0425 s/iter. Total: 0.0804 s/iter. ETA=0:08:10\n",
      "\u001b[32m[07/12 16:05:20 d2.evaluation.evaluator]: \u001b[0mInference done 515/6546. Dataloading: 0.0020 s/iter. Inference: 0.0358 s/iter. Eval: 0.0422 s/iter. Total: 0.0801 s/iter. ETA=0:08:03\n",
      "\u001b[32m[07/12 16:05:25 d2.evaluation.evaluator]: \u001b[0mInference done 579/6546. Dataloading: 0.0020 s/iter. Inference: 0.0359 s/iter. Eval: 0.0420 s/iter. Total: 0.0800 s/iter. ETA=0:07:57\n",
      "\u001b[32m[07/12 16:05:30 d2.evaluation.evaluator]: \u001b[0mInference done 643/6546. Dataloading: 0.0020 s/iter. Inference: 0.0359 s/iter. Eval: 0.0419 s/iter. Total: 0.0799 s/iter. ETA=0:07:51\n",
      "\u001b[32m[07/12 16:05:35 d2.evaluation.evaluator]: \u001b[0mInference done 706/6546. Dataloading: 0.0020 s/iter. Inference: 0.0359 s/iter. Eval: 0.0420 s/iter. Total: 0.0800 s/iter. ETA=0:07:46\n",
      "\u001b[32m[07/12 16:05:40 d2.evaluation.evaluator]: \u001b[0mInference done 769/6546. Dataloading: 0.0020 s/iter. Inference: 0.0359 s/iter. Eval: 0.0420 s/iter. Total: 0.0800 s/iter. ETA=0:07:42\n",
      "\u001b[32m[07/12 16:05:45 d2.evaluation.evaluator]: \u001b[0mInference done 832/6546. Dataloading: 0.0020 s/iter. Inference: 0.0359 s/iter. Eval: 0.0420 s/iter. Total: 0.0800 s/iter. ETA=0:07:37\n",
      "\u001b[32m[07/12 16:05:50 d2.evaluation.evaluator]: \u001b[0mInference done 894/6546. Dataloading: 0.0020 s/iter. Inference: 0.0359 s/iter. Eval: 0.0422 s/iter. Total: 0.0802 s/iter. ETA=0:07:33\n",
      "\u001b[32m[07/12 16:05:55 d2.evaluation.evaluator]: \u001b[0mInference done 956/6546. Dataloading: 0.0020 s/iter. Inference: 0.0359 s/iter. Eval: 0.0423 s/iter. Total: 0.0803 s/iter. ETA=0:07:28\n",
      "\u001b[32m[07/12 16:06:00 d2.evaluation.evaluator]: \u001b[0mInference done 1018/6546. Dataloading: 0.0020 s/iter. Inference: 0.0359 s/iter. Eval: 0.0424 s/iter. Total: 0.0804 s/iter. ETA=0:07:24\n",
      "\u001b[32m[07/12 16:06:06 d2.evaluation.evaluator]: \u001b[0mInference done 1081/6546. Dataloading: 0.0020 s/iter. Inference: 0.0359 s/iter. Eval: 0.0423 s/iter. Total: 0.0803 s/iter. ETA=0:07:18\n",
      "\u001b[32m[07/12 16:06:11 d2.evaluation.evaluator]: \u001b[0mInference done 1143/6546. Dataloading: 0.0020 s/iter. Inference: 0.0359 s/iter. Eval: 0.0423 s/iter. Total: 0.0804 s/iter. ETA=0:07:14\n",
      "\u001b[32m[07/12 16:06:16 d2.evaluation.evaluator]: \u001b[0mInference done 1206/6546. Dataloading: 0.0020 s/iter. Inference: 0.0359 s/iter. Eval: 0.0423 s/iter. Total: 0.0803 s/iter. ETA=0:07:09\n",
      "\u001b[32m[07/12 16:06:21 d2.evaluation.evaluator]: \u001b[0mInference done 1268/6546. Dataloading: 0.0020 s/iter. Inference: 0.0359 s/iter. Eval: 0.0423 s/iter. Total: 0.0804 s/iter. ETA=0:07:04\n",
      "\u001b[32m[07/12 16:06:26 d2.evaluation.evaluator]: \u001b[0mInference done 1330/6546. Dataloading: 0.0020 s/iter. Inference: 0.0359 s/iter. Eval: 0.0423 s/iter. Total: 0.0804 s/iter. ETA=0:06:59\n",
      "\u001b[32m[07/12 16:06:31 d2.evaluation.evaluator]: \u001b[0mInference done 1394/6546. Dataloading: 0.0020 s/iter. Inference: 0.0359 s/iter. Eval: 0.0423 s/iter. Total: 0.0803 s/iter. ETA=0:06:53\n",
      "\u001b[32m[07/12 16:06:36 d2.evaluation.evaluator]: \u001b[0mInference done 1457/6546. Dataloading: 0.0020 s/iter. Inference: 0.0359 s/iter. Eval: 0.0422 s/iter. Total: 0.0803 s/iter. ETA=0:06:48\n",
      "\u001b[32m[07/12 16:06:41 d2.evaluation.evaluator]: \u001b[0mInference done 1520/6546. Dataloading: 0.0021 s/iter. Inference: 0.0359 s/iter. Eval: 0.0422 s/iter. Total: 0.0803 s/iter. ETA=0:06:43\n",
      "\u001b[32m[07/12 16:06:46 d2.evaluation.evaluator]: \u001b[0mInference done 1585/6546. Dataloading: 0.0021 s/iter. Inference: 0.0359 s/iter. Eval: 0.0421 s/iter. Total: 0.0802 s/iter. ETA=0:06:37\n",
      "\u001b[32m[07/12 16:06:51 d2.evaluation.evaluator]: \u001b[0mInference done 1652/6546. Dataloading: 0.0021 s/iter. Inference: 0.0360 s/iter. Eval: 0.0419 s/iter. Total: 0.0800 s/iter. ETA=0:06:31\n",
      "\u001b[32m[07/12 16:06:56 d2.evaluation.evaluator]: \u001b[0mInference done 1718/6546. Dataloading: 0.0021 s/iter. Inference: 0.0360 s/iter. Eval: 0.0418 s/iter. Total: 0.0799 s/iter. ETA=0:06:25\n",
      "\u001b[32m[07/12 16:07:01 d2.evaluation.evaluator]: \u001b[0mInference done 1785/6546. Dataloading: 0.0021 s/iter. Inference: 0.0360 s/iter. Eval: 0.0416 s/iter. Total: 0.0797 s/iter. ETA=0:06:19\n",
      "\u001b[32m[07/12 16:07:06 d2.evaluation.evaluator]: \u001b[0mInference done 1850/6546. Dataloading: 0.0021 s/iter. Inference: 0.0360 s/iter. Eval: 0.0415 s/iter. Total: 0.0796 s/iter. ETA=0:06:13\n",
      "\u001b[32m[07/12 16:07:11 d2.evaluation.evaluator]: \u001b[0mInference done 1914/6546. Dataloading: 0.0021 s/iter. Inference: 0.0360 s/iter. Eval: 0.0414 s/iter. Total: 0.0796 s/iter. ETA=0:06:08\n",
      "\u001b[32m[07/12 16:07:16 d2.evaluation.evaluator]: \u001b[0mInference done 1979/6546. Dataloading: 0.0021 s/iter. Inference: 0.0360 s/iter. Eval: 0.0414 s/iter. Total: 0.0795 s/iter. ETA=0:06:03\n",
      "\u001b[32m[07/12 16:07:21 d2.evaluation.evaluator]: \u001b[0mInference done 2045/6546. Dataloading: 0.0021 s/iter. Inference: 0.0360 s/iter. Eval: 0.0413 s/iter. Total: 0.0794 s/iter. ETA=0:05:57\n",
      "\u001b[32m[07/12 16:07:26 d2.evaluation.evaluator]: \u001b[0mInference done 2111/6546. Dataloading: 0.0021 s/iter. Inference: 0.0360 s/iter. Eval: 0.0412 s/iter. Total: 0.0793 s/iter. ETA=0:05:51\n",
      "\u001b[32m[07/12 16:07:31 d2.evaluation.evaluator]: \u001b[0mInference done 2175/6546. Dataloading: 0.0021 s/iter. Inference: 0.0360 s/iter. Eval: 0.0411 s/iter. Total: 0.0793 s/iter. ETA=0:05:46\n",
      "\u001b[32m[07/12 16:07:36 d2.evaluation.evaluator]: \u001b[0mInference done 2239/6546. Dataloading: 0.0021 s/iter. Inference: 0.0360 s/iter. Eval: 0.0411 s/iter. Total: 0.0793 s/iter. ETA=0:05:41\n",
      "\u001b[32m[07/12 16:07:41 d2.evaluation.evaluator]: \u001b[0mInference done 2306/6546. Dataloading: 0.0021 s/iter. Inference: 0.0360 s/iter. Eval: 0.0410 s/iter. Total: 0.0792 s/iter. ETA=0:05:35\n",
      "\u001b[32m[07/12 16:07:46 d2.evaluation.evaluator]: \u001b[0mInference done 2372/6546. Dataloading: 0.0021 s/iter. Inference: 0.0360 s/iter. Eval: 0.0409 s/iter. Total: 0.0791 s/iter. ETA=0:05:30\n",
      "\u001b[32m[07/12 16:07:51 d2.evaluation.evaluator]: \u001b[0mInference done 2438/6546. Dataloading: 0.0021 s/iter. Inference: 0.0360 s/iter. Eval: 0.0408 s/iter. Total: 0.0790 s/iter. ETA=0:05:24\n",
      "\u001b[32m[07/12 16:07:56 d2.evaluation.evaluator]: \u001b[0mInference done 2504/6546. Dataloading: 0.0021 s/iter. Inference: 0.0360 s/iter. Eval: 0.0407 s/iter. Total: 0.0789 s/iter. ETA=0:05:19\n",
      "\u001b[32m[07/12 16:08:01 d2.evaluation.evaluator]: \u001b[0mInference done 2570/6546. Dataloading: 0.0021 s/iter. Inference: 0.0360 s/iter. Eval: 0.0406 s/iter. Total: 0.0789 s/iter. ETA=0:05:13\n",
      "\u001b[32m[07/12 16:08:06 d2.evaluation.evaluator]: \u001b[0mInference done 2635/6546. Dataloading: 0.0021 s/iter. Inference: 0.0360 s/iter. Eval: 0.0406 s/iter. Total: 0.0788 s/iter. ETA=0:05:08\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/12 16:08:11 d2.evaluation.evaluator]: \u001b[0mInference done 2700/6546. Dataloading: 0.0021 s/iter. Inference: 0.0361 s/iter. Eval: 0.0406 s/iter. Total: 0.0788 s/iter. ETA=0:05:03\n",
      "\u001b[32m[07/12 16:08:16 d2.evaluation.evaluator]: \u001b[0mInference done 2765/6546. Dataloading: 0.0021 s/iter. Inference: 0.0361 s/iter. Eval: 0.0405 s/iter. Total: 0.0788 s/iter. ETA=0:04:57\n",
      "\u001b[32m[07/12 16:08:22 d2.evaluation.evaluator]: \u001b[0mInference done 2831/6546. Dataloading: 0.0021 s/iter. Inference: 0.0361 s/iter. Eval: 0.0405 s/iter. Total: 0.0787 s/iter. ETA=0:04:52\n",
      "\u001b[32m[07/12 16:08:27 d2.evaluation.evaluator]: \u001b[0mInference done 2899/6546. Dataloading: 0.0021 s/iter. Inference: 0.0361 s/iter. Eval: 0.0403 s/iter. Total: 0.0786 s/iter. ETA=0:04:46\n",
      "\u001b[32m[07/12 16:08:32 d2.evaluation.evaluator]: \u001b[0mInference done 2967/6546. Dataloading: 0.0021 s/iter. Inference: 0.0361 s/iter. Eval: 0.0402 s/iter. Total: 0.0785 s/iter. ETA=0:04:40\n",
      "\u001b[32m[07/12 16:08:37 d2.evaluation.evaluator]: \u001b[0mInference done 3034/6546. Dataloading: 0.0021 s/iter. Inference: 0.0361 s/iter. Eval: 0.0402 s/iter. Total: 0.0784 s/iter. ETA=0:04:35\n",
      "\u001b[32m[07/12 16:08:42 d2.evaluation.evaluator]: \u001b[0mInference done 3100/6546. Dataloading: 0.0021 s/iter. Inference: 0.0361 s/iter. Eval: 0.0401 s/iter. Total: 0.0784 s/iter. ETA=0:04:30\n",
      "\u001b[32m[07/12 16:08:47 d2.evaluation.evaluator]: \u001b[0mInference done 3167/6546. Dataloading: 0.0021 s/iter. Inference: 0.0361 s/iter. Eval: 0.0400 s/iter. Total: 0.0783 s/iter. ETA=0:04:24\n",
      "\u001b[32m[07/12 16:08:52 d2.evaluation.evaluator]: \u001b[0mInference done 3234/6546. Dataloading: 0.0021 s/iter. Inference: 0.0361 s/iter. Eval: 0.0399 s/iter. Total: 0.0782 s/iter. ETA=0:04:19\n",
      "\u001b[32m[07/12 16:08:57 d2.evaluation.evaluator]: \u001b[0mInference done 3301/6546. Dataloading: 0.0021 s/iter. Inference: 0.0361 s/iter. Eval: 0.0399 s/iter. Total: 0.0782 s/iter. ETA=0:04:13\n",
      "\u001b[32m[07/12 16:09:02 d2.evaluation.evaluator]: \u001b[0mInference done 3368/6546. Dataloading: 0.0021 s/iter. Inference: 0.0361 s/iter. Eval: 0.0398 s/iter. Total: 0.0781 s/iter. ETA=0:04:08\n",
      "\u001b[32m[07/12 16:09:07 d2.evaluation.evaluator]: \u001b[0mInference done 3435/6546. Dataloading: 0.0021 s/iter. Inference: 0.0361 s/iter. Eval: 0.0397 s/iter. Total: 0.0781 s/iter. ETA=0:04:02\n",
      "\u001b[32m[07/12 16:09:12 d2.evaluation.evaluator]: \u001b[0mInference done 3499/6546. Dataloading: 0.0021 s/iter. Inference: 0.0362 s/iter. Eval: 0.0397 s/iter. Total: 0.0781 s/iter. ETA=0:03:57\n",
      "\u001b[32m[07/12 16:09:17 d2.evaluation.evaluator]: \u001b[0mInference done 3565/6546. Dataloading: 0.0021 s/iter. Inference: 0.0362 s/iter. Eval: 0.0397 s/iter. Total: 0.0780 s/iter. ETA=0:03:52\n",
      "\u001b[32m[07/12 16:09:22 d2.evaluation.evaluator]: \u001b[0mInference done 3632/6546. Dataloading: 0.0021 s/iter. Inference: 0.0362 s/iter. Eval: 0.0396 s/iter. Total: 0.0780 s/iter. ETA=0:03:47\n",
      "\u001b[32m[07/12 16:09:27 d2.evaluation.evaluator]: \u001b[0mInference done 3699/6546. Dataloading: 0.0021 s/iter. Inference: 0.0362 s/iter. Eval: 0.0396 s/iter. Total: 0.0780 s/iter. ETA=0:03:41\n",
      "\u001b[32m[07/12 16:09:32 d2.evaluation.evaluator]: \u001b[0mInference done 3766/6546. Dataloading: 0.0021 s/iter. Inference: 0.0362 s/iter. Eval: 0.0395 s/iter. Total: 0.0779 s/iter. ETA=0:03:36\n",
      "\u001b[32m[07/12 16:09:37 d2.evaluation.evaluator]: \u001b[0mInference done 3833/6546. Dataloading: 0.0021 s/iter. Inference: 0.0362 s/iter. Eval: 0.0395 s/iter. Total: 0.0779 s/iter. ETA=0:03:31\n",
      "\u001b[32m[07/12 16:09:42 d2.evaluation.evaluator]: \u001b[0mInference done 3899/6546. Dataloading: 0.0021 s/iter. Inference: 0.0362 s/iter. Eval: 0.0394 s/iter. Total: 0.0778 s/iter. ETA=0:03:26\n",
      "\u001b[32m[07/12 16:09:47 d2.evaluation.evaluator]: \u001b[0mInference done 3965/6546. Dataloading: 0.0021 s/iter. Inference: 0.0362 s/iter. Eval: 0.0394 s/iter. Total: 0.0778 s/iter. ETA=0:03:20\n",
      "\u001b[32m[07/12 16:09:52 d2.evaluation.evaluator]: \u001b[0mInference done 4031/6546. Dataloading: 0.0021 s/iter. Inference: 0.0362 s/iter. Eval: 0.0394 s/iter. Total: 0.0778 s/iter. ETA=0:03:15\n",
      "\u001b[32m[07/12 16:09:57 d2.evaluation.evaluator]: \u001b[0mInference done 4097/6546. Dataloading: 0.0021 s/iter. Inference: 0.0362 s/iter. Eval: 0.0394 s/iter. Total: 0.0778 s/iter. ETA=0:03:10\n",
      "\u001b[32m[07/12 16:10:02 d2.evaluation.evaluator]: \u001b[0mInference done 4164/6546. Dataloading: 0.0021 s/iter. Inference: 0.0362 s/iter. Eval: 0.0393 s/iter. Total: 0.0777 s/iter. ETA=0:03:05\n",
      "\u001b[32m[07/12 16:10:07 d2.evaluation.evaluator]: \u001b[0mInference done 4232/6546. Dataloading: 0.0022 s/iter. Inference: 0.0362 s/iter. Eval: 0.0393 s/iter. Total: 0.0777 s/iter. ETA=0:02:59\n",
      "\u001b[32m[07/12 16:10:12 d2.evaluation.evaluator]: \u001b[0mInference done 4299/6546. Dataloading: 0.0022 s/iter. Inference: 0.0362 s/iter. Eval: 0.0392 s/iter. Total: 0.0776 s/iter. ETA=0:02:54\n",
      "\u001b[32m[07/12 16:10:17 d2.evaluation.evaluator]: \u001b[0mInference done 4366/6546. Dataloading: 0.0022 s/iter. Inference: 0.0362 s/iter. Eval: 0.0392 s/iter. Total: 0.0776 s/iter. ETA=0:02:49\n",
      "\u001b[32m[07/12 16:10:22 d2.evaluation.evaluator]: \u001b[0mInference done 4434/6546. Dataloading: 0.0022 s/iter. Inference: 0.0362 s/iter. Eval: 0.0391 s/iter. Total: 0.0775 s/iter. ETA=0:02:43\n",
      "\u001b[32m[07/12 16:10:27 d2.evaluation.evaluator]: \u001b[0mInference done 4500/6546. Dataloading: 0.0022 s/iter. Inference: 0.0362 s/iter. Eval: 0.0391 s/iter. Total: 0.0775 s/iter. ETA=0:02:38\n",
      "\u001b[32m[07/12 16:10:32 d2.evaluation.evaluator]: \u001b[0mInference done 4567/6546. Dataloading: 0.0022 s/iter. Inference: 0.0362 s/iter. Eval: 0.0390 s/iter. Total: 0.0775 s/iter. ETA=0:02:33\n",
      "\u001b[32m[07/12 16:10:38 d2.evaluation.evaluator]: \u001b[0mInference done 4634/6546. Dataloading: 0.0022 s/iter. Inference: 0.0362 s/iter. Eval: 0.0390 s/iter. Total: 0.0774 s/iter. ETA=0:02:28\n",
      "\u001b[32m[07/12 16:10:43 d2.evaluation.evaluator]: \u001b[0mInference done 4701/6546. Dataloading: 0.0022 s/iter. Inference: 0.0362 s/iter. Eval: 0.0390 s/iter. Total: 0.0774 s/iter. ETA=0:02:22\n",
      "\u001b[32m[07/12 16:10:48 d2.evaluation.evaluator]: \u001b[0mInference done 4765/6546. Dataloading: 0.0022 s/iter. Inference: 0.0362 s/iter. Eval: 0.0390 s/iter. Total: 0.0774 s/iter. ETA=0:02:17\n",
      "\u001b[32m[07/12 16:10:53 d2.evaluation.evaluator]: \u001b[0mInference done 4829/6546. Dataloading: 0.0022 s/iter. Inference: 0.0362 s/iter. Eval: 0.0390 s/iter. Total: 0.0775 s/iter. ETA=0:02:12\n",
      "\u001b[32m[07/12 16:10:58 d2.evaluation.evaluator]: \u001b[0mInference done 4893/6546. Dataloading: 0.0022 s/iter. Inference: 0.0362 s/iter. Eval: 0.0390 s/iter. Total: 0.0775 s/iter. ETA=0:02:08\n",
      "\u001b[32m[07/12 16:11:03 d2.evaluation.evaluator]: \u001b[0mInference done 4956/6546. Dataloading: 0.0022 s/iter. Inference: 0.0362 s/iter. Eval: 0.0391 s/iter. Total: 0.0775 s/iter. ETA=0:02:03\n",
      "\u001b[32m[07/12 16:11:08 d2.evaluation.evaluator]: \u001b[0mInference done 5019/6546. Dataloading: 0.0022 s/iter. Inference: 0.0362 s/iter. Eval: 0.0391 s/iter. Total: 0.0775 s/iter. ETA=0:01:58\n",
      "\u001b[32m[07/12 16:11:13 d2.evaluation.evaluator]: \u001b[0mInference done 5082/6546. Dataloading: 0.0022 s/iter. Inference: 0.0362 s/iter. Eval: 0.0391 s/iter. Total: 0.0776 s/iter. ETA=0:01:53\n",
      "\u001b[32m[07/12 16:11:18 d2.evaluation.evaluator]: \u001b[0mInference done 5148/6546. Dataloading: 0.0022 s/iter. Inference: 0.0362 s/iter. Eval: 0.0391 s/iter. Total: 0.0775 s/iter. ETA=0:01:48\n",
      "\u001b[32m[07/12 16:11:23 d2.evaluation.evaluator]: \u001b[0mInference done 5213/6546. Dataloading: 0.0022 s/iter. Inference: 0.0362 s/iter. Eval: 0.0391 s/iter. Total: 0.0775 s/iter. ETA=0:01:43\n",
      "\u001b[32m[07/12 16:11:28 d2.evaluation.evaluator]: \u001b[0mInference done 5277/6546. Dataloading: 0.0022 s/iter. Inference: 0.0362 s/iter. Eval: 0.0391 s/iter. Total: 0.0775 s/iter. ETA=0:01:38\n",
      "\u001b[32m[07/12 16:11:33 d2.evaluation.evaluator]: \u001b[0mInference done 5341/6546. Dataloading: 0.0022 s/iter. Inference: 0.0362 s/iter. Eval: 0.0391 s/iter. Total: 0.0776 s/iter. ETA=0:01:33\n",
      "\u001b[32m[07/12 16:11:38 d2.evaluation.evaluator]: \u001b[0mInference done 5406/6546. Dataloading: 0.0022 s/iter. Inference: 0.0362 s/iter. Eval: 0.0391 s/iter. Total: 0.0776 s/iter. ETA=0:01:28\n",
      "\u001b[32m[07/12 16:11:43 d2.evaluation.evaluator]: \u001b[0mInference done 5473/6546. Dataloading: 0.0022 s/iter. Inference: 0.0362 s/iter. Eval: 0.0391 s/iter. Total: 0.0775 s/iter. ETA=0:01:23\n",
      "\u001b[32m[07/12 16:11:48 d2.evaluation.evaluator]: \u001b[0mInference done 5538/6546. Dataloading: 0.0022 s/iter. Inference: 0.0362 s/iter. Eval: 0.0391 s/iter. Total: 0.0775 s/iter. ETA=0:01:18\n",
      "\u001b[32m[07/12 16:11:53 d2.evaluation.evaluator]: \u001b[0mInference done 5603/6546. Dataloading: 0.0022 s/iter. Inference: 0.0362 s/iter. Eval: 0.0391 s/iter. Total: 0.0775 s/iter. ETA=0:01:13\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/12 16:11:58 d2.evaluation.evaluator]: \u001b[0mInference done 5668/6546. Dataloading: 0.0022 s/iter. Inference: 0.0362 s/iter. Eval: 0.0391 s/iter. Total: 0.0775 s/iter. ETA=0:01:08\n",
      "\u001b[32m[07/12 16:12:03 d2.evaluation.evaluator]: \u001b[0mInference done 5732/6546. Dataloading: 0.0022 s/iter. Inference: 0.0362 s/iter. Eval: 0.0391 s/iter. Total: 0.0775 s/iter. ETA=0:01:03\n",
      "\u001b[32m[07/12 16:12:08 d2.evaluation.evaluator]: \u001b[0mInference done 5797/6546. Dataloading: 0.0022 s/iter. Inference: 0.0362 s/iter. Eval: 0.0391 s/iter. Total: 0.0775 s/iter. ETA=0:00:58\n",
      "\u001b[32m[07/12 16:12:13 d2.evaluation.evaluator]: \u001b[0mInference done 5861/6546. Dataloading: 0.0022 s/iter. Inference: 0.0362 s/iter. Eval: 0.0391 s/iter. Total: 0.0776 s/iter. ETA=0:00:53\n",
      "\u001b[32m[07/12 16:12:18 d2.evaluation.evaluator]: \u001b[0mInference done 5925/6546. Dataloading: 0.0022 s/iter. Inference: 0.0362 s/iter. Eval: 0.0391 s/iter. Total: 0.0776 s/iter. ETA=0:00:48\n",
      "\u001b[32m[07/12 16:12:23 d2.evaluation.evaluator]: \u001b[0mInference done 5989/6546. Dataloading: 0.0022 s/iter. Inference: 0.0362 s/iter. Eval: 0.0391 s/iter. Total: 0.0776 s/iter. ETA=0:00:43\n",
      "\u001b[32m[07/12 16:12:28 d2.evaluation.evaluator]: \u001b[0mInference done 6055/6546. Dataloading: 0.0022 s/iter. Inference: 0.0362 s/iter. Eval: 0.0391 s/iter. Total: 0.0776 s/iter. ETA=0:00:38\n",
      "\u001b[32m[07/12 16:12:33 d2.evaluation.evaluator]: \u001b[0mInference done 6120/6546. Dataloading: 0.0022 s/iter. Inference: 0.0362 s/iter. Eval: 0.0391 s/iter. Total: 0.0776 s/iter. ETA=0:00:33\n",
      "\u001b[32m[07/12 16:12:38 d2.evaluation.evaluator]: \u001b[0mInference done 6185/6546. Dataloading: 0.0022 s/iter. Inference: 0.0362 s/iter. Eval: 0.0391 s/iter. Total: 0.0776 s/iter. ETA=0:00:28\n",
      "\u001b[32m[07/12 16:12:44 d2.evaluation.evaluator]: \u001b[0mInference done 6251/6546. Dataloading: 0.0022 s/iter. Inference: 0.0362 s/iter. Eval: 0.0391 s/iter. Total: 0.0776 s/iter. ETA=0:00:22\n",
      "\u001b[32m[07/12 16:12:49 d2.evaluation.evaluator]: \u001b[0mInference done 6316/6546. Dataloading: 0.0022 s/iter. Inference: 0.0362 s/iter. Eval: 0.0391 s/iter. Total: 0.0776 s/iter. ETA=0:00:17\n",
      "\u001b[32m[07/12 16:12:54 d2.evaluation.evaluator]: \u001b[0mInference done 6382/6546. Dataloading: 0.0022 s/iter. Inference: 0.0362 s/iter. Eval: 0.0391 s/iter. Total: 0.0776 s/iter. ETA=0:00:12\n",
      "\u001b[32m[07/12 16:12:59 d2.evaluation.evaluator]: \u001b[0mInference done 6448/6546. Dataloading: 0.0022 s/iter. Inference: 0.0362 s/iter. Eval: 0.0390 s/iter. Total: 0.0775 s/iter. ETA=0:00:07\n",
      "\u001b[32m[07/12 16:13:04 d2.evaluation.evaluator]: \u001b[0mInference done 6515/6546. Dataloading: 0.0022 s/iter. Inference: 0.0362 s/iter. Eval: 0.0390 s/iter. Total: 0.0775 s/iter. ETA=0:00:02\n",
      "\u001b[32m[07/12 16:13:06 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:08:27.055423 (0.077520 s / iter per device, on 1 devices)\n",
      "\u001b[32m[07/12 16:13:06 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:03:56 (0.036184 s / iter per device, on 1 devices)\n",
      "\u001b[32m[07/12 16:13:07 d2.evaluation.sem_seg_evaluation]: \u001b[0mOrderedDict([('sem_seg', {'mIoU': 35.96550169607352, 'fwIoU': 66.58630064681526, 'IoU-Unlabeled': nan, 'IoU-Building': 45.9060363384523, 'IoU-Fence': 11.773412107949207, 'IoU-Pedestrian': 20.22800535702547, 'IoU-Pole': 36.54150145343822, 'IoU-Road': 89.04453566992598, 'IoU-SideWalk': 43.960016933694206, 'IoU-Vegetation': 43.45788275981189, 'IoU-Vehicles': 51.74131234757433, 'IoU-Wall': 4.986994805604153, 'IoU-TrafficSign': 26.41439621732045, 'IoU-Sky': 77.90159360035781, 'IoU-TrafficLight': 23.696757422680335, 'IoU-Terrain': 0.023146347973945776, 'IoU-ConstructionVehicle': 60.36371251968545, 'IoU-workzone_object': 13.594857143012057, 'IoU-Detour': 25.813866112670453, 'mACC': 54.520281656798865, 'pACC': 78.13694171932237, 'ACC-Unlabeled': nan, 'ACC-Building': 91.88453486747292, 'ACC-Fence': 16.532118980403506, 'ACC-Pedestrian': 63.515017476929295, 'ACC-Pole': 43.33836894120079, 'ACC-Road': 94.88695844189401, 'ACC-SideWalk': 63.492468436235214, 'ACC-Vegetation': 52.36841010700736, 'ACC-Vehicles': 78.3038399071009, 'ACC-Wall': 5.112642678194488, 'ACC-TrafficSign': 45.740612569146414, 'ACC-Sky': 84.27820100365285, 'ACC-TrafficLight': 26.254874899300983, 'ACC-Terrain': 0.023164193449005464, 'ACC-ConstructionVehicle': 90.17518327717696, 'ACC-workzone_object': 78.36259137603956, 'ACC-Detour': 38.05551935357748})])\n",
      "\u001b[32m[07/12 16:13:07 d2.engine.defaults]: \u001b[0mEvaluation results for carla_night_all_val in csv format:\n",
      "\u001b[32m[07/12 16:13:07 d2.evaluation.testing]: \u001b[0mcopypaste: Task: sem_seg\n",
      "\u001b[32m[07/12 16:13:07 d2.evaluation.testing]: \u001b[0mcopypaste: mIoU,fwIoU,mACC,pACC\n",
      "\u001b[32m[07/12 16:13:07 d2.evaluation.testing]: \u001b[0mcopypaste: 35.9655,66.5863,54.5203,78.1369\n"
     ]
    }
   ],
   "source": [
    "trainer_day = Detectron2Trainer('carla_night_all_train', 'carla_night_all_val', output_folder='./output_night_40k')\n",
    "trainer_day.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a3d438f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainer_day = Detectron2Trainer('carla_night_all_train', 'combined_clear_val', output_folder='./output_night_40k')\n",
    "#trainer_day.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "db4c4996",
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainer_day = Detectron2Trainer('carla_night_all_train', 'cityscapes_rain_val', output_folder='./output_night_40k')\n",
    "#trainer_day.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "becec7d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainer_day = Detectron2Trainer('carla_night_all_train', 'combined_rain_val', output_folder='./output_night_40k')\n",
    "#trainer_day.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "95ac6f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainer_day = Detectron2Trainer('carla_night_all_train', 'combined_all_val', output_folder='./output_night_40k')\n",
    "#trainer_day.test()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "145a97b0",
   "metadata": {},
   "source": [
    "### 3. Day and Night"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e957df99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/07 13:31:52 d2.engine.defaults]: \u001b[0mModel:\n",
      "SemanticSegmentor(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (sem_seg_head): SemSegFPNHead(\n",
      "    (p2): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "    )\n",
      "    (p3): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (1): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "    )\n",
      "    (p4): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (1): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      (2): Conv2d(\n",
      "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (3): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "    )\n",
      "    (p5): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (1): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      (2): Conv2d(\n",
      "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (3): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      (4): Conv2d(\n",
      "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (5): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "    )\n",
      "    (predictor): Conv2d(128, 17, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/07 13:31:52 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(720, 720), max_size=2048, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[07/07 13:31:52 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[07/07 13:31:52 d2.data.common]: \u001b[0mSerializing 6626 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[07/07 13:31:52 d2.data.common]: \u001b[0mSerialized dataset takes 2.45 MiB\n",
      "Last checkpoint: model_final.pth\n",
      "\u001b[32m[07/07 13:31:53 d2.checkpoint.c2_model_loading]: \u001b[0mFollowing weights matched with model:\n",
      "| Names in Model                       | Names in Checkpoint                                                                                  | Shapes                                          |\n",
      "|:-------------------------------------|:-----------------------------------------------------------------------------------------------------|:------------------------------------------------|\n",
      "| backbone.bottom_up.res2.0.conv1.*    | backbone.bottom_up.res2.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,1,1)             |\n",
      "| backbone.bottom_up.res2.0.conv2.*    | backbone.bottom_up.res2.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |\n",
      "| backbone.bottom_up.res2.0.conv3.*    | backbone.bottom_up.res2.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res2.0.shortcut.* | backbone.bottom_up.res2.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res2.1.conv1.*    | backbone.bottom_up.res2.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |\n",
      "| backbone.bottom_up.res2.1.conv2.*    | backbone.bottom_up.res2.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |\n",
      "| backbone.bottom_up.res2.1.conv3.*    | backbone.bottom_up.res2.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res2.2.conv1.*    | backbone.bottom_up.res2.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |\n",
      "| backbone.bottom_up.res2.2.conv2.*    | backbone.bottom_up.res2.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |\n",
      "| backbone.bottom_up.res2.2.conv3.*    | backbone.bottom_up.res2.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res3.0.conv1.*    | backbone.bottom_up.res3.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,256,1,1)       |\n",
      "| backbone.bottom_up.res3.0.conv2.*    | backbone.bottom_up.res3.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.0.conv3.*    | backbone.bottom_up.res3.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res3.0.shortcut.* | backbone.bottom_up.res3.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (512,) (512,) (512,) (512,) (512,256,1,1)       |\n",
      "| backbone.bottom_up.res3.1.conv1.*    | backbone.bottom_up.res3.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |\n",
      "| backbone.bottom_up.res3.1.conv2.*    | backbone.bottom_up.res3.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.1.conv3.*    | backbone.bottom_up.res3.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res3.2.conv1.*    | backbone.bottom_up.res3.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |\n",
      "| backbone.bottom_up.res3.2.conv2.*    | backbone.bottom_up.res3.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.2.conv3.*    | backbone.bottom_up.res3.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res3.3.conv1.*    | backbone.bottom_up.res3.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |\n",
      "| backbone.bottom_up.res3.3.conv2.*    | backbone.bottom_up.res3.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.3.conv3.*    | backbone.bottom_up.res3.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res4.0.conv1.*    | backbone.bottom_up.res4.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,512,1,1)       |\n",
      "| backbone.bottom_up.res4.0.conv2.*    | backbone.bottom_up.res4.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.0.conv3.*    | backbone.bottom_up.res4.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.0.shortcut.* | backbone.bottom_up.res4.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (1024,) (1024,) (1024,) (1024,) (1024,512,1,1)  |\n",
      "| backbone.bottom_up.res4.1.conv1.*    | backbone.bottom_up.res4.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.1.conv2.*    | backbone.bottom_up.res4.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.1.conv3.*    | backbone.bottom_up.res4.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.2.conv1.*    | backbone.bottom_up.res4.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.2.conv2.*    | backbone.bottom_up.res4.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.2.conv3.*    | backbone.bottom_up.res4.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.3.conv1.*    | backbone.bottom_up.res4.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.3.conv2.*    | backbone.bottom_up.res4.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.3.conv3.*    | backbone.bottom_up.res4.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.4.conv1.*    | backbone.bottom_up.res4.4.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.4.conv2.*    | backbone.bottom_up.res4.4.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.4.conv3.*    | backbone.bottom_up.res4.4.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.5.conv1.*    | backbone.bottom_up.res4.5.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.5.conv2.*    | backbone.bottom_up.res4.5.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.5.conv3.*    | backbone.bottom_up.res4.5.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res5.0.conv1.*    | backbone.bottom_up.res5.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,1024,1,1)      |\n",
      "| backbone.bottom_up.res5.0.conv2.*    | backbone.bottom_up.res5.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |\n",
      "| backbone.bottom_up.res5.0.conv3.*    | backbone.bottom_up.res5.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
      "| backbone.bottom_up.res5.0.shortcut.* | backbone.bottom_up.res5.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (2048,) (2048,) (2048,) (2048,) (2048,1024,1,1) |\n",
      "| backbone.bottom_up.res5.1.conv1.*    | backbone.bottom_up.res5.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |\n",
      "| backbone.bottom_up.res5.1.conv2.*    | backbone.bottom_up.res5.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |\n",
      "| backbone.bottom_up.res5.1.conv3.*    | backbone.bottom_up.res5.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
      "| backbone.bottom_up.res5.2.conv1.*    | backbone.bottom_up.res5.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |\n",
      "| backbone.bottom_up.res5.2.conv2.*    | backbone.bottom_up.res5.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |\n",
      "| backbone.bottom_up.res5.2.conv3.*    | backbone.bottom_up.res5.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
      "| backbone.bottom_up.stem.conv1.*      | backbone.bottom_up.stem.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}      | (64,) (64,) (64,) (64,) (64,3,7,7)              |\n",
      "| backbone.fpn_lateral2.*              | backbone.fpn_lateral2.{bias,weight}                                                                  | (256,) (256,256,1,1)                            |\n",
      "| backbone.fpn_lateral3.*              | backbone.fpn_lateral3.{bias,weight}                                                                  | (256,) (256,512,1,1)                            |\n",
      "| backbone.fpn_lateral4.*              | backbone.fpn_lateral4.{bias,weight}                                                                  | (256,) (256,1024,1,1)                           |\n",
      "| backbone.fpn_lateral5.*              | backbone.fpn_lateral5.{bias,weight}                                                                  | (256,) (256,2048,1,1)                           |\n",
      "| backbone.fpn_output2.*               | backbone.fpn_output2.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| backbone.fpn_output3.*               | backbone.fpn_output3.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| backbone.fpn_output4.*               | backbone.fpn_output4.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| backbone.fpn_output5.*               | backbone.fpn_output5.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| sem_seg_head.p2.0.*                  | sem_seg_head.p2.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p3.0.*                  | sem_seg_head.p3.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p4.0.*                  | sem_seg_head.p4.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p4.2.*                  | sem_seg_head.p4.2.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,128,3,3)                     |\n",
      "| sem_seg_head.p5.0.*                  | sem_seg_head.p5.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p5.2.*                  | sem_seg_head.p5.2.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,128,3,3)                     |\n",
      "| sem_seg_head.p5.4.*                  | sem_seg_head.p5.4.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,128,3,3)                     |\n",
      "| sem_seg_head.predictor.*             | sem_seg_head.predictor.{bias,weight}                                                                 | (17,) (17,128,1,1)                              |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/07 13:31:53 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(720, 720), max_size=2048, sample_style='choice')]\n",
      "\u001b[32m[07/07 13:31:53 d2.data.common]: \u001b[0mSerializing 6531 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[07/07 13:31:53 d2.data.common]: \u001b[0mSerialized dataset takes 2.42 MiB\n",
      "\u001b[32m[07/07 13:31:53 d2.evaluation.evaluator]: \u001b[0mStart inference on 6531 batches\n",
      "\u001b[32m[07/07 13:31:54 d2.evaluation.evaluator]: \u001b[0mInference done 11/6531. Dataloading: 0.0016 s/iter. Inference: 0.0372 s/iter. Eval: 0.0428 s/iter. Total: 0.0816 s/iter. ETA=0:08:51\n",
      "\u001b[32m[07/07 13:31:59 d2.evaluation.evaluator]: \u001b[0mInference done 76/6531. Dataloading: 0.0019 s/iter. Inference: 0.0357 s/iter. Eval: 0.0406 s/iter. Total: 0.0783 s/iter. ETA=0:08:25\n",
      "\u001b[32m[07/07 13:32:04 d2.evaluation.evaluator]: \u001b[0mInference done 144/6531. Dataloading: 0.0020 s/iter. Inference: 0.0358 s/iter. Eval: 0.0386 s/iter. Total: 0.0765 s/iter. ETA=0:08:08\n",
      "\u001b[32m[07/07 13:32:09 d2.evaluation.evaluator]: \u001b[0mInference done 211/6531. Dataloading: 0.0020 s/iter. Inference: 0.0358 s/iter. Eval: 0.0381 s/iter. Total: 0.0760 s/iter. ETA=0:08:00\n",
      "\u001b[32m[07/07 13:32:14 d2.evaluation.evaluator]: \u001b[0mInference done 278/6531. Dataloading: 0.0020 s/iter. Inference: 0.0357 s/iter. Eval: 0.0378 s/iter. Total: 0.0757 s/iter. ETA=0:07:53\n",
      "\u001b[32m[07/07 13:32:19 d2.evaluation.evaluator]: \u001b[0mInference done 346/6531. Dataloading: 0.0021 s/iter. Inference: 0.0356 s/iter. Eval: 0.0376 s/iter. Total: 0.0754 s/iter. ETA=0:07:46\n",
      "\u001b[32m[07/07 13:32:24 d2.evaluation.evaluator]: \u001b[0mInference done 414/6531. Dataloading: 0.0024 s/iter. Inference: 0.0356 s/iter. Eval: 0.0373 s/iter. Total: 0.0753 s/iter. ETA=0:07:40\n",
      "\u001b[32m[07/07 13:32:29 d2.evaluation.evaluator]: \u001b[0mInference done 483/6531. Dataloading: 0.0024 s/iter. Inference: 0.0355 s/iter. Eval: 0.0370 s/iter. Total: 0.0750 s/iter. ETA=0:07:33\n",
      "\u001b[32m[07/07 13:32:34 d2.evaluation.evaluator]: \u001b[0mInference done 552/6531. Dataloading: 0.0024 s/iter. Inference: 0.0355 s/iter. Eval: 0.0367 s/iter. Total: 0.0747 s/iter. ETA=0:07:26\n",
      "\u001b[32m[07/07 13:32:39 d2.evaluation.evaluator]: \u001b[0mInference done 620/6531. Dataloading: 0.0024 s/iter. Inference: 0.0355 s/iter. Eval: 0.0367 s/iter. Total: 0.0746 s/iter. ETA=0:07:21\n",
      "\u001b[32m[07/07 13:32:44 d2.evaluation.evaluator]: \u001b[0mInference done 688/6531. Dataloading: 0.0024 s/iter. Inference: 0.0355 s/iter. Eval: 0.0366 s/iter. Total: 0.0746 s/iter. ETA=0:07:15\n",
      "\u001b[32m[07/07 13:32:49 d2.evaluation.evaluator]: \u001b[0mInference done 755/6531. Dataloading: 0.0024 s/iter. Inference: 0.0355 s/iter. Eval: 0.0367 s/iter. Total: 0.0747 s/iter. ETA=0:07:11\n",
      "\u001b[32m[07/07 13:32:54 d2.evaluation.evaluator]: \u001b[0mInference done 822/6531. Dataloading: 0.0024 s/iter. Inference: 0.0355 s/iter. Eval: 0.0368 s/iter. Total: 0.0747 s/iter. ETA=0:07:06\n",
      "\u001b[32m[07/07 13:32:59 d2.evaluation.evaluator]: \u001b[0mInference done 888/6531. Dataloading: 0.0024 s/iter. Inference: 0.0355 s/iter. Eval: 0.0369 s/iter. Total: 0.0748 s/iter. ETA=0:07:02\n",
      "\u001b[32m[07/07 13:33:04 d2.evaluation.evaluator]: \u001b[0mInference done 954/6531. Dataloading: 0.0024 s/iter. Inference: 0.0355 s/iter. Eval: 0.0369 s/iter. Total: 0.0749 s/iter. ETA=0:06:57\n",
      "\u001b[32m[07/07 13:33:10 d2.evaluation.evaluator]: \u001b[0mInference done 1019/6531. Dataloading: 0.0024 s/iter. Inference: 0.0355 s/iter. Eval: 0.0372 s/iter. Total: 0.0751 s/iter. ETA=0:06:53\n",
      "\u001b[32m[07/07 13:33:15 d2.evaluation.evaluator]: \u001b[0mInference done 1084/6531. Dataloading: 0.0024 s/iter. Inference: 0.0355 s/iter. Eval: 0.0373 s/iter. Total: 0.0752 s/iter. ETA=0:06:49\n",
      "\u001b[32m[07/07 13:33:20 d2.evaluation.evaluator]: \u001b[0mInference done 1150/6531. Dataloading: 0.0024 s/iter. Inference: 0.0355 s/iter. Eval: 0.0374 s/iter. Total: 0.0753 s/iter. ETA=0:06:45\n",
      "\u001b[32m[07/07 13:33:25 d2.evaluation.evaluator]: \u001b[0mInference done 1217/6531. Dataloading: 0.0024 s/iter. Inference: 0.0355 s/iter. Eval: 0.0374 s/iter. Total: 0.0753 s/iter. ETA=0:06:40\n",
      "\u001b[32m[07/07 13:33:30 d2.evaluation.evaluator]: \u001b[0mInference done 1283/6531. Dataloading: 0.0024 s/iter. Inference: 0.0355 s/iter. Eval: 0.0374 s/iter. Total: 0.0753 s/iter. ETA=0:06:35\n",
      "\u001b[32m[07/07 13:33:35 d2.evaluation.evaluator]: \u001b[0mInference done 1349/6531. Dataloading: 0.0024 s/iter. Inference: 0.0355 s/iter. Eval: 0.0374 s/iter. Total: 0.0753 s/iter. ETA=0:06:30\n",
      "\u001b[32m[07/07 13:33:40 d2.evaluation.evaluator]: \u001b[0mInference done 1416/6531. Dataloading: 0.0024 s/iter. Inference: 0.0355 s/iter. Eval: 0.0374 s/iter. Total: 0.0753 s/iter. ETA=0:06:25\n",
      "\u001b[32m[07/07 13:33:45 d2.evaluation.evaluator]: \u001b[0mInference done 1481/6531. Dataloading: 0.0024 s/iter. Inference: 0.0355 s/iter. Eval: 0.0375 s/iter. Total: 0.0754 s/iter. ETA=0:06:20\n",
      "\u001b[32m[07/07 13:33:50 d2.evaluation.evaluator]: \u001b[0mInference done 1546/6531. Dataloading: 0.0024 s/iter. Inference: 0.0355 s/iter. Eval: 0.0376 s/iter. Total: 0.0755 s/iter. ETA=0:06:16\n",
      "\u001b[32m[07/07 13:33:55 d2.evaluation.evaluator]: \u001b[0mInference done 1611/6531. Dataloading: 0.0024 s/iter. Inference: 0.0355 s/iter. Eval: 0.0377 s/iter. Total: 0.0756 s/iter. ETA=0:06:11\n",
      "\u001b[32m[07/07 13:34:00 d2.evaluation.evaluator]: \u001b[0mInference done 1675/6531. Dataloading: 0.0024 s/iter. Inference: 0.0355 s/iter. Eval: 0.0378 s/iter. Total: 0.0757 s/iter. ETA=0:06:07\n",
      "\u001b[32m[07/07 13:34:05 d2.evaluation.evaluator]: \u001b[0mInference done 1740/6531. Dataloading: 0.0024 s/iter. Inference: 0.0355 s/iter. Eval: 0.0379 s/iter. Total: 0.0758 s/iter. ETA=0:06:03\n",
      "\u001b[32m[07/07 13:34:10 d2.evaluation.evaluator]: \u001b[0mInference done 1806/6531. Dataloading: 0.0024 s/iter. Inference: 0.0355 s/iter. Eval: 0.0379 s/iter. Total: 0.0758 s/iter. ETA=0:05:58\n",
      "\u001b[32m[07/07 13:34:15 d2.evaluation.evaluator]: \u001b[0mInference done 1871/6531. Dataloading: 0.0024 s/iter. Inference: 0.0355 s/iter. Eval: 0.0380 s/iter. Total: 0.0759 s/iter. ETA=0:05:53\n",
      "\u001b[32m[07/07 13:34:20 d2.evaluation.evaluator]: \u001b[0mInference done 1938/6531. Dataloading: 0.0024 s/iter. Inference: 0.0355 s/iter. Eval: 0.0380 s/iter. Total: 0.0759 s/iter. ETA=0:05:48\n",
      "\u001b[32m[07/07 13:34:25 d2.evaluation.evaluator]: \u001b[0mInference done 2004/6531. Dataloading: 0.0024 s/iter. Inference: 0.0355 s/iter. Eval: 0.0380 s/iter. Total: 0.0759 s/iter. ETA=0:05:43\n",
      "\u001b[32m[07/07 13:34:30 d2.evaluation.evaluator]: \u001b[0mInference done 2071/6531. Dataloading: 0.0024 s/iter. Inference: 0.0355 s/iter. Eval: 0.0380 s/iter. Total: 0.0759 s/iter. ETA=0:05:38\n",
      "\u001b[32m[07/07 13:34:35 d2.evaluation.evaluator]: \u001b[0mInference done 2139/6531. Dataloading: 0.0024 s/iter. Inference: 0.0355 s/iter. Eval: 0.0379 s/iter. Total: 0.0758 s/iter. ETA=0:05:33\n",
      "\u001b[32m[07/07 13:34:40 d2.evaluation.evaluator]: \u001b[0mInference done 2207/6531. Dataloading: 0.0024 s/iter. Inference: 0.0355 s/iter. Eval: 0.0379 s/iter. Total: 0.0758 s/iter. ETA=0:05:27\n",
      "\u001b[32m[07/07 13:34:45 d2.evaluation.evaluator]: \u001b[0mInference done 2274/6531. Dataloading: 0.0024 s/iter. Inference: 0.0355 s/iter. Eval: 0.0378 s/iter. Total: 0.0758 s/iter. ETA=0:05:22\n",
      "\u001b[32m[07/07 13:34:50 d2.evaluation.evaluator]: \u001b[0mInference done 2341/6531. Dataloading: 0.0024 s/iter. Inference: 0.0355 s/iter. Eval: 0.0378 s/iter. Total: 0.0757 s/iter. ETA=0:05:17\n",
      "\u001b[32m[07/07 13:34:55 d2.evaluation.evaluator]: \u001b[0mInference done 2408/6531. Dataloading: 0.0024 s/iter. Inference: 0.0355 s/iter. Eval: 0.0378 s/iter. Total: 0.0757 s/iter. ETA=0:05:12\n",
      "\u001b[32m[07/07 13:35:00 d2.evaluation.evaluator]: \u001b[0mInference done 2475/6531. Dataloading: 0.0024 s/iter. Inference: 0.0355 s/iter. Eval: 0.0377 s/iter. Total: 0.0757 s/iter. ETA=0:05:06\n",
      "\u001b[32m[07/07 13:35:05 d2.evaluation.evaluator]: \u001b[0mInference done 2543/6531. Dataloading: 0.0024 s/iter. Inference: 0.0355 s/iter. Eval: 0.0377 s/iter. Total: 0.0756 s/iter. ETA=0:05:01\n",
      "\u001b[32m[07/07 13:35:10 d2.evaluation.evaluator]: \u001b[0mInference done 2611/6531. Dataloading: 0.0024 s/iter. Inference: 0.0355 s/iter. Eval: 0.0377 s/iter. Total: 0.0756 s/iter. ETA=0:04:56\n",
      "\u001b[32m[07/07 13:35:16 d2.evaluation.evaluator]: \u001b[0mInference done 2679/6531. Dataloading: 0.0024 s/iter. Inference: 0.0355 s/iter. Eval: 0.0376 s/iter. Total: 0.0756 s/iter. ETA=0:04:51\n",
      "\u001b[32m[07/07 13:35:21 d2.evaluation.evaluator]: \u001b[0mInference done 2746/6531. Dataloading: 0.0024 s/iter. Inference: 0.0355 s/iter. Eval: 0.0376 s/iter. Total: 0.0756 s/iter. ETA=0:04:45\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/07 13:35:26 d2.evaluation.evaluator]: \u001b[0mInference done 2813/6531. Dataloading: 0.0024 s/iter. Inference: 0.0355 s/iter. Eval: 0.0376 s/iter. Total: 0.0755 s/iter. ETA=0:04:40\n",
      "\u001b[32m[07/07 13:35:31 d2.evaluation.evaluator]: \u001b[0mInference done 2881/6531. Dataloading: 0.0024 s/iter. Inference: 0.0355 s/iter. Eval: 0.0376 s/iter. Total: 0.0755 s/iter. ETA=0:04:35\n",
      "\u001b[32m[07/07 13:35:36 d2.evaluation.evaluator]: \u001b[0mInference done 2949/6531. Dataloading: 0.0024 s/iter. Inference: 0.0355 s/iter. Eval: 0.0376 s/iter. Total: 0.0755 s/iter. ETA=0:04:30\n",
      "\u001b[32m[07/07 13:35:41 d2.evaluation.evaluator]: \u001b[0mInference done 3017/6531. Dataloading: 0.0024 s/iter. Inference: 0.0355 s/iter. Eval: 0.0375 s/iter. Total: 0.0755 s/iter. ETA=0:04:25\n",
      "\u001b[32m[07/07 13:35:46 d2.evaluation.evaluator]: \u001b[0mInference done 3084/6531. Dataloading: 0.0024 s/iter. Inference: 0.0355 s/iter. Eval: 0.0375 s/iter. Total: 0.0754 s/iter. ETA=0:04:20\n",
      "\u001b[32m[07/07 13:35:51 d2.evaluation.evaluator]: \u001b[0mInference done 3150/6531. Dataloading: 0.0024 s/iter. Inference: 0.0355 s/iter. Eval: 0.0375 s/iter. Total: 0.0755 s/iter. ETA=0:04:15\n",
      "\u001b[32m[07/07 13:35:56 d2.evaluation.evaluator]: \u001b[0mInference done 3217/6531. Dataloading: 0.0024 s/iter. Inference: 0.0355 s/iter. Eval: 0.0375 s/iter. Total: 0.0755 s/iter. ETA=0:04:10\n",
      "\u001b[32m[07/07 13:36:01 d2.evaluation.evaluator]: \u001b[0mInference done 3283/6531. Dataloading: 0.0024 s/iter. Inference: 0.0355 s/iter. Eval: 0.0375 s/iter. Total: 0.0755 s/iter. ETA=0:04:05\n",
      "\u001b[32m[07/07 13:36:06 d2.evaluation.evaluator]: \u001b[0mInference done 3347/6531. Dataloading: 0.0024 s/iter. Inference: 0.0355 s/iter. Eval: 0.0375 s/iter. Total: 0.0755 s/iter. ETA=0:04:00\n",
      "\u001b[32m[07/07 13:36:11 d2.evaluation.evaluator]: \u001b[0mInference done 3412/6531. Dataloading: 0.0024 s/iter. Inference: 0.0355 s/iter. Eval: 0.0376 s/iter. Total: 0.0756 s/iter. ETA=0:03:55\n",
      "\u001b[32m[07/07 13:36:16 d2.evaluation.evaluator]: \u001b[0mInference done 3477/6531. Dataloading: 0.0024 s/iter. Inference: 0.0355 s/iter. Eval: 0.0376 s/iter. Total: 0.0756 s/iter. ETA=0:03:50\n",
      "\u001b[32m[07/07 13:36:21 d2.evaluation.evaluator]: \u001b[0mInference done 3542/6531. Dataloading: 0.0024 s/iter. Inference: 0.0355 s/iter. Eval: 0.0377 s/iter. Total: 0.0757 s/iter. ETA=0:03:46\n",
      "\u001b[32m[07/07 13:36:26 d2.evaluation.evaluator]: \u001b[0mInference done 3606/6531. Dataloading: 0.0024 s/iter. Inference: 0.0355 s/iter. Eval: 0.0377 s/iter. Total: 0.0757 s/iter. ETA=0:03:41\n",
      "\u001b[32m[07/07 13:36:31 d2.evaluation.evaluator]: \u001b[0mInference done 3670/6531. Dataloading: 0.0024 s/iter. Inference: 0.0355 s/iter. Eval: 0.0378 s/iter. Total: 0.0758 s/iter. ETA=0:03:36\n",
      "\u001b[32m[07/07 13:36:36 d2.evaluation.evaluator]: \u001b[0mInference done 3734/6531. Dataloading: 0.0024 s/iter. Inference: 0.0355 s/iter. Eval: 0.0378 s/iter. Total: 0.0758 s/iter. ETA=0:03:32\n",
      "\u001b[32m[07/07 13:36:41 d2.evaluation.evaluator]: \u001b[0mInference done 3797/6531. Dataloading: 0.0024 s/iter. Inference: 0.0355 s/iter. Eval: 0.0379 s/iter. Total: 0.0759 s/iter. ETA=0:03:27\n",
      "\u001b[32m[07/07 13:36:46 d2.evaluation.evaluator]: \u001b[0mInference done 3861/6531. Dataloading: 0.0024 s/iter. Inference: 0.0355 s/iter. Eval: 0.0380 s/iter. Total: 0.0759 s/iter. ETA=0:03:22\n",
      "\u001b[32m[07/07 13:36:51 d2.evaluation.evaluator]: \u001b[0mInference done 3925/6531. Dataloading: 0.0024 s/iter. Inference: 0.0355 s/iter. Eval: 0.0380 s/iter. Total: 0.0760 s/iter. ETA=0:03:18\n",
      "\u001b[32m[07/07 13:36:56 d2.evaluation.evaluator]: \u001b[0mInference done 3989/6531. Dataloading: 0.0024 s/iter. Inference: 0.0355 s/iter. Eval: 0.0380 s/iter. Total: 0.0760 s/iter. ETA=0:03:13\n",
      "\u001b[32m[07/07 13:37:01 d2.evaluation.evaluator]: \u001b[0mInference done 4055/6531. Dataloading: 0.0024 s/iter. Inference: 0.0355 s/iter. Eval: 0.0381 s/iter. Total: 0.0760 s/iter. ETA=0:03:08\n",
      "\u001b[32m[07/07 13:37:06 d2.evaluation.evaluator]: \u001b[0mInference done 4123/6531. Dataloading: 0.0024 s/iter. Inference: 0.0355 s/iter. Eval: 0.0380 s/iter. Total: 0.0760 s/iter. ETA=0:03:03\n",
      "\u001b[32m[07/07 13:37:12 d2.evaluation.evaluator]: \u001b[0mInference done 4191/6531. Dataloading: 0.0024 s/iter. Inference: 0.0355 s/iter. Eval: 0.0380 s/iter. Total: 0.0760 s/iter. ETA=0:02:57\n",
      "\u001b[32m[07/07 13:37:17 d2.evaluation.evaluator]: \u001b[0mInference done 4257/6531. Dataloading: 0.0024 s/iter. Inference: 0.0355 s/iter. Eval: 0.0380 s/iter. Total: 0.0760 s/iter. ETA=0:02:52\n",
      "\u001b[32m[07/07 13:37:22 d2.evaluation.evaluator]: \u001b[0mInference done 4323/6531. Dataloading: 0.0024 s/iter. Inference: 0.0355 s/iter. Eval: 0.0380 s/iter. Total: 0.0760 s/iter. ETA=0:02:47\n",
      "\u001b[32m[07/07 13:37:27 d2.evaluation.evaluator]: \u001b[0mInference done 4389/6531. Dataloading: 0.0024 s/iter. Inference: 0.0355 s/iter. Eval: 0.0380 s/iter. Total: 0.0760 s/iter. ETA=0:02:42\n",
      "\u001b[32m[07/07 13:37:32 d2.evaluation.evaluator]: \u001b[0mInference done 4455/6531. Dataloading: 0.0024 s/iter. Inference: 0.0355 s/iter. Eval: 0.0380 s/iter. Total: 0.0760 s/iter. ETA=0:02:37\n",
      "\u001b[32m[07/07 13:37:37 d2.evaluation.evaluator]: \u001b[0mInference done 4521/6531. Dataloading: 0.0024 s/iter. Inference: 0.0355 s/iter. Eval: 0.0380 s/iter. Total: 0.0760 s/iter. ETA=0:02:32\n",
      "\u001b[32m[07/07 13:37:42 d2.evaluation.evaluator]: \u001b[0mInference done 4586/6531. Dataloading: 0.0024 s/iter. Inference: 0.0355 s/iter. Eval: 0.0380 s/iter. Total: 0.0760 s/iter. ETA=0:02:27\n",
      "\u001b[32m[07/07 13:37:47 d2.evaluation.evaluator]: \u001b[0mInference done 4652/6531. Dataloading: 0.0024 s/iter. Inference: 0.0355 s/iter. Eval: 0.0381 s/iter. Total: 0.0760 s/iter. ETA=0:02:22\n",
      "\u001b[32m[07/07 13:37:52 d2.evaluation.evaluator]: \u001b[0mInference done 4718/6531. Dataloading: 0.0024 s/iter. Inference: 0.0355 s/iter. Eval: 0.0381 s/iter. Total: 0.0760 s/iter. ETA=0:02:17\n",
      "\u001b[32m[07/07 13:37:57 d2.evaluation.evaluator]: \u001b[0mInference done 4784/6531. Dataloading: 0.0024 s/iter. Inference: 0.0355 s/iter. Eval: 0.0381 s/iter. Total: 0.0760 s/iter. ETA=0:02:12\n",
      "\u001b[32m[07/07 13:38:02 d2.evaluation.evaluator]: \u001b[0mInference done 4850/6531. Dataloading: 0.0024 s/iter. Inference: 0.0355 s/iter. Eval: 0.0381 s/iter. Total: 0.0760 s/iter. ETA=0:02:07\n",
      "\u001b[32m[07/07 13:38:07 d2.evaluation.evaluator]: \u001b[0mInference done 4917/6531. Dataloading: 0.0024 s/iter. Inference: 0.0355 s/iter. Eval: 0.0381 s/iter. Total: 0.0760 s/iter. ETA=0:02:02\n",
      "\u001b[32m[07/07 13:38:12 d2.evaluation.evaluator]: \u001b[0mInference done 4984/6531. Dataloading: 0.0024 s/iter. Inference: 0.0355 s/iter. Eval: 0.0380 s/iter. Total: 0.0760 s/iter. ETA=0:01:57\n",
      "\u001b[32m[07/07 13:38:17 d2.evaluation.evaluator]: \u001b[0mInference done 5051/6531. Dataloading: 0.0024 s/iter. Inference: 0.0355 s/iter. Eval: 0.0380 s/iter. Total: 0.0760 s/iter. ETA=0:01:52\n",
      "\u001b[32m[07/07 13:38:22 d2.evaluation.evaluator]: \u001b[0mInference done 5118/6531. Dataloading: 0.0024 s/iter. Inference: 0.0355 s/iter. Eval: 0.0380 s/iter. Total: 0.0760 s/iter. ETA=0:01:47\n",
      "\u001b[32m[07/07 13:38:27 d2.evaluation.evaluator]: \u001b[0mInference done 5184/6531. Dataloading: 0.0024 s/iter. Inference: 0.0355 s/iter. Eval: 0.0380 s/iter. Total: 0.0760 s/iter. ETA=0:01:42\n",
      "\u001b[32m[07/07 13:38:32 d2.evaluation.evaluator]: \u001b[0mInference done 5250/6531. Dataloading: 0.0024 s/iter. Inference: 0.0355 s/iter. Eval: 0.0380 s/iter. Total: 0.0760 s/iter. ETA=0:01:37\n",
      "\u001b[32m[07/07 13:38:37 d2.evaluation.evaluator]: \u001b[0mInference done 5316/6531. Dataloading: 0.0024 s/iter. Inference: 0.0355 s/iter. Eval: 0.0380 s/iter. Total: 0.0760 s/iter. ETA=0:01:32\n",
      "\u001b[32m[07/07 13:38:42 d2.evaluation.evaluator]: \u001b[0mInference done 5382/6531. Dataloading: 0.0024 s/iter. Inference: 0.0355 s/iter. Eval: 0.0380 s/iter. Total: 0.0760 s/iter. ETA=0:01:27\n",
      "\u001b[32m[07/07 13:38:47 d2.evaluation.evaluator]: \u001b[0mInference done 5448/6531. Dataloading: 0.0024 s/iter. Inference: 0.0355 s/iter. Eval: 0.0380 s/iter. Total: 0.0760 s/iter. ETA=0:01:22\n",
      "\u001b[32m[07/07 13:38:52 d2.evaluation.evaluator]: \u001b[0mInference done 5514/6531. Dataloading: 0.0024 s/iter. Inference: 0.0355 s/iter. Eval: 0.0381 s/iter. Total: 0.0760 s/iter. ETA=0:01:17\n",
      "\u001b[32m[07/07 13:38:57 d2.evaluation.evaluator]: \u001b[0mInference done 5580/6531. Dataloading: 0.0024 s/iter. Inference: 0.0355 s/iter. Eval: 0.0381 s/iter. Total: 0.0760 s/iter. ETA=0:01:12\n",
      "\u001b[32m[07/07 13:39:02 d2.evaluation.evaluator]: \u001b[0mInference done 5646/6531. Dataloading: 0.0024 s/iter. Inference: 0.0355 s/iter. Eval: 0.0381 s/iter. Total: 0.0760 s/iter. ETA=0:01:07\n",
      "\u001b[32m[07/07 13:39:07 d2.evaluation.evaluator]: \u001b[0mInference done 5712/6531. Dataloading: 0.0024 s/iter. Inference: 0.0355 s/iter. Eval: 0.0381 s/iter. Total: 0.0760 s/iter. ETA=0:01:02\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/07 13:39:12 d2.evaluation.evaluator]: \u001b[0mInference done 5777/6531. Dataloading: 0.0024 s/iter. Inference: 0.0355 s/iter. Eval: 0.0381 s/iter. Total: 0.0761 s/iter. ETA=0:00:57\n",
      "\u001b[32m[07/07 13:39:17 d2.evaluation.evaluator]: \u001b[0mInference done 5843/6531. Dataloading: 0.0024 s/iter. Inference: 0.0355 s/iter. Eval: 0.0381 s/iter. Total: 0.0761 s/iter. ETA=0:00:52\n",
      "\u001b[32m[07/07 13:39:22 d2.evaluation.evaluator]: \u001b[0mInference done 5909/6531. Dataloading: 0.0024 s/iter. Inference: 0.0355 s/iter. Eval: 0.0381 s/iter. Total: 0.0761 s/iter. ETA=0:00:47\n",
      "\u001b[32m[07/07 13:39:27 d2.evaluation.evaluator]: \u001b[0mInference done 5974/6531. Dataloading: 0.0024 s/iter. Inference: 0.0355 s/iter. Eval: 0.0381 s/iter. Total: 0.0761 s/iter. ETA=0:00:42\n",
      "\u001b[32m[07/07 13:39:32 d2.evaluation.evaluator]: \u001b[0mInference done 6037/6531. Dataloading: 0.0024 s/iter. Inference: 0.0355 s/iter. Eval: 0.0381 s/iter. Total: 0.0761 s/iter. ETA=0:00:37\n",
      "\u001b[32m[07/07 13:39:37 d2.evaluation.evaluator]: \u001b[0mInference done 6101/6531. Dataloading: 0.0024 s/iter. Inference: 0.0355 s/iter. Eval: 0.0381 s/iter. Total: 0.0761 s/iter. ETA=0:00:32\n",
      "\u001b[32m[07/07 13:39:43 d2.evaluation.evaluator]: \u001b[0mInference done 6166/6531. Dataloading: 0.0024 s/iter. Inference: 0.0355 s/iter. Eval: 0.0382 s/iter. Total: 0.0761 s/iter. ETA=0:00:27\n",
      "\u001b[32m[07/07 13:39:48 d2.evaluation.evaluator]: \u001b[0mInference done 6229/6531. Dataloading: 0.0024 s/iter. Inference: 0.0355 s/iter. Eval: 0.0382 s/iter. Total: 0.0762 s/iter. ETA=0:00:23\n",
      "\u001b[32m[07/07 13:39:53 d2.evaluation.evaluator]: \u001b[0mInference done 6296/6531. Dataloading: 0.0024 s/iter. Inference: 0.0355 s/iter. Eval: 0.0382 s/iter. Total: 0.0762 s/iter. ETA=0:00:17\n",
      "\u001b[32m[07/07 13:39:58 d2.evaluation.evaluator]: \u001b[0mInference done 6363/6531. Dataloading: 0.0024 s/iter. Inference: 0.0355 s/iter. Eval: 0.0382 s/iter. Total: 0.0762 s/iter. ETA=0:00:12\n",
      "\u001b[32m[07/07 13:40:03 d2.evaluation.evaluator]: \u001b[0mInference done 6428/6531. Dataloading: 0.0024 s/iter. Inference: 0.0355 s/iter. Eval: 0.0382 s/iter. Total: 0.0762 s/iter. ETA=0:00:07\n",
      "\u001b[32m[07/07 13:40:08 d2.evaluation.evaluator]: \u001b[0mInference done 6496/6531. Dataloading: 0.0024 s/iter. Inference: 0.0355 s/iter. Eval: 0.0382 s/iter. Total: 0.0762 s/iter. ETA=0:00:02\n",
      "\u001b[32m[07/07 13:40:11 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:08:17.085851 (0.076170 s / iter per device, on 1 devices)\n",
      "\u001b[32m[07/07 13:40:11 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:03:51 (0.035527 s / iter per device, on 1 devices)\n",
      "\u001b[32m[07/07 13:40:12 d2.evaluation.sem_seg_evaluation]: \u001b[0mOrderedDict([('sem_seg', {'mIoU': 46.7223458244844, 'fwIoU': 65.15447278584459, 'IoU-Unlabeled': nan, 'IoU-Building': 54.2009867811284, 'IoU-Fence': 23.242770692226657, 'IoU-Pedestrian': 35.97826493422813, 'IoU-Pole': 47.841409455357876, 'IoU-Road': 92.5754003556314, 'IoU-SideWalk': 65.38096979112545, 'IoU-Vegetation': 48.04640633238083, 'IoU-Vehicles': 63.71319201619882, 'IoU-Wall': 40.779828553672196, 'IoU-TrafficSign': 43.46484961691745, 'IoU-Sky': 44.37764889802901, 'IoU-TrafficLight': 55.77622836976045, 'IoU-Terrain': 22.356008594217684, 'IoU-ConstructionVehicle': 85.88499992472526, 'IoU-workzone_object': 61.0223604837678, 'IoU-Detour': 9.63855421686747, 'mACC': 63.51206110432675, 'pACC': 77.5009260346142, 'ACC-Unlabeled': nan, 'ACC-Building': 96.84424586196081, 'ACC-Fence': 30.46783297757197, 'ACC-Pedestrian': 65.37948266263822, 'ACC-Pole': 57.730064937792534, 'ACC-Road': 95.32173911294034, 'ACC-SideWalk': 81.24002686331663, 'ACC-Vegetation': 73.08778439729599, 'ACC-Vehicles': 88.63779814288125, 'ACC-Wall': 55.51328475913634, 'ACC-TrafficSign': 54.03113577871772, 'ACC-Sky': 44.63316744078974, 'ACC-TrafficLight': 63.685799726281786, 'ACC-Terrain': 23.491081699912396, 'ACC-ConstructionVehicle': 91.36249924066291, 'ACC-workzone_object': 81.30931574401222, 'ACC-Detour': 13.457718323317156})])\n",
      "\u001b[32m[07/07 13:40:12 d2.engine.defaults]: \u001b[0mEvaluation results for carla_both_clear_val in csv format:\n",
      "\u001b[32m[07/07 13:40:12 d2.evaluation.testing]: \u001b[0mcopypaste: Task: sem_seg\n",
      "\u001b[32m[07/07 13:40:12 d2.evaluation.testing]: \u001b[0mcopypaste: mIoU,fwIoU,mACC,pACC\n",
      "\u001b[32m[07/07 13:40:12 d2.evaluation.testing]: \u001b[0mcopypaste: 46.7223,65.1545,63.5121,77.5009\n"
     ]
    }
   ],
   "source": [
    "#all carla clear\n",
    "trainer_both = Detectron2Trainer('combined_clear_both_train', 'carla_both_clear_val', output_folder='./output_both_clear_40k')\n",
    "trainer_both.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7c43d334",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/07 13:40:12 d2.engine.defaults]: \u001b[0mModel:\n",
      "SemanticSegmentor(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (sem_seg_head): SemSegFPNHead(\n",
      "    (p2): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "    )\n",
      "    (p3): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (1): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "    )\n",
      "    (p4): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (1): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      (2): Conv2d(\n",
      "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (3): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "    )\n",
      "    (p5): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (1): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      (2): Conv2d(\n",
      "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (3): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      (4): Conv2d(\n",
      "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (5): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "    )\n",
      "    (predictor): Conv2d(128, 17, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/07 13:40:12 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(720, 720), max_size=2048, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[07/07 13:40:12 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[07/07 13:40:12 d2.data.common]: \u001b[0mSerializing 6626 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[07/07 13:40:12 d2.data.common]: \u001b[0mSerialized dataset takes 2.45 MiB\n",
      "Last checkpoint: model_final.pth\n",
      "\u001b[32m[07/07 13:40:13 d2.checkpoint.c2_model_loading]: \u001b[0mFollowing weights matched with model:\n",
      "| Names in Model                       | Names in Checkpoint                                                                                  | Shapes                                          |\n",
      "|:-------------------------------------|:-----------------------------------------------------------------------------------------------------|:------------------------------------------------|\n",
      "| backbone.bottom_up.res2.0.conv1.*    | backbone.bottom_up.res2.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,1,1)             |\n",
      "| backbone.bottom_up.res2.0.conv2.*    | backbone.bottom_up.res2.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |\n",
      "| backbone.bottom_up.res2.0.conv3.*    | backbone.bottom_up.res2.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res2.0.shortcut.* | backbone.bottom_up.res2.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res2.1.conv1.*    | backbone.bottom_up.res2.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |\n",
      "| backbone.bottom_up.res2.1.conv2.*    | backbone.bottom_up.res2.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |\n",
      "| backbone.bottom_up.res2.1.conv3.*    | backbone.bottom_up.res2.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res2.2.conv1.*    | backbone.bottom_up.res2.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |\n",
      "| backbone.bottom_up.res2.2.conv2.*    | backbone.bottom_up.res2.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |\n",
      "| backbone.bottom_up.res2.2.conv3.*    | backbone.bottom_up.res2.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res3.0.conv1.*    | backbone.bottom_up.res3.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,256,1,1)       |\n",
      "| backbone.bottom_up.res3.0.conv2.*    | backbone.bottom_up.res3.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.0.conv3.*    | backbone.bottom_up.res3.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res3.0.shortcut.* | backbone.bottom_up.res3.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (512,) (512,) (512,) (512,) (512,256,1,1)       |\n",
      "| backbone.bottom_up.res3.1.conv1.*    | backbone.bottom_up.res3.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |\n",
      "| backbone.bottom_up.res3.1.conv2.*    | backbone.bottom_up.res3.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.1.conv3.*    | backbone.bottom_up.res3.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res3.2.conv1.*    | backbone.bottom_up.res3.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |\n",
      "| backbone.bottom_up.res3.2.conv2.*    | backbone.bottom_up.res3.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.2.conv3.*    | backbone.bottom_up.res3.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res3.3.conv1.*    | backbone.bottom_up.res3.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |\n",
      "| backbone.bottom_up.res3.3.conv2.*    | backbone.bottom_up.res3.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.3.conv3.*    | backbone.bottom_up.res3.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res4.0.conv1.*    | backbone.bottom_up.res4.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,512,1,1)       |\n",
      "| backbone.bottom_up.res4.0.conv2.*    | backbone.bottom_up.res4.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.0.conv3.*    | backbone.bottom_up.res4.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.0.shortcut.* | backbone.bottom_up.res4.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (1024,) (1024,) (1024,) (1024,) (1024,512,1,1)  |\n",
      "| backbone.bottom_up.res4.1.conv1.*    | backbone.bottom_up.res4.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.1.conv2.*    | backbone.bottom_up.res4.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.1.conv3.*    | backbone.bottom_up.res4.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.2.conv1.*    | backbone.bottom_up.res4.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.2.conv2.*    | backbone.bottom_up.res4.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.2.conv3.*    | backbone.bottom_up.res4.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.3.conv1.*    | backbone.bottom_up.res4.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.3.conv2.*    | backbone.bottom_up.res4.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.3.conv3.*    | backbone.bottom_up.res4.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.4.conv1.*    | backbone.bottom_up.res4.4.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.4.conv2.*    | backbone.bottom_up.res4.4.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.4.conv3.*    | backbone.bottom_up.res4.4.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.5.conv1.*    | backbone.bottom_up.res4.5.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.5.conv2.*    | backbone.bottom_up.res4.5.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.5.conv3.*    | backbone.bottom_up.res4.5.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res5.0.conv1.*    | backbone.bottom_up.res5.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,1024,1,1)      |\n",
      "| backbone.bottom_up.res5.0.conv2.*    | backbone.bottom_up.res5.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |\n",
      "| backbone.bottom_up.res5.0.conv3.*    | backbone.bottom_up.res5.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
      "| backbone.bottom_up.res5.0.shortcut.* | backbone.bottom_up.res5.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (2048,) (2048,) (2048,) (2048,) (2048,1024,1,1) |\n",
      "| backbone.bottom_up.res5.1.conv1.*    | backbone.bottom_up.res5.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |\n",
      "| backbone.bottom_up.res5.1.conv2.*    | backbone.bottom_up.res5.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |\n",
      "| backbone.bottom_up.res5.1.conv3.*    | backbone.bottom_up.res5.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
      "| backbone.bottom_up.res5.2.conv1.*    | backbone.bottom_up.res5.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |\n",
      "| backbone.bottom_up.res5.2.conv2.*    | backbone.bottom_up.res5.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |\n",
      "| backbone.bottom_up.res5.2.conv3.*    | backbone.bottom_up.res5.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
      "| backbone.bottom_up.stem.conv1.*      | backbone.bottom_up.stem.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}      | (64,) (64,) (64,) (64,) (64,3,7,7)              |\n",
      "| backbone.fpn_lateral2.*              | backbone.fpn_lateral2.{bias,weight}                                                                  | (256,) (256,256,1,1)                            |\n",
      "| backbone.fpn_lateral3.*              | backbone.fpn_lateral3.{bias,weight}                                                                  | (256,) (256,512,1,1)                            |\n",
      "| backbone.fpn_lateral4.*              | backbone.fpn_lateral4.{bias,weight}                                                                  | (256,) (256,1024,1,1)                           |\n",
      "| backbone.fpn_lateral5.*              | backbone.fpn_lateral5.{bias,weight}                                                                  | (256,) (256,2048,1,1)                           |\n",
      "| backbone.fpn_output2.*               | backbone.fpn_output2.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| backbone.fpn_output3.*               | backbone.fpn_output3.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| backbone.fpn_output4.*               | backbone.fpn_output4.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| backbone.fpn_output5.*               | backbone.fpn_output5.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| sem_seg_head.p2.0.*                  | sem_seg_head.p2.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p3.0.*                  | sem_seg_head.p3.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p4.0.*                  | sem_seg_head.p4.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p4.2.*                  | sem_seg_head.p4.2.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,128,3,3)                     |\n",
      "| sem_seg_head.p5.0.*                  | sem_seg_head.p5.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p5.2.*                  | sem_seg_head.p5.2.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,128,3,3)                     |\n",
      "| sem_seg_head.p5.4.*                  | sem_seg_head.p5.4.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,128,3,3)                     |\n",
      "| sem_seg_head.predictor.*             | sem_seg_head.predictor.{bias,weight}                                                                 | (17,) (17,128,1,1)                              |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/07 13:40:13 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(720, 720), max_size=2048, sample_style='choice')]\n",
      "\u001b[32m[07/07 13:40:13 d2.data.common]: \u001b[0mSerializing 699 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[07/07 13:40:13 d2.data.common]: \u001b[0mSerialized dataset takes 0.25 MiB\n",
      "\u001b[32m[07/07 13:40:13 d2.evaluation.evaluator]: \u001b[0mStart inference on 699 batches\n",
      "\u001b[32m[07/07 13:40:16 d2.evaluation.evaluator]: \u001b[0mInference done 11/699. Dataloading: 0.0018 s/iter. Inference: 0.0466 s/iter. Eval: 0.1550 s/iter. Total: 0.2034 s/iter. ETA=0:02:19\n",
      "\u001b[32m[07/07 13:40:21 d2.evaluation.evaluator]: \u001b[0mInference done 36/699. Dataloading: 0.0022 s/iter. Inference: 0.0466 s/iter. Eval: 0.1519 s/iter. Total: 0.2009 s/iter. ETA=0:02:13\n",
      "\u001b[32m[07/07 13:40:26 d2.evaluation.evaluator]: \u001b[0mInference done 61/699. Dataloading: 0.0023 s/iter. Inference: 0.0467 s/iter. Eval: 0.1525 s/iter. Total: 0.2015 s/iter. ETA=0:02:08\n",
      "\u001b[32m[07/07 13:40:31 d2.evaluation.evaluator]: \u001b[0mInference done 87/699. Dataloading: 0.0023 s/iter. Inference: 0.0467 s/iter. Eval: 0.1514 s/iter. Total: 0.2005 s/iter. ETA=0:02:02\n",
      "\u001b[32m[07/07 13:40:36 d2.evaluation.evaluator]: \u001b[0mInference done 113/699. Dataloading: 0.0023 s/iter. Inference: 0.0467 s/iter. Eval: 0.1501 s/iter. Total: 0.1991 s/iter. ETA=0:01:56\n",
      "\u001b[32m[07/07 13:40:42 d2.evaluation.evaluator]: \u001b[0mInference done 140/699. Dataloading: 0.0023 s/iter. Inference: 0.0467 s/iter. Eval: 0.1482 s/iter. Total: 0.1972 s/iter. ETA=0:01:50\n",
      "\u001b[32m[07/07 13:40:47 d2.evaluation.evaluator]: \u001b[0mInference done 167/699. Dataloading: 0.0023 s/iter. Inference: 0.0467 s/iter. Eval: 0.1474 s/iter. Total: 0.1965 s/iter. ETA=0:01:44\n",
      "\u001b[32m[07/07 13:40:52 d2.evaluation.evaluator]: \u001b[0mInference done 192/699. Dataloading: 0.0023 s/iter. Inference: 0.0467 s/iter. Eval: 0.1487 s/iter. Total: 0.1978 s/iter. ETA=0:01:40\n",
      "\u001b[32m[07/07 13:40:57 d2.evaluation.evaluator]: \u001b[0mInference done 217/699. Dataloading: 0.0023 s/iter. Inference: 0.0467 s/iter. Eval: 0.1493 s/iter. Total: 0.1984 s/iter. ETA=0:01:35\n",
      "\u001b[32m[07/07 13:41:02 d2.evaluation.evaluator]: \u001b[0mInference done 242/699. Dataloading: 0.0023 s/iter. Inference: 0.0467 s/iter. Eval: 0.1498 s/iter. Total: 0.1989 s/iter. ETA=0:01:30\n",
      "\u001b[32m[07/07 13:41:07 d2.evaluation.evaluator]: \u001b[0mInference done 268/699. Dataloading: 0.0023 s/iter. Inference: 0.0467 s/iter. Eval: 0.1499 s/iter. Total: 0.1990 s/iter. ETA=0:01:25\n",
      "\u001b[32m[07/07 13:41:12 d2.evaluation.evaluator]: \u001b[0mInference done 294/699. Dataloading: 0.0023 s/iter. Inference: 0.0467 s/iter. Eval: 0.1499 s/iter. Total: 0.1990 s/iter. ETA=0:01:20\n",
      "\u001b[32m[07/07 13:41:17 d2.evaluation.evaluator]: \u001b[0mInference done 319/699. Dataloading: 0.0023 s/iter. Inference: 0.0467 s/iter. Eval: 0.1501 s/iter. Total: 0.1992 s/iter. ETA=0:01:15\n",
      "\u001b[32m[07/07 13:41:23 d2.evaluation.evaluator]: \u001b[0mInference done 345/699. Dataloading: 0.0023 s/iter. Inference: 0.0467 s/iter. Eval: 0.1501 s/iter. Total: 0.1992 s/iter. ETA=0:01:10\n",
      "\u001b[32m[07/07 13:41:28 d2.evaluation.evaluator]: \u001b[0mInference done 370/699. Dataloading: 0.0023 s/iter. Inference: 0.0467 s/iter. Eval: 0.1502 s/iter. Total: 0.1993 s/iter. ETA=0:01:05\n",
      "\u001b[32m[07/07 13:41:33 d2.evaluation.evaluator]: \u001b[0mInference done 395/699. Dataloading: 0.0023 s/iter. Inference: 0.0467 s/iter. Eval: 0.1505 s/iter. Total: 0.1996 s/iter. ETA=0:01:00\n",
      "\u001b[32m[07/07 13:41:38 d2.evaluation.evaluator]: \u001b[0mInference done 421/699. Dataloading: 0.0023 s/iter. Inference: 0.0467 s/iter. Eval: 0.1504 s/iter. Total: 0.1995 s/iter. ETA=0:00:55\n",
      "\u001b[32m[07/07 13:41:43 d2.evaluation.evaluator]: \u001b[0mInference done 447/699. Dataloading: 0.0023 s/iter. Inference: 0.0467 s/iter. Eval: 0.1504 s/iter. Total: 0.1995 s/iter. ETA=0:00:50\n",
      "\u001b[32m[07/07 13:41:48 d2.evaluation.evaluator]: \u001b[0mInference done 473/699. Dataloading: 0.0023 s/iter. Inference: 0.0467 s/iter. Eval: 0.1501 s/iter. Total: 0.1992 s/iter. ETA=0:00:45\n",
      "\u001b[32m[07/07 13:41:53 d2.evaluation.evaluator]: \u001b[0mInference done 498/699. Dataloading: 0.0023 s/iter. Inference: 0.0467 s/iter. Eval: 0.1502 s/iter. Total: 0.1993 s/iter. ETA=0:00:40\n",
      "\u001b[32m[07/07 13:41:58 d2.evaluation.evaluator]: \u001b[0mInference done 524/699. Dataloading: 0.0023 s/iter. Inference: 0.0467 s/iter. Eval: 0.1502 s/iter. Total: 0.1993 s/iter. ETA=0:00:34\n",
      "\u001b[32m[07/07 13:42:03 d2.evaluation.evaluator]: \u001b[0mInference done 550/699. Dataloading: 0.0023 s/iter. Inference: 0.0467 s/iter. Eval: 0.1501 s/iter. Total: 0.1992 s/iter. ETA=0:00:29\n",
      "\u001b[32m[07/07 13:42:09 d2.evaluation.evaluator]: \u001b[0mInference done 575/699. Dataloading: 0.0023 s/iter. Inference: 0.0467 s/iter. Eval: 0.1502 s/iter. Total: 0.1993 s/iter. ETA=0:00:24\n",
      "\u001b[32m[07/07 13:42:14 d2.evaluation.evaluator]: \u001b[0mInference done 600/699. Dataloading: 0.0023 s/iter. Inference: 0.0467 s/iter. Eval: 0.1504 s/iter. Total: 0.1995 s/iter. ETA=0:00:19\n",
      "\u001b[32m[07/07 13:42:19 d2.evaluation.evaluator]: \u001b[0mInference done 625/699. Dataloading: 0.0023 s/iter. Inference: 0.0467 s/iter. Eval: 0.1506 s/iter. Total: 0.1997 s/iter. ETA=0:00:14\n",
      "\u001b[32m[07/07 13:42:24 d2.evaluation.evaluator]: \u001b[0mInference done 651/699. Dataloading: 0.0023 s/iter. Inference: 0.0467 s/iter. Eval: 0.1504 s/iter. Total: 0.1996 s/iter. ETA=0:00:09\n",
      "\u001b[32m[07/07 13:42:29 d2.evaluation.evaluator]: \u001b[0mInference done 677/699. Dataloading: 0.0023 s/iter. Inference: 0.0467 s/iter. Eval: 0.1504 s/iter. Total: 0.1996 s/iter. ETA=0:00:04\n",
      "\u001b[32m[07/07 13:42:34 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:02:18.698426 (0.199854 s / iter per device, on 1 devices)\n",
      "\u001b[32m[07/07 13:42:34 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:32 (0.046706 s / iter per device, on 1 devices)\n",
      "\u001b[32m[07/07 13:42:34 d2.evaluation.sem_seg_evaluation]: \u001b[0mOrderedDict([('sem_seg', {'mIoU': 60.70918324565551, 'fwIoU': 88.84323090715182, 'IoU-Unlabeled': nan, 'IoU-Building': 89.16629674106449, 'IoU-Fence': 46.30508031185344, 'IoU-Pedestrian': 75.13306751924131, 'IoU-Pole': 49.591445603199844, 'IoU-Road': 95.73304174034611, 'IoU-SideWalk': 75.83524743516223, 'IoU-Vegetation': 89.46340370526778, 'IoU-Vehicles': 89.62723997969111, 'IoU-Wall': 44.59147867639251, 'IoU-TrafficSign': 62.09378253681095, 'IoU-Sky': 87.27288984683064, 'IoU-TrafficLight': 50.683047534671935, 'IoU-Terrain': 55.141727054300205, 'IoU-ConstructionVehicle': nan, 'IoU-workzone_object': nan, 'IoU-Detour': nan, 'mACC': 79.1818623237346, 'pACC': 93.80263777739069, 'ACC-Unlabeled': nan, 'ACC-Building': 95.58802792865484, 'ACC-Fence': 55.559619036257345, 'ACC-Pedestrian': 87.28739792997338, 'ACC-Pole': 63.62528913207732, 'ACC-Road': 97.55586076172239, 'ACC-SideWalk': 85.35805832871944, 'ACC-Vegetation': 95.0685864334002, 'ACC-Vehicles': 94.61411702946289, 'ACC-Wall': 58.444136924198006, 'ACC-TrafficSign': 70.62900359331856, 'ACC-Sky': 89.7884911256018, 'ACC-TrafficLight': 59.59054416416788, 'ACC-Terrain': 76.2550778209959, 'ACC-ConstructionVehicle': nan, 'ACC-workzone_object': nan, 'ACC-Detour': nan})])\n",
      "\u001b[32m[07/07 13:42:34 d2.engine.defaults]: \u001b[0mEvaluation results for cityscapes_clear_val in csv format:\n",
      "\u001b[32m[07/07 13:42:34 d2.evaluation.testing]: \u001b[0mcopypaste: Task: sem_seg\n",
      "\u001b[32m[07/07 13:42:34 d2.evaluation.testing]: \u001b[0mcopypaste: mIoU,fwIoU,mACC,pACC\n",
      "\u001b[32m[07/07 13:42:34 d2.evaluation.testing]: \u001b[0mcopypaste: 60.7092,88.8432,79.1819,93.8026\n"
     ]
    }
   ],
   "source": [
    "#all cityscapes clear\n",
    "trainer_both = Detectron2Trainer('combined_clear_both_train', 'cityscapes_clear_val', output_folder='./output_both_clear_40k')\n",
    "trainer_both.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "745a61f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/07 13:42:34 d2.engine.defaults]: \u001b[0mModel:\n",
      "SemanticSegmentor(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (sem_seg_head): SemSegFPNHead(\n",
      "    (p2): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "    )\n",
      "    (p3): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (1): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "    )\n",
      "    (p4): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (1): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      (2): Conv2d(\n",
      "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (3): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "    )\n",
      "    (p5): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (1): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      (2): Conv2d(\n",
      "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (3): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      (4): Conv2d(\n",
      "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (5): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "    )\n",
      "    (predictor): Conv2d(128, 17, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/07 13:42:34 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(720, 720), max_size=2048, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[07/07 13:42:34 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[07/07 13:42:34 d2.data.common]: \u001b[0mSerializing 6626 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[07/07 13:42:34 d2.data.common]: \u001b[0mSerialized dataset takes 2.45 MiB\n",
      "Last checkpoint: model_final.pth\n",
      "\u001b[32m[07/07 13:42:35 d2.checkpoint.c2_model_loading]: \u001b[0mFollowing weights matched with model:\n",
      "| Names in Model                       | Names in Checkpoint                                                                                  | Shapes                                          |\n",
      "|:-------------------------------------|:-----------------------------------------------------------------------------------------------------|:------------------------------------------------|\n",
      "| backbone.bottom_up.res2.0.conv1.*    | backbone.bottom_up.res2.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,1,1)             |\n",
      "| backbone.bottom_up.res2.0.conv2.*    | backbone.bottom_up.res2.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |\n",
      "| backbone.bottom_up.res2.0.conv3.*    | backbone.bottom_up.res2.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res2.0.shortcut.* | backbone.bottom_up.res2.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res2.1.conv1.*    | backbone.bottom_up.res2.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |\n",
      "| backbone.bottom_up.res2.1.conv2.*    | backbone.bottom_up.res2.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |\n",
      "| backbone.bottom_up.res2.1.conv3.*    | backbone.bottom_up.res2.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res2.2.conv1.*    | backbone.bottom_up.res2.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |\n",
      "| backbone.bottom_up.res2.2.conv2.*    | backbone.bottom_up.res2.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |\n",
      "| backbone.bottom_up.res2.2.conv3.*    | backbone.bottom_up.res2.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res3.0.conv1.*    | backbone.bottom_up.res3.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,256,1,1)       |\n",
      "| backbone.bottom_up.res3.0.conv2.*    | backbone.bottom_up.res3.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.0.conv3.*    | backbone.bottom_up.res3.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res3.0.shortcut.* | backbone.bottom_up.res3.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (512,) (512,) (512,) (512,) (512,256,1,1)       |\n",
      "| backbone.bottom_up.res3.1.conv1.*    | backbone.bottom_up.res3.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |\n",
      "| backbone.bottom_up.res3.1.conv2.*    | backbone.bottom_up.res3.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.1.conv3.*    | backbone.bottom_up.res3.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res3.2.conv1.*    | backbone.bottom_up.res3.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |\n",
      "| backbone.bottom_up.res3.2.conv2.*    | backbone.bottom_up.res3.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.2.conv3.*    | backbone.bottom_up.res3.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res3.3.conv1.*    | backbone.bottom_up.res3.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |\n",
      "| backbone.bottom_up.res3.3.conv2.*    | backbone.bottom_up.res3.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.3.conv3.*    | backbone.bottom_up.res3.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res4.0.conv1.*    | backbone.bottom_up.res4.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,512,1,1)       |\n",
      "| backbone.bottom_up.res4.0.conv2.*    | backbone.bottom_up.res4.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.0.conv3.*    | backbone.bottom_up.res4.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.0.shortcut.* | backbone.bottom_up.res4.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (1024,) (1024,) (1024,) (1024,) (1024,512,1,1)  |\n",
      "| backbone.bottom_up.res4.1.conv1.*    | backbone.bottom_up.res4.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.1.conv2.*    | backbone.bottom_up.res4.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.1.conv3.*    | backbone.bottom_up.res4.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.2.conv1.*    | backbone.bottom_up.res4.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.2.conv2.*    | backbone.bottom_up.res4.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.2.conv3.*    | backbone.bottom_up.res4.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.3.conv1.*    | backbone.bottom_up.res4.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.3.conv2.*    | backbone.bottom_up.res4.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.3.conv3.*    | backbone.bottom_up.res4.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.4.conv1.*    | backbone.bottom_up.res4.4.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.4.conv2.*    | backbone.bottom_up.res4.4.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.4.conv3.*    | backbone.bottom_up.res4.4.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.5.conv1.*    | backbone.bottom_up.res4.5.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.5.conv2.*    | backbone.bottom_up.res4.5.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.5.conv3.*    | backbone.bottom_up.res4.5.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res5.0.conv1.*    | backbone.bottom_up.res5.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,1024,1,1)      |\n",
      "| backbone.bottom_up.res5.0.conv2.*    | backbone.bottom_up.res5.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |\n",
      "| backbone.bottom_up.res5.0.conv3.*    | backbone.bottom_up.res5.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
      "| backbone.bottom_up.res5.0.shortcut.* | backbone.bottom_up.res5.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (2048,) (2048,) (2048,) (2048,) (2048,1024,1,1) |\n",
      "| backbone.bottom_up.res5.1.conv1.*    | backbone.bottom_up.res5.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |\n",
      "| backbone.bottom_up.res5.1.conv2.*    | backbone.bottom_up.res5.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |\n",
      "| backbone.bottom_up.res5.1.conv3.*    | backbone.bottom_up.res5.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
      "| backbone.bottom_up.res5.2.conv1.*    | backbone.bottom_up.res5.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |\n",
      "| backbone.bottom_up.res5.2.conv2.*    | backbone.bottom_up.res5.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |\n",
      "| backbone.bottom_up.res5.2.conv3.*    | backbone.bottom_up.res5.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
      "| backbone.bottom_up.stem.conv1.*      | backbone.bottom_up.stem.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}      | (64,) (64,) (64,) (64,) (64,3,7,7)              |\n",
      "| backbone.fpn_lateral2.*              | backbone.fpn_lateral2.{bias,weight}                                                                  | (256,) (256,256,1,1)                            |\n",
      "| backbone.fpn_lateral3.*              | backbone.fpn_lateral3.{bias,weight}                                                                  | (256,) (256,512,1,1)                            |\n",
      "| backbone.fpn_lateral4.*              | backbone.fpn_lateral4.{bias,weight}                                                                  | (256,) (256,1024,1,1)                           |\n",
      "| backbone.fpn_lateral5.*              | backbone.fpn_lateral5.{bias,weight}                                                                  | (256,) (256,2048,1,1)                           |\n",
      "| backbone.fpn_output2.*               | backbone.fpn_output2.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| backbone.fpn_output3.*               | backbone.fpn_output3.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| backbone.fpn_output4.*               | backbone.fpn_output4.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| backbone.fpn_output5.*               | backbone.fpn_output5.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| sem_seg_head.p2.0.*                  | sem_seg_head.p2.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p3.0.*                  | sem_seg_head.p3.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p4.0.*                  | sem_seg_head.p4.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p4.2.*                  | sem_seg_head.p4.2.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,128,3,3)                     |\n",
      "| sem_seg_head.p5.0.*                  | sem_seg_head.p5.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p5.2.*                  | sem_seg_head.p5.2.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,128,3,3)                     |\n",
      "| sem_seg_head.p5.4.*                  | sem_seg_head.p5.4.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,128,3,3)                     |\n",
      "| sem_seg_head.predictor.*             | sem_seg_head.predictor.{bias,weight}                                                                 | (17,) (17,128,1,1)                              |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/07 13:42:35 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(720, 720), max_size=2048, sample_style='choice')]\n",
      "\u001b[32m[07/07 13:42:35 d2.data.common]: \u001b[0mSerializing 7230 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[07/07 13:42:35 d2.data.common]: \u001b[0mSerialized dataset takes 2.67 MiB\n",
      "\u001b[32m[07/07 13:42:35 d2.evaluation.evaluator]: \u001b[0mStart inference on 7230 batches\n",
      "\u001b[32m[07/07 13:42:36 d2.evaluation.evaluator]: \u001b[0mInference done 11/7230. Dataloading: 0.0019 s/iter. Inference: 0.0354 s/iter. Eval: 0.0432 s/iter. Total: 0.0804 s/iter. ETA=0:09:40\n",
      "\u001b[32m[07/07 13:42:41 d2.evaluation.evaluator]: \u001b[0mInference done 75/7230. Dataloading: 0.0022 s/iter. Inference: 0.0351 s/iter. Eval: 0.0413 s/iter. Total: 0.0787 s/iter. ETA=0:09:23\n",
      "\u001b[32m[07/07 13:42:46 d2.evaluation.evaluator]: \u001b[0mInference done 142/7230. Dataloading: 0.0022 s/iter. Inference: 0.0352 s/iter. Eval: 0.0396 s/iter. Total: 0.0770 s/iter. ETA=0:09:06\n",
      "\u001b[32m[07/07 13:42:51 d2.evaluation.evaluator]: \u001b[0mInference done 209/7230. Dataloading: 0.0022 s/iter. Inference: 0.0352 s/iter. Eval: 0.0390 s/iter. Total: 0.0765 s/iter. ETA=0:08:57\n",
      "\u001b[32m[07/07 13:42:56 d2.evaluation.evaluator]: \u001b[0mInference done 275/7230. Dataloading: 0.0022 s/iter. Inference: 0.0352 s/iter. Eval: 0.0390 s/iter. Total: 0.0765 s/iter. ETA=0:08:51\n",
      "\u001b[32m[07/07 13:43:01 d2.evaluation.evaluator]: \u001b[0mInference done 341/7230. Dataloading: 0.0022 s/iter. Inference: 0.0352 s/iter. Eval: 0.0390 s/iter. Total: 0.0766 s/iter. ETA=0:08:47\n",
      "\u001b[32m[07/07 13:43:06 d2.evaluation.evaluator]: \u001b[0mInference done 407/7230. Dataloading: 0.0022 s/iter. Inference: 0.0352 s/iter. Eval: 0.0390 s/iter. Total: 0.0765 s/iter. ETA=0:08:41\n",
      "\u001b[32m[07/07 13:43:11 d2.evaluation.evaluator]: \u001b[0mInference done 474/7230. Dataloading: 0.0022 s/iter. Inference: 0.0352 s/iter. Eval: 0.0388 s/iter. Total: 0.0763 s/iter. ETA=0:08:35\n",
      "\u001b[32m[07/07 13:43:16 d2.evaluation.evaluator]: \u001b[0mInference done 540/7230. Dataloading: 0.0023 s/iter. Inference: 0.0352 s/iter. Eval: 0.0387 s/iter. Total: 0.0763 s/iter. ETA=0:08:30\n",
      "\u001b[32m[07/07 13:43:21 d2.evaluation.evaluator]: \u001b[0mInference done 606/7230. Dataloading: 0.0023 s/iter. Inference: 0.0353 s/iter. Eval: 0.0387 s/iter. Total: 0.0763 s/iter. ETA=0:08:25\n",
      "\u001b[32m[07/07 13:43:26 d2.evaluation.evaluator]: \u001b[0mInference done 671/7230. Dataloading: 0.0023 s/iter. Inference: 0.0353 s/iter. Eval: 0.0388 s/iter. Total: 0.0764 s/iter. ETA=0:08:21\n",
      "\u001b[32m[07/07 13:43:31 d2.evaluation.evaluator]: \u001b[0mInference done 736/7230. Dataloading: 0.0023 s/iter. Inference: 0.0353 s/iter. Eval: 0.0389 s/iter. Total: 0.0766 s/iter. ETA=0:08:17\n",
      "\u001b[32m[07/07 13:43:36 d2.evaluation.evaluator]: \u001b[0mInference done 800/7230. Dataloading: 0.0023 s/iter. Inference: 0.0353 s/iter. Eval: 0.0390 s/iter. Total: 0.0767 s/iter. ETA=0:08:13\n",
      "\u001b[32m[07/07 13:43:41 d2.evaluation.evaluator]: \u001b[0mInference done 864/7230. Dataloading: 0.0023 s/iter. Inference: 0.0353 s/iter. Eval: 0.0392 s/iter. Total: 0.0768 s/iter. ETA=0:08:09\n",
      "\u001b[32m[07/07 13:43:46 d2.evaluation.evaluator]: \u001b[0mInference done 928/7230. Dataloading: 0.0023 s/iter. Inference: 0.0353 s/iter. Eval: 0.0393 s/iter. Total: 0.0770 s/iter. ETA=0:08:05\n",
      "\u001b[32m[07/07 13:43:51 d2.evaluation.evaluator]: \u001b[0mInference done 992/7230. Dataloading: 0.0023 s/iter. Inference: 0.0353 s/iter. Eval: 0.0394 s/iter. Total: 0.0771 s/iter. ETA=0:08:01\n",
      "\u001b[32m[07/07 13:43:56 d2.evaluation.evaluator]: \u001b[0mInference done 1056/7230. Dataloading: 0.0023 s/iter. Inference: 0.0353 s/iter. Eval: 0.0395 s/iter. Total: 0.0772 s/iter. ETA=0:07:56\n",
      "\u001b[32m[07/07 13:44:01 d2.evaluation.evaluator]: \u001b[0mInference done 1120/7230. Dataloading: 0.0023 s/iter. Inference: 0.0353 s/iter. Eval: 0.0396 s/iter. Total: 0.0773 s/iter. ETA=0:07:52\n",
      "\u001b[32m[07/07 13:44:07 d2.evaluation.evaluator]: \u001b[0mInference done 1185/7230. Dataloading: 0.0023 s/iter. Inference: 0.0353 s/iter. Eval: 0.0396 s/iter. Total: 0.0773 s/iter. ETA=0:07:47\n",
      "\u001b[32m[07/07 13:44:12 d2.evaluation.evaluator]: \u001b[0mInference done 1249/7230. Dataloading: 0.0023 s/iter. Inference: 0.0353 s/iter. Eval: 0.0397 s/iter. Total: 0.0774 s/iter. ETA=0:07:42\n",
      "\u001b[32m[07/07 13:44:17 d2.evaluation.evaluator]: \u001b[0mInference done 1313/7230. Dataloading: 0.0023 s/iter. Inference: 0.0353 s/iter. Eval: 0.0397 s/iter. Total: 0.0774 s/iter. ETA=0:07:38\n",
      "\u001b[32m[07/07 13:44:22 d2.evaluation.evaluator]: \u001b[0mInference done 1377/7230. Dataloading: 0.0023 s/iter. Inference: 0.0353 s/iter. Eval: 0.0398 s/iter. Total: 0.0775 s/iter. ETA=0:07:33\n",
      "\u001b[32m[07/07 13:44:27 d2.evaluation.evaluator]: \u001b[0mInference done 1441/7230. Dataloading: 0.0023 s/iter. Inference: 0.0354 s/iter. Eval: 0.0398 s/iter. Total: 0.0775 s/iter. ETA=0:07:28\n",
      "\u001b[32m[07/07 13:44:32 d2.evaluation.evaluator]: \u001b[0mInference done 1506/7230. Dataloading: 0.0023 s/iter. Inference: 0.0354 s/iter. Eval: 0.0398 s/iter. Total: 0.0775 s/iter. ETA=0:07:23\n",
      "\u001b[32m[07/07 13:44:37 d2.evaluation.evaluator]: \u001b[0mInference done 1570/7230. Dataloading: 0.0023 s/iter. Inference: 0.0354 s/iter. Eval: 0.0399 s/iter. Total: 0.0776 s/iter. ETA=0:07:19\n",
      "\u001b[32m[07/07 13:44:42 d2.evaluation.evaluator]: \u001b[0mInference done 1635/7230. Dataloading: 0.0023 s/iter. Inference: 0.0354 s/iter. Eval: 0.0399 s/iter. Total: 0.0776 s/iter. ETA=0:07:14\n",
      "\u001b[32m[07/07 13:44:47 d2.evaluation.evaluator]: \u001b[0mInference done 1698/7230. Dataloading: 0.0023 s/iter. Inference: 0.0354 s/iter. Eval: 0.0399 s/iter. Total: 0.0777 s/iter. ETA=0:07:09\n",
      "\u001b[32m[07/07 13:44:52 d2.evaluation.evaluator]: \u001b[0mInference done 1763/7230. Dataloading: 0.0023 s/iter. Inference: 0.0354 s/iter. Eval: 0.0399 s/iter. Total: 0.0777 s/iter. ETA=0:07:04\n",
      "\u001b[32m[07/07 13:44:57 d2.evaluation.evaluator]: \u001b[0mInference done 1826/7230. Dataloading: 0.0024 s/iter. Inference: 0.0354 s/iter. Eval: 0.0400 s/iter. Total: 0.0778 s/iter. ETA=0:07:00\n",
      "\u001b[32m[07/07 13:45:02 d2.evaluation.evaluator]: \u001b[0mInference done 1889/7230. Dataloading: 0.0024 s/iter. Inference: 0.0354 s/iter. Eval: 0.0400 s/iter. Total: 0.0778 s/iter. ETA=0:06:55\n",
      "\u001b[32m[07/07 13:45:07 d2.evaluation.evaluator]: \u001b[0mInference done 1954/7230. Dataloading: 0.0024 s/iter. Inference: 0.0354 s/iter. Eval: 0.0400 s/iter. Total: 0.0778 s/iter. ETA=0:06:50\n",
      "\u001b[32m[07/07 13:45:12 d2.evaluation.evaluator]: \u001b[0mInference done 2020/7230. Dataloading: 0.0023 s/iter. Inference: 0.0354 s/iter. Eval: 0.0400 s/iter. Total: 0.0778 s/iter. ETA=0:06:45\n",
      "\u001b[32m[07/07 13:45:17 d2.evaluation.evaluator]: \u001b[0mInference done 2086/7230. Dataloading: 0.0023 s/iter. Inference: 0.0354 s/iter. Eval: 0.0399 s/iter. Total: 0.0777 s/iter. ETA=0:06:39\n",
      "\u001b[32m[07/07 13:45:22 d2.evaluation.evaluator]: \u001b[0mInference done 2152/7230. Dataloading: 0.0023 s/iter. Inference: 0.0354 s/iter. Eval: 0.0399 s/iter. Total: 0.0777 s/iter. ETA=0:06:34\n",
      "\u001b[32m[07/07 13:45:27 d2.evaluation.evaluator]: \u001b[0mInference done 2218/7230. Dataloading: 0.0023 s/iter. Inference: 0.0354 s/iter. Eval: 0.0398 s/iter. Total: 0.0777 s/iter. ETA=0:06:29\n",
      "\u001b[32m[07/07 13:45:32 d2.evaluation.evaluator]: \u001b[0mInference done 2284/7230. Dataloading: 0.0023 s/iter. Inference: 0.0354 s/iter. Eval: 0.0398 s/iter. Total: 0.0776 s/iter. ETA=0:06:23\n",
      "\u001b[32m[07/07 13:45:37 d2.evaluation.evaluator]: \u001b[0mInference done 2350/7230. Dataloading: 0.0023 s/iter. Inference: 0.0354 s/iter. Eval: 0.0398 s/iter. Total: 0.0776 s/iter. ETA=0:06:18\n",
      "\u001b[32m[07/07 13:45:42 d2.evaluation.evaluator]: \u001b[0mInference done 2416/7230. Dataloading: 0.0023 s/iter. Inference: 0.0354 s/iter. Eval: 0.0398 s/iter. Total: 0.0776 s/iter. ETA=0:06:13\n",
      "\u001b[32m[07/07 13:45:47 d2.evaluation.evaluator]: \u001b[0mInference done 2482/7230. Dataloading: 0.0023 s/iter. Inference: 0.0354 s/iter. Eval: 0.0397 s/iter. Total: 0.0776 s/iter. ETA=0:06:08\n",
      "\u001b[32m[07/07 13:45:52 d2.evaluation.evaluator]: \u001b[0mInference done 2548/7230. Dataloading: 0.0023 s/iter. Inference: 0.0354 s/iter. Eval: 0.0397 s/iter. Total: 0.0775 s/iter. ETA=0:06:02\n",
      "\u001b[32m[07/07 13:45:57 d2.evaluation.evaluator]: \u001b[0mInference done 2614/7230. Dataloading: 0.0023 s/iter. Inference: 0.0354 s/iter. Eval: 0.0396 s/iter. Total: 0.0775 s/iter. ETA=0:05:57\n",
      "\u001b[32m[07/07 13:46:02 d2.evaluation.evaluator]: \u001b[0mInference done 2680/7230. Dataloading: 0.0023 s/iter. Inference: 0.0354 s/iter. Eval: 0.0396 s/iter. Total: 0.0774 s/iter. ETA=0:05:52\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/07 13:46:08 d2.evaluation.evaluator]: \u001b[0mInference done 2746/7230. Dataloading: 0.0023 s/iter. Inference: 0.0354 s/iter. Eval: 0.0396 s/iter. Total: 0.0774 s/iter. ETA=0:05:47\n",
      "\u001b[32m[07/07 13:46:13 d2.evaluation.evaluator]: \u001b[0mInference done 2812/7230. Dataloading: 0.0023 s/iter. Inference: 0.0354 s/iter. Eval: 0.0395 s/iter. Total: 0.0774 s/iter. ETA=0:05:41\n",
      "\u001b[32m[07/07 13:46:18 d2.evaluation.evaluator]: \u001b[0mInference done 2878/7230. Dataloading: 0.0023 s/iter. Inference: 0.0354 s/iter. Eval: 0.0395 s/iter. Total: 0.0773 s/iter. ETA=0:05:36\n",
      "\u001b[32m[07/07 13:46:23 d2.evaluation.evaluator]: \u001b[0mInference done 2944/7230. Dataloading: 0.0023 s/iter. Inference: 0.0354 s/iter. Eval: 0.0395 s/iter. Total: 0.0773 s/iter. ETA=0:05:31\n",
      "\u001b[32m[07/07 13:46:28 d2.evaluation.evaluator]: \u001b[0mInference done 3010/7230. Dataloading: 0.0023 s/iter. Inference: 0.0354 s/iter. Eval: 0.0394 s/iter. Total: 0.0773 s/iter. ETA=0:05:26\n",
      "\u001b[32m[07/07 13:46:33 d2.evaluation.evaluator]: \u001b[0mInference done 3076/7230. Dataloading: 0.0023 s/iter. Inference: 0.0354 s/iter. Eval: 0.0394 s/iter. Total: 0.0773 s/iter. ETA=0:05:20\n",
      "\u001b[32m[07/07 13:46:38 d2.evaluation.evaluator]: \u001b[0mInference done 3142/7230. Dataloading: 0.0023 s/iter. Inference: 0.0354 s/iter. Eval: 0.0394 s/iter. Total: 0.0772 s/iter. ETA=0:05:15\n",
      "\u001b[32m[07/07 13:46:43 d2.evaluation.evaluator]: \u001b[0mInference done 3208/7230. Dataloading: 0.0023 s/iter. Inference: 0.0354 s/iter. Eval: 0.0394 s/iter. Total: 0.0772 s/iter. ETA=0:05:10\n",
      "\u001b[32m[07/07 13:46:48 d2.evaluation.evaluator]: \u001b[0mInference done 3265/7230. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0396 s/iter. Total: 0.0774 s/iter. ETA=0:05:06\n",
      "\u001b[32m[07/07 13:46:53 d2.evaluation.evaluator]: \u001b[0mInference done 3292/7230. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0404 s/iter. Total: 0.0783 s/iter. ETA=0:05:08\n",
      "\u001b[32m[07/07 13:46:58 d2.evaluation.evaluator]: \u001b[0mInference done 3318/7230. Dataloading: 0.0023 s/iter. Inference: 0.0356 s/iter. Eval: 0.0412 s/iter. Total: 0.0792 s/iter. ETA=0:05:10\n",
      "\u001b[32m[07/07 13:47:03 d2.evaluation.evaluator]: \u001b[0mInference done 3345/7230. Dataloading: 0.0023 s/iter. Inference: 0.0357 s/iter. Eval: 0.0420 s/iter. Total: 0.0801 s/iter. ETA=0:05:11\n",
      "\u001b[32m[07/07 13:47:08 d2.evaluation.evaluator]: \u001b[0mInference done 3373/7230. Dataloading: 0.0023 s/iter. Inference: 0.0358 s/iter. Eval: 0.0428 s/iter. Total: 0.0810 s/iter. ETA=0:05:12\n",
      "\u001b[32m[07/07 13:47:13 d2.evaluation.evaluator]: \u001b[0mInference done 3401/7230. Dataloading: 0.0023 s/iter. Inference: 0.0359 s/iter. Eval: 0.0435 s/iter. Total: 0.0818 s/iter. ETA=0:05:13\n",
      "\u001b[32m[07/07 13:47:18 d2.evaluation.evaluator]: \u001b[0mInference done 3428/7230. Dataloading: 0.0023 s/iter. Inference: 0.0360 s/iter. Eval: 0.0442 s/iter. Total: 0.0826 s/iter. ETA=0:05:14\n",
      "\u001b[32m[07/07 13:47:23 d2.evaluation.evaluator]: \u001b[0mInference done 3454/7230. Dataloading: 0.0023 s/iter. Inference: 0.0361 s/iter. Eval: 0.0450 s/iter. Total: 0.0835 s/iter. ETA=0:05:15\n",
      "\u001b[32m[07/07 13:47:28 d2.evaluation.evaluator]: \u001b[0mInference done 3480/7230. Dataloading: 0.0023 s/iter. Inference: 0.0361 s/iter. Eval: 0.0457 s/iter. Total: 0.0843 s/iter. ETA=0:05:16\n",
      "\u001b[32m[07/07 13:47:33 d2.evaluation.evaluator]: \u001b[0mInference done 3507/7230. Dataloading: 0.0023 s/iter. Inference: 0.0362 s/iter. Eval: 0.0465 s/iter. Total: 0.0851 s/iter. ETA=0:05:16\n",
      "\u001b[32m[07/07 13:47:39 d2.evaluation.evaluator]: \u001b[0mInference done 3534/7230. Dataloading: 0.0023 s/iter. Inference: 0.0363 s/iter. Eval: 0.0472 s/iter. Total: 0.0859 s/iter. ETA=0:05:17\n",
      "\u001b[32m[07/07 13:47:44 d2.evaluation.evaluator]: \u001b[0mInference done 3561/7230. Dataloading: 0.0023 s/iter. Inference: 0.0364 s/iter. Eval: 0.0479 s/iter. Total: 0.0867 s/iter. ETA=0:05:18\n",
      "\u001b[32m[07/07 13:47:49 d2.evaluation.evaluator]: \u001b[0mInference done 3587/7230. Dataloading: 0.0023 s/iter. Inference: 0.0365 s/iter. Eval: 0.0486 s/iter. Total: 0.0875 s/iter. ETA=0:05:18\n",
      "\u001b[32m[07/07 13:47:54 d2.evaluation.evaluator]: \u001b[0mInference done 3614/7230. Dataloading: 0.0023 s/iter. Inference: 0.0365 s/iter. Eval: 0.0493 s/iter. Total: 0.0883 s/iter. ETA=0:05:19\n",
      "\u001b[32m[07/07 13:47:59 d2.evaluation.evaluator]: \u001b[0mInference done 3640/7230. Dataloading: 0.0023 s/iter. Inference: 0.0366 s/iter. Eval: 0.0500 s/iter. Total: 0.0891 s/iter. ETA=0:05:19\n",
      "\u001b[32m[07/07 13:48:04 d2.evaluation.evaluator]: \u001b[0mInference done 3666/7230. Dataloading: 0.0023 s/iter. Inference: 0.0367 s/iter. Eval: 0.0507 s/iter. Total: 0.0898 s/iter. ETA=0:05:20\n",
      "\u001b[32m[07/07 13:48:09 d2.evaluation.evaluator]: \u001b[0mInference done 3693/7230. Dataloading: 0.0023 s/iter. Inference: 0.0368 s/iter. Eval: 0.0513 s/iter. Total: 0.0905 s/iter. ETA=0:05:20\n",
      "\u001b[32m[07/07 13:48:14 d2.evaluation.evaluator]: \u001b[0mInference done 3720/7230. Dataloading: 0.0024 s/iter. Inference: 0.0368 s/iter. Eval: 0.0520 s/iter. Total: 0.0912 s/iter. ETA=0:05:20\n",
      "\u001b[32m[07/07 13:48:19 d2.evaluation.evaluator]: \u001b[0mInference done 3747/7230. Dataloading: 0.0024 s/iter. Inference: 0.0369 s/iter. Eval: 0.0526 s/iter. Total: 0.0920 s/iter. ETA=0:05:20\n",
      "\u001b[32m[07/07 13:48:24 d2.evaluation.evaluator]: \u001b[0mInference done 3773/7230. Dataloading: 0.0024 s/iter. Inference: 0.0370 s/iter. Eval: 0.0532 s/iter. Total: 0.0926 s/iter. ETA=0:05:20\n",
      "\u001b[32m[07/07 13:48:29 d2.evaluation.evaluator]: \u001b[0mInference done 3800/7230. Dataloading: 0.0024 s/iter. Inference: 0.0370 s/iter. Eval: 0.0538 s/iter. Total: 0.0933 s/iter. ETA=0:05:20\n",
      "\u001b[32m[07/07 13:48:35 d2.evaluation.evaluator]: \u001b[0mInference done 3826/7230. Dataloading: 0.0024 s/iter. Inference: 0.0371 s/iter. Eval: 0.0545 s/iter. Total: 0.0940 s/iter. ETA=0:05:19\n",
      "\u001b[32m[07/07 13:48:40 d2.evaluation.evaluator]: \u001b[0mInference done 3852/7230. Dataloading: 0.0024 s/iter. Inference: 0.0372 s/iter. Eval: 0.0551 s/iter. Total: 0.0947 s/iter. ETA=0:05:19\n",
      "\u001b[32m[07/07 13:48:45 d2.evaluation.evaluator]: \u001b[0mInference done 3878/7230. Dataloading: 0.0024 s/iter. Inference: 0.0372 s/iter. Eval: 0.0557 s/iter. Total: 0.0954 s/iter. ETA=0:05:19\n",
      "\u001b[32m[07/07 13:48:50 d2.evaluation.evaluator]: \u001b[0mInference done 3905/7230. Dataloading: 0.0024 s/iter. Inference: 0.0373 s/iter. Eval: 0.0563 s/iter. Total: 0.0960 s/iter. ETA=0:05:19\n",
      "\u001b[32m[07/07 13:48:55 d2.evaluation.evaluator]: \u001b[0mInference done 3932/7230. Dataloading: 0.0024 s/iter. Inference: 0.0374 s/iter. Eval: 0.0569 s/iter. Total: 0.0967 s/iter. ETA=0:05:18\n",
      "\u001b[32m[07/07 13:49:00 d2.evaluation.evaluator]: \u001b[0mInference done 3959/7230. Dataloading: 0.0024 s/iter. Inference: 0.0374 s/iter. Eval: 0.0574 s/iter. Total: 0.0973 s/iter. ETA=0:05:18\n",
      "\u001b[32m[07/07 13:49:05 d2.evaluation.evaluator]: \u001b[0mInference done 4023/7230. Dataloading: 0.0024 s/iter. Inference: 0.0374 s/iter. Eval: 0.0572 s/iter. Total: 0.0970 s/iter. ETA=0:05:11\n",
      "\u001b[32m[07/07 13:49:10 d2.evaluation.evaluator]: \u001b[0mInference done 4087/7230. Dataloading: 0.0024 s/iter. Inference: 0.0374 s/iter. Eval: 0.0569 s/iter. Total: 0.0967 s/iter. ETA=0:05:03\n",
      "\u001b[32m[07/07 13:49:15 d2.evaluation.evaluator]: \u001b[0mInference done 4151/7230. Dataloading: 0.0024 s/iter. Inference: 0.0373 s/iter. Eval: 0.0567 s/iter. Total: 0.0964 s/iter. ETA=0:04:56\n",
      "\u001b[32m[07/07 13:49:20 d2.evaluation.evaluator]: \u001b[0mInference done 4215/7230. Dataloading: 0.0024 s/iter. Inference: 0.0373 s/iter. Eval: 0.0564 s/iter. Total: 0.0961 s/iter. ETA=0:04:49\n",
      "\u001b[32m[07/07 13:49:25 d2.evaluation.evaluator]: \u001b[0mInference done 4279/7230. Dataloading: 0.0024 s/iter. Inference: 0.0373 s/iter. Eval: 0.0562 s/iter. Total: 0.0959 s/iter. ETA=0:04:42\n",
      "\u001b[32m[07/07 13:49:30 d2.evaluation.evaluator]: \u001b[0mInference done 4342/7230. Dataloading: 0.0024 s/iter. Inference: 0.0372 s/iter. Eval: 0.0560 s/iter. Total: 0.0957 s/iter. ETA=0:04:36\n",
      "\u001b[32m[07/07 13:49:35 d2.evaluation.evaluator]: \u001b[0mInference done 4404/7230. Dataloading: 0.0024 s/iter. Inference: 0.0372 s/iter. Eval: 0.0558 s/iter. Total: 0.0955 s/iter. ETA=0:04:29\n",
      "\u001b[32m[07/07 13:49:40 d2.evaluation.evaluator]: \u001b[0mInference done 4465/7230. Dataloading: 0.0024 s/iter. Inference: 0.0372 s/iter. Eval: 0.0556 s/iter. Total: 0.0953 s/iter. ETA=0:04:23\n",
      "\u001b[32m[07/07 13:49:45 d2.evaluation.evaluator]: \u001b[0mInference done 4528/7230. Dataloading: 0.0024 s/iter. Inference: 0.0372 s/iter. Eval: 0.0555 s/iter. Total: 0.0951 s/iter. ETA=0:04:16\n",
      "\u001b[32m[07/07 13:49:50 d2.evaluation.evaluator]: \u001b[0mInference done 4591/7230. Dataloading: 0.0024 s/iter. Inference: 0.0371 s/iter. Eval: 0.0553 s/iter. Total: 0.0949 s/iter. ETA=0:04:10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/07 13:49:55 d2.evaluation.evaluator]: \u001b[0mInference done 4654/7230. Dataloading: 0.0024 s/iter. Inference: 0.0371 s/iter. Eval: 0.0551 s/iter. Total: 0.0947 s/iter. ETA=0:04:03\n",
      "\u001b[32m[07/07 13:50:00 d2.evaluation.evaluator]: \u001b[0mInference done 4718/7230. Dataloading: 0.0024 s/iter. Inference: 0.0371 s/iter. Eval: 0.0549 s/iter. Total: 0.0944 s/iter. ETA=0:03:57\n",
      "\u001b[32m[07/07 13:50:06 d2.evaluation.evaluator]: \u001b[0mInference done 4785/7230. Dataloading: 0.0024 s/iter. Inference: 0.0371 s/iter. Eval: 0.0547 s/iter. Total: 0.0942 s/iter. ETA=0:03:50\n",
      "\u001b[32m[07/07 13:50:11 d2.evaluation.evaluator]: \u001b[0mInference done 4852/7230. Dataloading: 0.0024 s/iter. Inference: 0.0370 s/iter. Eval: 0.0544 s/iter. Total: 0.0939 s/iter. ETA=0:03:43\n",
      "\u001b[32m[07/07 13:50:16 d2.evaluation.evaluator]: \u001b[0mInference done 4919/7230. Dataloading: 0.0024 s/iter. Inference: 0.0370 s/iter. Eval: 0.0542 s/iter. Total: 0.0937 s/iter. ETA=0:03:36\n",
      "\u001b[32m[07/07 13:50:21 d2.evaluation.evaluator]: \u001b[0mInference done 4986/7230. Dataloading: 0.0024 s/iter. Inference: 0.0370 s/iter. Eval: 0.0539 s/iter. Total: 0.0934 s/iter. ETA=0:03:29\n",
      "\u001b[32m[07/07 13:50:26 d2.evaluation.evaluator]: \u001b[0mInference done 5052/7230. Dataloading: 0.0024 s/iter. Inference: 0.0370 s/iter. Eval: 0.0537 s/iter. Total: 0.0932 s/iter. ETA=0:03:22\n",
      "\u001b[32m[07/07 13:50:31 d2.evaluation.evaluator]: \u001b[0mInference done 5119/7230. Dataloading: 0.0024 s/iter. Inference: 0.0370 s/iter. Eval: 0.0535 s/iter. Total: 0.0929 s/iter. ETA=0:03:16\n",
      "\u001b[32m[07/07 13:50:36 d2.evaluation.evaluator]: \u001b[0mInference done 5185/7230. Dataloading: 0.0024 s/iter. Inference: 0.0370 s/iter. Eval: 0.0533 s/iter. Total: 0.0927 s/iter. ETA=0:03:09\n",
      "\u001b[32m[07/07 13:50:41 d2.evaluation.evaluator]: \u001b[0mInference done 5251/7230. Dataloading: 0.0024 s/iter. Inference: 0.0369 s/iter. Eval: 0.0531 s/iter. Total: 0.0925 s/iter. ETA=0:03:03\n",
      "\u001b[32m[07/07 13:50:46 d2.evaluation.evaluator]: \u001b[0mInference done 5316/7230. Dataloading: 0.0024 s/iter. Inference: 0.0369 s/iter. Eval: 0.0530 s/iter. Total: 0.0923 s/iter. ETA=0:02:56\n",
      "\u001b[32m[07/07 13:50:51 d2.evaluation.evaluator]: \u001b[0mInference done 5383/7230. Dataloading: 0.0024 s/iter. Inference: 0.0369 s/iter. Eval: 0.0528 s/iter. Total: 0.0921 s/iter. ETA=0:02:50\n",
      "\u001b[32m[07/07 13:50:56 d2.evaluation.evaluator]: \u001b[0mInference done 5450/7230. Dataloading: 0.0024 s/iter. Inference: 0.0369 s/iter. Eval: 0.0526 s/iter. Total: 0.0919 s/iter. ETA=0:02:43\n",
      "\u001b[32m[07/07 13:51:01 d2.evaluation.evaluator]: \u001b[0mInference done 5516/7230. Dataloading: 0.0024 s/iter. Inference: 0.0369 s/iter. Eval: 0.0524 s/iter. Total: 0.0917 s/iter. ETA=0:02:37\n",
      "\u001b[32m[07/07 13:51:06 d2.evaluation.evaluator]: \u001b[0mInference done 5582/7230. Dataloading: 0.0024 s/iter. Inference: 0.0368 s/iter. Eval: 0.0523 s/iter. Total: 0.0916 s/iter. ETA=0:02:30\n",
      "\u001b[32m[07/07 13:51:11 d2.evaluation.evaluator]: \u001b[0mInference done 5648/7230. Dataloading: 0.0024 s/iter. Inference: 0.0368 s/iter. Eval: 0.0521 s/iter. Total: 0.0914 s/iter. ETA=0:02:24\n",
      "\u001b[32m[07/07 13:51:16 d2.evaluation.evaluator]: \u001b[0mInference done 5714/7230. Dataloading: 0.0024 s/iter. Inference: 0.0368 s/iter. Eval: 0.0519 s/iter. Total: 0.0912 s/iter. ETA=0:02:18\n",
      "\u001b[32m[07/07 13:51:21 d2.evaluation.evaluator]: \u001b[0mInference done 5781/7230. Dataloading: 0.0024 s/iter. Inference: 0.0368 s/iter. Eval: 0.0518 s/iter. Total: 0.0910 s/iter. ETA=0:02:11\n",
      "\u001b[32m[07/07 13:51:26 d2.evaluation.evaluator]: \u001b[0mInference done 5847/7230. Dataloading: 0.0024 s/iter. Inference: 0.0368 s/iter. Eval: 0.0516 s/iter. Total: 0.0909 s/iter. ETA=0:02:05\n",
      "\u001b[32m[07/07 13:51:31 d2.evaluation.evaluator]: \u001b[0mInference done 5913/7230. Dataloading: 0.0024 s/iter. Inference: 0.0368 s/iter. Eval: 0.0515 s/iter. Total: 0.0907 s/iter. ETA=0:01:59\n",
      "\u001b[32m[07/07 13:51:36 d2.evaluation.evaluator]: \u001b[0mInference done 5979/7230. Dataloading: 0.0024 s/iter. Inference: 0.0368 s/iter. Eval: 0.0513 s/iter. Total: 0.0905 s/iter. ETA=0:01:53\n",
      "\u001b[32m[07/07 13:51:41 d2.evaluation.evaluator]: \u001b[0mInference done 6046/7230. Dataloading: 0.0024 s/iter. Inference: 0.0367 s/iter. Eval: 0.0512 s/iter. Total: 0.0904 s/iter. ETA=0:01:46\n",
      "\u001b[32m[07/07 13:51:46 d2.evaluation.evaluator]: \u001b[0mInference done 6113/7230. Dataloading: 0.0024 s/iter. Inference: 0.0367 s/iter. Eval: 0.0510 s/iter. Total: 0.0902 s/iter. ETA=0:01:40\n",
      "\u001b[32m[07/07 13:51:51 d2.evaluation.evaluator]: \u001b[0mInference done 6180/7230. Dataloading: 0.0024 s/iter. Inference: 0.0367 s/iter. Eval: 0.0509 s/iter. Total: 0.0900 s/iter. ETA=0:01:34\n",
      "\u001b[32m[07/07 13:51:56 d2.evaluation.evaluator]: \u001b[0mInference done 6246/7230. Dataloading: 0.0024 s/iter. Inference: 0.0367 s/iter. Eval: 0.0507 s/iter. Total: 0.0899 s/iter. ETA=0:01:28\n",
      "\u001b[32m[07/07 13:52:01 d2.evaluation.evaluator]: \u001b[0mInference done 6312/7230. Dataloading: 0.0024 s/iter. Inference: 0.0367 s/iter. Eval: 0.0506 s/iter. Total: 0.0897 s/iter. ETA=0:01:22\n",
      "\u001b[32m[07/07 13:52:06 d2.evaluation.evaluator]: \u001b[0mInference done 6378/7230. Dataloading: 0.0024 s/iter. Inference: 0.0367 s/iter. Eval: 0.0505 s/iter. Total: 0.0896 s/iter. ETA=0:01:16\n",
      "\u001b[32m[07/07 13:52:11 d2.evaluation.evaluator]: \u001b[0mInference done 6443/7230. Dataloading: 0.0024 s/iter. Inference: 0.0367 s/iter. Eval: 0.0504 s/iter. Total: 0.0895 s/iter. ETA=0:01:10\n",
      "\u001b[32m[07/07 13:52:16 d2.evaluation.evaluator]: \u001b[0mInference done 6508/7230. Dataloading: 0.0024 s/iter. Inference: 0.0367 s/iter. Eval: 0.0502 s/iter. Total: 0.0894 s/iter. ETA=0:01:04\n",
      "\u001b[32m[07/07 13:52:21 d2.evaluation.evaluator]: \u001b[0mInference done 6574/7230. Dataloading: 0.0024 s/iter. Inference: 0.0367 s/iter. Eval: 0.0501 s/iter. Total: 0.0892 s/iter. ETA=0:00:58\n",
      "\u001b[32m[07/07 13:52:27 d2.evaluation.evaluator]: \u001b[0mInference done 6639/7230. Dataloading: 0.0024 s/iter. Inference: 0.0366 s/iter. Eval: 0.0500 s/iter. Total: 0.0891 s/iter. ETA=0:00:52\n",
      "\u001b[32m[07/07 13:52:32 d2.evaluation.evaluator]: \u001b[0mInference done 6704/7230. Dataloading: 0.0024 s/iter. Inference: 0.0366 s/iter. Eval: 0.0499 s/iter. Total: 0.0890 s/iter. ETA=0:00:46\n",
      "\u001b[32m[07/07 13:52:37 d2.evaluation.evaluator]: \u001b[0mInference done 6769/7230. Dataloading: 0.0024 s/iter. Inference: 0.0366 s/iter. Eval: 0.0498 s/iter. Total: 0.0889 s/iter. ETA=0:00:40\n",
      "\u001b[32m[07/07 13:52:42 d2.evaluation.evaluator]: \u001b[0mInference done 6833/7230. Dataloading: 0.0024 s/iter. Inference: 0.0366 s/iter. Eval: 0.0497 s/iter. Total: 0.0888 s/iter. ETA=0:00:35\n",
      "\u001b[32m[07/07 13:52:47 d2.evaluation.evaluator]: \u001b[0mInference done 6896/7230. Dataloading: 0.0024 s/iter. Inference: 0.0366 s/iter. Eval: 0.0496 s/iter. Total: 0.0887 s/iter. ETA=0:00:29\n",
      "\u001b[32m[07/07 13:52:52 d2.evaluation.evaluator]: \u001b[0mInference done 6959/7230. Dataloading: 0.0024 s/iter. Inference: 0.0366 s/iter. Eval: 0.0496 s/iter. Total: 0.0886 s/iter. ETA=0:00:24\n",
      "\u001b[32m[07/07 13:52:57 d2.evaluation.evaluator]: \u001b[0mInference done 7027/7230. Dataloading: 0.0024 s/iter. Inference: 0.0366 s/iter. Eval: 0.0494 s/iter. Total: 0.0885 s/iter. ETA=0:00:17\n",
      "\u001b[32m[07/07 13:53:02 d2.evaluation.evaluator]: \u001b[0mInference done 7092/7230. Dataloading: 0.0024 s/iter. Inference: 0.0366 s/iter. Eval: 0.0494 s/iter. Total: 0.0884 s/iter. ETA=0:00:12\n",
      "\u001b[32m[07/07 13:53:07 d2.evaluation.evaluator]: \u001b[0mInference done 7157/7230. Dataloading: 0.0024 s/iter. Inference: 0.0366 s/iter. Eval: 0.0493 s/iter. Total: 0.0883 s/iter. ETA=0:00:06\n",
      "\u001b[32m[07/07 13:53:12 d2.evaluation.evaluator]: \u001b[0mInference done 7224/7230. Dataloading: 0.0024 s/iter. Inference: 0.0366 s/iter. Eval: 0.0492 s/iter. Total: 0.0882 s/iter. ETA=0:00:00\n",
      "\u001b[32m[07/07 13:53:12 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:10:36.925120 (0.088156 s / iter per device, on 1 devices)\n",
      "\u001b[32m[07/07 13:53:12 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:04:24 (0.036554 s / iter per device, on 1 devices)\n",
      "\u001b[32m[07/07 13:53:14 d2.evaluation.sem_seg_evaluation]: \u001b[0mOrderedDict([('sem_seg', {'mIoU': 51.60186627612484, 'fwIoU': 68.78245093838402, 'IoU-Unlabeled': nan, 'IoU-Building': 59.55569913948251, 'IoU-Fence': 28.59741426329138, 'IoU-Pedestrian': 69.53155230543636, 'IoU-Pole': 48.08423184094136, 'IoU-Road': 93.15167861185726, 'IoU-SideWalk': 67.58010792479058, 'IoU-Vegetation': 59.18984633675615, 'IoU-Vehicles': 73.33885142420756, 'IoU-Wall': 41.10699698990764, 'IoU-TrafficSign': 53.96121609213627, 'IoU-Sky': 46.06393497075917, 'IoU-TrafficLight': 54.492262421422296, 'IoU-Terrain': 26.189140479140814, 'IoU-ConstructionVehicle': 85.88495533874135, 'IoU-workzone_object': 60.86528433838415, 'IoU-Detour': 9.63855421686747, 'mACC': 66.86095126659852, 'pACC': 80.58732639923804, 'ACC-Unlabeled': nan, 'ACC-Building': 96.5533049487041, 'ACC-Fence': 36.69877186528588, 'ACC-Pedestrian': 85.17464517185044, 'ACC-Pole': 58.50580334107469, 'ACC-Road': 95.73294133699733, 'ACC-SideWalk': 82.1758636590519, 'ACC-Vegetation': 80.67310891573129, 'ACC-Vehicles': 91.25436986474017, 'ACC-Wall': 55.773706333843585, 'ACC-TrafficSign': 63.74343567537557, 'ACC-Sky': 46.37003279949935, 'ACC-TrafficLight': 62.675858180623614, 'ACC-Terrain': 28.313844864806132, 'ACC-ConstructionVehicle': 91.36249924066291, 'ACC-workzone_object': 81.30931574401222, 'ACC-Detour': 13.457718323317156})])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/07 13:53:14 d2.engine.defaults]: \u001b[0mEvaluation results for combined_clear_both_val in csv format:\n",
      "\u001b[32m[07/07 13:53:14 d2.evaluation.testing]: \u001b[0mcopypaste: Task: sem_seg\n",
      "\u001b[32m[07/07 13:53:14 d2.evaluation.testing]: \u001b[0mcopypaste: mIoU,fwIoU,mACC,pACC\n",
      "\u001b[32m[07/07 13:53:14 d2.evaluation.testing]: \u001b[0mcopypaste: 51.6019,68.7825,66.8610,80.5873\n"
     ]
    }
   ],
   "source": [
    "#all clear\n",
    "trainer_both = Detectron2Trainer('combined_clear_both_train', 'combined_clear_both_val', output_folder='./output_both_clear_40k')\n",
    "trainer_both.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fe5db305",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/06 04:52:10 d2.engine.defaults]: \u001b[0mModel:\n",
      "SemanticSegmentor(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (sem_seg_head): SemSegFPNHead(\n",
      "    (p2): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "    )\n",
      "    (p3): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (1): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "    )\n",
      "    (p4): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (1): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      (2): Conv2d(\n",
      "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (3): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "    )\n",
      "    (p5): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (1): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      (2): Conv2d(\n",
      "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (3): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      (4): Conv2d(\n",
      "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (5): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "    )\n",
      "    (predictor): Conv2d(128, 17, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/06 04:52:10 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(720, 720), max_size=2048, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[07/06 04:52:10 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[07/06 04:52:10 d2.data.common]: \u001b[0mSerializing 2286 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[07/06 04:52:10 d2.data.common]: \u001b[0mSerialized dataset takes 0.84 MiB\n",
      "Last checkpoint: model_final.pth\n",
      "\u001b[32m[07/06 04:52:10 d2.checkpoint.c2_model_loading]: \u001b[0mFollowing weights matched with model:\n",
      "| Names in Model                       | Names in Checkpoint                                                                                  | Shapes                                          |\n",
      "|:-------------------------------------|:-----------------------------------------------------------------------------------------------------|:------------------------------------------------|\n",
      "| backbone.bottom_up.res2.0.conv1.*    | backbone.bottom_up.res2.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,1,1)             |\n",
      "| backbone.bottom_up.res2.0.conv2.*    | backbone.bottom_up.res2.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |\n",
      "| backbone.bottom_up.res2.0.conv3.*    | backbone.bottom_up.res2.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res2.0.shortcut.* | backbone.bottom_up.res2.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res2.1.conv1.*    | backbone.bottom_up.res2.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |\n",
      "| backbone.bottom_up.res2.1.conv2.*    | backbone.bottom_up.res2.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |\n",
      "| backbone.bottom_up.res2.1.conv3.*    | backbone.bottom_up.res2.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res2.2.conv1.*    | backbone.bottom_up.res2.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |\n",
      "| backbone.bottom_up.res2.2.conv2.*    | backbone.bottom_up.res2.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |\n",
      "| backbone.bottom_up.res2.2.conv3.*    | backbone.bottom_up.res2.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res3.0.conv1.*    | backbone.bottom_up.res3.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,256,1,1)       |\n",
      "| backbone.bottom_up.res3.0.conv2.*    | backbone.bottom_up.res3.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.0.conv3.*    | backbone.bottom_up.res3.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res3.0.shortcut.* | backbone.bottom_up.res3.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (512,) (512,) (512,) (512,) (512,256,1,1)       |\n",
      "| backbone.bottom_up.res3.1.conv1.*    | backbone.bottom_up.res3.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |\n",
      "| backbone.bottom_up.res3.1.conv2.*    | backbone.bottom_up.res3.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.1.conv3.*    | backbone.bottom_up.res3.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res3.2.conv1.*    | backbone.bottom_up.res3.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |\n",
      "| backbone.bottom_up.res3.2.conv2.*    | backbone.bottom_up.res3.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.2.conv3.*    | backbone.bottom_up.res3.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res3.3.conv1.*    | backbone.bottom_up.res3.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |\n",
      "| backbone.bottom_up.res3.3.conv2.*    | backbone.bottom_up.res3.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.3.conv3.*    | backbone.bottom_up.res3.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res4.0.conv1.*    | backbone.bottom_up.res4.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,512,1,1)       |\n",
      "| backbone.bottom_up.res4.0.conv2.*    | backbone.bottom_up.res4.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.0.conv3.*    | backbone.bottom_up.res4.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.0.shortcut.* | backbone.bottom_up.res4.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (1024,) (1024,) (1024,) (1024,) (1024,512,1,1)  |\n",
      "| backbone.bottom_up.res4.1.conv1.*    | backbone.bottom_up.res4.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.1.conv2.*    | backbone.bottom_up.res4.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.1.conv3.*    | backbone.bottom_up.res4.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.2.conv1.*    | backbone.bottom_up.res4.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.2.conv2.*    | backbone.bottom_up.res4.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.2.conv3.*    | backbone.bottom_up.res4.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.3.conv1.*    | backbone.bottom_up.res4.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.3.conv2.*    | backbone.bottom_up.res4.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.3.conv3.*    | backbone.bottom_up.res4.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.4.conv1.*    | backbone.bottom_up.res4.4.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.4.conv2.*    | backbone.bottom_up.res4.4.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.4.conv3.*    | backbone.bottom_up.res4.4.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.5.conv1.*    | backbone.bottom_up.res4.5.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.5.conv2.*    | backbone.bottom_up.res4.5.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.5.conv3.*    | backbone.bottom_up.res4.5.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res5.0.conv1.*    | backbone.bottom_up.res5.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,1024,1,1)      |\n",
      "| backbone.bottom_up.res5.0.conv2.*    | backbone.bottom_up.res5.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |\n",
      "| backbone.bottom_up.res5.0.conv3.*    | backbone.bottom_up.res5.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
      "| backbone.bottom_up.res5.0.shortcut.* | backbone.bottom_up.res5.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (2048,) (2048,) (2048,) (2048,) (2048,1024,1,1) |\n",
      "| backbone.bottom_up.res5.1.conv1.*    | backbone.bottom_up.res5.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |\n",
      "| backbone.bottom_up.res5.1.conv2.*    | backbone.bottom_up.res5.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |\n",
      "| backbone.bottom_up.res5.1.conv3.*    | backbone.bottom_up.res5.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
      "| backbone.bottom_up.res5.2.conv1.*    | backbone.bottom_up.res5.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |\n",
      "| backbone.bottom_up.res5.2.conv2.*    | backbone.bottom_up.res5.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |\n",
      "| backbone.bottom_up.res5.2.conv3.*    | backbone.bottom_up.res5.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
      "| backbone.bottom_up.stem.conv1.*      | backbone.bottom_up.stem.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}      | (64,) (64,) (64,) (64,) (64,3,7,7)              |\n",
      "| backbone.fpn_lateral2.*              | backbone.fpn_lateral2.{bias,weight}                                                                  | (256,) (256,256,1,1)                            |\n",
      "| backbone.fpn_lateral3.*              | backbone.fpn_lateral3.{bias,weight}                                                                  | (256,) (256,512,1,1)                            |\n",
      "| backbone.fpn_lateral4.*              | backbone.fpn_lateral4.{bias,weight}                                                                  | (256,) (256,1024,1,1)                           |\n",
      "| backbone.fpn_lateral5.*              | backbone.fpn_lateral5.{bias,weight}                                                                  | (256,) (256,2048,1,1)                           |\n",
      "| backbone.fpn_output2.*               | backbone.fpn_output2.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| backbone.fpn_output3.*               | backbone.fpn_output3.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| backbone.fpn_output4.*               | backbone.fpn_output4.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| backbone.fpn_output5.*               | backbone.fpn_output5.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| sem_seg_head.p2.0.*                  | sem_seg_head.p2.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p3.0.*                  | sem_seg_head.p3.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p4.0.*                  | sem_seg_head.p4.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p4.2.*                  | sem_seg_head.p4.2.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,128,3,3)                     |\n",
      "| sem_seg_head.p5.0.*                  | sem_seg_head.p5.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p5.2.*                  | sem_seg_head.p5.2.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,128,3,3)                     |\n",
      "| sem_seg_head.p5.4.*                  | sem_seg_head.p5.4.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,128,3,3)                     |\n",
      "| sem_seg_head.predictor.*             | sem_seg_head.predictor.{bias,weight}                                                                 | (17,) (17,128,1,1)                              |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/06 04:52:10 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(720, 720), max_size=2048, sample_style='choice')]\n",
      "\u001b[32m[07/06 04:52:10 d2.data.common]: \u001b[0mSerializing 2191 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[07/06 04:52:10 d2.data.common]: \u001b[0mSerialized dataset takes 0.81 MiB\n",
      "\u001b[32m[07/06 04:52:10 d2.evaluation.evaluator]: \u001b[0mStart inference on 2191 batches\n",
      "\u001b[32m[07/06 04:52:11 d2.evaluation.evaluator]: \u001b[0mInference done 11/2191. Dataloading: 0.0017 s/iter. Inference: 0.0352 s/iter. Eval: 0.0417 s/iter. Total: 0.0786 s/iter. ETA=0:02:51\n",
      "\u001b[32m[07/06 04:52:17 d2.evaluation.evaluator]: \u001b[0mInference done 77/2191. Dataloading: 0.0022 s/iter. Inference: 0.0348 s/iter. Eval: 0.0397 s/iter. Total: 0.0768 s/iter. ETA=0:02:42\n",
      "\u001b[32m[07/06 04:52:22 d2.evaluation.evaluator]: \u001b[0mInference done 143/2191. Dataloading: 0.0023 s/iter. Inference: 0.0348 s/iter. Eval: 0.0391 s/iter. Total: 0.0763 s/iter. ETA=0:02:36\n",
      "\u001b[32m[07/06 04:52:27 d2.evaluation.evaluator]: \u001b[0mInference done 210/2191. Dataloading: 0.0023 s/iter. Inference: 0.0349 s/iter. Eval: 0.0388 s/iter. Total: 0.0761 s/iter. ETA=0:02:30\n",
      "\u001b[32m[07/06 04:52:32 d2.evaluation.evaluator]: \u001b[0mInference done 276/2191. Dataloading: 0.0023 s/iter. Inference: 0.0349 s/iter. Eval: 0.0387 s/iter. Total: 0.0760 s/iter. ETA=0:02:25\n",
      "\u001b[32m[07/06 04:52:37 d2.evaluation.evaluator]: \u001b[0mInference done 342/2191. Dataloading: 0.0023 s/iter. Inference: 0.0350 s/iter. Eval: 0.0388 s/iter. Total: 0.0761 s/iter. ETA=0:02:20\n",
      "\u001b[32m[07/06 04:52:42 d2.evaluation.evaluator]: \u001b[0mInference done 408/2191. Dataloading: 0.0023 s/iter. Inference: 0.0350 s/iter. Eval: 0.0388 s/iter. Total: 0.0762 s/iter. ETA=0:02:15\n",
      "\u001b[32m[07/06 04:52:47 d2.evaluation.evaluator]: \u001b[0mInference done 474/2191. Dataloading: 0.0023 s/iter. Inference: 0.0350 s/iter. Eval: 0.0389 s/iter. Total: 0.0763 s/iter. ETA=0:02:11\n",
      "\u001b[32m[07/06 04:52:52 d2.evaluation.evaluator]: \u001b[0mInference done 539/2191. Dataloading: 0.0023 s/iter. Inference: 0.0350 s/iter. Eval: 0.0390 s/iter. Total: 0.0764 s/iter. ETA=0:02:06\n",
      "\u001b[32m[07/06 04:52:57 d2.evaluation.evaluator]: \u001b[0mInference done 602/2191. Dataloading: 0.0023 s/iter. Inference: 0.0352 s/iter. Eval: 0.0391 s/iter. Total: 0.0768 s/iter. ETA=0:02:01\n",
      "\u001b[32m[07/06 04:53:02 d2.evaluation.evaluator]: \u001b[0mInference done 666/2191. Dataloading: 0.0023 s/iter. Inference: 0.0352 s/iter. Eval: 0.0393 s/iter. Total: 0.0769 s/iter. ETA=0:01:57\n",
      "\u001b[32m[07/06 04:53:07 d2.evaluation.evaluator]: \u001b[0mInference done 732/2191. Dataloading: 0.0023 s/iter. Inference: 0.0352 s/iter. Eval: 0.0393 s/iter. Total: 0.0769 s/iter. ETA=0:01:52\n",
      "\u001b[32m[07/06 04:53:12 d2.evaluation.evaluator]: \u001b[0mInference done 798/2191. Dataloading: 0.0023 s/iter. Inference: 0.0352 s/iter. Eval: 0.0392 s/iter. Total: 0.0769 s/iter. ETA=0:01:47\n",
      "\u001b[32m[07/06 04:53:17 d2.evaluation.evaluator]: \u001b[0mInference done 864/2191. Dataloading: 0.0023 s/iter. Inference: 0.0352 s/iter. Eval: 0.0392 s/iter. Total: 0.0769 s/iter. ETA=0:01:42\n",
      "\u001b[32m[07/06 04:53:22 d2.evaluation.evaluator]: \u001b[0mInference done 929/2191. Dataloading: 0.0023 s/iter. Inference: 0.0353 s/iter. Eval: 0.0393 s/iter. Total: 0.0769 s/iter. ETA=0:01:37\n",
      "\u001b[32m[07/06 04:53:27 d2.evaluation.evaluator]: \u001b[0mInference done 994/2191. Dataloading: 0.0023 s/iter. Inference: 0.0353 s/iter. Eval: 0.0393 s/iter. Total: 0.0769 s/iter. ETA=0:01:32\n",
      "\u001b[32m[07/06 04:53:32 d2.evaluation.evaluator]: \u001b[0mInference done 1060/2191. Dataloading: 0.0023 s/iter. Inference: 0.0353 s/iter. Eval: 0.0392 s/iter. Total: 0.0769 s/iter. ETA=0:01:26\n",
      "\u001b[32m[07/06 04:53:37 d2.evaluation.evaluator]: \u001b[0mInference done 1125/2191. Dataloading: 0.0023 s/iter. Inference: 0.0353 s/iter. Eval: 0.0393 s/iter. Total: 0.0769 s/iter. ETA=0:01:22\n",
      "\u001b[32m[07/06 04:53:42 d2.evaluation.evaluator]: \u001b[0mInference done 1188/2191. Dataloading: 0.0023 s/iter. Inference: 0.0353 s/iter. Eval: 0.0394 s/iter. Total: 0.0771 s/iter. ETA=0:01:17\n",
      "\u001b[32m[07/06 04:53:47 d2.evaluation.evaluator]: \u001b[0mInference done 1250/2191. Dataloading: 0.0023 s/iter. Inference: 0.0353 s/iter. Eval: 0.0396 s/iter. Total: 0.0773 s/iter. ETA=0:01:12\n",
      "\u001b[32m[07/06 04:53:52 d2.evaluation.evaluator]: \u001b[0mInference done 1312/2191. Dataloading: 0.0023 s/iter. Inference: 0.0353 s/iter. Eval: 0.0398 s/iter. Total: 0.0774 s/iter. ETA=0:01:08\n",
      "\u001b[32m[07/06 04:53:57 d2.evaluation.evaluator]: \u001b[0mInference done 1375/2191. Dataloading: 0.0023 s/iter. Inference: 0.0353 s/iter. Eval: 0.0399 s/iter. Total: 0.0775 s/iter. ETA=0:01:03\n",
      "\u001b[32m[07/06 04:54:02 d2.evaluation.evaluator]: \u001b[0mInference done 1442/2191. Dataloading: 0.0023 s/iter. Inference: 0.0353 s/iter. Eval: 0.0398 s/iter. Total: 0.0774 s/iter. ETA=0:00:57\n",
      "\u001b[32m[07/06 04:54:07 d2.evaluation.evaluator]: \u001b[0mInference done 1508/2191. Dataloading: 0.0023 s/iter. Inference: 0.0353 s/iter. Eval: 0.0397 s/iter. Total: 0.0773 s/iter. ETA=0:00:52\n",
      "\u001b[32m[07/06 04:54:12 d2.evaluation.evaluator]: \u001b[0mInference done 1574/2191. Dataloading: 0.0023 s/iter. Inference: 0.0353 s/iter. Eval: 0.0396 s/iter. Total: 0.0773 s/iter. ETA=0:00:47\n",
      "\u001b[32m[07/06 04:54:17 d2.evaluation.evaluator]: \u001b[0mInference done 1639/2191. Dataloading: 0.0023 s/iter. Inference: 0.0353 s/iter. Eval: 0.0397 s/iter. Total: 0.0773 s/iter. ETA=0:00:42\n",
      "\u001b[32m[07/06 04:54:22 d2.evaluation.evaluator]: \u001b[0mInference done 1705/2191. Dataloading: 0.0023 s/iter. Inference: 0.0353 s/iter. Eval: 0.0396 s/iter. Total: 0.0773 s/iter. ETA=0:00:37\n",
      "\u001b[32m[07/06 04:54:27 d2.evaluation.evaluator]: \u001b[0mInference done 1771/2191. Dataloading: 0.0023 s/iter. Inference: 0.0353 s/iter. Eval: 0.0396 s/iter. Total: 0.0773 s/iter. ETA=0:00:32\n",
      "\u001b[32m[07/06 04:54:32 d2.evaluation.evaluator]: \u001b[0mInference done 1837/2191. Dataloading: 0.0023 s/iter. Inference: 0.0353 s/iter. Eval: 0.0395 s/iter. Total: 0.0772 s/iter. ETA=0:00:27\n",
      "\u001b[32m[07/06 04:54:38 d2.evaluation.evaluator]: \u001b[0mInference done 1903/2191. Dataloading: 0.0023 s/iter. Inference: 0.0353 s/iter. Eval: 0.0395 s/iter. Total: 0.0772 s/iter. ETA=0:00:22\n",
      "\u001b[32m[07/06 04:54:43 d2.evaluation.evaluator]: \u001b[0mInference done 1969/2191. Dataloading: 0.0023 s/iter. Inference: 0.0353 s/iter. Eval: 0.0395 s/iter. Total: 0.0772 s/iter. ETA=0:00:17\n",
      "\u001b[32m[07/06 04:54:48 d2.evaluation.evaluator]: \u001b[0mInference done 2035/2191. Dataloading: 0.0023 s/iter. Inference: 0.0353 s/iter. Eval: 0.0394 s/iter. Total: 0.0772 s/iter. ETA=0:00:12\n",
      "\u001b[32m[07/06 04:54:53 d2.evaluation.evaluator]: \u001b[0mInference done 2099/2191. Dataloading: 0.0023 s/iter. Inference: 0.0353 s/iter. Eval: 0.0395 s/iter. Total: 0.0772 s/iter. ETA=0:00:07\n",
      "\u001b[32m[07/06 04:54:58 d2.evaluation.evaluator]: \u001b[0mInference done 2166/2191. Dataloading: 0.0023 s/iter. Inference: 0.0353 s/iter. Eval: 0.0394 s/iter. Total: 0.0771 s/iter. ETA=0:00:01\n",
      "\u001b[32m[07/06 04:55:00 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:02:48.661016 (0.077155 s / iter per device, on 1 devices)\n",
      "\u001b[32m[07/06 04:55:00 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:01:17 (0.035341 s / iter per device, on 1 devices)\n",
      "\u001b[32m[07/06 04:55:00 d2.evaluation.sem_seg_evaluation]: \u001b[0mOrderedDict([('sem_seg', {'mIoU': 47.13831553828105, 'fwIoU': 63.869316402419415, 'IoU-Unlabeled': nan, 'IoU-Building': 51.22974920396123, 'IoU-Fence': 22.165029009901133, 'IoU-Pedestrian': 23.379534488184824, 'IoU-Pole': 46.72541920568305, 'IoU-Road': 88.13623878004965, 'IoU-SideWalk': 61.32361593793375, 'IoU-Vegetation': 55.906681752306945, 'IoU-Vehicles': 38.593360391033336, 'IoU-Wall': 45.77109594935323, 'IoU-TrafficSign': 44.69653366240339, 'IoU-Sky': 48.9326954479969, 'IoU-TrafficLight': 59.67495626174723, 'IoU-Terrain': 19.851295356934624, 'IoU-ConstructionVehicle': 84.29871170512362, 'IoU-workzone_object': 54.565953734455384, 'IoU-Detour': 8.962177725428608, 'mACC': 63.1515218936127, 'pACC': 76.16343399222188, 'ACC-Unlabeled': nan, 'ACC-Building': 96.84274647687975, 'ACC-Fence': 28.813088145730507, 'ACC-Pedestrian': 66.18988587678597, 'ACC-Pole': 55.96352024915148, 'ACC-Road': 90.91140038699567, 'ACC-SideWalk': 77.99711201963456, 'ACC-Vegetation': 65.65055155661038, 'ACC-Vehicles': 89.35426662469489, 'ACC-Wall': 57.219339688889335, 'ACC-TrafficSign': 55.78198976480767, 'ACC-Sky': 49.554235180539784, 'ACC-TrafficLight': 69.61620077567775, 'ACC-Terrain': 21.097226441711044, 'ACC-ConstructionVehicle': 91.94772961104806, 'ACC-workzone_object': 80.32038373187342, 'ACC-Detour': 13.164673766773042})])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/06 04:55:00 d2.engine.defaults]: \u001b[0mEvaluation results for carla_both_rain_val in csv format:\n",
      "\u001b[32m[07/06 04:55:00 d2.evaluation.testing]: \u001b[0mcopypaste: Task: sem_seg\n",
      "\u001b[32m[07/06 04:55:00 d2.evaluation.testing]: \u001b[0mcopypaste: mIoU,fwIoU,mACC,pACC\n",
      "\u001b[32m[07/06 04:55:00 d2.evaluation.testing]: \u001b[0mcopypaste: 47.1383,63.8693,63.1515,76.1634\n"
     ]
    }
   ],
   "source": [
    "#all carla rain\n",
    "trainer_both = Detectron2Trainer('combined_clear_both_train', 'carla_both_rain_val', output_folder='./output_both_clear_40k')\n",
    "trainer_both.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d4caf169",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/06 04:55:00 d2.engine.defaults]: \u001b[0mModel:\n",
      "SemanticSegmentor(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (sem_seg_head): SemSegFPNHead(\n",
      "    (p2): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "    )\n",
      "    (p3): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (1): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "    )\n",
      "    (p4): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (1): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      (2): Conv2d(\n",
      "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (3): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "    )\n",
      "    (p5): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (1): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      (2): Conv2d(\n",
      "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (3): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      (4): Conv2d(\n",
      "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (5): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "    )\n",
      "    (predictor): Conv2d(128, 17, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/06 04:55:00 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(720, 720), max_size=2048, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[07/06 04:55:00 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[07/06 04:55:00 d2.data.common]: \u001b[0mSerializing 2286 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[07/06 04:55:00 d2.data.common]: \u001b[0mSerialized dataset takes 0.84 MiB\n",
      "Last checkpoint: model_final.pth\n",
      "\u001b[32m[07/06 04:55:01 d2.checkpoint.c2_model_loading]: \u001b[0mFollowing weights matched with model:\n",
      "| Names in Model                       | Names in Checkpoint                                                                                  | Shapes                                          |\n",
      "|:-------------------------------------|:-----------------------------------------------------------------------------------------------------|:------------------------------------------------|\n",
      "| backbone.bottom_up.res2.0.conv1.*    | backbone.bottom_up.res2.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,1,1)             |\n",
      "| backbone.bottom_up.res2.0.conv2.*    | backbone.bottom_up.res2.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |\n",
      "| backbone.bottom_up.res2.0.conv3.*    | backbone.bottom_up.res2.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res2.0.shortcut.* | backbone.bottom_up.res2.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res2.1.conv1.*    | backbone.bottom_up.res2.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |\n",
      "| backbone.bottom_up.res2.1.conv2.*    | backbone.bottom_up.res2.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |\n",
      "| backbone.bottom_up.res2.1.conv3.*    | backbone.bottom_up.res2.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res2.2.conv1.*    | backbone.bottom_up.res2.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |\n",
      "| backbone.bottom_up.res2.2.conv2.*    | backbone.bottom_up.res2.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |\n",
      "| backbone.bottom_up.res2.2.conv3.*    | backbone.bottom_up.res2.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res3.0.conv1.*    | backbone.bottom_up.res3.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,256,1,1)       |\n",
      "| backbone.bottom_up.res3.0.conv2.*    | backbone.bottom_up.res3.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.0.conv3.*    | backbone.bottom_up.res3.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res3.0.shortcut.* | backbone.bottom_up.res3.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (512,) (512,) (512,) (512,) (512,256,1,1)       |\n",
      "| backbone.bottom_up.res3.1.conv1.*    | backbone.bottom_up.res3.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |\n",
      "| backbone.bottom_up.res3.1.conv2.*    | backbone.bottom_up.res3.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.1.conv3.*    | backbone.bottom_up.res3.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res3.2.conv1.*    | backbone.bottom_up.res3.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |\n",
      "| backbone.bottom_up.res3.2.conv2.*    | backbone.bottom_up.res3.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.2.conv3.*    | backbone.bottom_up.res3.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res3.3.conv1.*    | backbone.bottom_up.res3.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |\n",
      "| backbone.bottom_up.res3.3.conv2.*    | backbone.bottom_up.res3.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.3.conv3.*    | backbone.bottom_up.res3.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res4.0.conv1.*    | backbone.bottom_up.res4.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,512,1,1)       |\n",
      "| backbone.bottom_up.res4.0.conv2.*    | backbone.bottom_up.res4.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.0.conv3.*    | backbone.bottom_up.res4.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.0.shortcut.* | backbone.bottom_up.res4.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (1024,) (1024,) (1024,) (1024,) (1024,512,1,1)  |\n",
      "| backbone.bottom_up.res4.1.conv1.*    | backbone.bottom_up.res4.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.1.conv2.*    | backbone.bottom_up.res4.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.1.conv3.*    | backbone.bottom_up.res4.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.2.conv1.*    | backbone.bottom_up.res4.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.2.conv2.*    | backbone.bottom_up.res4.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.2.conv3.*    | backbone.bottom_up.res4.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.3.conv1.*    | backbone.bottom_up.res4.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.3.conv2.*    | backbone.bottom_up.res4.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.3.conv3.*    | backbone.bottom_up.res4.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.4.conv1.*    | backbone.bottom_up.res4.4.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.4.conv2.*    | backbone.bottom_up.res4.4.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.4.conv3.*    | backbone.bottom_up.res4.4.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.5.conv1.*    | backbone.bottom_up.res4.5.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.5.conv2.*    | backbone.bottom_up.res4.5.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.5.conv3.*    | backbone.bottom_up.res4.5.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res5.0.conv1.*    | backbone.bottom_up.res5.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,1024,1,1)      |\n",
      "| backbone.bottom_up.res5.0.conv2.*    | backbone.bottom_up.res5.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |\n",
      "| backbone.bottom_up.res5.0.conv3.*    | backbone.bottom_up.res5.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
      "| backbone.bottom_up.res5.0.shortcut.* | backbone.bottom_up.res5.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (2048,) (2048,) (2048,) (2048,) (2048,1024,1,1) |\n",
      "| backbone.bottom_up.res5.1.conv1.*    | backbone.bottom_up.res5.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |\n",
      "| backbone.bottom_up.res5.1.conv2.*    | backbone.bottom_up.res5.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |\n",
      "| backbone.bottom_up.res5.1.conv3.*    | backbone.bottom_up.res5.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
      "| backbone.bottom_up.res5.2.conv1.*    | backbone.bottom_up.res5.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |\n",
      "| backbone.bottom_up.res5.2.conv2.*    | backbone.bottom_up.res5.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |\n",
      "| backbone.bottom_up.res5.2.conv3.*    | backbone.bottom_up.res5.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
      "| backbone.bottom_up.stem.conv1.*      | backbone.bottom_up.stem.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}      | (64,) (64,) (64,) (64,) (64,3,7,7)              |\n",
      "| backbone.fpn_lateral2.*              | backbone.fpn_lateral2.{bias,weight}                                                                  | (256,) (256,256,1,1)                            |\n",
      "| backbone.fpn_lateral3.*              | backbone.fpn_lateral3.{bias,weight}                                                                  | (256,) (256,512,1,1)                            |\n",
      "| backbone.fpn_lateral4.*              | backbone.fpn_lateral4.{bias,weight}                                                                  | (256,) (256,1024,1,1)                           |\n",
      "| backbone.fpn_lateral5.*              | backbone.fpn_lateral5.{bias,weight}                                                                  | (256,) (256,2048,1,1)                           |\n",
      "| backbone.fpn_output2.*               | backbone.fpn_output2.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| backbone.fpn_output3.*               | backbone.fpn_output3.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| backbone.fpn_output4.*               | backbone.fpn_output4.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| backbone.fpn_output5.*               | backbone.fpn_output5.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| sem_seg_head.p2.0.*                  | sem_seg_head.p2.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p3.0.*                  | sem_seg_head.p3.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p4.0.*                  | sem_seg_head.p4.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p4.2.*                  | sem_seg_head.p4.2.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,128,3,3)                     |\n",
      "| sem_seg_head.p5.0.*                  | sem_seg_head.p5.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p5.2.*                  | sem_seg_head.p5.2.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,128,3,3)                     |\n",
      "| sem_seg_head.p5.4.*                  | sem_seg_head.p5.4.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,128,3,3)                     |\n",
      "| sem_seg_head.predictor.*             | sem_seg_head.predictor.{bias,weight}                                                                 | (17,) (17,128,1,1)                              |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/06 04:55:01 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(720, 720), max_size=2048, sample_style='choice')]\n",
      "\u001b[32m[07/06 04:55:01 d2.data.common]: \u001b[0mSerializing 699 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[07/06 04:55:01 d2.data.common]: \u001b[0mSerialized dataset takes 0.24 MiB\n",
      "\u001b[32m[07/06 04:55:01 d2.evaluation.evaluator]: \u001b[0mStart inference on 699 batches\n",
      "\u001b[32m[07/06 04:55:04 d2.evaluation.evaluator]: \u001b[0mInference done 11/699. Dataloading: 0.0018 s/iter. Inference: 0.0468 s/iter. Eval: 0.1554 s/iter. Total: 0.2040 s/iter. ETA=0:02:20\n",
      "\u001b[32m[07/06 04:55:09 d2.evaluation.evaluator]: \u001b[0mInference done 36/699. Dataloading: 0.0020 s/iter. Inference: 0.0467 s/iter. Eval: 0.1526 s/iter. Total: 0.2014 s/iter. ETA=0:02:13\n",
      "\u001b[32m[07/06 04:55:14 d2.evaluation.evaluator]: \u001b[0mInference done 61/699. Dataloading: 0.0020 s/iter. Inference: 0.0467 s/iter. Eval: 0.1532 s/iter. Total: 0.2020 s/iter. ETA=0:02:08\n",
      "\u001b[32m[07/06 04:55:19 d2.evaluation.evaluator]: \u001b[0mInference done 87/699. Dataloading: 0.0020 s/iter. Inference: 0.0466 s/iter. Eval: 0.1512 s/iter. Total: 0.1999 s/iter. ETA=0:02:02\n",
      "\u001b[32m[07/06 04:55:24 d2.evaluation.evaluator]: \u001b[0mInference done 113/699. Dataloading: 0.0020 s/iter. Inference: 0.0467 s/iter. Eval: 0.1493 s/iter. Total: 0.1981 s/iter. ETA=0:01:56\n",
      "\u001b[32m[07/06 04:55:29 d2.evaluation.evaluator]: \u001b[0mInference done 141/699. Dataloading: 0.0020 s/iter. Inference: 0.0464 s/iter. Eval: 0.1467 s/iter. Total: 0.1953 s/iter. ETA=0:01:48\n",
      "\u001b[32m[07/06 04:55:34 d2.evaluation.evaluator]: \u001b[0mInference done 168/699. Dataloading: 0.0020 s/iter. Inference: 0.0465 s/iter. Eval: 0.1459 s/iter. Total: 0.1944 s/iter. ETA=0:01:43\n",
      "\u001b[32m[07/06 04:55:39 d2.evaluation.evaluator]: \u001b[0mInference done 193/699. Dataloading: 0.0020 s/iter. Inference: 0.0465 s/iter. Eval: 0.1474 s/iter. Total: 0.1960 s/iter. ETA=0:01:39\n",
      "\u001b[32m[07/06 04:55:44 d2.evaluation.evaluator]: \u001b[0mInference done 218/699. Dataloading: 0.0020 s/iter. Inference: 0.0465 s/iter. Eval: 0.1481 s/iter. Total: 0.1967 s/iter. ETA=0:01:34\n",
      "\u001b[32m[07/06 04:55:49 d2.evaluation.evaluator]: \u001b[0mInference done 244/699. Dataloading: 0.0020 s/iter. Inference: 0.0466 s/iter. Eval: 0.1483 s/iter. Total: 0.1970 s/iter. ETA=0:01:29\n",
      "\u001b[32m[07/06 04:55:55 d2.evaluation.evaluator]: \u001b[0mInference done 270/699. Dataloading: 0.0020 s/iter. Inference: 0.0466 s/iter. Eval: 0.1483 s/iter. Total: 0.1970 s/iter. ETA=0:01:24\n",
      "\u001b[32m[07/06 04:56:00 d2.evaluation.evaluator]: \u001b[0mInference done 295/699. Dataloading: 0.0020 s/iter. Inference: 0.0466 s/iter. Eval: 0.1487 s/iter. Total: 0.1974 s/iter. ETA=0:01:19\n",
      "\u001b[32m[07/06 04:56:05 d2.evaluation.evaluator]: \u001b[0mInference done 320/699. Dataloading: 0.0020 s/iter. Inference: 0.0466 s/iter. Eval: 0.1490 s/iter. Total: 0.1977 s/iter. ETA=0:01:14\n",
      "\u001b[32m[07/06 04:56:10 d2.evaluation.evaluator]: \u001b[0mInference done 345/699. Dataloading: 0.0020 s/iter. Inference: 0.0466 s/iter. Eval: 0.1492 s/iter. Total: 0.1980 s/iter. ETA=0:01:10\n",
      "\u001b[32m[07/06 04:56:15 d2.evaluation.evaluator]: \u001b[0mInference done 370/699. Dataloading: 0.0020 s/iter. Inference: 0.0466 s/iter. Eval: 0.1495 s/iter. Total: 0.1983 s/iter. ETA=0:01:05\n",
      "\u001b[32m[07/06 04:56:20 d2.evaluation.evaluator]: \u001b[0mInference done 395/699. Dataloading: 0.0020 s/iter. Inference: 0.0466 s/iter. Eval: 0.1499 s/iter. Total: 0.1987 s/iter. ETA=0:01:00\n",
      "\u001b[32m[07/06 04:56:25 d2.evaluation.evaluator]: \u001b[0mInference done 420/699. Dataloading: 0.0020 s/iter. Inference: 0.0466 s/iter. Eval: 0.1500 s/iter. Total: 0.1988 s/iter. ETA=0:00:55\n",
      "\u001b[32m[07/06 04:56:30 d2.evaluation.evaluator]: \u001b[0mInference done 446/699. Dataloading: 0.0020 s/iter. Inference: 0.0467 s/iter. Eval: 0.1500 s/iter. Total: 0.1988 s/iter. ETA=0:00:50\n",
      "\u001b[32m[07/06 04:56:35 d2.evaluation.evaluator]: \u001b[0mInference done 472/699. Dataloading: 0.0020 s/iter. Inference: 0.0466 s/iter. Eval: 0.1497 s/iter. Total: 0.1985 s/iter. ETA=0:00:45\n",
      "\u001b[32m[07/06 04:56:40 d2.evaluation.evaluator]: \u001b[0mInference done 497/699. Dataloading: 0.0020 s/iter. Inference: 0.0466 s/iter. Eval: 0.1500 s/iter. Total: 0.1987 s/iter. ETA=0:00:40\n",
      "\u001b[32m[07/06 04:56:45 d2.evaluation.evaluator]: \u001b[0mInference done 523/699. Dataloading: 0.0020 s/iter. Inference: 0.0466 s/iter. Eval: 0.1500 s/iter. Total: 0.1988 s/iter. ETA=0:00:34\n",
      "\u001b[32m[07/06 04:56:50 d2.evaluation.evaluator]: \u001b[0mInference done 549/699. Dataloading: 0.0020 s/iter. Inference: 0.0466 s/iter. Eval: 0.1500 s/iter. Total: 0.1988 s/iter. ETA=0:00:29\n",
      "\u001b[32m[07/06 04:56:56 d2.evaluation.evaluator]: \u001b[0mInference done 574/699. Dataloading: 0.0020 s/iter. Inference: 0.0466 s/iter. Eval: 0.1501 s/iter. Total: 0.1989 s/iter. ETA=0:00:24\n",
      "\u001b[32m[07/06 04:57:01 d2.evaluation.evaluator]: \u001b[0mInference done 599/699. Dataloading: 0.0020 s/iter. Inference: 0.0467 s/iter. Eval: 0.1503 s/iter. Total: 0.1990 s/iter. ETA=0:00:19\n",
      "\u001b[32m[07/06 04:57:06 d2.evaluation.evaluator]: \u001b[0mInference done 624/699. Dataloading: 0.0020 s/iter. Inference: 0.0467 s/iter. Eval: 0.1504 s/iter. Total: 0.1991 s/iter. ETA=0:00:14\n",
      "\u001b[32m[07/06 04:57:11 d2.evaluation.evaluator]: \u001b[0mInference done 651/699. Dataloading: 0.0020 s/iter. Inference: 0.0467 s/iter. Eval: 0.1500 s/iter. Total: 0.1988 s/iter. ETA=0:00:09\n",
      "\u001b[32m[07/06 04:57:16 d2.evaluation.evaluator]: \u001b[0mInference done 677/699. Dataloading: 0.0020 s/iter. Inference: 0.0467 s/iter. Eval: 0.1499 s/iter. Total: 0.1987 s/iter. ETA=0:00:04\n",
      "\u001b[32m[07/06 04:57:20 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:02:18.090518 (0.198978 s / iter per device, on 1 devices)\n",
      "\u001b[32m[07/06 04:57:20 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:32 (0.046777 s / iter per device, on 1 devices)\n",
      "\u001b[32m[07/06 04:57:21 d2.evaluation.sem_seg_evaluation]: \u001b[0mOrderedDict([('sem_seg', {'mIoU': 63.68298492053618, 'fwIoU': 87.71037738279568, 'IoU-Unlabeled': nan, 'IoU-Building': 87.1203477384973, 'IoU-Fence': 45.14641956982099, 'IoU-Pedestrian': 74.3988975479838, 'IoU-Pole': 48.69026280648849, 'IoU-Road': 95.45965573006715, 'IoU-SideWalk': 74.85370356693515, 'IoU-Vegetation': 88.54424990104344, 'IoU-Vehicles': 89.10106811528166, 'IoU-Wall': 42.22215034670448, 'IoU-TrafficSign': 61.23761846941298, 'IoU-Sky': 80.96396781175213, 'IoU-TrafficLight': 49.577456500553296, 'IoU-Terrain': 54.24599078296579, 'IoU-ConstructionVehicle': nan, 'IoU-workzone_object': nan, 'IoU-Detour': nan, 'mACC': 77.99854423198417, 'pACC': 93.13637058662617, 'ACC-Unlabeled': nan, 'ACC-Building': 95.6692606124102, 'ACC-Fence': 53.77024277923167, 'ACC-Pedestrian': 86.94473297406515, 'ACC-Pole': 62.304519234525934, 'ACC-Road': 97.24618715711642, 'ACC-SideWalk': 84.82500221276965, 'ACC-Vegetation': 93.77392292290992, 'ACC-Vehicles': 94.48535919302732, 'ACC-Wall': 57.95494971572852, 'ACC-TrafficSign': 69.38663576861276, 'ACC-Sky': 83.42578290580968, 'ACC-TrafficLight': 58.410530458710085, 'ACC-Terrain': 75.78394908087674, 'ACC-ConstructionVehicle': nan, 'ACC-workzone_object': nan, 'ACC-Detour': nan})])\n",
      "\u001b[32m[07/06 04:57:21 d2.engine.defaults]: \u001b[0mEvaluation results for cityscapes_rain_val in csv format:\n",
      "\u001b[32m[07/06 04:57:21 d2.evaluation.testing]: \u001b[0mcopypaste: Task: sem_seg\n",
      "\u001b[32m[07/06 04:57:21 d2.evaluation.testing]: \u001b[0mcopypaste: mIoU,fwIoU,mACC,pACC\n",
      "\u001b[32m[07/06 04:57:21 d2.evaluation.testing]: \u001b[0mcopypaste: 63.6830,87.7104,77.9985,93.1364\n"
     ]
    }
   ],
   "source": [
    "#all cityscapes rain\n",
    "trainer_both = Detectron2Trainer('combined_clear_both_train', 'cityscapes_rain_val', output_folder='./output_both_clear_40k')\n",
    "trainer_both.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "99fef81f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/06 04:57:21 d2.engine.defaults]: \u001b[0mModel:\n",
      "SemanticSegmentor(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (sem_seg_head): SemSegFPNHead(\n",
      "    (p2): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "    )\n",
      "    (p3): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (1): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "    )\n",
      "    (p4): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (1): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      (2): Conv2d(\n",
      "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (3): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "    )\n",
      "    (p5): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (1): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      (2): Conv2d(\n",
      "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (3): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      (4): Conv2d(\n",
      "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (5): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "    )\n",
      "    (predictor): Conv2d(128, 17, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/06 04:57:21 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(720, 720), max_size=2048, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[07/06 04:57:21 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[07/06 04:57:21 d2.data.common]: \u001b[0mSerializing 2286 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[07/06 04:57:21 d2.data.common]: \u001b[0mSerialized dataset takes 0.84 MiB\n",
      "Last checkpoint: model_final.pth\n",
      "\u001b[32m[07/06 04:57:21 d2.checkpoint.c2_model_loading]: \u001b[0mFollowing weights matched with model:\n",
      "| Names in Model                       | Names in Checkpoint                                                                                  | Shapes                                          |\n",
      "|:-------------------------------------|:-----------------------------------------------------------------------------------------------------|:------------------------------------------------|\n",
      "| backbone.bottom_up.res2.0.conv1.*    | backbone.bottom_up.res2.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,1,1)             |\n",
      "| backbone.bottom_up.res2.0.conv2.*    | backbone.bottom_up.res2.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |\n",
      "| backbone.bottom_up.res2.0.conv3.*    | backbone.bottom_up.res2.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res2.0.shortcut.* | backbone.bottom_up.res2.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res2.1.conv1.*    | backbone.bottom_up.res2.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |\n",
      "| backbone.bottom_up.res2.1.conv2.*    | backbone.bottom_up.res2.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |\n",
      "| backbone.bottom_up.res2.1.conv3.*    | backbone.bottom_up.res2.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res2.2.conv1.*    | backbone.bottom_up.res2.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |\n",
      "| backbone.bottom_up.res2.2.conv2.*    | backbone.bottom_up.res2.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |\n",
      "| backbone.bottom_up.res2.2.conv3.*    | backbone.bottom_up.res2.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res3.0.conv1.*    | backbone.bottom_up.res3.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,256,1,1)       |\n",
      "| backbone.bottom_up.res3.0.conv2.*    | backbone.bottom_up.res3.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.0.conv3.*    | backbone.bottom_up.res3.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res3.0.shortcut.* | backbone.bottom_up.res3.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (512,) (512,) (512,) (512,) (512,256,1,1)       |\n",
      "| backbone.bottom_up.res3.1.conv1.*    | backbone.bottom_up.res3.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |\n",
      "| backbone.bottom_up.res3.1.conv2.*    | backbone.bottom_up.res3.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.1.conv3.*    | backbone.bottom_up.res3.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res3.2.conv1.*    | backbone.bottom_up.res3.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |\n",
      "| backbone.bottom_up.res3.2.conv2.*    | backbone.bottom_up.res3.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.2.conv3.*    | backbone.bottom_up.res3.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res3.3.conv1.*    | backbone.bottom_up.res3.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |\n",
      "| backbone.bottom_up.res3.3.conv2.*    | backbone.bottom_up.res3.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.3.conv3.*    | backbone.bottom_up.res3.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res4.0.conv1.*    | backbone.bottom_up.res4.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,512,1,1)       |\n",
      "| backbone.bottom_up.res4.0.conv2.*    | backbone.bottom_up.res4.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.0.conv3.*    | backbone.bottom_up.res4.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.0.shortcut.* | backbone.bottom_up.res4.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (1024,) (1024,) (1024,) (1024,) (1024,512,1,1)  |\n",
      "| backbone.bottom_up.res4.1.conv1.*    | backbone.bottom_up.res4.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.1.conv2.*    | backbone.bottom_up.res4.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.1.conv3.*    | backbone.bottom_up.res4.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.2.conv1.*    | backbone.bottom_up.res4.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.2.conv2.*    | backbone.bottom_up.res4.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.2.conv3.*    | backbone.bottom_up.res4.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.3.conv1.*    | backbone.bottom_up.res4.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.3.conv2.*    | backbone.bottom_up.res4.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.3.conv3.*    | backbone.bottom_up.res4.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.4.conv1.*    | backbone.bottom_up.res4.4.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.4.conv2.*    | backbone.bottom_up.res4.4.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.4.conv3.*    | backbone.bottom_up.res4.4.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.5.conv1.*    | backbone.bottom_up.res4.5.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.5.conv2.*    | backbone.bottom_up.res4.5.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.5.conv3.*    | backbone.bottom_up.res4.5.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res5.0.conv1.*    | backbone.bottom_up.res5.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,1024,1,1)      |\n",
      "| backbone.bottom_up.res5.0.conv2.*    | backbone.bottom_up.res5.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |\n",
      "| backbone.bottom_up.res5.0.conv3.*    | backbone.bottom_up.res5.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
      "| backbone.bottom_up.res5.0.shortcut.* | backbone.bottom_up.res5.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (2048,) (2048,) (2048,) (2048,) (2048,1024,1,1) |\n",
      "| backbone.bottom_up.res5.1.conv1.*    | backbone.bottom_up.res5.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |\n",
      "| backbone.bottom_up.res5.1.conv2.*    | backbone.bottom_up.res5.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |\n",
      "| backbone.bottom_up.res5.1.conv3.*    | backbone.bottom_up.res5.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
      "| backbone.bottom_up.res5.2.conv1.*    | backbone.bottom_up.res5.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |\n",
      "| backbone.bottom_up.res5.2.conv2.*    | backbone.bottom_up.res5.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |\n",
      "| backbone.bottom_up.res5.2.conv3.*    | backbone.bottom_up.res5.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
      "| backbone.bottom_up.stem.conv1.*      | backbone.bottom_up.stem.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}      | (64,) (64,) (64,) (64,) (64,3,7,7)              |\n",
      "| backbone.fpn_lateral2.*              | backbone.fpn_lateral2.{bias,weight}                                                                  | (256,) (256,256,1,1)                            |\n",
      "| backbone.fpn_lateral3.*              | backbone.fpn_lateral3.{bias,weight}                                                                  | (256,) (256,512,1,1)                            |\n",
      "| backbone.fpn_lateral4.*              | backbone.fpn_lateral4.{bias,weight}                                                                  | (256,) (256,1024,1,1)                           |\n",
      "| backbone.fpn_lateral5.*              | backbone.fpn_lateral5.{bias,weight}                                                                  | (256,) (256,2048,1,1)                           |\n",
      "| backbone.fpn_output2.*               | backbone.fpn_output2.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| backbone.fpn_output3.*               | backbone.fpn_output3.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| backbone.fpn_output4.*               | backbone.fpn_output4.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| backbone.fpn_output5.*               | backbone.fpn_output5.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| sem_seg_head.p2.0.*                  | sem_seg_head.p2.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p3.0.*                  | sem_seg_head.p3.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p4.0.*                  | sem_seg_head.p4.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p4.2.*                  | sem_seg_head.p4.2.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,128,3,3)                     |\n",
      "| sem_seg_head.p5.0.*                  | sem_seg_head.p5.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p5.2.*                  | sem_seg_head.p5.2.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,128,3,3)                     |\n",
      "| sem_seg_head.p5.4.*                  | sem_seg_head.p5.4.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,128,3,3)                     |\n",
      "| sem_seg_head.predictor.*             | sem_seg_head.predictor.{bias,weight}                                                                 | (17,) (17,128,1,1)                              |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/06 04:57:21 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(720, 720), max_size=2048, sample_style='choice')]\n",
      "\u001b[32m[07/06 04:57:21 d2.data.common]: \u001b[0mSerializing 2890 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[07/06 04:57:21 d2.data.common]: \u001b[0mSerialized dataset takes 1.05 MiB\n",
      "\u001b[32m[07/06 04:57:21 d2.evaluation.evaluator]: \u001b[0mStart inference on 2890 batches\n",
      "\u001b[32m[07/06 04:57:23 d2.evaluation.evaluator]: \u001b[0mInference done 11/2890. Dataloading: 0.0017 s/iter. Inference: 0.0358 s/iter. Eval: 0.0425 s/iter. Total: 0.0800 s/iter. ETA=0:03:50\n",
      "\u001b[32m[07/06 04:57:28 d2.evaluation.evaluator]: \u001b[0mInference done 76/2890. Dataloading: 0.0021 s/iter. Inference: 0.0352 s/iter. Eval: 0.0401 s/iter. Total: 0.0774 s/iter. ETA=0:03:37\n",
      "\u001b[32m[07/06 04:57:33 d2.evaluation.evaluator]: \u001b[0mInference done 142/2890. Dataloading: 0.0021 s/iter. Inference: 0.0352 s/iter. Eval: 0.0396 s/iter. Total: 0.0769 s/iter. ETA=0:03:31\n",
      "\u001b[32m[07/06 04:57:38 d2.evaluation.evaluator]: \u001b[0mInference done 208/2890. Dataloading: 0.0021 s/iter. Inference: 0.0352 s/iter. Eval: 0.0395 s/iter. Total: 0.0769 s/iter. ETA=0:03:26\n",
      "\u001b[32m[07/06 04:57:43 d2.evaluation.evaluator]: \u001b[0mInference done 274/2890. Dataloading: 0.0021 s/iter. Inference: 0.0352 s/iter. Eval: 0.0395 s/iter. Total: 0.0769 s/iter. ETA=0:03:21\n",
      "\u001b[32m[07/06 04:57:48 d2.evaluation.evaluator]: \u001b[0mInference done 338/2890. Dataloading: 0.0021 s/iter. Inference: 0.0353 s/iter. Eval: 0.0397 s/iter. Total: 0.0772 s/iter. ETA=0:03:16\n",
      "\u001b[32m[07/06 04:57:53 d2.evaluation.evaluator]: \u001b[0mInference done 403/2890. Dataloading: 0.0021 s/iter. Inference: 0.0353 s/iter. Eval: 0.0398 s/iter. Total: 0.0772 s/iter. ETA=0:03:12\n",
      "\u001b[32m[07/06 04:57:58 d2.evaluation.evaluator]: \u001b[0mInference done 467/2890. Dataloading: 0.0021 s/iter. Inference: 0.0353 s/iter. Eval: 0.0399 s/iter. Total: 0.0774 s/iter. ETA=0:03:07\n",
      "\u001b[32m[07/06 04:58:03 d2.evaluation.evaluator]: \u001b[0mInference done 532/2890. Dataloading: 0.0021 s/iter. Inference: 0.0353 s/iter. Eval: 0.0400 s/iter. Total: 0.0775 s/iter. ETA=0:03:02\n",
      "\u001b[32m[07/06 04:58:08 d2.evaluation.evaluator]: \u001b[0mInference done 596/2890. Dataloading: 0.0021 s/iter. Inference: 0.0353 s/iter. Eval: 0.0402 s/iter. Total: 0.0776 s/iter. ETA=0:02:58\n",
      "\u001b[32m[07/06 04:58:13 d2.evaluation.evaluator]: \u001b[0mInference done 659/2890. Dataloading: 0.0021 s/iter. Inference: 0.0353 s/iter. Eval: 0.0404 s/iter. Total: 0.0779 s/iter. ETA=0:02:53\n",
      "\u001b[32m[07/06 04:58:18 d2.evaluation.evaluator]: \u001b[0mInference done 725/2890. Dataloading: 0.0021 s/iter. Inference: 0.0354 s/iter. Eval: 0.0402 s/iter. Total: 0.0778 s/iter. ETA=0:02:48\n",
      "\u001b[32m[07/06 04:58:23 d2.evaluation.evaluator]: \u001b[0mInference done 791/2890. Dataloading: 0.0021 s/iter. Inference: 0.0354 s/iter. Eval: 0.0401 s/iter. Total: 0.0776 s/iter. ETA=0:02:42\n",
      "\u001b[32m[07/06 04:58:28 d2.evaluation.evaluator]: \u001b[0mInference done 857/2890. Dataloading: 0.0021 s/iter. Inference: 0.0354 s/iter. Eval: 0.0400 s/iter. Total: 0.0775 s/iter. ETA=0:02:37\n",
      "\u001b[32m[07/06 04:58:33 d2.evaluation.evaluator]: \u001b[0mInference done 923/2890. Dataloading: 0.0021 s/iter. Inference: 0.0354 s/iter. Eval: 0.0399 s/iter. Total: 0.0775 s/iter. ETA=0:02:32\n",
      "\u001b[32m[07/06 04:58:38 d2.evaluation.evaluator]: \u001b[0mInference done 988/2890. Dataloading: 0.0021 s/iter. Inference: 0.0354 s/iter. Eval: 0.0398 s/iter. Total: 0.0775 s/iter. ETA=0:02:27\n",
      "\u001b[32m[07/06 04:58:43 d2.evaluation.evaluator]: \u001b[0mInference done 1054/2890. Dataloading: 0.0021 s/iter. Inference: 0.0354 s/iter. Eval: 0.0398 s/iter. Total: 0.0774 s/iter. ETA=0:02:22\n",
      "\u001b[32m[07/06 04:58:48 d2.evaluation.evaluator]: \u001b[0mInference done 1119/2890. Dataloading: 0.0022 s/iter. Inference: 0.0354 s/iter. Eval: 0.0397 s/iter. Total: 0.0774 s/iter. ETA=0:02:17\n",
      "\u001b[32m[07/06 04:58:53 d2.evaluation.evaluator]: \u001b[0mInference done 1183/2890. Dataloading: 0.0022 s/iter. Inference: 0.0354 s/iter. Eval: 0.0398 s/iter. Total: 0.0775 s/iter. ETA=0:02:12\n",
      "\u001b[32m[07/06 04:58:59 d2.evaluation.evaluator]: \u001b[0mInference done 1246/2890. Dataloading: 0.0022 s/iter. Inference: 0.0354 s/iter. Eval: 0.0399 s/iter. Total: 0.0776 s/iter. ETA=0:02:07\n",
      "\u001b[32m[07/06 04:59:04 d2.evaluation.evaluator]: \u001b[0mInference done 1309/2890. Dataloading: 0.0022 s/iter. Inference: 0.0354 s/iter. Eval: 0.0400 s/iter. Total: 0.0777 s/iter. ETA=0:02:02\n",
      "\u001b[32m[07/06 04:59:09 d2.evaluation.evaluator]: \u001b[0mInference done 1373/2890. Dataloading: 0.0022 s/iter. Inference: 0.0354 s/iter. Eval: 0.0401 s/iter. Total: 0.0778 s/iter. ETA=0:01:57\n",
      "\u001b[32m[07/06 04:59:14 d2.evaluation.evaluator]: \u001b[0mInference done 1441/2890. Dataloading: 0.0022 s/iter. Inference: 0.0354 s/iter. Eval: 0.0399 s/iter. Total: 0.0776 s/iter. ETA=0:01:52\n",
      "\u001b[32m[07/06 04:59:19 d2.evaluation.evaluator]: \u001b[0mInference done 1508/2890. Dataloading: 0.0022 s/iter. Inference: 0.0354 s/iter. Eval: 0.0398 s/iter. Total: 0.0775 s/iter. ETA=0:01:47\n",
      "\u001b[32m[07/06 04:59:24 d2.evaluation.evaluator]: \u001b[0mInference done 1575/2890. Dataloading: 0.0022 s/iter. Inference: 0.0354 s/iter. Eval: 0.0397 s/iter. Total: 0.0774 s/iter. ETA=0:01:41\n",
      "\u001b[32m[07/06 04:59:29 d2.evaluation.evaluator]: \u001b[0mInference done 1640/2890. Dataloading: 0.0022 s/iter. Inference: 0.0355 s/iter. Eval: 0.0397 s/iter. Total: 0.0774 s/iter. ETA=0:01:36\n",
      "\u001b[32m[07/06 04:59:34 d2.evaluation.evaluator]: \u001b[0mInference done 1704/2890. Dataloading: 0.0022 s/iter. Inference: 0.0355 s/iter. Eval: 0.0397 s/iter. Total: 0.0774 s/iter. ETA=0:01:31\n",
      "\u001b[32m[07/06 04:59:39 d2.evaluation.evaluator]: \u001b[0mInference done 1768/2890. Dataloading: 0.0022 s/iter. Inference: 0.0355 s/iter. Eval: 0.0397 s/iter. Total: 0.0775 s/iter. ETA=0:01:26\n",
      "\u001b[32m[07/06 04:59:44 d2.evaluation.evaluator]: \u001b[0mInference done 1833/2890. Dataloading: 0.0022 s/iter. Inference: 0.0355 s/iter. Eval: 0.0397 s/iter. Total: 0.0775 s/iter. ETA=0:01:21\n",
      "\u001b[32m[07/06 04:59:49 d2.evaluation.evaluator]: \u001b[0mInference done 1898/2890. Dataloading: 0.0022 s/iter. Inference: 0.0355 s/iter. Eval: 0.0398 s/iter. Total: 0.0775 s/iter. ETA=0:01:16\n",
      "\u001b[32m[07/06 04:59:54 d2.evaluation.evaluator]: \u001b[0mInference done 1962/2890. Dataloading: 0.0022 s/iter. Inference: 0.0355 s/iter. Eval: 0.0398 s/iter. Total: 0.0776 s/iter. ETA=0:01:11\n",
      "\u001b[32m[07/06 04:59:59 d2.evaluation.evaluator]: \u001b[0mInference done 2027/2890. Dataloading: 0.0022 s/iter. Inference: 0.0355 s/iter. Eval: 0.0398 s/iter. Total: 0.0776 s/iter. ETA=0:01:06\n",
      "\u001b[32m[07/06 05:00:04 d2.evaluation.evaluator]: \u001b[0mInference done 2090/2890. Dataloading: 0.0022 s/iter. Inference: 0.0355 s/iter. Eval: 0.0399 s/iter. Total: 0.0776 s/iter. ETA=0:01:02\n",
      "\u001b[32m[07/06 05:00:09 d2.evaluation.evaluator]: \u001b[0mInference done 2156/2890. Dataloading: 0.0022 s/iter. Inference: 0.0355 s/iter. Eval: 0.0398 s/iter. Total: 0.0776 s/iter. ETA=0:00:56\n",
      "\u001b[32m[07/06 05:00:14 d2.evaluation.evaluator]: \u001b[0mInference done 2204/2890. Dataloading: 0.0022 s/iter. Inference: 0.0356 s/iter. Eval: 0.0404 s/iter. Total: 0.0782 s/iter. ETA=0:00:53\n",
      "\u001b[32m[07/06 05:00:19 d2.evaluation.evaluator]: \u001b[0mInference done 2230/2890. Dataloading: 0.0022 s/iter. Inference: 0.0357 s/iter. Eval: 0.0416 s/iter. Total: 0.0796 s/iter. ETA=0:00:52\n",
      "\u001b[32m[07/06 05:00:24 d2.evaluation.evaluator]: \u001b[0mInference done 2256/2890. Dataloading: 0.0022 s/iter. Inference: 0.0358 s/iter. Eval: 0.0428 s/iter. Total: 0.0809 s/iter. ETA=0:00:51\n",
      "\u001b[32m[07/06 05:00:29 d2.evaluation.evaluator]: \u001b[0mInference done 2283/2890. Dataloading: 0.0022 s/iter. Inference: 0.0360 s/iter. Eval: 0.0440 s/iter. Total: 0.0822 s/iter. ETA=0:00:49\n",
      "\u001b[32m[07/06 05:00:35 d2.evaluation.evaluator]: \u001b[0mInference done 2311/2890. Dataloading: 0.0022 s/iter. Inference: 0.0361 s/iter. Eval: 0.0451 s/iter. Total: 0.0834 s/iter. ETA=0:00:48\n",
      "\u001b[32m[07/06 05:00:40 d2.evaluation.evaluator]: \u001b[0mInference done 2340/2890. Dataloading: 0.0022 s/iter. Inference: 0.0362 s/iter. Eval: 0.0461 s/iter. Total: 0.0846 s/iter. ETA=0:00:46\n",
      "\u001b[32m[07/06 05:00:45 d2.evaluation.evaluator]: \u001b[0mInference done 2366/2890. Dataloading: 0.0022 s/iter. Inference: 0.0363 s/iter. Eval: 0.0472 s/iter. Total: 0.0858 s/iter. ETA=0:00:44\n",
      "\u001b[32m[07/06 05:00:50 d2.evaluation.evaluator]: \u001b[0mInference done 2392/2890. Dataloading: 0.0022 s/iter. Inference: 0.0364 s/iter. Eval: 0.0483 s/iter. Total: 0.0870 s/iter. ETA=0:00:43\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/06 05:00:55 d2.evaluation.evaluator]: \u001b[0mInference done 2418/2890. Dataloading: 0.0022 s/iter. Inference: 0.0365 s/iter. Eval: 0.0493 s/iter. Total: 0.0882 s/iter. ETA=0:00:41\n",
      "\u001b[32m[07/06 05:01:00 d2.evaluation.evaluator]: \u001b[0mInference done 2444/2890. Dataloading: 0.0022 s/iter. Inference: 0.0366 s/iter. Eval: 0.0503 s/iter. Total: 0.0893 s/iter. ETA=0:00:39\n",
      "\u001b[32m[07/06 05:01:05 d2.evaluation.evaluator]: \u001b[0mInference done 2470/2890. Dataloading: 0.0022 s/iter. Inference: 0.0368 s/iter. Eval: 0.0513 s/iter. Total: 0.0904 s/iter. ETA=0:00:37\n",
      "\u001b[32m[07/06 05:01:10 d2.evaluation.evaluator]: \u001b[0mInference done 2496/2890. Dataloading: 0.0022 s/iter. Inference: 0.0369 s/iter. Eval: 0.0523 s/iter. Total: 0.0915 s/iter. ETA=0:00:36\n",
      "\u001b[32m[07/06 05:01:15 d2.evaluation.evaluator]: \u001b[0mInference done 2522/2890. Dataloading: 0.0022 s/iter. Inference: 0.0370 s/iter. Eval: 0.0533 s/iter. Total: 0.0926 s/iter. ETA=0:00:34\n",
      "\u001b[32m[07/06 05:01:20 d2.evaluation.evaluator]: \u001b[0mInference done 2549/2890. Dataloading: 0.0022 s/iter. Inference: 0.0371 s/iter. Eval: 0.0543 s/iter. Total: 0.0937 s/iter. ETA=0:00:31\n",
      "\u001b[32m[07/06 05:01:26 d2.evaluation.evaluator]: \u001b[0mInference done 2574/2890. Dataloading: 0.0022 s/iter. Inference: 0.0372 s/iter. Eval: 0.0552 s/iter. Total: 0.0947 s/iter. ETA=0:00:29\n",
      "\u001b[32m[07/06 05:01:31 d2.evaluation.evaluator]: \u001b[0mInference done 2600/2890. Dataloading: 0.0022 s/iter. Inference: 0.0373 s/iter. Eval: 0.0562 s/iter. Total: 0.0957 s/iter. ETA=0:00:27\n",
      "\u001b[32m[07/06 05:01:36 d2.evaluation.evaluator]: \u001b[0mInference done 2626/2890. Dataloading: 0.0022 s/iter. Inference: 0.0374 s/iter. Eval: 0.0570 s/iter. Total: 0.0967 s/iter. ETA=0:00:25\n",
      "\u001b[32m[07/06 05:01:41 d2.evaluation.evaluator]: \u001b[0mInference done 2652/2890. Dataloading: 0.0022 s/iter. Inference: 0.0374 s/iter. Eval: 0.0579 s/iter. Total: 0.0977 s/iter. ETA=0:00:23\n",
      "\u001b[32m[07/06 05:01:46 d2.evaluation.evaluator]: \u001b[0mInference done 2679/2890. Dataloading: 0.0022 s/iter. Inference: 0.0375 s/iter. Eval: 0.0587 s/iter. Total: 0.0986 s/iter. ETA=0:00:20\n",
      "\u001b[32m[07/06 05:01:51 d2.evaluation.evaluator]: \u001b[0mInference done 2705/2890. Dataloading: 0.0022 s/iter. Inference: 0.0376 s/iter. Eval: 0.0596 s/iter. Total: 0.0995 s/iter. ETA=0:00:18\n",
      "\u001b[32m[07/06 05:01:56 d2.evaluation.evaluator]: \u001b[0mInference done 2732/2890. Dataloading: 0.0022 s/iter. Inference: 0.0377 s/iter. Eval: 0.0604 s/iter. Total: 0.1004 s/iter. ETA=0:00:15\n",
      "\u001b[32m[07/06 05:02:01 d2.evaluation.evaluator]: \u001b[0mInference done 2758/2890. Dataloading: 0.0022 s/iter. Inference: 0.0378 s/iter. Eval: 0.0612 s/iter. Total: 0.1013 s/iter. ETA=0:00:13\n",
      "\u001b[32m[07/06 05:02:06 d2.evaluation.evaluator]: \u001b[0mInference done 2784/2890. Dataloading: 0.0022 s/iter. Inference: 0.0379 s/iter. Eval: 0.0620 s/iter. Total: 0.1022 s/iter. ETA=0:00:10\n",
      "\u001b[32m[07/06 05:02:11 d2.evaluation.evaluator]: \u001b[0mInference done 2810/2890. Dataloading: 0.0022 s/iter. Inference: 0.0380 s/iter. Eval: 0.0628 s/iter. Total: 0.1031 s/iter. ETA=0:00:08\n",
      "\u001b[32m[07/06 05:02:16 d2.evaluation.evaluator]: \u001b[0mInference done 2837/2890. Dataloading: 0.0022 s/iter. Inference: 0.0381 s/iter. Eval: 0.0635 s/iter. Total: 0.1039 s/iter. ETA=0:00:05\n",
      "\u001b[32m[07/06 05:02:22 d2.evaluation.evaluator]: \u001b[0mInference done 2864/2890. Dataloading: 0.0022 s/iter. Inference: 0.0381 s/iter. Eval: 0.0643 s/iter. Total: 0.1047 s/iter. ETA=0:00:02\n",
      "\u001b[32m[07/06 05:02:27 d2.evaluation.evaluator]: \u001b[0mInference done 2890/2890. Dataloading: 0.0022 s/iter. Inference: 0.0382 s/iter. Eval: 0.0650 s/iter. Total: 0.1055 s/iter. ETA=0:00:00\n",
      "\u001b[32m[07/06 05:02:27 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:05:04.534520 (0.105558 s / iter per device, on 1 devices)\n",
      "\u001b[32m[07/06 05:02:27 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:01:50 (0.038222 s / iter per device, on 1 devices)\n",
      "\u001b[32m[07/06 05:02:27 d2.evaluation.sem_seg_evaluation]: \u001b[0mOrderedDict([('sem_seg', {'mIoU': 56.173875237957304, 'fwIoU': 72.22311261132562, 'IoU-Unlabeled': nan, 'IoU-Building': 63.533048093839405, 'IoU-Fence': 32.777053514771204, 'IoU-Pedestrian': 70.00662959706055, 'IoU-Pole': 47.356763287529446, 'IoU-Road': 91.05868316173056, 'IoU-SideWalk': 67.18710003254003, 'IoU-Vegetation': 74.95661344845819, 'IoU-Vehicles': 65.26272926889334, 'IoU-Wall': 44.89688149783068, 'IoU-TrafficSign': 57.75990665058638, 'IoU-Sky': 52.39275141993336, 'IoU-TrafficLight': 54.746085905933526, 'IoU-Terrain': 29.61304490244498, 'IoU-ConstructionVehicle': 84.29871170512362, 'IoU-workzone_object': 53.97382359521299, 'IoU-Detour': 8.962177725428608, 'mACC': 68.26697539947148, 'pACC': 83.12595959692685, 'ACC-Unlabeled': nan, 'ACC-Building': 96.28756313997413, 'ACC-Fence': 40.881701712877856, 'ACC-Pedestrian': 86.16790665253222, 'ACC-Pole': 57.91064960741349, 'ACC-Road': 93.45827865957878, 'ACC-SideWalk': 81.15094559263537, 'ACC-Vegetation': 82.76475888177625, 'ACC-Vehicles': 92.99490239886427, 'ACC-Wall': 57.38808107823588, 'ACC-TrafficSign': 66.73846245244047, 'ACC-Sky': 53.15690043939243, 'ACC-TrafficLight': 64.17404676382696, 'ACC-Terrain': 33.76462190230106, 'ACC-ConstructionVehicle': 91.94772961104806, 'ACC-workzone_object': 80.32038373187342, 'ACC-Detour': 13.164673766773042})])\n",
      "\u001b[32m[07/06 05:02:27 d2.engine.defaults]: \u001b[0mEvaluation results for combined_both_rain_val in csv format:\n",
      "\u001b[32m[07/06 05:02:27 d2.evaluation.testing]: \u001b[0mcopypaste: Task: sem_seg\n",
      "\u001b[32m[07/06 05:02:27 d2.evaluation.testing]: \u001b[0mcopypaste: mIoU,fwIoU,mACC,pACC\n",
      "\u001b[32m[07/06 05:02:27 d2.evaluation.testing]: \u001b[0mcopypaste: 56.1739,72.2231,68.2670,83.1260\n"
     ]
    }
   ],
   "source": [
    "#all rain\n",
    "trainer_both = Detectron2Trainer('combined_clear_both_train', 'combined_both_rain_val', output_folder='./output_both_clear_40k')\n",
    "trainer_both.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "77dc5efa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/07 13:53:14 d2.engine.defaults]: \u001b[0mModel:\n",
      "SemanticSegmentor(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (sem_seg_head): SemSegFPNHead(\n",
      "    (p2): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "    )\n",
      "    (p3): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (1): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "    )\n",
      "    (p4): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (1): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      (2): Conv2d(\n",
      "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (3): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "    )\n",
      "    (p5): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (1): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      (2): Conv2d(\n",
      "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (3): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      (4): Conv2d(\n",
      "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (5): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "    )\n",
      "    (predictor): Conv2d(128, 17, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/07 13:53:14 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(720, 720), max_size=2048, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[07/07 13:53:14 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[07/07 13:53:14 d2.data.common]: \u001b[0mSerializing 6626 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[07/07 13:53:14 d2.data.common]: \u001b[0mSerialized dataset takes 2.45 MiB\n",
      "Last checkpoint: model_final.pth\n",
      "\u001b[32m[07/07 13:53:15 d2.checkpoint.c2_model_loading]: \u001b[0mFollowing weights matched with model:\n",
      "| Names in Model                       | Names in Checkpoint                                                                                  | Shapes                                          |\n",
      "|:-------------------------------------|:-----------------------------------------------------------------------------------------------------|:------------------------------------------------|\n",
      "| backbone.bottom_up.res2.0.conv1.*    | backbone.bottom_up.res2.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,1,1)             |\n",
      "| backbone.bottom_up.res2.0.conv2.*    | backbone.bottom_up.res2.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |\n",
      "| backbone.bottom_up.res2.0.conv3.*    | backbone.bottom_up.res2.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res2.0.shortcut.* | backbone.bottom_up.res2.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res2.1.conv1.*    | backbone.bottom_up.res2.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |\n",
      "| backbone.bottom_up.res2.1.conv2.*    | backbone.bottom_up.res2.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |\n",
      "| backbone.bottom_up.res2.1.conv3.*    | backbone.bottom_up.res2.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res2.2.conv1.*    | backbone.bottom_up.res2.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |\n",
      "| backbone.bottom_up.res2.2.conv2.*    | backbone.bottom_up.res2.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |\n",
      "| backbone.bottom_up.res2.2.conv3.*    | backbone.bottom_up.res2.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res3.0.conv1.*    | backbone.bottom_up.res3.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,256,1,1)       |\n",
      "| backbone.bottom_up.res3.0.conv2.*    | backbone.bottom_up.res3.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.0.conv3.*    | backbone.bottom_up.res3.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res3.0.shortcut.* | backbone.bottom_up.res3.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (512,) (512,) (512,) (512,) (512,256,1,1)       |\n",
      "| backbone.bottom_up.res3.1.conv1.*    | backbone.bottom_up.res3.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |\n",
      "| backbone.bottom_up.res3.1.conv2.*    | backbone.bottom_up.res3.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.1.conv3.*    | backbone.bottom_up.res3.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res3.2.conv1.*    | backbone.bottom_up.res3.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |\n",
      "| backbone.bottom_up.res3.2.conv2.*    | backbone.bottom_up.res3.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.2.conv3.*    | backbone.bottom_up.res3.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res3.3.conv1.*    | backbone.bottom_up.res3.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |\n",
      "| backbone.bottom_up.res3.3.conv2.*    | backbone.bottom_up.res3.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.3.conv3.*    | backbone.bottom_up.res3.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res4.0.conv1.*    | backbone.bottom_up.res4.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,512,1,1)       |\n",
      "| backbone.bottom_up.res4.0.conv2.*    | backbone.bottom_up.res4.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.0.conv3.*    | backbone.bottom_up.res4.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.0.shortcut.* | backbone.bottom_up.res4.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (1024,) (1024,) (1024,) (1024,) (1024,512,1,1)  |\n",
      "| backbone.bottom_up.res4.1.conv1.*    | backbone.bottom_up.res4.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.1.conv2.*    | backbone.bottom_up.res4.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.1.conv3.*    | backbone.bottom_up.res4.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.2.conv1.*    | backbone.bottom_up.res4.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.2.conv2.*    | backbone.bottom_up.res4.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.2.conv3.*    | backbone.bottom_up.res4.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.3.conv1.*    | backbone.bottom_up.res4.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.3.conv2.*    | backbone.bottom_up.res4.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.3.conv3.*    | backbone.bottom_up.res4.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.4.conv1.*    | backbone.bottom_up.res4.4.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.4.conv2.*    | backbone.bottom_up.res4.4.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.4.conv3.*    | backbone.bottom_up.res4.4.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.5.conv1.*    | backbone.bottom_up.res4.5.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.5.conv2.*    | backbone.bottom_up.res4.5.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.5.conv3.*    | backbone.bottom_up.res4.5.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res5.0.conv1.*    | backbone.bottom_up.res5.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,1024,1,1)      |\n",
      "| backbone.bottom_up.res5.0.conv2.*    | backbone.bottom_up.res5.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |\n",
      "| backbone.bottom_up.res5.0.conv3.*    | backbone.bottom_up.res5.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
      "| backbone.bottom_up.res5.0.shortcut.* | backbone.bottom_up.res5.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (2048,) (2048,) (2048,) (2048,) (2048,1024,1,1) |\n",
      "| backbone.bottom_up.res5.1.conv1.*    | backbone.bottom_up.res5.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |\n",
      "| backbone.bottom_up.res5.1.conv2.*    | backbone.bottom_up.res5.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |\n",
      "| backbone.bottom_up.res5.1.conv3.*    | backbone.bottom_up.res5.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
      "| backbone.bottom_up.res5.2.conv1.*    | backbone.bottom_up.res5.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |\n",
      "| backbone.bottom_up.res5.2.conv2.*    | backbone.bottom_up.res5.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |\n",
      "| backbone.bottom_up.res5.2.conv3.*    | backbone.bottom_up.res5.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
      "| backbone.bottom_up.stem.conv1.*      | backbone.bottom_up.stem.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}      | (64,) (64,) (64,) (64,) (64,3,7,7)              |\n",
      "| backbone.fpn_lateral2.*              | backbone.fpn_lateral2.{bias,weight}                                                                  | (256,) (256,256,1,1)                            |\n",
      "| backbone.fpn_lateral3.*              | backbone.fpn_lateral3.{bias,weight}                                                                  | (256,) (256,512,1,1)                            |\n",
      "| backbone.fpn_lateral4.*              | backbone.fpn_lateral4.{bias,weight}                                                                  | (256,) (256,1024,1,1)                           |\n",
      "| backbone.fpn_lateral5.*              | backbone.fpn_lateral5.{bias,weight}                                                                  | (256,) (256,2048,1,1)                           |\n",
      "| backbone.fpn_output2.*               | backbone.fpn_output2.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| backbone.fpn_output3.*               | backbone.fpn_output3.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| backbone.fpn_output4.*               | backbone.fpn_output4.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| backbone.fpn_output5.*               | backbone.fpn_output5.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| sem_seg_head.p2.0.*                  | sem_seg_head.p2.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p3.0.*                  | sem_seg_head.p3.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p4.0.*                  | sem_seg_head.p4.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p4.2.*                  | sem_seg_head.p4.2.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,128,3,3)                     |\n",
      "| sem_seg_head.p5.0.*                  | sem_seg_head.p5.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p5.2.*                  | sem_seg_head.p5.2.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,128,3,3)                     |\n",
      "| sem_seg_head.p5.4.*                  | sem_seg_head.p5.4.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,128,3,3)                     |\n",
      "| sem_seg_head.predictor.*             | sem_seg_head.predictor.{bias,weight}                                                                 | (17,) (17,128,1,1)                              |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/07 13:53:15 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(720, 720), max_size=2048, sample_style='choice')]\n",
      "\u001b[32m[07/07 13:53:15 d2.data.common]: \u001b[0mSerializing 14460 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[07/07 13:53:15 d2.data.common]: \u001b[0mSerialized dataset takes 5.32 MiB\n",
      "\u001b[32m[07/07 13:53:15 d2.evaluation.evaluator]: \u001b[0mStart inference on 14460 batches\n",
      "\u001b[32m[07/07 13:53:17 d2.evaluation.evaluator]: \u001b[0mInference done 23/14460. Dataloading: 0.0021 s/iter. Inference: 0.0357 s/iter. Eval: 0.0421 s/iter. Total: 0.0800 s/iter. ETA=0:19:14\n",
      "\u001b[32m[07/07 13:53:22 d2.evaluation.evaluator]: \u001b[0mInference done 87/14460. Dataloading: 0.0022 s/iter. Inference: 0.0356 s/iter. Eval: 0.0416 s/iter. Total: 0.0795 s/iter. ETA=0:19:02\n",
      "\u001b[32m[07/07 13:53:27 d2.evaluation.evaluator]: \u001b[0mInference done 153/14460. Dataloading: 0.0022 s/iter. Inference: 0.0355 s/iter. Eval: 0.0401 s/iter. Total: 0.0779 s/iter. ETA=0:18:34\n",
      "\u001b[32m[07/07 13:53:32 d2.evaluation.evaluator]: \u001b[0mInference done 220/14460. Dataloading: 0.0022 s/iter. Inference: 0.0355 s/iter. Eval: 0.0393 s/iter. Total: 0.0772 s/iter. ETA=0:18:18\n",
      "\u001b[32m[07/07 13:53:37 d2.evaluation.evaluator]: \u001b[0mInference done 287/14460. Dataloading: 0.0022 s/iter. Inference: 0.0355 s/iter. Eval: 0.0388 s/iter. Total: 0.0766 s/iter. ETA=0:18:05\n",
      "\u001b[32m[07/07 13:53:42 d2.evaluation.evaluator]: \u001b[0mInference done 352/14460. Dataloading: 0.0025 s/iter. Inference: 0.0355 s/iter. Eval: 0.0386 s/iter. Total: 0.0767 s/iter. ETA=0:18:02\n",
      "\u001b[32m[07/07 13:53:47 d2.evaluation.evaluator]: \u001b[0mInference done 419/14460. Dataloading: 0.0025 s/iter. Inference: 0.0355 s/iter. Eval: 0.0384 s/iter. Total: 0.0765 s/iter. ETA=0:17:53\n",
      "\u001b[32m[07/07 13:53:52 d2.evaluation.evaluator]: \u001b[0mInference done 485/14460. Dataloading: 0.0024 s/iter. Inference: 0.0355 s/iter. Eval: 0.0384 s/iter. Total: 0.0765 s/iter. ETA=0:17:48\n",
      "\u001b[32m[07/07 13:53:57 d2.evaluation.evaluator]: \u001b[0mInference done 551/14460. Dataloading: 0.0024 s/iter. Inference: 0.0355 s/iter. Eval: 0.0384 s/iter. Total: 0.0765 s/iter. ETA=0:17:43\n",
      "\u001b[32m[07/07 13:54:02 d2.evaluation.evaluator]: \u001b[0mInference done 618/14460. Dataloading: 0.0024 s/iter. Inference: 0.0355 s/iter. Eval: 0.0384 s/iter. Total: 0.0764 s/iter. ETA=0:17:37\n",
      "\u001b[32m[07/07 13:54:07 d2.evaluation.evaluator]: \u001b[0mInference done 684/14460. Dataloading: 0.0024 s/iter. Inference: 0.0355 s/iter. Eval: 0.0383 s/iter. Total: 0.0763 s/iter. ETA=0:17:31\n",
      "\u001b[32m[07/07 13:54:12 d2.evaluation.evaluator]: \u001b[0mInference done 751/14460. Dataloading: 0.0024 s/iter. Inference: 0.0355 s/iter. Eval: 0.0382 s/iter. Total: 0.0762 s/iter. ETA=0:17:25\n",
      "\u001b[32m[07/07 13:54:17 d2.evaluation.evaluator]: \u001b[0mInference done 817/14460. Dataloading: 0.0024 s/iter. Inference: 0.0355 s/iter. Eval: 0.0382 s/iter. Total: 0.0763 s/iter. ETA=0:17:20\n",
      "\u001b[32m[07/07 13:54:22 d2.evaluation.evaluator]: \u001b[0mInference done 884/14460. Dataloading: 0.0024 s/iter. Inference: 0.0355 s/iter. Eval: 0.0381 s/iter. Total: 0.0761 s/iter. ETA=0:17:13\n",
      "\u001b[32m[07/07 13:54:27 d2.evaluation.evaluator]: \u001b[0mInference done 952/14460. Dataloading: 0.0024 s/iter. Inference: 0.0356 s/iter. Eval: 0.0380 s/iter. Total: 0.0760 s/iter. ETA=0:17:06\n",
      "\u001b[32m[07/07 13:54:32 d2.evaluation.evaluator]: \u001b[0mInference done 1019/14460. Dataloading: 0.0024 s/iter. Inference: 0.0356 s/iter. Eval: 0.0379 s/iter. Total: 0.0759 s/iter. ETA=0:17:00\n",
      "\u001b[32m[07/07 13:54:37 d2.evaluation.evaluator]: \u001b[0mInference done 1086/14460. Dataloading: 0.0024 s/iter. Inference: 0.0356 s/iter. Eval: 0.0379 s/iter. Total: 0.0758 s/iter. ETA=0:16:54\n",
      "\u001b[32m[07/07 13:54:42 d2.evaluation.evaluator]: \u001b[0mInference done 1154/14460. Dataloading: 0.0024 s/iter. Inference: 0.0356 s/iter. Eval: 0.0378 s/iter. Total: 0.0758 s/iter. ETA=0:16:48\n",
      "\u001b[32m[07/07 13:54:47 d2.evaluation.evaluator]: \u001b[0mInference done 1221/14460. Dataloading: 0.0024 s/iter. Inference: 0.0356 s/iter. Eval: 0.0377 s/iter. Total: 0.0757 s/iter. ETA=0:16:42\n",
      "\u001b[32m[07/07 13:54:52 d2.evaluation.evaluator]: \u001b[0mInference done 1287/14460. Dataloading: 0.0023 s/iter. Inference: 0.0356 s/iter. Eval: 0.0378 s/iter. Total: 0.0758 s/iter. ETA=0:16:37\n",
      "\u001b[32m[07/07 13:54:57 d2.evaluation.evaluator]: \u001b[0mInference done 1355/14460. Dataloading: 0.0023 s/iter. Inference: 0.0356 s/iter. Eval: 0.0377 s/iter. Total: 0.0757 s/iter. ETA=0:16:31\n",
      "\u001b[32m[07/07 13:55:02 d2.evaluation.evaluator]: \u001b[0mInference done 1422/14460. Dataloading: 0.0023 s/iter. Inference: 0.0356 s/iter. Eval: 0.0376 s/iter. Total: 0.0756 s/iter. ETA=0:16:26\n",
      "\u001b[32m[07/07 13:55:08 d2.evaluation.evaluator]: \u001b[0mInference done 1488/14460. Dataloading: 0.0023 s/iter. Inference: 0.0356 s/iter. Eval: 0.0377 s/iter. Total: 0.0757 s/iter. ETA=0:16:21\n",
      "\u001b[32m[07/07 13:55:13 d2.evaluation.evaluator]: \u001b[0mInference done 1554/14460. Dataloading: 0.0023 s/iter. Inference: 0.0356 s/iter. Eval: 0.0377 s/iter. Total: 0.0757 s/iter. ETA=0:16:16\n",
      "\u001b[32m[07/07 13:55:18 d2.evaluation.evaluator]: \u001b[0mInference done 1621/14460. Dataloading: 0.0023 s/iter. Inference: 0.0356 s/iter. Eval: 0.0376 s/iter. Total: 0.0757 s/iter. ETA=0:16:11\n",
      "\u001b[32m[07/07 13:55:23 d2.evaluation.evaluator]: \u001b[0mInference done 1687/14460. Dataloading: 0.0023 s/iter. Inference: 0.0356 s/iter. Eval: 0.0377 s/iter. Total: 0.0757 s/iter. ETA=0:16:06\n",
      "\u001b[32m[07/07 13:55:28 d2.evaluation.evaluator]: \u001b[0mInference done 1752/14460. Dataloading: 0.0023 s/iter. Inference: 0.0356 s/iter. Eval: 0.0377 s/iter. Total: 0.0757 s/iter. ETA=0:16:02\n",
      "\u001b[32m[07/07 13:55:33 d2.evaluation.evaluator]: \u001b[0mInference done 1817/14460. Dataloading: 0.0023 s/iter. Inference: 0.0356 s/iter. Eval: 0.0378 s/iter. Total: 0.0758 s/iter. ETA=0:15:58\n",
      "\u001b[32m[07/07 13:55:38 d2.evaluation.evaluator]: \u001b[0mInference done 1882/14460. Dataloading: 0.0023 s/iter. Inference: 0.0356 s/iter. Eval: 0.0379 s/iter. Total: 0.0759 s/iter. ETA=0:15:54\n",
      "\u001b[32m[07/07 13:55:43 d2.evaluation.evaluator]: \u001b[0mInference done 1948/14460. Dataloading: 0.0023 s/iter. Inference: 0.0356 s/iter. Eval: 0.0379 s/iter. Total: 0.0759 s/iter. ETA=0:15:49\n",
      "\u001b[32m[07/07 13:55:48 d2.evaluation.evaluator]: \u001b[0mInference done 2014/14460. Dataloading: 0.0023 s/iter. Inference: 0.0356 s/iter. Eval: 0.0379 s/iter. Total: 0.0759 s/iter. ETA=0:15:44\n",
      "\u001b[32m[07/07 13:55:53 d2.evaluation.evaluator]: \u001b[0mInference done 2080/14460. Dataloading: 0.0023 s/iter. Inference: 0.0356 s/iter. Eval: 0.0379 s/iter. Total: 0.0759 s/iter. ETA=0:15:39\n",
      "\u001b[32m[07/07 13:55:58 d2.evaluation.evaluator]: \u001b[0mInference done 2147/14460. Dataloading: 0.0023 s/iter. Inference: 0.0356 s/iter. Eval: 0.0379 s/iter. Total: 0.0759 s/iter. ETA=0:15:34\n",
      "\u001b[32m[07/07 13:56:03 d2.evaluation.evaluator]: \u001b[0mInference done 2213/14460. Dataloading: 0.0023 s/iter. Inference: 0.0356 s/iter. Eval: 0.0379 s/iter. Total: 0.0759 s/iter. ETA=0:15:29\n",
      "\u001b[32m[07/07 13:56:08 d2.evaluation.evaluator]: \u001b[0mInference done 2279/14460. Dataloading: 0.0023 s/iter. Inference: 0.0356 s/iter. Eval: 0.0379 s/iter. Total: 0.0759 s/iter. ETA=0:15:24\n",
      "\u001b[32m[07/07 13:56:13 d2.evaluation.evaluator]: \u001b[0mInference done 2346/14460. Dataloading: 0.0023 s/iter. Inference: 0.0356 s/iter. Eval: 0.0379 s/iter. Total: 0.0759 s/iter. ETA=0:15:19\n",
      "\u001b[32m[07/07 13:56:18 d2.evaluation.evaluator]: \u001b[0mInference done 2412/14460. Dataloading: 0.0023 s/iter. Inference: 0.0356 s/iter. Eval: 0.0379 s/iter. Total: 0.0759 s/iter. ETA=0:15:14\n",
      "\u001b[32m[07/07 13:56:23 d2.evaluation.evaluator]: \u001b[0mInference done 2478/14460. Dataloading: 0.0023 s/iter. Inference: 0.0356 s/iter. Eval: 0.0379 s/iter. Total: 0.0759 s/iter. ETA=0:15:09\n",
      "\u001b[32m[07/07 13:56:28 d2.evaluation.evaluator]: \u001b[0mInference done 2543/14460. Dataloading: 0.0023 s/iter. Inference: 0.0356 s/iter. Eval: 0.0380 s/iter. Total: 0.0760 s/iter. ETA=0:15:05\n",
      "\u001b[32m[07/07 13:56:33 d2.evaluation.evaluator]: \u001b[0mInference done 2609/14460. Dataloading: 0.0023 s/iter. Inference: 0.0356 s/iter. Eval: 0.0380 s/iter. Total: 0.0760 s/iter. ETA=0:15:00\n",
      "\u001b[32m[07/07 13:56:38 d2.evaluation.evaluator]: \u001b[0mInference done 2675/14460. Dataloading: 0.0023 s/iter. Inference: 0.0356 s/iter. Eval: 0.0380 s/iter. Total: 0.0760 s/iter. ETA=0:14:55\n",
      "\u001b[32m[07/07 13:56:43 d2.evaluation.evaluator]: \u001b[0mInference done 2742/14460. Dataloading: 0.0023 s/iter. Inference: 0.0356 s/iter. Eval: 0.0380 s/iter. Total: 0.0760 s/iter. ETA=0:14:50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/07 13:56:48 d2.evaluation.evaluator]: \u001b[0mInference done 2810/14460. Dataloading: 0.0023 s/iter. Inference: 0.0356 s/iter. Eval: 0.0379 s/iter. Total: 0.0759 s/iter. ETA=0:14:44\n",
      "\u001b[32m[07/07 13:56:53 d2.evaluation.evaluator]: \u001b[0mInference done 2875/14460. Dataloading: 0.0023 s/iter. Inference: 0.0356 s/iter. Eval: 0.0380 s/iter. Total: 0.0760 s/iter. ETA=0:14:40\n",
      "\u001b[32m[07/07 13:56:58 d2.evaluation.evaluator]: \u001b[0mInference done 2943/14460. Dataloading: 0.0023 s/iter. Inference: 0.0356 s/iter. Eval: 0.0379 s/iter. Total: 0.0759 s/iter. ETA=0:14:34\n",
      "\u001b[32m[07/07 13:57:03 d2.evaluation.evaluator]: \u001b[0mInference done 3007/14460. Dataloading: 0.0023 s/iter. Inference: 0.0356 s/iter. Eval: 0.0379 s/iter. Total: 0.0760 s/iter. ETA=0:14:30\n",
      "\u001b[32m[07/07 13:57:08 d2.evaluation.evaluator]: \u001b[0mInference done 3073/14460. Dataloading: 0.0023 s/iter. Inference: 0.0356 s/iter. Eval: 0.0379 s/iter. Total: 0.0760 s/iter. ETA=0:14:25\n",
      "\u001b[32m[07/07 13:57:14 d2.evaluation.evaluator]: \u001b[0mInference done 3140/14460. Dataloading: 0.0023 s/iter. Inference: 0.0356 s/iter. Eval: 0.0379 s/iter. Total: 0.0760 s/iter. ETA=0:14:20\n",
      "\u001b[32m[07/07 13:57:19 d2.evaluation.evaluator]: \u001b[0mInference done 3208/14460. Dataloading: 0.0023 s/iter. Inference: 0.0356 s/iter. Eval: 0.0379 s/iter. Total: 0.0759 s/iter. ETA=0:14:14\n",
      "\u001b[32m[07/07 13:57:24 d2.evaluation.evaluator]: \u001b[0mInference done 3274/14460. Dataloading: 0.0023 s/iter. Inference: 0.0356 s/iter. Eval: 0.0379 s/iter. Total: 0.0759 s/iter. ETA=0:14:09\n",
      "\u001b[32m[07/07 13:57:29 d2.evaluation.evaluator]: \u001b[0mInference done 3339/14460. Dataloading: 0.0023 s/iter. Inference: 0.0356 s/iter. Eval: 0.0379 s/iter. Total: 0.0760 s/iter. ETA=0:14:04\n",
      "\u001b[32m[07/07 13:57:34 d2.evaluation.evaluator]: \u001b[0mInference done 3405/14460. Dataloading: 0.0023 s/iter. Inference: 0.0356 s/iter. Eval: 0.0379 s/iter. Total: 0.0760 s/iter. ETA=0:13:59\n",
      "\u001b[32m[07/07 13:57:39 d2.evaluation.evaluator]: \u001b[0mInference done 3472/14460. Dataloading: 0.0023 s/iter. Inference: 0.0356 s/iter. Eval: 0.0379 s/iter. Total: 0.0760 s/iter. ETA=0:13:54\n",
      "\u001b[32m[07/07 13:57:44 d2.evaluation.evaluator]: \u001b[0mInference done 3539/14460. Dataloading: 0.0023 s/iter. Inference: 0.0356 s/iter. Eval: 0.0379 s/iter. Total: 0.0759 s/iter. ETA=0:13:49\n",
      "\u001b[32m[07/07 13:57:49 d2.evaluation.evaluator]: \u001b[0mInference done 3605/14460. Dataloading: 0.0023 s/iter. Inference: 0.0356 s/iter. Eval: 0.0379 s/iter. Total: 0.0760 s/iter. ETA=0:13:44\n",
      "\u001b[32m[07/07 13:57:54 d2.evaluation.evaluator]: \u001b[0mInference done 3671/14460. Dataloading: 0.0023 s/iter. Inference: 0.0356 s/iter. Eval: 0.0379 s/iter. Total: 0.0760 s/iter. ETA=0:13:39\n",
      "\u001b[32m[07/07 13:57:59 d2.evaluation.evaluator]: \u001b[0mInference done 3735/14460. Dataloading: 0.0023 s/iter. Inference: 0.0356 s/iter. Eval: 0.0380 s/iter. Total: 0.0760 s/iter. ETA=0:13:35\n",
      "\u001b[32m[07/07 13:58:04 d2.evaluation.evaluator]: \u001b[0mInference done 3802/14460. Dataloading: 0.0023 s/iter. Inference: 0.0356 s/iter. Eval: 0.0380 s/iter. Total: 0.0760 s/iter. ETA=0:13:29\n",
      "\u001b[32m[07/07 13:58:09 d2.evaluation.evaluator]: \u001b[0mInference done 3868/14460. Dataloading: 0.0023 s/iter. Inference: 0.0356 s/iter. Eval: 0.0380 s/iter. Total: 0.0760 s/iter. ETA=0:13:24\n",
      "\u001b[32m[07/07 13:58:14 d2.evaluation.evaluator]: \u001b[0mInference done 3933/14460. Dataloading: 0.0023 s/iter. Inference: 0.0356 s/iter. Eval: 0.0380 s/iter. Total: 0.0760 s/iter. ETA=0:13:20\n",
      "\u001b[32m[07/07 13:58:19 d2.evaluation.evaluator]: \u001b[0mInference done 4000/14460. Dataloading: 0.0023 s/iter. Inference: 0.0356 s/iter. Eval: 0.0380 s/iter. Total: 0.0760 s/iter. ETA=0:13:14\n",
      "\u001b[32m[07/07 13:58:24 d2.evaluation.evaluator]: \u001b[0mInference done 4067/14460. Dataloading: 0.0023 s/iter. Inference: 0.0356 s/iter. Eval: 0.0380 s/iter. Total: 0.0760 s/iter. ETA=0:13:09\n",
      "\u001b[32m[07/07 13:58:29 d2.evaluation.evaluator]: \u001b[0mInference done 4135/14460. Dataloading: 0.0023 s/iter. Inference: 0.0356 s/iter. Eval: 0.0379 s/iter. Total: 0.0760 s/iter. ETA=0:13:04\n",
      "\u001b[32m[07/07 13:58:34 d2.evaluation.evaluator]: \u001b[0mInference done 4202/14460. Dataloading: 0.0023 s/iter. Inference: 0.0356 s/iter. Eval: 0.0379 s/iter. Total: 0.0759 s/iter. ETA=0:12:58\n",
      "\u001b[32m[07/07 13:58:39 d2.evaluation.evaluator]: \u001b[0mInference done 4269/14460. Dataloading: 0.0023 s/iter. Inference: 0.0356 s/iter. Eval: 0.0379 s/iter. Total: 0.0759 s/iter. ETA=0:12:53\n",
      "\u001b[32m[07/07 13:58:44 d2.evaluation.evaluator]: \u001b[0mInference done 4336/14460. Dataloading: 0.0023 s/iter. Inference: 0.0356 s/iter. Eval: 0.0379 s/iter. Total: 0.0759 s/iter. ETA=0:12:48\n",
      "\u001b[32m[07/07 13:58:49 d2.evaluation.evaluator]: \u001b[0mInference done 4403/14460. Dataloading: 0.0023 s/iter. Inference: 0.0356 s/iter. Eval: 0.0379 s/iter. Total: 0.0759 s/iter. ETA=0:12:43\n",
      "\u001b[32m[07/07 13:58:54 d2.evaluation.evaluator]: \u001b[0mInference done 4470/14460. Dataloading: 0.0023 s/iter. Inference: 0.0356 s/iter. Eval: 0.0379 s/iter. Total: 0.0759 s/iter. ETA=0:12:37\n",
      "\u001b[32m[07/07 13:58:59 d2.evaluation.evaluator]: \u001b[0mInference done 4536/14460. Dataloading: 0.0023 s/iter. Inference: 0.0356 s/iter. Eval: 0.0379 s/iter. Total: 0.0759 s/iter. ETA=0:12:33\n",
      "\u001b[32m[07/07 13:59:04 d2.evaluation.evaluator]: \u001b[0mInference done 4602/14460. Dataloading: 0.0023 s/iter. Inference: 0.0356 s/iter. Eval: 0.0379 s/iter. Total: 0.0759 s/iter. ETA=0:12:28\n",
      "\u001b[32m[07/07 13:59:09 d2.evaluation.evaluator]: \u001b[0mInference done 4668/14460. Dataloading: 0.0023 s/iter. Inference: 0.0356 s/iter. Eval: 0.0379 s/iter. Total: 0.0759 s/iter. ETA=0:12:23\n",
      "\u001b[32m[07/07 13:59:14 d2.evaluation.evaluator]: \u001b[0mInference done 4734/14460. Dataloading: 0.0023 s/iter. Inference: 0.0356 s/iter. Eval: 0.0379 s/iter. Total: 0.0759 s/iter. ETA=0:12:18\n",
      "\u001b[32m[07/07 13:59:19 d2.evaluation.evaluator]: \u001b[0mInference done 4800/14460. Dataloading: 0.0023 s/iter. Inference: 0.0356 s/iter. Eval: 0.0379 s/iter. Total: 0.0759 s/iter. ETA=0:12:13\n",
      "\u001b[32m[07/07 13:59:24 d2.evaluation.evaluator]: \u001b[0mInference done 4866/14460. Dataloading: 0.0023 s/iter. Inference: 0.0356 s/iter. Eval: 0.0379 s/iter. Total: 0.0759 s/iter. ETA=0:12:08\n",
      "\u001b[32m[07/07 13:59:29 d2.evaluation.evaluator]: \u001b[0mInference done 4932/14460. Dataloading: 0.0023 s/iter. Inference: 0.0356 s/iter. Eval: 0.0379 s/iter. Total: 0.0759 s/iter. ETA=0:12:03\n",
      "\u001b[32m[07/07 13:59:34 d2.evaluation.evaluator]: \u001b[0mInference done 4998/14460. Dataloading: 0.0023 s/iter. Inference: 0.0356 s/iter. Eval: 0.0379 s/iter. Total: 0.0759 s/iter. ETA=0:11:58\n",
      "\u001b[32m[07/07 13:59:39 d2.evaluation.evaluator]: \u001b[0mInference done 5064/14460. Dataloading: 0.0023 s/iter. Inference: 0.0356 s/iter. Eval: 0.0379 s/iter. Total: 0.0759 s/iter. ETA=0:11:53\n",
      "\u001b[32m[07/07 13:59:44 d2.evaluation.evaluator]: \u001b[0mInference done 5131/14460. Dataloading: 0.0023 s/iter. Inference: 0.0356 s/iter. Eval: 0.0379 s/iter. Total: 0.0759 s/iter. ETA=0:11:48\n",
      "\u001b[32m[07/07 13:59:49 d2.evaluation.evaluator]: \u001b[0mInference done 5198/14460. Dataloading: 0.0023 s/iter. Inference: 0.0356 s/iter. Eval: 0.0379 s/iter. Total: 0.0759 s/iter. ETA=0:11:42\n",
      "\u001b[32m[07/07 13:59:55 d2.evaluation.evaluator]: \u001b[0mInference done 5266/14460. Dataloading: 0.0023 s/iter. Inference: 0.0356 s/iter. Eval: 0.0379 s/iter. Total: 0.0759 s/iter. ETA=0:11:37\n",
      "\u001b[32m[07/07 14:00:00 d2.evaluation.evaluator]: \u001b[0mInference done 5333/14460. Dataloading: 0.0023 s/iter. Inference: 0.0356 s/iter. Eval: 0.0379 s/iter. Total: 0.0759 s/iter. ETA=0:11:32\n",
      "\u001b[32m[07/07 14:00:05 d2.evaluation.evaluator]: \u001b[0mInference done 5401/14460. Dataloading: 0.0023 s/iter. Inference: 0.0356 s/iter. Eval: 0.0379 s/iter. Total: 0.0759 s/iter. ETA=0:11:27\n",
      "\u001b[32m[07/07 14:00:10 d2.evaluation.evaluator]: \u001b[0mInference done 5469/14460. Dataloading: 0.0023 s/iter. Inference: 0.0356 s/iter. Eval: 0.0379 s/iter. Total: 0.0758 s/iter. ETA=0:11:21\n",
      "\u001b[32m[07/07 14:00:15 d2.evaluation.evaluator]: \u001b[0mInference done 5537/14460. Dataloading: 0.0023 s/iter. Inference: 0.0356 s/iter. Eval: 0.0378 s/iter. Total: 0.0758 s/iter. ETA=0:11:16\n",
      "\u001b[32m[07/07 14:00:20 d2.evaluation.evaluator]: \u001b[0mInference done 5605/14460. Dataloading: 0.0023 s/iter. Inference: 0.0356 s/iter. Eval: 0.0378 s/iter. Total: 0.0758 s/iter. ETA=0:11:11\n",
      "\u001b[32m[07/07 14:00:25 d2.evaluation.evaluator]: \u001b[0mInference done 5671/14460. Dataloading: 0.0023 s/iter. Inference: 0.0356 s/iter. Eval: 0.0378 s/iter. Total: 0.0758 s/iter. ETA=0:11:06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/07 14:00:30 d2.evaluation.evaluator]: \u001b[0mInference done 5737/14460. Dataloading: 0.0023 s/iter. Inference: 0.0356 s/iter. Eval: 0.0378 s/iter. Total: 0.0758 s/iter. ETA=0:11:01\n",
      "\u001b[32m[07/07 14:00:35 d2.evaluation.evaluator]: \u001b[0mInference done 5803/14460. Dataloading: 0.0023 s/iter. Inference: 0.0356 s/iter. Eval: 0.0378 s/iter. Total: 0.0758 s/iter. ETA=0:10:56\n",
      "\u001b[32m[07/07 14:00:40 d2.evaluation.evaluator]: \u001b[0mInference done 5869/14460. Dataloading: 0.0023 s/iter. Inference: 0.0356 s/iter. Eval: 0.0378 s/iter. Total: 0.0758 s/iter. ETA=0:10:51\n",
      "\u001b[32m[07/07 14:00:45 d2.evaluation.evaluator]: \u001b[0mInference done 5933/14460. Dataloading: 0.0023 s/iter. Inference: 0.0357 s/iter. Eval: 0.0378 s/iter. Total: 0.0758 s/iter. ETA=0:10:46\n",
      "\u001b[32m[07/07 14:00:50 d2.evaluation.evaluator]: \u001b[0mInference done 6000/14460. Dataloading: 0.0023 s/iter. Inference: 0.0357 s/iter. Eval: 0.0378 s/iter. Total: 0.0758 s/iter. ETA=0:10:41\n",
      "\u001b[32m[07/07 14:00:55 d2.evaluation.evaluator]: \u001b[0mInference done 6068/14460. Dataloading: 0.0023 s/iter. Inference: 0.0357 s/iter. Eval: 0.0378 s/iter. Total: 0.0758 s/iter. ETA=0:10:36\n",
      "\u001b[32m[07/07 14:01:00 d2.evaluation.evaluator]: \u001b[0mInference done 6136/14460. Dataloading: 0.0023 s/iter. Inference: 0.0357 s/iter. Eval: 0.0378 s/iter. Total: 0.0758 s/iter. ETA=0:10:30\n",
      "\u001b[32m[07/07 14:01:05 d2.evaluation.evaluator]: \u001b[0mInference done 6204/14460. Dataloading: 0.0023 s/iter. Inference: 0.0357 s/iter. Eval: 0.0378 s/iter. Total: 0.0758 s/iter. ETA=0:10:25\n",
      "\u001b[32m[07/07 14:01:10 d2.evaluation.evaluator]: \u001b[0mInference done 6272/14460. Dataloading: 0.0023 s/iter. Inference: 0.0357 s/iter. Eval: 0.0378 s/iter. Total: 0.0758 s/iter. ETA=0:10:20\n",
      "\u001b[32m[07/07 14:01:15 d2.evaluation.evaluator]: \u001b[0mInference done 6340/14460. Dataloading: 0.0023 s/iter. Inference: 0.0357 s/iter. Eval: 0.0378 s/iter. Total: 0.0758 s/iter. ETA=0:10:15\n",
      "\u001b[32m[07/07 14:01:20 d2.evaluation.evaluator]: \u001b[0mInference done 6408/14460. Dataloading: 0.0023 s/iter. Inference: 0.0357 s/iter. Eval: 0.0377 s/iter. Total: 0.0757 s/iter. ETA=0:10:09\n",
      "\u001b[32m[07/07 14:01:25 d2.evaluation.evaluator]: \u001b[0mInference done 6476/14460. Dataloading: 0.0022 s/iter. Inference: 0.0357 s/iter. Eval: 0.0377 s/iter. Total: 0.0757 s/iter. ETA=0:10:04\n",
      "\u001b[32m[07/07 14:01:30 d2.evaluation.evaluator]: \u001b[0mInference done 6527/14460. Dataloading: 0.0022 s/iter. Inference: 0.0357 s/iter. Eval: 0.0379 s/iter. Total: 0.0759 s/iter. ETA=0:10:02\n",
      "\u001b[32m[07/07 14:01:36 d2.evaluation.evaluator]: \u001b[0mInference done 6553/14460. Dataloading: 0.0022 s/iter. Inference: 0.0357 s/iter. Eval: 0.0384 s/iter. Total: 0.0764 s/iter. ETA=0:10:04\n",
      "\u001b[32m[07/07 14:01:41 d2.evaluation.evaluator]: \u001b[0mInference done 6580/14460. Dataloading: 0.0022 s/iter. Inference: 0.0358 s/iter. Eval: 0.0388 s/iter. Total: 0.0769 s/iter. ETA=0:10:05\n",
      "\u001b[32m[07/07 14:01:46 d2.evaluation.evaluator]: \u001b[0mInference done 6606/14460. Dataloading: 0.0022 s/iter. Inference: 0.0358 s/iter. Eval: 0.0392 s/iter. Total: 0.0774 s/iter. ETA=0:10:07\n",
      "\u001b[32m[07/07 14:01:51 d2.evaluation.evaluator]: \u001b[0mInference done 6632/14460. Dataloading: 0.0022 s/iter. Inference: 0.0359 s/iter. Eval: 0.0397 s/iter. Total: 0.0778 s/iter. ETA=0:10:09\n",
      "\u001b[32m[07/07 14:01:56 d2.evaluation.evaluator]: \u001b[0mInference done 6658/14460. Dataloading: 0.0022 s/iter. Inference: 0.0359 s/iter. Eval: 0.0401 s/iter. Total: 0.0783 s/iter. ETA=0:10:10\n",
      "\u001b[32m[07/07 14:02:01 d2.evaluation.evaluator]: \u001b[0mInference done 6685/14460. Dataloading: 0.0022 s/iter. Inference: 0.0359 s/iter. Eval: 0.0405 s/iter. Total: 0.0788 s/iter. ETA=0:10:12\n",
      "\u001b[32m[07/07 14:02:07 d2.evaluation.evaluator]: \u001b[0mInference done 6712/14460. Dataloading: 0.0022 s/iter. Inference: 0.0360 s/iter. Eval: 0.0409 s/iter. Total: 0.0792 s/iter. ETA=0:10:13\n",
      "\u001b[32m[07/07 14:02:12 d2.evaluation.evaluator]: \u001b[0mInference done 6739/14460. Dataloading: 0.0022 s/iter. Inference: 0.0360 s/iter. Eval: 0.0413 s/iter. Total: 0.0796 s/iter. ETA=0:10:14\n",
      "\u001b[32m[07/07 14:02:17 d2.evaluation.evaluator]: \u001b[0mInference done 6766/14460. Dataloading: 0.0022 s/iter. Inference: 0.0361 s/iter. Eval: 0.0417 s/iter. Total: 0.0801 s/iter. ETA=0:10:16\n",
      "\u001b[32m[07/07 14:02:22 d2.evaluation.evaluator]: \u001b[0mInference done 6794/14460. Dataloading: 0.0022 s/iter. Inference: 0.0361 s/iter. Eval: 0.0421 s/iter. Total: 0.0805 s/iter. ETA=0:10:17\n",
      "\u001b[32m[07/07 14:02:27 d2.evaluation.evaluator]: \u001b[0mInference done 6821/14460. Dataloading: 0.0022 s/iter. Inference: 0.0362 s/iter. Eval: 0.0424 s/iter. Total: 0.0809 s/iter. ETA=0:10:18\n",
      "\u001b[32m[07/07 14:02:32 d2.evaluation.evaluator]: \u001b[0mInference done 6848/14460. Dataloading: 0.0022 s/iter. Inference: 0.0362 s/iter. Eval: 0.0428 s/iter. Total: 0.0813 s/iter. ETA=0:10:19\n",
      "\u001b[32m[07/07 14:02:37 d2.evaluation.evaluator]: \u001b[0mInference done 6873/14460. Dataloading: 0.0022 s/iter. Inference: 0.0362 s/iter. Eval: 0.0432 s/iter. Total: 0.0818 s/iter. ETA=0:10:20\n",
      "\u001b[32m[07/07 14:02:42 d2.evaluation.evaluator]: \u001b[0mInference done 6899/14460. Dataloading: 0.0022 s/iter. Inference: 0.0363 s/iter. Eval: 0.0436 s/iter. Total: 0.0822 s/iter. ETA=0:10:21\n",
      "\u001b[32m[07/07 14:02:47 d2.evaluation.evaluator]: \u001b[0mInference done 6925/14460. Dataloading: 0.0022 s/iter. Inference: 0.0363 s/iter. Eval: 0.0440 s/iter. Total: 0.0827 s/iter. ETA=0:10:22\n",
      "\u001b[32m[07/07 14:02:52 d2.evaluation.evaluator]: \u001b[0mInference done 6950/14460. Dataloading: 0.0022 s/iter. Inference: 0.0363 s/iter. Eval: 0.0444 s/iter. Total: 0.0831 s/iter. ETA=0:10:23\n",
      "\u001b[32m[07/07 14:02:57 d2.evaluation.evaluator]: \u001b[0mInference done 6975/14460. Dataloading: 0.0022 s/iter. Inference: 0.0364 s/iter. Eval: 0.0448 s/iter. Total: 0.0835 s/iter. ETA=0:10:25\n",
      "\u001b[32m[07/07 14:03:03 d2.evaluation.evaluator]: \u001b[0mInference done 7001/14460. Dataloading: 0.0022 s/iter. Inference: 0.0364 s/iter. Eval: 0.0452 s/iter. Total: 0.0839 s/iter. ETA=0:10:26\n",
      "\u001b[32m[07/07 14:03:08 d2.evaluation.evaluator]: \u001b[0mInference done 7027/14460. Dataloading: 0.0022 s/iter. Inference: 0.0365 s/iter. Eval: 0.0456 s/iter. Total: 0.0843 s/iter. ETA=0:10:26\n",
      "\u001b[32m[07/07 14:03:13 d2.evaluation.evaluator]: \u001b[0mInference done 7053/14460. Dataloading: 0.0022 s/iter. Inference: 0.0365 s/iter. Eval: 0.0459 s/iter. Total: 0.0848 s/iter. ETA=0:10:27\n",
      "\u001b[32m[07/07 14:03:18 d2.evaluation.evaluator]: \u001b[0mInference done 7079/14460. Dataloading: 0.0022 s/iter. Inference: 0.0365 s/iter. Eval: 0.0463 s/iter. Total: 0.0852 s/iter. ETA=0:10:28\n",
      "\u001b[32m[07/07 14:03:23 d2.evaluation.evaluator]: \u001b[0mInference done 7105/14460. Dataloading: 0.0022 s/iter. Inference: 0.0366 s/iter. Eval: 0.0467 s/iter. Total: 0.0856 s/iter. ETA=0:10:29\n",
      "\u001b[32m[07/07 14:03:28 d2.evaluation.evaluator]: \u001b[0mInference done 7131/14460. Dataloading: 0.0022 s/iter. Inference: 0.0366 s/iter. Eval: 0.0470 s/iter. Total: 0.0860 s/iter. ETA=0:10:30\n",
      "\u001b[32m[07/07 14:03:33 d2.evaluation.evaluator]: \u001b[0mInference done 7157/14460. Dataloading: 0.0022 s/iter. Inference: 0.0366 s/iter. Eval: 0.0474 s/iter. Total: 0.0864 s/iter. ETA=0:10:30\n",
      "\u001b[32m[07/07 14:03:38 d2.evaluation.evaluator]: \u001b[0mInference done 7183/14460. Dataloading: 0.0022 s/iter. Inference: 0.0367 s/iter. Eval: 0.0478 s/iter. Total: 0.0868 s/iter. ETA=0:10:31\n",
      "\u001b[32m[07/07 14:03:43 d2.evaluation.evaluator]: \u001b[0mInference done 7209/14460. Dataloading: 0.0022 s/iter. Inference: 0.0367 s/iter. Eval: 0.0481 s/iter. Total: 0.0872 s/iter. ETA=0:10:32\n",
      "\u001b[32m[07/07 14:03:48 d2.evaluation.evaluator]: \u001b[0mInference done 7236/14460. Dataloading: 0.0022 s/iter. Inference: 0.0368 s/iter. Eval: 0.0485 s/iter. Total: 0.0876 s/iter. ETA=0:10:32\n",
      "\u001b[32m[07/07 14:03:53 d2.evaluation.evaluator]: \u001b[0mInference done 7261/14460. Dataloading: 0.0022 s/iter. Inference: 0.0368 s/iter. Eval: 0.0488 s/iter. Total: 0.0879 s/iter. ETA=0:10:33\n",
      "\u001b[32m[07/07 14:03:58 d2.evaluation.evaluator]: \u001b[0mInference done 7286/14460. Dataloading: 0.0022 s/iter. Inference: 0.0368 s/iter. Eval: 0.0492 s/iter. Total: 0.0883 s/iter. ETA=0:10:33\n",
      "\u001b[32m[07/07 14:04:04 d2.evaluation.evaluator]: \u001b[0mInference done 7311/14460. Dataloading: 0.0022 s/iter. Inference: 0.0369 s/iter. Eval: 0.0496 s/iter. Total: 0.0887 s/iter. ETA=0:10:34\n",
      "\u001b[32m[07/07 14:04:09 d2.evaluation.evaluator]: \u001b[0mInference done 7337/14460. Dataloading: 0.0022 s/iter. Inference: 0.0369 s/iter. Eval: 0.0499 s/iter. Total: 0.0891 s/iter. ETA=0:10:34\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/07 14:04:14 d2.evaluation.evaluator]: \u001b[0mInference done 7363/14460. Dataloading: 0.0022 s/iter. Inference: 0.0369 s/iter. Eval: 0.0502 s/iter. Total: 0.0895 s/iter. ETA=0:10:34\n",
      "\u001b[32m[07/07 14:04:19 d2.evaluation.evaluator]: \u001b[0mInference done 7389/14460. Dataloading: 0.0022 s/iter. Inference: 0.0370 s/iter. Eval: 0.0506 s/iter. Total: 0.0898 s/iter. ETA=0:10:35\n",
      "\u001b[32m[07/07 14:04:24 d2.evaluation.evaluator]: \u001b[0mInference done 7415/14460. Dataloading: 0.0022 s/iter. Inference: 0.0370 s/iter. Eval: 0.0509 s/iter. Total: 0.0902 s/iter. ETA=0:10:35\n",
      "\u001b[32m[07/07 14:04:29 d2.evaluation.evaluator]: \u001b[0mInference done 7442/14460. Dataloading: 0.0022 s/iter. Inference: 0.0370 s/iter. Eval: 0.0512 s/iter. Total: 0.0906 s/iter. ETA=0:10:35\n",
      "\u001b[32m[07/07 14:04:34 d2.evaluation.evaluator]: \u001b[0mInference done 7469/14460. Dataloading: 0.0022 s/iter. Inference: 0.0371 s/iter. Eval: 0.0516 s/iter. Total: 0.0909 s/iter. ETA=0:10:35\n",
      "\u001b[32m[07/07 14:04:39 d2.evaluation.evaluator]: \u001b[0mInference done 7495/14460. Dataloading: 0.0022 s/iter. Inference: 0.0371 s/iter. Eval: 0.0519 s/iter. Total: 0.0913 s/iter. ETA=0:10:35\n",
      "\u001b[32m[07/07 14:04:44 d2.evaluation.evaluator]: \u001b[0mInference done 7521/14460. Dataloading: 0.0022 s/iter. Inference: 0.0371 s/iter. Eval: 0.0522 s/iter. Total: 0.0917 s/iter. ETA=0:10:36\n",
      "\u001b[32m[07/07 14:04:49 d2.evaluation.evaluator]: \u001b[0mInference done 7547/14460. Dataloading: 0.0022 s/iter. Inference: 0.0372 s/iter. Eval: 0.0526 s/iter. Total: 0.0920 s/iter. ETA=0:10:36\n",
      "\u001b[32m[07/07 14:04:54 d2.evaluation.evaluator]: \u001b[0mInference done 7574/14460. Dataloading: 0.0022 s/iter. Inference: 0.0372 s/iter. Eval: 0.0529 s/iter. Total: 0.0924 s/iter. ETA=0:10:36\n",
      "\u001b[32m[07/07 14:04:59 d2.evaluation.evaluator]: \u001b[0mInference done 7600/14460. Dataloading: 0.0022 s/iter. Inference: 0.0372 s/iter. Eval: 0.0532 s/iter. Total: 0.0927 s/iter. ETA=0:10:36\n",
      "\u001b[32m[07/07 14:05:05 d2.evaluation.evaluator]: \u001b[0mInference done 7625/14460. Dataloading: 0.0022 s/iter. Inference: 0.0373 s/iter. Eval: 0.0535 s/iter. Total: 0.0931 s/iter. ETA=0:10:36\n",
      "\u001b[32m[07/07 14:05:10 d2.evaluation.evaluator]: \u001b[0mInference done 7651/14460. Dataloading: 0.0022 s/iter. Inference: 0.0373 s/iter. Eval: 0.0538 s/iter. Total: 0.0934 s/iter. ETA=0:10:36\n",
      "\u001b[32m[07/07 14:05:15 d2.evaluation.evaluator]: \u001b[0mInference done 7677/14460. Dataloading: 0.0022 s/iter. Inference: 0.0373 s/iter. Eval: 0.0541 s/iter. Total: 0.0938 s/iter. ETA=0:10:36\n",
      "\u001b[32m[07/07 14:05:20 d2.evaluation.evaluator]: \u001b[0mInference done 7703/14460. Dataloading: 0.0022 s/iter. Inference: 0.0374 s/iter. Eval: 0.0545 s/iter. Total: 0.0941 s/iter. ETA=0:10:36\n",
      "\u001b[32m[07/07 14:05:25 d2.evaluation.evaluator]: \u001b[0mInference done 7728/14460. Dataloading: 0.0022 s/iter. Inference: 0.0374 s/iter. Eval: 0.0548 s/iter. Total: 0.0945 s/iter. ETA=0:10:36\n",
      "\u001b[32m[07/07 14:05:30 d2.evaluation.evaluator]: \u001b[0mInference done 7753/14460. Dataloading: 0.0022 s/iter. Inference: 0.0374 s/iter. Eval: 0.0551 s/iter. Total: 0.0948 s/iter. ETA=0:10:36\n",
      "\u001b[32m[07/07 14:05:35 d2.evaluation.evaluator]: \u001b[0mInference done 7779/14460. Dataloading: 0.0022 s/iter. Inference: 0.0375 s/iter. Eval: 0.0554 s/iter. Total: 0.0952 s/iter. ETA=0:10:35\n",
      "\u001b[32m[07/07 14:05:40 d2.evaluation.evaluator]: \u001b[0mInference done 7806/14460. Dataloading: 0.0022 s/iter. Inference: 0.0375 s/iter. Eval: 0.0557 s/iter. Total: 0.0955 s/iter. ETA=0:10:35\n",
      "\u001b[32m[07/07 14:05:45 d2.evaluation.evaluator]: \u001b[0mInference done 7832/14460. Dataloading: 0.0022 s/iter. Inference: 0.0375 s/iter. Eval: 0.0560 s/iter. Total: 0.0958 s/iter. ETA=0:10:35\n",
      "\u001b[32m[07/07 14:05:50 d2.evaluation.evaluator]: \u001b[0mInference done 7858/14460. Dataloading: 0.0022 s/iter. Inference: 0.0375 s/iter. Eval: 0.0563 s/iter. Total: 0.0962 s/iter. ETA=0:10:34\n",
      "\u001b[32m[07/07 14:05:56 d2.evaluation.evaluator]: \u001b[0mInference done 7884/14460. Dataloading: 0.0022 s/iter. Inference: 0.0376 s/iter. Eval: 0.0566 s/iter. Total: 0.0965 s/iter. ETA=0:10:34\n",
      "\u001b[32m[07/07 14:06:01 d2.evaluation.evaluator]: \u001b[0mInference done 7909/14460. Dataloading: 0.0022 s/iter. Inference: 0.0376 s/iter. Eval: 0.0569 s/iter. Total: 0.0968 s/iter. ETA=0:10:34\n",
      "\u001b[32m[07/07 14:06:06 d2.evaluation.evaluator]: \u001b[0mInference done 7966/14460. Dataloading: 0.0022 s/iter. Inference: 0.0376 s/iter. Eval: 0.0569 s/iter. Total: 0.0968 s/iter. ETA=0:10:28\n",
      "\u001b[32m[07/07 14:06:11 d2.evaluation.evaluator]: \u001b[0mInference done 8031/14460. Dataloading: 0.0022 s/iter. Inference: 0.0376 s/iter. Eval: 0.0567 s/iter. Total: 0.0966 s/iter. ETA=0:10:21\n",
      "\u001b[32m[07/07 14:06:16 d2.evaluation.evaluator]: \u001b[0mInference done 8097/14460. Dataloading: 0.0022 s/iter. Inference: 0.0376 s/iter. Eval: 0.0566 s/iter. Total: 0.0965 s/iter. ETA=0:10:13\n",
      "\u001b[32m[07/07 14:06:21 d2.evaluation.evaluator]: \u001b[0mInference done 8163/14460. Dataloading: 0.0022 s/iter. Inference: 0.0375 s/iter. Eval: 0.0565 s/iter. Total: 0.0963 s/iter. ETA=0:10:06\n",
      "\u001b[32m[07/07 14:06:26 d2.evaluation.evaluator]: \u001b[0mInference done 8229/14460. Dataloading: 0.0022 s/iter. Inference: 0.0375 s/iter. Eval: 0.0563 s/iter. Total: 0.0961 s/iter. ETA=0:09:59\n",
      "\u001b[32m[07/07 14:06:31 d2.evaluation.evaluator]: \u001b[0mInference done 8295/14460. Dataloading: 0.0022 s/iter. Inference: 0.0375 s/iter. Eval: 0.0562 s/iter. Total: 0.0960 s/iter. ETA=0:09:51\n",
      "\u001b[32m[07/07 14:06:36 d2.evaluation.evaluator]: \u001b[0mInference done 8361/14460. Dataloading: 0.0022 s/iter. Inference: 0.0375 s/iter. Eval: 0.0560 s/iter. Total: 0.0958 s/iter. ETA=0:09:44\n",
      "\u001b[32m[07/07 14:06:41 d2.evaluation.evaluator]: \u001b[0mInference done 8427/14460. Dataloading: 0.0022 s/iter. Inference: 0.0375 s/iter. Eval: 0.0559 s/iter. Total: 0.0957 s/iter. ETA=0:09:37\n",
      "\u001b[32m[07/07 14:06:46 d2.evaluation.evaluator]: \u001b[0mInference done 8492/14460. Dataloading: 0.0022 s/iter. Inference: 0.0375 s/iter. Eval: 0.0558 s/iter. Total: 0.0955 s/iter. ETA=0:09:30\n",
      "\u001b[32m[07/07 14:06:51 d2.evaluation.evaluator]: \u001b[0mInference done 8555/14460. Dataloading: 0.0022 s/iter. Inference: 0.0374 s/iter. Eval: 0.0557 s/iter. Total: 0.0954 s/iter. ETA=0:09:23\n",
      "\u001b[32m[07/07 14:06:56 d2.evaluation.evaluator]: \u001b[0mInference done 8617/14460. Dataloading: 0.0022 s/iter. Inference: 0.0374 s/iter. Eval: 0.0556 s/iter. Total: 0.0953 s/iter. ETA=0:09:16\n",
      "\u001b[32m[07/07 14:07:01 d2.evaluation.evaluator]: \u001b[0mInference done 8680/14460. Dataloading: 0.0022 s/iter. Inference: 0.0374 s/iter. Eval: 0.0555 s/iter. Total: 0.0952 s/iter. ETA=0:09:10\n",
      "\u001b[32m[07/07 14:07:06 d2.evaluation.evaluator]: \u001b[0mInference done 8743/14460. Dataloading: 0.0022 s/iter. Inference: 0.0374 s/iter. Eval: 0.0554 s/iter. Total: 0.0951 s/iter. ETA=0:09:03\n",
      "\u001b[32m[07/07 14:07:11 d2.evaluation.evaluator]: \u001b[0mInference done 8807/14460. Dataloading: 0.0022 s/iter. Inference: 0.0374 s/iter. Eval: 0.0553 s/iter. Total: 0.0950 s/iter. ETA=0:08:56\n",
      "\u001b[32m[07/07 14:07:16 d2.evaluation.evaluator]: \u001b[0mInference done 8871/14460. Dataloading: 0.0022 s/iter. Inference: 0.0374 s/iter. Eval: 0.0552 s/iter. Total: 0.0949 s/iter. ETA=0:08:50\n",
      "\u001b[32m[07/07 14:07:21 d2.evaluation.evaluator]: \u001b[0mInference done 8934/14460. Dataloading: 0.0022 s/iter. Inference: 0.0374 s/iter. Eval: 0.0551 s/iter. Total: 0.0948 s/iter. ETA=0:08:43\n",
      "\u001b[32m[07/07 14:07:26 d2.evaluation.evaluator]: \u001b[0mInference done 8996/14460. Dataloading: 0.0022 s/iter. Inference: 0.0373 s/iter. Eval: 0.0550 s/iter. Total: 0.0947 s/iter. ETA=0:08:37\n",
      "\u001b[32m[07/07 14:07:31 d2.evaluation.evaluator]: \u001b[0mInference done 9058/14460. Dataloading: 0.0022 s/iter. Inference: 0.0373 s/iter. Eval: 0.0549 s/iter. Total: 0.0946 s/iter. ETA=0:08:30\n",
      "\u001b[32m[07/07 14:07:36 d2.evaluation.evaluator]: \u001b[0mInference done 9123/14460. Dataloading: 0.0022 s/iter. Inference: 0.0373 s/iter. Eval: 0.0548 s/iter. Total: 0.0944 s/iter. ETA=0:08:24\n",
      "\u001b[32m[07/07 14:07:41 d2.evaluation.evaluator]: \u001b[0mInference done 9188/14460. Dataloading: 0.0022 s/iter. Inference: 0.0373 s/iter. Eval: 0.0547 s/iter. Total: 0.0943 s/iter. ETA=0:08:17\n",
      "\u001b[32m[07/07 14:07:47 d2.evaluation.evaluator]: \u001b[0mInference done 9250/14460. Dataloading: 0.0022 s/iter. Inference: 0.0373 s/iter. Eval: 0.0546 s/iter. Total: 0.0942 s/iter. ETA=0:08:10\n",
      "\u001b[32m[07/07 14:07:52 d2.evaluation.evaluator]: \u001b[0mInference done 9313/14460. Dataloading: 0.0022 s/iter. Inference: 0.0373 s/iter. Eval: 0.0546 s/iter. Total: 0.0941 s/iter. ETA=0:08:04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/07 14:07:57 d2.evaluation.evaluator]: \u001b[0mInference done 9375/14460. Dataloading: 0.0022 s/iter. Inference: 0.0373 s/iter. Eval: 0.0545 s/iter. Total: 0.0940 s/iter. ETA=0:07:58\n",
      "\u001b[32m[07/07 14:08:02 d2.evaluation.evaluator]: \u001b[0mInference done 9439/14460. Dataloading: 0.0022 s/iter. Inference: 0.0373 s/iter. Eval: 0.0544 s/iter. Total: 0.0939 s/iter. ETA=0:07:51\n",
      "\u001b[32m[07/07 14:08:07 d2.evaluation.evaluator]: \u001b[0mInference done 9505/14460. Dataloading: 0.0022 s/iter. Inference: 0.0373 s/iter. Eval: 0.0543 s/iter. Total: 0.0938 s/iter. ETA=0:07:44\n",
      "\u001b[32m[07/07 14:08:12 d2.evaluation.evaluator]: \u001b[0mInference done 9573/14460. Dataloading: 0.0022 s/iter. Inference: 0.0372 s/iter. Eval: 0.0541 s/iter. Total: 0.0937 s/iter. ETA=0:07:37\n",
      "\u001b[32m[07/07 14:08:17 d2.evaluation.evaluator]: \u001b[0mInference done 9640/14460. Dataloading: 0.0022 s/iter. Inference: 0.0372 s/iter. Eval: 0.0540 s/iter. Total: 0.0936 s/iter. ETA=0:07:30\n",
      "\u001b[32m[07/07 14:08:22 d2.evaluation.evaluator]: \u001b[0mInference done 9707/14460. Dataloading: 0.0022 s/iter. Inference: 0.0372 s/iter. Eval: 0.0539 s/iter. Total: 0.0934 s/iter. ETA=0:07:24\n",
      "\u001b[32m[07/07 14:08:27 d2.evaluation.evaluator]: \u001b[0mInference done 9775/14460. Dataloading: 0.0022 s/iter. Inference: 0.0372 s/iter. Eval: 0.0538 s/iter. Total: 0.0933 s/iter. ETA=0:07:17\n",
      "\u001b[32m[07/07 14:08:32 d2.evaluation.evaluator]: \u001b[0mInference done 9842/14460. Dataloading: 0.0022 s/iter. Inference: 0.0372 s/iter. Eval: 0.0537 s/iter. Total: 0.0932 s/iter. ETA=0:07:10\n",
      "\u001b[32m[07/07 14:08:37 d2.evaluation.evaluator]: \u001b[0mInference done 9909/14460. Dataloading: 0.0022 s/iter. Inference: 0.0372 s/iter. Eval: 0.0536 s/iter. Total: 0.0931 s/iter. ETA=0:07:03\n",
      "\u001b[32m[07/07 14:08:42 d2.evaluation.evaluator]: \u001b[0mInference done 9977/14460. Dataloading: 0.0022 s/iter. Inference: 0.0372 s/iter. Eval: 0.0535 s/iter. Total: 0.0929 s/iter. ETA=0:06:56\n",
      "\u001b[32m[07/07 14:08:47 d2.evaluation.evaluator]: \u001b[0mInference done 10044/14460. Dataloading: 0.0022 s/iter. Inference: 0.0372 s/iter. Eval: 0.0533 s/iter. Total: 0.0928 s/iter. ETA=0:06:49\n",
      "\u001b[32m[07/07 14:08:52 d2.evaluation.evaluator]: \u001b[0mInference done 10110/14460. Dataloading: 0.0022 s/iter. Inference: 0.0372 s/iter. Eval: 0.0533 s/iter. Total: 0.0927 s/iter. ETA=0:06:43\n",
      "\u001b[32m[07/07 14:08:57 d2.evaluation.evaluator]: \u001b[0mInference done 10178/14460. Dataloading: 0.0022 s/iter. Inference: 0.0371 s/iter. Eval: 0.0531 s/iter. Total: 0.0926 s/iter. ETA=0:06:36\n",
      "\u001b[32m[07/07 14:09:02 d2.evaluation.evaluator]: \u001b[0mInference done 10246/14460. Dataloading: 0.0022 s/iter. Inference: 0.0371 s/iter. Eval: 0.0530 s/iter. Total: 0.0924 s/iter. ETA=0:06:29\n",
      "\u001b[32m[07/07 14:09:07 d2.evaluation.evaluator]: \u001b[0mInference done 10314/14460. Dataloading: 0.0022 s/iter. Inference: 0.0371 s/iter. Eval: 0.0529 s/iter. Total: 0.0923 s/iter. ETA=0:06:22\n",
      "\u001b[32m[07/07 14:09:12 d2.evaluation.evaluator]: \u001b[0mInference done 10381/14460. Dataloading: 0.0022 s/iter. Inference: 0.0371 s/iter. Eval: 0.0528 s/iter. Total: 0.0922 s/iter. ETA=0:06:16\n",
      "\u001b[32m[07/07 14:09:17 d2.evaluation.evaluator]: \u001b[0mInference done 10449/14460. Dataloading: 0.0022 s/iter. Inference: 0.0371 s/iter. Eval: 0.0527 s/iter. Total: 0.0921 s/iter. ETA=0:06:09\n",
      "\u001b[32m[07/07 14:09:22 d2.evaluation.evaluator]: \u001b[0mInference done 10516/14460. Dataloading: 0.0022 s/iter. Inference: 0.0371 s/iter. Eval: 0.0526 s/iter. Total: 0.0920 s/iter. ETA=0:06:02\n",
      "\u001b[32m[07/07 14:09:27 d2.evaluation.evaluator]: \u001b[0mInference done 10583/14460. Dataloading: 0.0022 s/iter. Inference: 0.0371 s/iter. Eval: 0.0525 s/iter. Total: 0.0919 s/iter. ETA=0:05:56\n",
      "\u001b[32m[07/07 14:09:32 d2.evaluation.evaluator]: \u001b[0mInference done 10649/14460. Dataloading: 0.0022 s/iter. Inference: 0.0371 s/iter. Eval: 0.0524 s/iter. Total: 0.0918 s/iter. ETA=0:05:49\n",
      "\u001b[32m[07/07 14:09:37 d2.evaluation.evaluator]: \u001b[0mInference done 10717/14460. Dataloading: 0.0022 s/iter. Inference: 0.0371 s/iter. Eval: 0.0523 s/iter. Total: 0.0917 s/iter. ETA=0:05:43\n",
      "\u001b[32m[07/07 14:09:42 d2.evaluation.evaluator]: \u001b[0mInference done 10784/14460. Dataloading: 0.0022 s/iter. Inference: 0.0371 s/iter. Eval: 0.0522 s/iter. Total: 0.0916 s/iter. ETA=0:05:36\n",
      "\u001b[32m[07/07 14:09:47 d2.evaluation.evaluator]: \u001b[0mInference done 10851/14460. Dataloading: 0.0022 s/iter. Inference: 0.0370 s/iter. Eval: 0.0521 s/iter. Total: 0.0915 s/iter. ETA=0:05:30\n",
      "\u001b[32m[07/07 14:09:52 d2.evaluation.evaluator]: \u001b[0mInference done 10918/14460. Dataloading: 0.0022 s/iter. Inference: 0.0370 s/iter. Eval: 0.0520 s/iter. Total: 0.0914 s/iter. ETA=0:05:23\n",
      "\u001b[32m[07/07 14:09:57 d2.evaluation.evaluator]: \u001b[0mInference done 10984/14460. Dataloading: 0.0022 s/iter. Inference: 0.0370 s/iter. Eval: 0.0520 s/iter. Total: 0.0913 s/iter. ETA=0:05:17\n",
      "\u001b[32m[07/07 14:10:02 d2.evaluation.evaluator]: \u001b[0mInference done 11051/14460. Dataloading: 0.0022 s/iter. Inference: 0.0370 s/iter. Eval: 0.0519 s/iter. Total: 0.0912 s/iter. ETA=0:05:10\n",
      "\u001b[32m[07/07 14:10:08 d2.evaluation.evaluator]: \u001b[0mInference done 11118/14460. Dataloading: 0.0022 s/iter. Inference: 0.0370 s/iter. Eval: 0.0518 s/iter. Total: 0.0911 s/iter. ETA=0:05:04\n",
      "\u001b[32m[07/07 14:10:13 d2.evaluation.evaluator]: \u001b[0mInference done 11184/14460. Dataloading: 0.0022 s/iter. Inference: 0.0370 s/iter. Eval: 0.0517 s/iter. Total: 0.0910 s/iter. ETA=0:04:58\n",
      "\u001b[32m[07/07 14:10:18 d2.evaluation.evaluator]: \u001b[0mInference done 11251/14460. Dataloading: 0.0022 s/iter. Inference: 0.0370 s/iter. Eval: 0.0516 s/iter. Total: 0.0909 s/iter. ETA=0:04:51\n",
      "\u001b[32m[07/07 14:10:23 d2.evaluation.evaluator]: \u001b[0mInference done 11318/14460. Dataloading: 0.0022 s/iter. Inference: 0.0370 s/iter. Eval: 0.0515 s/iter. Total: 0.0908 s/iter. ETA=0:04:45\n",
      "\u001b[32m[07/07 14:10:28 d2.evaluation.evaluator]: \u001b[0mInference done 11385/14460. Dataloading: 0.0022 s/iter. Inference: 0.0370 s/iter. Eval: 0.0514 s/iter. Total: 0.0907 s/iter. ETA=0:04:38\n",
      "\u001b[32m[07/07 14:10:33 d2.evaluation.evaluator]: \u001b[0mInference done 11453/14460. Dataloading: 0.0022 s/iter. Inference: 0.0370 s/iter. Eval: 0.0514 s/iter. Total: 0.0906 s/iter. ETA=0:04:32\n",
      "\u001b[32m[07/07 14:10:38 d2.evaluation.evaluator]: \u001b[0mInference done 11520/14460. Dataloading: 0.0022 s/iter. Inference: 0.0370 s/iter. Eval: 0.0513 s/iter. Total: 0.0905 s/iter. ETA=0:04:26\n",
      "\u001b[32m[07/07 14:10:43 d2.evaluation.evaluator]: \u001b[0mInference done 11587/14460. Dataloading: 0.0022 s/iter. Inference: 0.0370 s/iter. Eval: 0.0512 s/iter. Total: 0.0904 s/iter. ETA=0:04:19\n",
      "\u001b[32m[07/07 14:10:48 d2.evaluation.evaluator]: \u001b[0mInference done 11655/14460. Dataloading: 0.0022 s/iter. Inference: 0.0369 s/iter. Eval: 0.0511 s/iter. Total: 0.0903 s/iter. ETA=0:04:13\n",
      "\u001b[32m[07/07 14:10:53 d2.evaluation.evaluator]: \u001b[0mInference done 11722/14460. Dataloading: 0.0022 s/iter. Inference: 0.0369 s/iter. Eval: 0.0510 s/iter. Total: 0.0903 s/iter. ETA=0:04:07\n",
      "\u001b[32m[07/07 14:10:58 d2.evaluation.evaluator]: \u001b[0mInference done 11789/14460. Dataloading: 0.0022 s/iter. Inference: 0.0369 s/iter. Eval: 0.0509 s/iter. Total: 0.0902 s/iter. ETA=0:04:00\n",
      "\u001b[32m[07/07 14:11:03 d2.evaluation.evaluator]: \u001b[0mInference done 11856/14460. Dataloading: 0.0022 s/iter. Inference: 0.0369 s/iter. Eval: 0.0509 s/iter. Total: 0.0901 s/iter. ETA=0:03:54\n",
      "\u001b[32m[07/07 14:11:08 d2.evaluation.evaluator]: \u001b[0mInference done 11923/14460. Dataloading: 0.0022 s/iter. Inference: 0.0369 s/iter. Eval: 0.0508 s/iter. Total: 0.0900 s/iter. ETA=0:03:48\n",
      "\u001b[32m[07/07 14:11:13 d2.evaluation.evaluator]: \u001b[0mInference done 11990/14460. Dataloading: 0.0022 s/iter. Inference: 0.0369 s/iter. Eval: 0.0507 s/iter. Total: 0.0899 s/iter. ETA=0:03:42\n",
      "\u001b[32m[07/07 14:11:18 d2.evaluation.evaluator]: \u001b[0mInference done 12057/14460. Dataloading: 0.0022 s/iter. Inference: 0.0369 s/iter. Eval: 0.0506 s/iter. Total: 0.0898 s/iter. ETA=0:03:35\n",
      "\u001b[32m[07/07 14:11:23 d2.evaluation.evaluator]: \u001b[0mInference done 12124/14460. Dataloading: 0.0022 s/iter. Inference: 0.0369 s/iter. Eval: 0.0506 s/iter. Total: 0.0897 s/iter. ETA=0:03:29\n",
      "\u001b[32m[07/07 14:11:28 d2.evaluation.evaluator]: \u001b[0mInference done 12191/14460. Dataloading: 0.0022 s/iter. Inference: 0.0369 s/iter. Eval: 0.0505 s/iter. Total: 0.0897 s/iter. ETA=0:03:23\n",
      "\u001b[32m[07/07 14:11:33 d2.evaluation.evaluator]: \u001b[0mInference done 12258/14460. Dataloading: 0.0022 s/iter. Inference: 0.0369 s/iter. Eval: 0.0504 s/iter. Total: 0.0896 s/iter. ETA=0:03:17\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/07 14:11:38 d2.evaluation.evaluator]: \u001b[0mInference done 12325/14460. Dataloading: 0.0022 s/iter. Inference: 0.0369 s/iter. Eval: 0.0503 s/iter. Total: 0.0895 s/iter. ETA=0:03:11\n",
      "\u001b[32m[07/07 14:11:43 d2.evaluation.evaluator]: \u001b[0mInference done 12392/14460. Dataloading: 0.0022 s/iter. Inference: 0.0369 s/iter. Eval: 0.0503 s/iter. Total: 0.0894 s/iter. ETA=0:03:04\n",
      "\u001b[32m[07/07 14:11:48 d2.evaluation.evaluator]: \u001b[0mInference done 12458/14460. Dataloading: 0.0022 s/iter. Inference: 0.0369 s/iter. Eval: 0.0502 s/iter. Total: 0.0894 s/iter. ETA=0:02:58\n",
      "\u001b[32m[07/07 14:11:53 d2.evaluation.evaluator]: \u001b[0mInference done 12525/14460. Dataloading: 0.0022 s/iter. Inference: 0.0369 s/iter. Eval: 0.0501 s/iter. Total: 0.0893 s/iter. ETA=0:02:52\n",
      "\u001b[32m[07/07 14:11:58 d2.evaluation.evaluator]: \u001b[0mInference done 12592/14460. Dataloading: 0.0022 s/iter. Inference: 0.0369 s/iter. Eval: 0.0501 s/iter. Total: 0.0892 s/iter. ETA=0:02:46\n",
      "\u001b[32m[07/07 14:12:03 d2.evaluation.evaluator]: \u001b[0mInference done 12659/14460. Dataloading: 0.0022 s/iter. Inference: 0.0368 s/iter. Eval: 0.0500 s/iter. Total: 0.0891 s/iter. ETA=0:02:40\n",
      "\u001b[32m[07/07 14:12:08 d2.evaluation.evaluator]: \u001b[0mInference done 12726/14460. Dataloading: 0.0022 s/iter. Inference: 0.0368 s/iter. Eval: 0.0499 s/iter. Total: 0.0891 s/iter. ETA=0:02:34\n",
      "\u001b[32m[07/07 14:12:13 d2.evaluation.evaluator]: \u001b[0mInference done 12792/14460. Dataloading: 0.0022 s/iter. Inference: 0.0368 s/iter. Eval: 0.0499 s/iter. Total: 0.0890 s/iter. ETA=0:02:28\n",
      "\u001b[32m[07/07 14:12:18 d2.evaluation.evaluator]: \u001b[0mInference done 12858/14460. Dataloading: 0.0022 s/iter. Inference: 0.0368 s/iter. Eval: 0.0498 s/iter. Total: 0.0889 s/iter. ETA=0:02:22\n",
      "\u001b[32m[07/07 14:12:23 d2.evaluation.evaluator]: \u001b[0mInference done 12925/14460. Dataloading: 0.0022 s/iter. Inference: 0.0368 s/iter. Eval: 0.0497 s/iter. Total: 0.0889 s/iter. ETA=0:02:16\n",
      "\u001b[32m[07/07 14:12:28 d2.evaluation.evaluator]: \u001b[0mInference done 12991/14460. Dataloading: 0.0022 s/iter. Inference: 0.0368 s/iter. Eval: 0.0497 s/iter. Total: 0.0888 s/iter. ETA=0:02:10\n",
      "\u001b[32m[07/07 14:12:33 d2.evaluation.evaluator]: \u001b[0mInference done 13058/14460. Dataloading: 0.0022 s/iter. Inference: 0.0368 s/iter. Eval: 0.0496 s/iter. Total: 0.0887 s/iter. ETA=0:02:04\n",
      "\u001b[32m[07/07 14:12:38 d2.evaluation.evaluator]: \u001b[0mInference done 13125/14460. Dataloading: 0.0022 s/iter. Inference: 0.0368 s/iter. Eval: 0.0496 s/iter. Total: 0.0887 s/iter. ETA=0:01:58\n",
      "\u001b[32m[07/07 14:12:44 d2.evaluation.evaluator]: \u001b[0mInference done 13191/14460. Dataloading: 0.0022 s/iter. Inference: 0.0368 s/iter. Eval: 0.0495 s/iter. Total: 0.0886 s/iter. ETA=0:01:52\n",
      "\u001b[32m[07/07 14:12:49 d2.evaluation.evaluator]: \u001b[0mInference done 13256/14460. Dataloading: 0.0022 s/iter. Inference: 0.0368 s/iter. Eval: 0.0495 s/iter. Total: 0.0885 s/iter. ETA=0:01:46\n",
      "\u001b[32m[07/07 14:12:54 d2.evaluation.evaluator]: \u001b[0mInference done 13322/14460. Dataloading: 0.0022 s/iter. Inference: 0.0368 s/iter. Eval: 0.0494 s/iter. Total: 0.0885 s/iter. ETA=0:01:40\n",
      "\u001b[32m[07/07 14:12:59 d2.evaluation.evaluator]: \u001b[0mInference done 13388/14460. Dataloading: 0.0022 s/iter. Inference: 0.0368 s/iter. Eval: 0.0493 s/iter. Total: 0.0884 s/iter. ETA=0:01:34\n",
      "\u001b[32m[07/07 14:13:04 d2.evaluation.evaluator]: \u001b[0mInference done 13454/14460. Dataloading: 0.0022 s/iter. Inference: 0.0368 s/iter. Eval: 0.0493 s/iter. Total: 0.0884 s/iter. ETA=0:01:28\n",
      "\u001b[32m[07/07 14:13:09 d2.evaluation.evaluator]: \u001b[0mInference done 13520/14460. Dataloading: 0.0022 s/iter. Inference: 0.0368 s/iter. Eval: 0.0492 s/iter. Total: 0.0883 s/iter. ETA=0:01:22\n",
      "\u001b[32m[07/07 14:13:14 d2.evaluation.evaluator]: \u001b[0mInference done 13586/14460. Dataloading: 0.0022 s/iter. Inference: 0.0368 s/iter. Eval: 0.0492 s/iter. Total: 0.0882 s/iter. ETA=0:01:17\n",
      "\u001b[32m[07/07 14:13:19 d2.evaluation.evaluator]: \u001b[0mInference done 13651/14460. Dataloading: 0.0022 s/iter. Inference: 0.0368 s/iter. Eval: 0.0491 s/iter. Total: 0.0882 s/iter. ETA=0:01:11\n",
      "\u001b[32m[07/07 14:13:24 d2.evaluation.evaluator]: \u001b[0mInference done 13717/14460. Dataloading: 0.0022 s/iter. Inference: 0.0368 s/iter. Eval: 0.0491 s/iter. Total: 0.0881 s/iter. ETA=0:01:05\n",
      "\u001b[32m[07/07 14:13:29 d2.evaluation.evaluator]: \u001b[0mInference done 13779/14460. Dataloading: 0.0022 s/iter. Inference: 0.0368 s/iter. Eval: 0.0491 s/iter. Total: 0.0881 s/iter. ETA=0:01:00\n",
      "\u001b[32m[07/07 14:13:34 d2.evaluation.evaluator]: \u001b[0mInference done 13843/14460. Dataloading: 0.0022 s/iter. Inference: 0.0367 s/iter. Eval: 0.0490 s/iter. Total: 0.0881 s/iter. ETA=0:00:54\n",
      "\u001b[32m[07/07 14:13:39 d2.evaluation.evaluator]: \u001b[0mInference done 13908/14460. Dataloading: 0.0022 s/iter. Inference: 0.0367 s/iter. Eval: 0.0490 s/iter. Total: 0.0880 s/iter. ETA=0:00:48\n",
      "\u001b[32m[07/07 14:13:44 d2.evaluation.evaluator]: \u001b[0mInference done 13976/14460. Dataloading: 0.0022 s/iter. Inference: 0.0367 s/iter. Eval: 0.0489 s/iter. Total: 0.0879 s/iter. ETA=0:00:42\n",
      "\u001b[32m[07/07 14:13:49 d2.evaluation.evaluator]: \u001b[0mInference done 14045/14460. Dataloading: 0.0022 s/iter. Inference: 0.0367 s/iter. Eval: 0.0488 s/iter. Total: 0.0879 s/iter. ETA=0:00:36\n",
      "\u001b[32m[07/07 14:13:54 d2.evaluation.evaluator]: \u001b[0mInference done 14111/14460. Dataloading: 0.0022 s/iter. Inference: 0.0367 s/iter. Eval: 0.0488 s/iter. Total: 0.0878 s/iter. ETA=0:00:30\n",
      "\u001b[32m[07/07 14:13:59 d2.evaluation.evaluator]: \u001b[0mInference done 14177/14460. Dataloading: 0.0022 s/iter. Inference: 0.0367 s/iter. Eval: 0.0487 s/iter. Total: 0.0878 s/iter. ETA=0:00:24\n",
      "\u001b[32m[07/07 14:14:04 d2.evaluation.evaluator]: \u001b[0mInference done 14241/14460. Dataloading: 0.0022 s/iter. Inference: 0.0367 s/iter. Eval: 0.0487 s/iter. Total: 0.0877 s/iter. ETA=0:00:19\n",
      "\u001b[32m[07/07 14:14:09 d2.evaluation.evaluator]: \u001b[0mInference done 14307/14460. Dataloading: 0.0022 s/iter. Inference: 0.0367 s/iter. Eval: 0.0487 s/iter. Total: 0.0877 s/iter. ETA=0:00:13\n",
      "\u001b[32m[07/07 14:14:14 d2.evaluation.evaluator]: \u001b[0mInference done 14374/14460. Dataloading: 0.0022 s/iter. Inference: 0.0367 s/iter. Eval: 0.0486 s/iter. Total: 0.0876 s/iter. ETA=0:00:07\n",
      "\u001b[32m[07/07 14:14:19 d2.evaluation.evaluator]: \u001b[0mInference done 14440/14460. Dataloading: 0.0022 s/iter. Inference: 0.0367 s/iter. Eval: 0.0486 s/iter. Total: 0.0876 s/iter. ETA=0:00:01\n",
      "\u001b[32m[07/07 14:14:21 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:21:05.615643 (0.087556 s / iter per device, on 1 devices)\n",
      "\u001b[32m[07/07 14:14:21 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:08:50 (0.036700 s / iter per device, on 1 devices)\n",
      "\u001b[32m[07/07 14:14:24 d2.evaluation.sem_seg_evaluation]: \u001b[0mOrderedDict([('sem_seg', {'mIoU': 48.86272798298576, 'fwIoU': 66.160704973598, 'IoU-Unlabeled': nan, 'IoU-Building': 55.93209856362831, 'IoU-Fence': 26.658183319414476, 'IoU-Pedestrian': 64.2443892300274, 'IoU-Pole': 46.2227397897698, 'IoU-Road': 90.53195389292817, 'IoU-SideWalk': 63.39083185799712, 'IoU-Vegetation': 61.05266838168466, 'IoU-Vehicles': 58.70888158474501, 'IoU-Wall': 41.005565829284855, 'IoU-TrafficSign': 53.301665674175716, 'IoU-Sky': 44.33070977161905, 'IoU-TrafficLight': 55.79805201296626, 'IoU-Terrain': 23.771465190052364, 'IoU-ConstructionVehicle': 82.08008788197333, 'IoU-workzone_object': 56.61841092037054, 'IoU-Detour': 7.018671810120818, 'mACC': 65.20532132538712, 'pACC': 78.55146342429386, 'ACC-Unlabeled': nan, 'ACC-Building': 96.518973213044, 'ACC-Fence': 34.19257280028931, 'ACC-Pedestrian': 84.79015191549205, 'ACC-Pole': 55.95539842138892, 'ACC-Road': 93.29746138065873, 'ACC-SideWalk': 77.87055648589919, 'ACC-Vegetation': 76.1326476537718, 'ACC-Vehicles': 90.70669859742368, 'ACC-Wall': 54.91601804734039, 'ACC-TrafficSign': 62.74808480611193, 'ACC-Sky': 44.7127938076947, 'ACC-TrafficLight': 64.8826388873685, 'ACC-Terrain': 25.95923359369102, 'ACC-ConstructionVehicle': 90.5102054904213, 'ACC-workzone_object': 80.20963715742265, 'ACC-Detour': 9.882068948175714})])\n",
      "\u001b[32m[07/07 14:14:24 d2.engine.defaults]: \u001b[0mEvaluation results for combined_all_night_val in csv format:\n",
      "\u001b[32m[07/07 14:14:24 d2.evaluation.testing]: \u001b[0mcopypaste: Task: sem_seg\n",
      "\u001b[32m[07/07 14:14:24 d2.evaluation.testing]: \u001b[0mcopypaste: mIoU,fwIoU,mACC,pACC\n",
      "\u001b[32m[07/07 14:14:24 d2.evaluation.testing]: \u001b[0mcopypaste: 48.8627,66.1607,65.2053,78.5515\n"
     ]
    }
   ],
   "source": [
    "#all\n",
    "trainer_both = Detectron2Trainer('combined_clear_both_train', 'combined_all_night_val', output_folder='./output_both_clear_40k')\n",
    "trainer_both.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e3a7fb8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "6c843117",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/05 21:25:31 d2.engine.defaults]: \u001b[0mModel:\n",
      "SemanticSegmentor(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (sem_seg_head): SemSegFPNHead(\n",
      "    (p2): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "    )\n",
      "    (p3): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (1): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "    )\n",
      "    (p4): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (1): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      (2): Conv2d(\n",
      "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (3): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "    )\n",
      "    (p5): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (1): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      (2): Conv2d(\n",
      "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (3): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      (4): Conv2d(\n",
      "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (5): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "    )\n",
      "    (predictor): Conv2d(128, 17, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/05 21:25:31 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(720, 720), max_size=2048, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[07/05 21:25:31 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[07/05 21:25:31 d2.data.common]: \u001b[0mSerializing 37734 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[07/05 21:25:31 d2.data.common]: \u001b[0mSerialized dataset takes 11.85 MiB\n",
      "Last checkpoint: model_final.pth\n",
      "\u001b[32m[07/05 21:25:32 d2.checkpoint.c2_model_loading]: \u001b[0mFollowing weights matched with model:\n",
      "| Names in Model                       | Names in Checkpoint                                                                                  | Shapes                                          |\n",
      "|:-------------------------------------|:-----------------------------------------------------------------------------------------------------|:------------------------------------------------|\n",
      "| backbone.bottom_up.res2.0.conv1.*    | backbone.bottom_up.res2.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,1,1)             |\n",
      "| backbone.bottom_up.res2.0.conv2.*    | backbone.bottom_up.res2.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |\n",
      "| backbone.bottom_up.res2.0.conv3.*    | backbone.bottom_up.res2.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res2.0.shortcut.* | backbone.bottom_up.res2.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res2.1.conv1.*    | backbone.bottom_up.res2.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |\n",
      "| backbone.bottom_up.res2.1.conv2.*    | backbone.bottom_up.res2.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |\n",
      "| backbone.bottom_up.res2.1.conv3.*    | backbone.bottom_up.res2.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res2.2.conv1.*    | backbone.bottom_up.res2.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |\n",
      "| backbone.bottom_up.res2.2.conv2.*    | backbone.bottom_up.res2.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |\n",
      "| backbone.bottom_up.res2.2.conv3.*    | backbone.bottom_up.res2.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res3.0.conv1.*    | backbone.bottom_up.res3.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,256,1,1)       |\n",
      "| backbone.bottom_up.res3.0.conv2.*    | backbone.bottom_up.res3.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.0.conv3.*    | backbone.bottom_up.res3.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res3.0.shortcut.* | backbone.bottom_up.res3.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (512,) (512,) (512,) (512,) (512,256,1,1)       |\n",
      "| backbone.bottom_up.res3.1.conv1.*    | backbone.bottom_up.res3.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |\n",
      "| backbone.bottom_up.res3.1.conv2.*    | backbone.bottom_up.res3.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.1.conv3.*    | backbone.bottom_up.res3.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res3.2.conv1.*    | backbone.bottom_up.res3.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |\n",
      "| backbone.bottom_up.res3.2.conv2.*    | backbone.bottom_up.res3.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.2.conv3.*    | backbone.bottom_up.res3.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res3.3.conv1.*    | backbone.bottom_up.res3.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |\n",
      "| backbone.bottom_up.res3.3.conv2.*    | backbone.bottom_up.res3.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.3.conv3.*    | backbone.bottom_up.res3.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res4.0.conv1.*    | backbone.bottom_up.res4.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,512,1,1)       |\n",
      "| backbone.bottom_up.res4.0.conv2.*    | backbone.bottom_up.res4.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.0.conv3.*    | backbone.bottom_up.res4.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.0.shortcut.* | backbone.bottom_up.res4.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (1024,) (1024,) (1024,) (1024,) (1024,512,1,1)  |\n",
      "| backbone.bottom_up.res4.1.conv1.*    | backbone.bottom_up.res4.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.1.conv2.*    | backbone.bottom_up.res4.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.1.conv3.*    | backbone.bottom_up.res4.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.2.conv1.*    | backbone.bottom_up.res4.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.2.conv2.*    | backbone.bottom_up.res4.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.2.conv3.*    | backbone.bottom_up.res4.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.3.conv1.*    | backbone.bottom_up.res4.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.3.conv2.*    | backbone.bottom_up.res4.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.3.conv3.*    | backbone.bottom_up.res4.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.4.conv1.*    | backbone.bottom_up.res4.4.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.4.conv2.*    | backbone.bottom_up.res4.4.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.4.conv3.*    | backbone.bottom_up.res4.4.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.5.conv1.*    | backbone.bottom_up.res4.5.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.5.conv2.*    | backbone.bottom_up.res4.5.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.5.conv3.*    | backbone.bottom_up.res4.5.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res5.0.conv1.*    | backbone.bottom_up.res5.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,1024,1,1)      |\n",
      "| backbone.bottom_up.res5.0.conv2.*    | backbone.bottom_up.res5.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |\n",
      "| backbone.bottom_up.res5.0.conv3.*    | backbone.bottom_up.res5.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
      "| backbone.bottom_up.res5.0.shortcut.* | backbone.bottom_up.res5.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (2048,) (2048,) (2048,) (2048,) (2048,1024,1,1) |\n",
      "| backbone.bottom_up.res5.1.conv1.*    | backbone.bottom_up.res5.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |\n",
      "| backbone.bottom_up.res5.1.conv2.*    | backbone.bottom_up.res5.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |\n",
      "| backbone.bottom_up.res5.1.conv3.*    | backbone.bottom_up.res5.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
      "| backbone.bottom_up.res5.2.conv1.*    | backbone.bottom_up.res5.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |\n",
      "| backbone.bottom_up.res5.2.conv2.*    | backbone.bottom_up.res5.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |\n",
      "| backbone.bottom_up.res5.2.conv3.*    | backbone.bottom_up.res5.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
      "| backbone.bottom_up.stem.conv1.*      | backbone.bottom_up.stem.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}      | (64,) (64,) (64,) (64,) (64,3,7,7)              |\n",
      "| backbone.fpn_lateral2.*              | backbone.fpn_lateral2.{bias,weight}                                                                  | (256,) (256,256,1,1)                            |\n",
      "| backbone.fpn_lateral3.*              | backbone.fpn_lateral3.{bias,weight}                                                                  | (256,) (256,512,1,1)                            |\n",
      "| backbone.fpn_lateral4.*              | backbone.fpn_lateral4.{bias,weight}                                                                  | (256,) (256,1024,1,1)                           |\n",
      "| backbone.fpn_lateral5.*              | backbone.fpn_lateral5.{bias,weight}                                                                  | (256,) (256,2048,1,1)                           |\n",
      "| backbone.fpn_output2.*               | backbone.fpn_output2.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| backbone.fpn_output3.*               | backbone.fpn_output3.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| backbone.fpn_output4.*               | backbone.fpn_output4.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| backbone.fpn_output5.*               | backbone.fpn_output5.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| sem_seg_head.p2.0.*                  | sem_seg_head.p2.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p3.0.*                  | sem_seg_head.p3.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p4.0.*                  | sem_seg_head.p4.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p4.2.*                  | sem_seg_head.p4.2.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,128,3,3)                     |\n",
      "| sem_seg_head.p5.0.*                  | sem_seg_head.p5.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p5.2.*                  | sem_seg_head.p5.2.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,128,3,3)                     |\n",
      "| sem_seg_head.p5.4.*                  | sem_seg_head.p5.4.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,128,3,3)                     |\n",
      "| sem_seg_head.predictor.*             | sem_seg_head.predictor.{bias,weight}                                                                 | (17,) (17,128,1,1)                              |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/05 21:25:32 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(720, 720), max_size=2048, sample_style='choice')]\n",
      "\u001b[32m[07/05 21:25:32 d2.data.common]: \u001b[0mSerializing 6531 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[07/05 21:25:32 d2.data.common]: \u001b[0mSerialized dataset takes 2.03 MiB\n",
      "\u001b[32m[07/05 21:25:32 d2.evaluation.evaluator]: \u001b[0mStart inference on 6531 batches\n",
      "\u001b[32m[07/05 21:25:33 d2.evaluation.evaluator]: \u001b[0mInference done 11/6531. Dataloading: 0.0016 s/iter. Inference: 0.0356 s/iter. Eval: 0.0440 s/iter. Total: 0.0813 s/iter. ETA=0:08:50\n",
      "\u001b[32m[07/05 21:25:38 d2.evaluation.evaluator]: \u001b[0mInference done 75/6531. Dataloading: 0.0021 s/iter. Inference: 0.0350 s/iter. Eval: 0.0415 s/iter. Total: 0.0787 s/iter. ETA=0:08:27\n",
      "\u001b[32m[07/05 21:25:43 d2.evaluation.evaluator]: \u001b[0mInference done 142/6531. Dataloading: 0.0021 s/iter. Inference: 0.0350 s/iter. Eval: 0.0397 s/iter. Total: 0.0769 s/iter. ETA=0:08:11\n",
      "\u001b[32m[07/05 21:25:48 d2.evaluation.evaluator]: \u001b[0mInference done 209/6531. Dataloading: 0.0021 s/iter. Inference: 0.0350 s/iter. Eval: 0.0389 s/iter. Total: 0.0761 s/iter. ETA=0:08:01\n",
      "\u001b[32m[07/05 21:25:53 d2.evaluation.evaluator]: \u001b[0mInference done 276/6531. Dataloading: 0.0022 s/iter. Inference: 0.0351 s/iter. Eval: 0.0385 s/iter. Total: 0.0758 s/iter. ETA=0:07:54\n",
      "\u001b[32m[07/05 21:25:58 d2.evaluation.evaluator]: \u001b[0mInference done 342/6531. Dataloading: 0.0022 s/iter. Inference: 0.0351 s/iter. Eval: 0.0385 s/iter. Total: 0.0758 s/iter. ETA=0:07:49\n",
      "\u001b[32m[07/05 21:26:03 d2.evaluation.evaluator]: \u001b[0mInference done 409/6531. Dataloading: 0.0022 s/iter. Inference: 0.0351 s/iter. Eval: 0.0384 s/iter. Total: 0.0758 s/iter. ETA=0:07:43\n",
      "\u001b[32m[07/05 21:26:08 d2.evaluation.evaluator]: \u001b[0mInference done 476/6531. Dataloading: 0.0022 s/iter. Inference: 0.0351 s/iter. Eval: 0.0383 s/iter. Total: 0.0757 s/iter. ETA=0:07:38\n",
      "\u001b[32m[07/05 21:26:13 d2.evaluation.evaluator]: \u001b[0mInference done 543/6531. Dataloading: 0.0022 s/iter. Inference: 0.0351 s/iter. Eval: 0.0383 s/iter. Total: 0.0757 s/iter. ETA=0:07:33\n",
      "\u001b[32m[07/05 21:26:18 d2.evaluation.evaluator]: \u001b[0mInference done 609/6531. Dataloading: 0.0022 s/iter. Inference: 0.0352 s/iter. Eval: 0.0383 s/iter. Total: 0.0757 s/iter. ETA=0:07:28\n",
      "\u001b[32m[07/05 21:26:23 d2.evaluation.evaluator]: \u001b[0mInference done 676/6531. Dataloading: 0.0022 s/iter. Inference: 0.0352 s/iter. Eval: 0.0383 s/iter. Total: 0.0757 s/iter. ETA=0:07:23\n",
      "\u001b[32m[07/05 21:26:28 d2.evaluation.evaluator]: \u001b[0mInference done 742/6531. Dataloading: 0.0022 s/iter. Inference: 0.0352 s/iter. Eval: 0.0384 s/iter. Total: 0.0758 s/iter. ETA=0:07:18\n",
      "\u001b[32m[07/05 21:26:33 d2.evaluation.evaluator]: \u001b[0mInference done 808/6531. Dataloading: 0.0022 s/iter. Inference: 0.0352 s/iter. Eval: 0.0383 s/iter. Total: 0.0758 s/iter. ETA=0:07:13\n",
      "\u001b[32m[07/05 21:26:38 d2.evaluation.evaluator]: \u001b[0mInference done 874/6531. Dataloading: 0.0022 s/iter. Inference: 0.0352 s/iter. Eval: 0.0384 s/iter. Total: 0.0759 s/iter. ETA=0:07:09\n",
      "\u001b[32m[07/05 21:26:43 d2.evaluation.evaluator]: \u001b[0mInference done 939/6531. Dataloading: 0.0022 s/iter. Inference: 0.0352 s/iter. Eval: 0.0385 s/iter. Total: 0.0760 s/iter. ETA=0:07:05\n",
      "\u001b[32m[07/05 21:26:48 d2.evaluation.evaluator]: \u001b[0mInference done 1004/6531. Dataloading: 0.0022 s/iter. Inference: 0.0352 s/iter. Eval: 0.0387 s/iter. Total: 0.0762 s/iter. ETA=0:07:00\n",
      "\u001b[32m[07/05 21:26:54 d2.evaluation.evaluator]: \u001b[0mInference done 1068/6531. Dataloading: 0.0024 s/iter. Inference: 0.0352 s/iter. Eval: 0.0387 s/iter. Total: 0.0763 s/iter. ETA=0:06:56\n",
      "\u001b[32m[07/05 21:26:59 d2.evaluation.evaluator]: \u001b[0mInference done 1135/6531. Dataloading: 0.0024 s/iter. Inference: 0.0353 s/iter. Eval: 0.0386 s/iter. Total: 0.0763 s/iter. ETA=0:06:51\n",
      "\u001b[32m[07/05 21:27:04 d2.evaluation.evaluator]: \u001b[0mInference done 1202/6531. Dataloading: 0.0023 s/iter. Inference: 0.0353 s/iter. Eval: 0.0386 s/iter. Total: 0.0763 s/iter. ETA=0:06:46\n",
      "\u001b[32m[07/05 21:27:09 d2.evaluation.evaluator]: \u001b[0mInference done 1268/6531. Dataloading: 0.0023 s/iter. Inference: 0.0353 s/iter. Eval: 0.0385 s/iter. Total: 0.0762 s/iter. ETA=0:06:41\n",
      "\u001b[32m[07/05 21:27:14 d2.evaluation.evaluator]: \u001b[0mInference done 1334/6531. Dataloading: 0.0023 s/iter. Inference: 0.0353 s/iter. Eval: 0.0385 s/iter. Total: 0.0762 s/iter. ETA=0:06:36\n",
      "\u001b[32m[07/05 21:27:19 d2.evaluation.evaluator]: \u001b[0mInference done 1402/6531. Dataloading: 0.0023 s/iter. Inference: 0.0353 s/iter. Eval: 0.0384 s/iter. Total: 0.0761 s/iter. ETA=0:06:30\n",
      "\u001b[32m[07/05 21:27:24 d2.evaluation.evaluator]: \u001b[0mInference done 1469/6531. Dataloading: 0.0023 s/iter. Inference: 0.0353 s/iter. Eval: 0.0383 s/iter. Total: 0.0761 s/iter. ETA=0:06:24\n",
      "\u001b[32m[07/05 21:27:29 d2.evaluation.evaluator]: \u001b[0mInference done 1535/6531. Dataloading: 0.0023 s/iter. Inference: 0.0353 s/iter. Eval: 0.0384 s/iter. Total: 0.0761 s/iter. ETA=0:06:20\n",
      "\u001b[32m[07/05 21:27:34 d2.evaluation.evaluator]: \u001b[0mInference done 1602/6531. Dataloading: 0.0023 s/iter. Inference: 0.0353 s/iter. Eval: 0.0383 s/iter. Total: 0.0760 s/iter. ETA=0:06:14\n",
      "\u001b[32m[07/05 21:27:39 d2.evaluation.evaluator]: \u001b[0mInference done 1668/6531. Dataloading: 0.0023 s/iter. Inference: 0.0353 s/iter. Eval: 0.0383 s/iter. Total: 0.0761 s/iter. ETA=0:06:09\n",
      "\u001b[32m[07/05 21:27:44 d2.evaluation.evaluator]: \u001b[0mInference done 1734/6531. Dataloading: 0.0023 s/iter. Inference: 0.0354 s/iter. Eval: 0.0384 s/iter. Total: 0.0761 s/iter. ETA=0:06:05\n",
      "\u001b[32m[07/05 21:27:49 d2.evaluation.evaluator]: \u001b[0mInference done 1801/6531. Dataloading: 0.0023 s/iter. Inference: 0.0354 s/iter. Eval: 0.0383 s/iter. Total: 0.0761 s/iter. ETA=0:05:59\n",
      "\u001b[32m[07/05 21:27:54 d2.evaluation.evaluator]: \u001b[0mInference done 1865/6531. Dataloading: 0.0023 s/iter. Inference: 0.0354 s/iter. Eval: 0.0384 s/iter. Total: 0.0761 s/iter. ETA=0:05:55\n",
      "\u001b[32m[07/05 21:27:59 d2.evaluation.evaluator]: \u001b[0mInference done 1931/6531. Dataloading: 0.0023 s/iter. Inference: 0.0354 s/iter. Eval: 0.0384 s/iter. Total: 0.0762 s/iter. ETA=0:05:50\n",
      "\u001b[32m[07/05 21:28:04 d2.evaluation.evaluator]: \u001b[0mInference done 1998/6531. Dataloading: 0.0023 s/iter. Inference: 0.0354 s/iter. Eval: 0.0384 s/iter. Total: 0.0762 s/iter. ETA=0:05:45\n",
      "\u001b[32m[07/05 21:28:09 d2.evaluation.evaluator]: \u001b[0mInference done 2065/6531. Dataloading: 0.0023 s/iter. Inference: 0.0354 s/iter. Eval: 0.0384 s/iter. Total: 0.0761 s/iter. ETA=0:05:39\n",
      "\u001b[32m[07/05 21:28:14 d2.evaluation.evaluator]: \u001b[0mInference done 2132/6531. Dataloading: 0.0023 s/iter. Inference: 0.0354 s/iter. Eval: 0.0383 s/iter. Total: 0.0761 s/iter. ETA=0:05:34\n",
      "\u001b[32m[07/05 21:28:19 d2.evaluation.evaluator]: \u001b[0mInference done 2199/6531. Dataloading: 0.0023 s/iter. Inference: 0.0354 s/iter. Eval: 0.0383 s/iter. Total: 0.0761 s/iter. ETA=0:05:29\n",
      "\u001b[32m[07/05 21:28:24 d2.evaluation.evaluator]: \u001b[0mInference done 2266/6531. Dataloading: 0.0023 s/iter. Inference: 0.0354 s/iter. Eval: 0.0383 s/iter. Total: 0.0760 s/iter. ETA=0:05:24\n",
      "\u001b[32m[07/05 21:28:29 d2.evaluation.evaluator]: \u001b[0mInference done 2333/6531. Dataloading: 0.0023 s/iter. Inference: 0.0354 s/iter. Eval: 0.0382 s/iter. Total: 0.0760 s/iter. ETA=0:05:19\n",
      "\u001b[32m[07/05 21:28:34 d2.evaluation.evaluator]: \u001b[0mInference done 2400/6531. Dataloading: 0.0023 s/iter. Inference: 0.0354 s/iter. Eval: 0.0382 s/iter. Total: 0.0760 s/iter. ETA=0:05:13\n",
      "\u001b[32m[07/05 21:28:39 d2.evaluation.evaluator]: \u001b[0mInference done 2467/6531. Dataloading: 0.0023 s/iter. Inference: 0.0354 s/iter. Eval: 0.0382 s/iter. Total: 0.0760 s/iter. ETA=0:05:08\n",
      "\u001b[32m[07/05 21:28:44 d2.evaluation.evaluator]: \u001b[0mInference done 2534/6531. Dataloading: 0.0023 s/iter. Inference: 0.0354 s/iter. Eval: 0.0382 s/iter. Total: 0.0760 s/iter. ETA=0:05:03\n",
      "\u001b[32m[07/05 21:28:50 d2.evaluation.evaluator]: \u001b[0mInference done 2601/6531. Dataloading: 0.0023 s/iter. Inference: 0.0354 s/iter. Eval: 0.0381 s/iter. Total: 0.0759 s/iter. ETA=0:04:58\n",
      "\u001b[32m[07/05 21:28:55 d2.evaluation.evaluator]: \u001b[0mInference done 2668/6531. Dataloading: 0.0023 s/iter. Inference: 0.0354 s/iter. Eval: 0.0381 s/iter. Total: 0.0759 s/iter. ETA=0:04:53\n",
      "\u001b[32m[07/05 21:29:00 d2.evaluation.evaluator]: \u001b[0mInference done 2735/6531. Dataloading: 0.0023 s/iter. Inference: 0.0354 s/iter. Eval: 0.0381 s/iter. Total: 0.0759 s/iter. ETA=0:04:48\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/05 21:29:05 d2.evaluation.evaluator]: \u001b[0mInference done 2802/6531. Dataloading: 0.0023 s/iter. Inference: 0.0354 s/iter. Eval: 0.0381 s/iter. Total: 0.0759 s/iter. ETA=0:04:42\n",
      "\u001b[32m[07/05 21:29:10 d2.evaluation.evaluator]: \u001b[0mInference done 2869/6531. Dataloading: 0.0023 s/iter. Inference: 0.0354 s/iter. Eval: 0.0380 s/iter. Total: 0.0759 s/iter. ETA=0:04:37\n",
      "\u001b[32m[07/05 21:29:15 d2.evaluation.evaluator]: \u001b[0mInference done 2936/6531. Dataloading: 0.0023 s/iter. Inference: 0.0354 s/iter. Eval: 0.0380 s/iter. Total: 0.0758 s/iter. ETA=0:04:32\n",
      "\u001b[32m[07/05 21:29:20 d2.evaluation.evaluator]: \u001b[0mInference done 3003/6531. Dataloading: 0.0023 s/iter. Inference: 0.0354 s/iter. Eval: 0.0380 s/iter. Total: 0.0758 s/iter. ETA=0:04:27\n",
      "\u001b[32m[07/05 21:29:25 d2.evaluation.evaluator]: \u001b[0mInference done 3069/6531. Dataloading: 0.0023 s/iter. Inference: 0.0354 s/iter. Eval: 0.0380 s/iter. Total: 0.0759 s/iter. ETA=0:04:22\n",
      "\u001b[32m[07/05 21:29:30 d2.evaluation.evaluator]: \u001b[0mInference done 3134/6531. Dataloading: 0.0023 s/iter. Inference: 0.0354 s/iter. Eval: 0.0380 s/iter. Total: 0.0759 s/iter. ETA=0:04:17\n",
      "\u001b[32m[07/05 21:29:35 d2.evaluation.evaluator]: \u001b[0mInference done 3199/6531. Dataloading: 0.0023 s/iter. Inference: 0.0354 s/iter. Eval: 0.0381 s/iter. Total: 0.0759 s/iter. ETA=0:04:12\n",
      "\u001b[32m[07/05 21:29:40 d2.evaluation.evaluator]: \u001b[0mInference done 3264/6531. Dataloading: 0.0023 s/iter. Inference: 0.0354 s/iter. Eval: 0.0381 s/iter. Total: 0.0759 s/iter. ETA=0:04:08\n",
      "\u001b[32m[07/05 21:29:45 d2.evaluation.evaluator]: \u001b[0mInference done 3329/6531. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0381 s/iter. Total: 0.0760 s/iter. ETA=0:04:03\n",
      "\u001b[32m[07/05 21:29:50 d2.evaluation.evaluator]: \u001b[0mInference done 3394/6531. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0382 s/iter. Total: 0.0760 s/iter. ETA=0:03:58\n",
      "\u001b[32m[07/05 21:29:55 d2.evaluation.evaluator]: \u001b[0mInference done 3459/6531. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0382 s/iter. Total: 0.0760 s/iter. ETA=0:03:53\n",
      "\u001b[32m[07/05 21:30:00 d2.evaluation.evaluator]: \u001b[0mInference done 3524/6531. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0382 s/iter. Total: 0.0760 s/iter. ETA=0:03:48\n",
      "\u001b[32m[07/05 21:30:05 d2.evaluation.evaluator]: \u001b[0mInference done 3588/6531. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0382 s/iter. Total: 0.0761 s/iter. ETA=0:03:43\n",
      "\u001b[32m[07/05 21:30:10 d2.evaluation.evaluator]: \u001b[0mInference done 3652/6531. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0383 s/iter. Total: 0.0761 s/iter. ETA=0:03:39\n",
      "\u001b[32m[07/05 21:30:15 d2.evaluation.evaluator]: \u001b[0mInference done 3716/6531. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0383 s/iter. Total: 0.0762 s/iter. ETA=0:03:34\n",
      "\u001b[32m[07/05 21:30:20 d2.evaluation.evaluator]: \u001b[0mInference done 3780/6531. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0384 s/iter. Total: 0.0762 s/iter. ETA=0:03:29\n",
      "\u001b[32m[07/05 21:30:25 d2.evaluation.evaluator]: \u001b[0mInference done 3845/6531. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0384 s/iter. Total: 0.0763 s/iter. ETA=0:03:24\n",
      "\u001b[32m[07/05 21:30:30 d2.evaluation.evaluator]: \u001b[0mInference done 3909/6531. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0385 s/iter. Total: 0.0763 s/iter. ETA=0:03:20\n",
      "\u001b[32m[07/05 21:30:35 d2.evaluation.evaluator]: \u001b[0mInference done 3973/6531. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0385 s/iter. Total: 0.0763 s/iter. ETA=0:03:15\n",
      "\u001b[32m[07/05 21:30:40 d2.evaluation.evaluator]: \u001b[0mInference done 4038/6531. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0385 s/iter. Total: 0.0764 s/iter. ETA=0:03:10\n",
      "\u001b[32m[07/05 21:30:45 d2.evaluation.evaluator]: \u001b[0mInference done 4101/6531. Dataloading: 0.0024 s/iter. Inference: 0.0355 s/iter. Eval: 0.0385 s/iter. Total: 0.0764 s/iter. ETA=0:03:05\n",
      "\u001b[32m[07/05 21:30:50 d2.evaluation.evaluator]: \u001b[0mInference done 4165/6531. Dataloading: 0.0024 s/iter. Inference: 0.0355 s/iter. Eval: 0.0385 s/iter. Total: 0.0765 s/iter. ETA=0:03:00\n",
      "\u001b[32m[07/05 21:30:56 d2.evaluation.evaluator]: \u001b[0mInference done 4230/6531. Dataloading: 0.0024 s/iter. Inference: 0.0355 s/iter. Eval: 0.0386 s/iter. Total: 0.0765 s/iter. ETA=0:02:55\n",
      "\u001b[32m[07/05 21:31:01 d2.evaluation.evaluator]: \u001b[0mInference done 4295/6531. Dataloading: 0.0024 s/iter. Inference: 0.0355 s/iter. Eval: 0.0386 s/iter. Total: 0.0765 s/iter. ETA=0:02:51\n",
      "\u001b[32m[07/05 21:31:06 d2.evaluation.evaluator]: \u001b[0mInference done 4360/6531. Dataloading: 0.0024 s/iter. Inference: 0.0355 s/iter. Eval: 0.0386 s/iter. Total: 0.0765 s/iter. ETA=0:02:46\n",
      "\u001b[32m[07/05 21:31:11 d2.evaluation.evaluator]: \u001b[0mInference done 4425/6531. Dataloading: 0.0024 s/iter. Inference: 0.0355 s/iter. Eval: 0.0386 s/iter. Total: 0.0765 s/iter. ETA=0:02:41\n",
      "\u001b[32m[07/05 21:31:16 d2.evaluation.evaluator]: \u001b[0mInference done 4490/6531. Dataloading: 0.0024 s/iter. Inference: 0.0355 s/iter. Eval: 0.0386 s/iter. Total: 0.0765 s/iter. ETA=0:02:36\n",
      "\u001b[32m[07/05 21:31:21 d2.evaluation.evaluator]: \u001b[0mInference done 4555/6531. Dataloading: 0.0024 s/iter. Inference: 0.0355 s/iter. Eval: 0.0386 s/iter. Total: 0.0765 s/iter. ETA=0:02:31\n",
      "\u001b[32m[07/05 21:31:26 d2.evaluation.evaluator]: \u001b[0mInference done 4619/6531. Dataloading: 0.0024 s/iter. Inference: 0.0355 s/iter. Eval: 0.0387 s/iter. Total: 0.0766 s/iter. ETA=0:02:26\n",
      "\u001b[32m[07/05 21:31:31 d2.evaluation.evaluator]: \u001b[0mInference done 4684/6531. Dataloading: 0.0024 s/iter. Inference: 0.0355 s/iter. Eval: 0.0387 s/iter. Total: 0.0766 s/iter. ETA=0:02:21\n",
      "\u001b[32m[07/05 21:31:36 d2.evaluation.evaluator]: \u001b[0mInference done 4749/6531. Dataloading: 0.0024 s/iter. Inference: 0.0355 s/iter. Eval: 0.0387 s/iter. Total: 0.0766 s/iter. ETA=0:02:16\n",
      "\u001b[32m[07/05 21:31:41 d2.evaluation.evaluator]: \u001b[0mInference done 4815/6531. Dataloading: 0.0024 s/iter. Inference: 0.0355 s/iter. Eval: 0.0387 s/iter. Total: 0.0766 s/iter. ETA=0:02:11\n",
      "\u001b[32m[07/05 21:31:46 d2.evaluation.evaluator]: \u001b[0mInference done 4881/6531. Dataloading: 0.0024 s/iter. Inference: 0.0355 s/iter. Eval: 0.0387 s/iter. Total: 0.0766 s/iter. ETA=0:02:06\n",
      "\u001b[32m[07/05 21:31:51 d2.evaluation.evaluator]: \u001b[0mInference done 4946/6531. Dataloading: 0.0024 s/iter. Inference: 0.0355 s/iter. Eval: 0.0387 s/iter. Total: 0.0766 s/iter. ETA=0:02:01\n",
      "\u001b[32m[07/05 21:31:56 d2.evaluation.evaluator]: \u001b[0mInference done 5011/6531. Dataloading: 0.0024 s/iter. Inference: 0.0355 s/iter. Eval: 0.0387 s/iter. Total: 0.0766 s/iter. ETA=0:01:56\n",
      "\u001b[32m[07/05 21:32:01 d2.evaluation.evaluator]: \u001b[0mInference done 5077/6531. Dataloading: 0.0024 s/iter. Inference: 0.0355 s/iter. Eval: 0.0387 s/iter. Total: 0.0766 s/iter. ETA=0:01:51\n",
      "\u001b[32m[07/05 21:32:06 d2.evaluation.evaluator]: \u001b[0mInference done 5143/6531. Dataloading: 0.0024 s/iter. Inference: 0.0355 s/iter. Eval: 0.0387 s/iter. Total: 0.0766 s/iter. ETA=0:01:46\n",
      "\u001b[32m[07/05 21:32:11 d2.evaluation.evaluator]: \u001b[0mInference done 5209/6531. Dataloading: 0.0024 s/iter. Inference: 0.0355 s/iter. Eval: 0.0387 s/iter. Total: 0.0766 s/iter. ETA=0:01:41\n",
      "\u001b[32m[07/05 21:32:16 d2.evaluation.evaluator]: \u001b[0mInference done 5274/6531. Dataloading: 0.0024 s/iter. Inference: 0.0355 s/iter. Eval: 0.0387 s/iter. Total: 0.0766 s/iter. ETA=0:01:36\n",
      "\u001b[32m[07/05 21:32:21 d2.evaluation.evaluator]: \u001b[0mInference done 5338/6531. Dataloading: 0.0024 s/iter. Inference: 0.0355 s/iter. Eval: 0.0387 s/iter. Total: 0.0766 s/iter. ETA=0:01:31\n",
      "\u001b[32m[07/05 21:32:26 d2.evaluation.evaluator]: \u001b[0mInference done 5403/6531. Dataloading: 0.0024 s/iter. Inference: 0.0355 s/iter. Eval: 0.0387 s/iter. Total: 0.0766 s/iter. ETA=0:01:26\n",
      "\u001b[32m[07/05 21:32:31 d2.evaluation.evaluator]: \u001b[0mInference done 5469/6531. Dataloading: 0.0024 s/iter. Inference: 0.0355 s/iter. Eval: 0.0387 s/iter. Total: 0.0766 s/iter. ETA=0:01:21\n",
      "\u001b[32m[07/05 21:32:36 d2.evaluation.evaluator]: \u001b[0mInference done 5534/6531. Dataloading: 0.0024 s/iter. Inference: 0.0355 s/iter. Eval: 0.0387 s/iter. Total: 0.0766 s/iter. ETA=0:01:16\n",
      "\u001b[32m[07/05 21:32:41 d2.evaluation.evaluator]: \u001b[0mInference done 5599/6531. Dataloading: 0.0024 s/iter. Inference: 0.0355 s/iter. Eval: 0.0387 s/iter. Total: 0.0767 s/iter. ETA=0:01:11\n",
      "\u001b[32m[07/05 21:32:46 d2.evaluation.evaluator]: \u001b[0mInference done 5664/6531. Dataloading: 0.0024 s/iter. Inference: 0.0355 s/iter. Eval: 0.0388 s/iter. Total: 0.0767 s/iter. ETA=0:01:06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/05 21:32:51 d2.evaluation.evaluator]: \u001b[0mInference done 5728/6531. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0388 s/iter. Total: 0.0767 s/iter. ETA=0:01:01\n",
      "\u001b[32m[07/05 21:32:56 d2.evaluation.evaluator]: \u001b[0mInference done 5791/6531. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0388 s/iter. Total: 0.0767 s/iter. ETA=0:00:56\n",
      "\u001b[32m[07/05 21:33:01 d2.evaluation.evaluator]: \u001b[0mInference done 5856/6531. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0388 s/iter. Total: 0.0767 s/iter. ETA=0:00:51\n",
      "\u001b[32m[07/05 21:33:06 d2.evaluation.evaluator]: \u001b[0mInference done 5921/6531. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0388 s/iter. Total: 0.0767 s/iter. ETA=0:00:46\n",
      "\u001b[32m[07/05 21:33:11 d2.evaluation.evaluator]: \u001b[0mInference done 5986/6531. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0388 s/iter. Total: 0.0767 s/iter. ETA=0:00:41\n",
      "\u001b[32m[07/05 21:33:16 d2.evaluation.evaluator]: \u001b[0mInference done 6050/6531. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0389 s/iter. Total: 0.0768 s/iter. ETA=0:00:36\n",
      "\u001b[32m[07/05 21:33:21 d2.evaluation.evaluator]: \u001b[0mInference done 6114/6531. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0389 s/iter. Total: 0.0768 s/iter. ETA=0:00:32\n",
      "\u001b[32m[07/05 21:33:27 d2.evaluation.evaluator]: \u001b[0mInference done 6178/6531. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0389 s/iter. Total: 0.0768 s/iter. ETA=0:00:27\n",
      "\u001b[32m[07/05 21:33:32 d2.evaluation.evaluator]: \u001b[0mInference done 6240/6531. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0389 s/iter. Total: 0.0768 s/iter. ETA=0:00:22\n",
      "\u001b[32m[07/05 21:33:37 d2.evaluation.evaluator]: \u001b[0mInference done 6305/6531. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0389 s/iter. Total: 0.0769 s/iter. ETA=0:00:17\n",
      "\u001b[32m[07/05 21:33:42 d2.evaluation.evaluator]: \u001b[0mInference done 6370/6531. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0390 s/iter. Total: 0.0769 s/iter. ETA=0:00:12\n",
      "\u001b[32m[07/05 21:33:47 d2.evaluation.evaluator]: \u001b[0mInference done 6435/6531. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0390 s/iter. Total: 0.0769 s/iter. ETA=0:00:07\n",
      "\u001b[32m[07/05 21:33:52 d2.evaluation.evaluator]: \u001b[0mInference done 6502/6531. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0389 s/iter. Total: 0.0768 s/iter. ETA=0:00:02\n",
      "\u001b[32m[07/05 21:33:54 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:08:21.579618 (0.076859 s / iter per device, on 1 devices)\n",
      "\u001b[32m[07/05 21:33:54 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:03:51 (0.035486 s / iter per device, on 1 devices)\n",
      "\u001b[32m[07/05 21:33:55 d2.evaluation.sem_seg_evaluation]: \u001b[0mOrderedDict([('sem_seg', {'mIoU': 52.62254868897439, 'fwIoU': 79.54156817525944, 'IoU-Unlabeled': nan, 'IoU-Building': 69.8926855929057, 'IoU-Fence': 27.921905564708588, 'IoU-Pedestrian': 33.34862927328569, 'IoU-Pole': 53.33439376496403, 'IoU-Road': 95.66309014849892, 'IoU-SideWalk': 70.78649185986093, 'IoU-Vegetation': 63.92291559432819, 'IoU-Vehicles': 76.6466296687789, 'IoU-Wall': 58.28505012861771, 'IoU-TrafficSign': 50.069475497562586, 'IoU-Sky': 80.22918914957893, 'IoU-TrafficLight': 56.40868243877328, 'IoU-Terrain': 22.41025627014495, 'IoU-ConstructionVehicle': 56.639731861243234, 'IoU-workzone_object': 64.23457513287423, 'IoU-Detour': 14.78962576643879, 'mACC': 69.39284794709566, 'pACC': 87.8995599509259, 'ACC-Unlabeled': nan, 'ACC-Building': 95.7058868172878, 'ACC-Fence': 45.216266551659906, 'ACC-Pedestrian': 62.11101034204274, 'ACC-Pole': 62.01885607794968, 'ACC-Road': 97.36088959409099, 'ACC-SideWalk': 89.25165627551836, 'ACC-Vegetation': 77.5432606962878, 'ACC-Vehicles': 88.27149804289107, 'ACC-Wall': 64.83737101376535, 'ACC-TrafficSign': 59.472419713274995, 'ACC-Sky': 82.76955376645066, 'ACC-TrafficLight': 66.25209474690752, 'ACC-Terrain': 23.105280709171264, 'ACC-ConstructionVehicle': 94.23643823966336, 'ACC-workzone_object': 86.30291533928155, 'ACC-Detour': 15.830169227287586})])\n",
      "\u001b[32m[07/05 21:33:55 d2.engine.defaults]: \u001b[0mEvaluation results for carla_both_clear_val in csv format:\n",
      "\u001b[32m[07/05 21:33:55 d2.evaluation.testing]: \u001b[0mcopypaste: Task: sem_seg\n",
      "\u001b[32m[07/05 21:33:55 d2.evaluation.testing]: \u001b[0mcopypaste: mIoU,fwIoU,mACC,pACC\n",
      "\u001b[32m[07/05 21:33:55 d2.evaluation.testing]: \u001b[0mcopypaste: 52.6225,79.5416,69.3928,87.8996\n"
     ]
    }
   ],
   "source": [
    "trainer_both = Detectron2Trainer('combined_all_night_train', 'carla_both_clear_val', output_folder='./output_both_40k')\n",
    "trainer_both.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "073e8ef4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/05 21:33:55 d2.engine.defaults]: \u001b[0mModel:\n",
      "SemanticSegmentor(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (sem_seg_head): SemSegFPNHead(\n",
      "    (p2): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "    )\n",
      "    (p3): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (1): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "    )\n",
      "    (p4): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (1): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      (2): Conv2d(\n",
      "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (3): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "    )\n",
      "    (p5): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (1): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      (2): Conv2d(\n",
      "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (3): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      (4): Conv2d(\n",
      "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (5): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "    )\n",
      "    (predictor): Conv2d(128, 17, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/05 21:33:55 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(720, 720), max_size=2048, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[07/05 21:33:55 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[07/05 21:33:55 d2.data.common]: \u001b[0mSerializing 37734 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[07/05 21:33:55 d2.data.common]: \u001b[0mSerialized dataset takes 11.85 MiB\n",
      "Last checkpoint: model_final.pth\n",
      "\u001b[32m[07/05 21:33:56 d2.checkpoint.c2_model_loading]: \u001b[0mFollowing weights matched with model:\n",
      "| Names in Model                       | Names in Checkpoint                                                                                  | Shapes                                          |\n",
      "|:-------------------------------------|:-----------------------------------------------------------------------------------------------------|:------------------------------------------------|\n",
      "| backbone.bottom_up.res2.0.conv1.*    | backbone.bottom_up.res2.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,1,1)             |\n",
      "| backbone.bottom_up.res2.0.conv2.*    | backbone.bottom_up.res2.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |\n",
      "| backbone.bottom_up.res2.0.conv3.*    | backbone.bottom_up.res2.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res2.0.shortcut.* | backbone.bottom_up.res2.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res2.1.conv1.*    | backbone.bottom_up.res2.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |\n",
      "| backbone.bottom_up.res2.1.conv2.*    | backbone.bottom_up.res2.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |\n",
      "| backbone.bottom_up.res2.1.conv3.*    | backbone.bottom_up.res2.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res2.2.conv1.*    | backbone.bottom_up.res2.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |\n",
      "| backbone.bottom_up.res2.2.conv2.*    | backbone.bottom_up.res2.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |\n",
      "| backbone.bottom_up.res2.2.conv3.*    | backbone.bottom_up.res2.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res3.0.conv1.*    | backbone.bottom_up.res3.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,256,1,1)       |\n",
      "| backbone.bottom_up.res3.0.conv2.*    | backbone.bottom_up.res3.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.0.conv3.*    | backbone.bottom_up.res3.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res3.0.shortcut.* | backbone.bottom_up.res3.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (512,) (512,) (512,) (512,) (512,256,1,1)       |\n",
      "| backbone.bottom_up.res3.1.conv1.*    | backbone.bottom_up.res3.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |\n",
      "| backbone.bottom_up.res3.1.conv2.*    | backbone.bottom_up.res3.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.1.conv3.*    | backbone.bottom_up.res3.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res3.2.conv1.*    | backbone.bottom_up.res3.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |\n",
      "| backbone.bottom_up.res3.2.conv2.*    | backbone.bottom_up.res3.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.2.conv3.*    | backbone.bottom_up.res3.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res3.3.conv1.*    | backbone.bottom_up.res3.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |\n",
      "| backbone.bottom_up.res3.3.conv2.*    | backbone.bottom_up.res3.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.3.conv3.*    | backbone.bottom_up.res3.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res4.0.conv1.*    | backbone.bottom_up.res4.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,512,1,1)       |\n",
      "| backbone.bottom_up.res4.0.conv2.*    | backbone.bottom_up.res4.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.0.conv3.*    | backbone.bottom_up.res4.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.0.shortcut.* | backbone.bottom_up.res4.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (1024,) (1024,) (1024,) (1024,) (1024,512,1,1)  |\n",
      "| backbone.bottom_up.res4.1.conv1.*    | backbone.bottom_up.res4.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.1.conv2.*    | backbone.bottom_up.res4.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.1.conv3.*    | backbone.bottom_up.res4.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.2.conv1.*    | backbone.bottom_up.res4.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.2.conv2.*    | backbone.bottom_up.res4.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.2.conv3.*    | backbone.bottom_up.res4.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.3.conv1.*    | backbone.bottom_up.res4.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.3.conv2.*    | backbone.bottom_up.res4.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.3.conv3.*    | backbone.bottom_up.res4.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.4.conv1.*    | backbone.bottom_up.res4.4.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.4.conv2.*    | backbone.bottom_up.res4.4.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.4.conv3.*    | backbone.bottom_up.res4.4.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.5.conv1.*    | backbone.bottom_up.res4.5.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.5.conv2.*    | backbone.bottom_up.res4.5.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.5.conv3.*    | backbone.bottom_up.res4.5.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res5.0.conv1.*    | backbone.bottom_up.res5.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,1024,1,1)      |\n",
      "| backbone.bottom_up.res5.0.conv2.*    | backbone.bottom_up.res5.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |\n",
      "| backbone.bottom_up.res5.0.conv3.*    | backbone.bottom_up.res5.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
      "| backbone.bottom_up.res5.0.shortcut.* | backbone.bottom_up.res5.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (2048,) (2048,) (2048,) (2048,) (2048,1024,1,1) |\n",
      "| backbone.bottom_up.res5.1.conv1.*    | backbone.bottom_up.res5.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |\n",
      "| backbone.bottom_up.res5.1.conv2.*    | backbone.bottom_up.res5.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |\n",
      "| backbone.bottom_up.res5.1.conv3.*    | backbone.bottom_up.res5.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
      "| backbone.bottom_up.res5.2.conv1.*    | backbone.bottom_up.res5.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |\n",
      "| backbone.bottom_up.res5.2.conv2.*    | backbone.bottom_up.res5.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |\n",
      "| backbone.bottom_up.res5.2.conv3.*    | backbone.bottom_up.res5.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
      "| backbone.bottom_up.stem.conv1.*      | backbone.bottom_up.stem.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}      | (64,) (64,) (64,) (64,) (64,3,7,7)              |\n",
      "| backbone.fpn_lateral2.*              | backbone.fpn_lateral2.{bias,weight}                                                                  | (256,) (256,256,1,1)                            |\n",
      "| backbone.fpn_lateral3.*              | backbone.fpn_lateral3.{bias,weight}                                                                  | (256,) (256,512,1,1)                            |\n",
      "| backbone.fpn_lateral4.*              | backbone.fpn_lateral4.{bias,weight}                                                                  | (256,) (256,1024,1,1)                           |\n",
      "| backbone.fpn_lateral5.*              | backbone.fpn_lateral5.{bias,weight}                                                                  | (256,) (256,2048,1,1)                           |\n",
      "| backbone.fpn_output2.*               | backbone.fpn_output2.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| backbone.fpn_output3.*               | backbone.fpn_output3.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| backbone.fpn_output4.*               | backbone.fpn_output4.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| backbone.fpn_output5.*               | backbone.fpn_output5.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| sem_seg_head.p2.0.*                  | sem_seg_head.p2.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p3.0.*                  | sem_seg_head.p3.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p4.0.*                  | sem_seg_head.p4.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p4.2.*                  | sem_seg_head.p4.2.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,128,3,3)                     |\n",
      "| sem_seg_head.p5.0.*                  | sem_seg_head.p5.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p5.2.*                  | sem_seg_head.p5.2.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,128,3,3)                     |\n",
      "| sem_seg_head.p5.4.*                  | sem_seg_head.p5.4.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,128,3,3)                     |\n",
      "| sem_seg_head.predictor.*             | sem_seg_head.predictor.{bias,weight}                                                                 | (17,) (17,128,1,1)                              |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/05 21:33:56 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(720, 720), max_size=2048, sample_style='choice')]\n",
      "\u001b[32m[07/05 21:33:56 d2.data.common]: \u001b[0mSerializing 699 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[07/05 21:33:56 d2.data.common]: \u001b[0mSerialized dataset takes 0.22 MiB\n",
      "\u001b[32m[07/05 21:33:56 d2.evaluation.evaluator]: \u001b[0mStart inference on 699 batches\n",
      "\u001b[32m[07/05 21:33:59 d2.evaluation.evaluator]: \u001b[0mInference done 11/699. Dataloading: 0.0019 s/iter. Inference: 0.0469 s/iter. Eval: 0.1485 s/iter. Total: 0.1974 s/iter. ETA=0:02:15\n",
      "\u001b[32m[07/05 21:34:04 d2.evaluation.evaluator]: \u001b[0mInference done 37/699. Dataloading: 0.0022 s/iter. Inference: 0.0468 s/iter. Eval: 0.1474 s/iter. Total: 0.1965 s/iter. ETA=0:02:10\n",
      "\u001b[32m[07/05 21:34:09 d2.evaluation.evaluator]: \u001b[0mInference done 63/699. Dataloading: 0.0023 s/iter. Inference: 0.0466 s/iter. Eval: 0.1464 s/iter. Total: 0.1954 s/iter. ETA=0:02:04\n",
      "\u001b[32m[07/05 21:34:14 d2.evaluation.evaluator]: \u001b[0mInference done 89/699. Dataloading: 0.0023 s/iter. Inference: 0.0467 s/iter. Eval: 0.1461 s/iter. Total: 0.1951 s/iter. ETA=0:01:59\n",
      "\u001b[32m[07/05 21:34:19 d2.evaluation.evaluator]: \u001b[0mInference done 116/699. Dataloading: 0.0023 s/iter. Inference: 0.0464 s/iter. Eval: 0.1446 s/iter. Total: 0.1934 s/iter. ETA=0:01:52\n",
      "\u001b[32m[07/05 21:34:24 d2.evaluation.evaluator]: \u001b[0mInference done 144/699. Dataloading: 0.0023 s/iter. Inference: 0.0464 s/iter. Eval: 0.1426 s/iter. Total: 0.1914 s/iter. ETA=0:01:46\n",
      "\u001b[32m[07/05 21:34:29 d2.evaluation.evaluator]: \u001b[0mInference done 171/699. Dataloading: 0.0023 s/iter. Inference: 0.0465 s/iter. Eval: 0.1422 s/iter. Total: 0.1911 s/iter. ETA=0:01:40\n",
      "\u001b[32m[07/05 21:34:34 d2.evaluation.evaluator]: \u001b[0mInference done 196/699. Dataloading: 0.0023 s/iter. Inference: 0.0465 s/iter. Eval: 0.1435 s/iter. Total: 0.1924 s/iter. ETA=0:01:36\n",
      "\u001b[32m[07/05 21:34:39 d2.evaluation.evaluator]: \u001b[0mInference done 222/699. Dataloading: 0.0023 s/iter. Inference: 0.0465 s/iter. Eval: 0.1442 s/iter. Total: 0.1931 s/iter. ETA=0:01:32\n",
      "\u001b[32m[07/05 21:34:44 d2.evaluation.evaluator]: \u001b[0mInference done 248/699. Dataloading: 0.0023 s/iter. Inference: 0.0466 s/iter. Eval: 0.1445 s/iter. Total: 0.1935 s/iter. ETA=0:01:27\n",
      "\u001b[32m[07/05 21:34:49 d2.evaluation.evaluator]: \u001b[0mInference done 274/699. Dataloading: 0.0023 s/iter. Inference: 0.0466 s/iter. Eval: 0.1445 s/iter. Total: 0.1935 s/iter. ETA=0:01:22\n",
      "\u001b[32m[07/05 21:34:55 d2.evaluation.evaluator]: \u001b[0mInference done 301/699. Dataloading: 0.0023 s/iter. Inference: 0.0466 s/iter. Eval: 0.1444 s/iter. Total: 0.1933 s/iter. ETA=0:01:16\n",
      "\u001b[32m[07/05 21:35:00 d2.evaluation.evaluator]: \u001b[0mInference done 327/699. Dataloading: 0.0023 s/iter. Inference: 0.0466 s/iter. Eval: 0.1447 s/iter. Total: 0.1937 s/iter. ETA=0:01:12\n",
      "\u001b[32m[07/05 21:35:05 d2.evaluation.evaluator]: \u001b[0mInference done 353/699. Dataloading: 0.0023 s/iter. Inference: 0.0466 s/iter. Eval: 0.1448 s/iter. Total: 0.1938 s/iter. ETA=0:01:07\n",
      "\u001b[32m[07/05 21:35:10 d2.evaluation.evaluator]: \u001b[0mInference done 379/699. Dataloading: 0.0023 s/iter. Inference: 0.0466 s/iter. Eval: 0.1452 s/iter. Total: 0.1942 s/iter. ETA=0:01:02\n",
      "\u001b[32m[07/05 21:35:15 d2.evaluation.evaluator]: \u001b[0mInference done 404/699. Dataloading: 0.0023 s/iter. Inference: 0.0466 s/iter. Eval: 0.1456 s/iter. Total: 0.1946 s/iter. ETA=0:00:57\n",
      "\u001b[32m[07/05 21:35:20 d2.evaluation.evaluator]: \u001b[0mInference done 431/699. Dataloading: 0.0023 s/iter. Inference: 0.0466 s/iter. Eval: 0.1455 s/iter. Total: 0.1945 s/iter. ETA=0:00:52\n",
      "\u001b[32m[07/05 21:35:25 d2.evaluation.evaluator]: \u001b[0mInference done 457/699. Dataloading: 0.0023 s/iter. Inference: 0.0466 s/iter. Eval: 0.1455 s/iter. Total: 0.1945 s/iter. ETA=0:00:47\n",
      "\u001b[32m[07/05 21:35:30 d2.evaluation.evaluator]: \u001b[0mInference done 484/699. Dataloading: 0.0023 s/iter. Inference: 0.0466 s/iter. Eval: 0.1453 s/iter. Total: 0.1943 s/iter. ETA=0:00:41\n",
      "\u001b[32m[07/05 21:35:36 d2.evaluation.evaluator]: \u001b[0mInference done 510/699. Dataloading: 0.0023 s/iter. Inference: 0.0466 s/iter. Eval: 0.1456 s/iter. Total: 0.1946 s/iter. ETA=0:00:36\n",
      "\u001b[32m[07/05 21:35:41 d2.evaluation.evaluator]: \u001b[0mInference done 536/699. Dataloading: 0.0023 s/iter. Inference: 0.0466 s/iter. Eval: 0.1456 s/iter. Total: 0.1946 s/iter. ETA=0:00:31\n",
      "\u001b[32m[07/05 21:35:46 d2.evaluation.evaluator]: \u001b[0mInference done 562/699. Dataloading: 0.0023 s/iter. Inference: 0.0466 s/iter. Eval: 0.1457 s/iter. Total: 0.1947 s/iter. ETA=0:00:26\n",
      "\u001b[32m[07/05 21:35:51 d2.evaluation.evaluator]: \u001b[0mInference done 588/699. Dataloading: 0.0023 s/iter. Inference: 0.0466 s/iter. Eval: 0.1459 s/iter. Total: 0.1949 s/iter. ETA=0:00:21\n",
      "\u001b[32m[07/05 21:35:56 d2.evaluation.evaluator]: \u001b[0mInference done 614/699. Dataloading: 0.0023 s/iter. Inference: 0.0466 s/iter. Eval: 0.1460 s/iter. Total: 0.1950 s/iter. ETA=0:00:16\n",
      "\u001b[32m[07/05 21:36:01 d2.evaluation.evaluator]: \u001b[0mInference done 640/699. Dataloading: 0.0023 s/iter. Inference: 0.0466 s/iter. Eval: 0.1461 s/iter. Total: 0.1951 s/iter. ETA=0:00:11\n",
      "\u001b[32m[07/05 21:36:06 d2.evaluation.evaluator]: \u001b[0mInference done 667/699. Dataloading: 0.0023 s/iter. Inference: 0.0466 s/iter. Eval: 0.1458 s/iter. Total: 0.1949 s/iter. ETA=0:00:06\n",
      "\u001b[32m[07/05 21:36:12 d2.evaluation.evaluator]: \u001b[0mInference done 693/699. Dataloading: 0.0023 s/iter. Inference: 0.0466 s/iter. Eval: 0.1460 s/iter. Total: 0.1950 s/iter. ETA=0:00:01\n",
      "\u001b[32m[07/05 21:36:13 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:02:15.445942 (0.195167 s / iter per device, on 1 devices)\n",
      "\u001b[32m[07/05 21:36:13 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:32 (0.046628 s / iter per device, on 1 devices)\n",
      "\u001b[32m[07/05 21:36:13 d2.evaluation.sem_seg_evaluation]: \u001b[0mOrderedDict([('sem_seg', {'mIoU': 62.89248653530076, 'fwIoU': 90.34391309182091, 'IoU-Unlabeled': nan, 'IoU-Building': 90.74915164175378, 'IoU-Fence': 51.67114209409185, 'IoU-Pedestrian': 77.02938087793967, 'IoU-Pole': 51.41697762053553, 'IoU-Road': 96.53018822329807, 'IoU-SideWalk': 78.09232939426133, 'IoU-Vegetation': 90.67063875263185, 'IoU-Vehicles': 90.30386663393595, 'IoU-Wall': 46.82984356668758, 'IoU-TrafficSign': 63.57947076679865, 'IoU-Sky': 94.29392972554764, 'IoU-TrafficLight': 51.78223956217939, 'IoU-Terrain': 60.438139169850004, 'IoU-ConstructionVehicle': nan, 'IoU-workzone_object': nan, 'IoU-Detour': nan, 'mACC': 80.96261096341627, 'pACC': 94.70473128365184, 'ACC-Unlabeled': nan, 'ACC-Building': 95.4960110148136, 'ACC-Fence': 70.9044092635115, 'ACC-Pedestrian': 86.96905203207237, 'ACC-Pole': 65.59038568381516, 'ACC-Road': 98.61234654396748, 'ACC-SideWalk': 85.58164249392559, 'ACC-Vegetation': 95.79928160092422, 'ACC-Vehicles': 94.98057374182733, 'ACC-Wall': 56.05426120385447, 'ACC-TrafficSign': 73.48669805444733, 'ACC-Sky': 97.18795445022307, 'ACC-TrafficLight': 60.31132780182973, 'ACC-Terrain': 71.53999863919978, 'ACC-ConstructionVehicle': nan, 'ACC-workzone_object': nan, 'ACC-Detour': nan})])\n",
      "\u001b[32m[07/05 21:36:13 d2.engine.defaults]: \u001b[0mEvaluation results for cityscapes_clear_val in csv format:\n",
      "\u001b[32m[07/05 21:36:13 d2.evaluation.testing]: \u001b[0mcopypaste: Task: sem_seg\n",
      "\u001b[32m[07/05 21:36:13 d2.evaluation.testing]: \u001b[0mcopypaste: mIoU,fwIoU,mACC,pACC\n",
      "\u001b[32m[07/05 21:36:13 d2.evaluation.testing]: \u001b[0mcopypaste: 62.8925,90.3439,80.9626,94.7047\n"
     ]
    }
   ],
   "source": [
    "trainer_both = Detectron2Trainer('combined_all_night_train', 'cityscapes_clear_val', output_folder='./output_both_40k')\n",
    "trainer_both.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "13e1c88a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/05 21:36:13 d2.engine.defaults]: \u001b[0mModel:\n",
      "SemanticSegmentor(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (sem_seg_head): SemSegFPNHead(\n",
      "    (p2): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "    )\n",
      "    (p3): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (1): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "    )\n",
      "    (p4): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (1): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      (2): Conv2d(\n",
      "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (3): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "    )\n",
      "    (p5): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (1): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      (2): Conv2d(\n",
      "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (3): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      (4): Conv2d(\n",
      "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (5): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "    )\n",
      "    (predictor): Conv2d(128, 17, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/05 21:36:13 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(720, 720), max_size=2048, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[07/05 21:36:13 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[07/05 21:36:13 d2.data.common]: \u001b[0mSerializing 37734 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[07/05 21:36:13 d2.data.common]: \u001b[0mSerialized dataset takes 11.85 MiB\n",
      "Last checkpoint: model_final.pth\n",
      "\u001b[32m[07/05 21:36:14 d2.checkpoint.c2_model_loading]: \u001b[0mFollowing weights matched with model:\n",
      "| Names in Model                       | Names in Checkpoint                                                                                  | Shapes                                          |\n",
      "|:-------------------------------------|:-----------------------------------------------------------------------------------------------------|:------------------------------------------------|\n",
      "| backbone.bottom_up.res2.0.conv1.*    | backbone.bottom_up.res2.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,1,1)             |\n",
      "| backbone.bottom_up.res2.0.conv2.*    | backbone.bottom_up.res2.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |\n",
      "| backbone.bottom_up.res2.0.conv3.*    | backbone.bottom_up.res2.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res2.0.shortcut.* | backbone.bottom_up.res2.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res2.1.conv1.*    | backbone.bottom_up.res2.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |\n",
      "| backbone.bottom_up.res2.1.conv2.*    | backbone.bottom_up.res2.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |\n",
      "| backbone.bottom_up.res2.1.conv3.*    | backbone.bottom_up.res2.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res2.2.conv1.*    | backbone.bottom_up.res2.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |\n",
      "| backbone.bottom_up.res2.2.conv2.*    | backbone.bottom_up.res2.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |\n",
      "| backbone.bottom_up.res2.2.conv3.*    | backbone.bottom_up.res2.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res3.0.conv1.*    | backbone.bottom_up.res3.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,256,1,1)       |\n",
      "| backbone.bottom_up.res3.0.conv2.*    | backbone.bottom_up.res3.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.0.conv3.*    | backbone.bottom_up.res3.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res3.0.shortcut.* | backbone.bottom_up.res3.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (512,) (512,) (512,) (512,) (512,256,1,1)       |\n",
      "| backbone.bottom_up.res3.1.conv1.*    | backbone.bottom_up.res3.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |\n",
      "| backbone.bottom_up.res3.1.conv2.*    | backbone.bottom_up.res3.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.1.conv3.*    | backbone.bottom_up.res3.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res3.2.conv1.*    | backbone.bottom_up.res3.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |\n",
      "| backbone.bottom_up.res3.2.conv2.*    | backbone.bottom_up.res3.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.2.conv3.*    | backbone.bottom_up.res3.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res3.3.conv1.*    | backbone.bottom_up.res3.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |\n",
      "| backbone.bottom_up.res3.3.conv2.*    | backbone.bottom_up.res3.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.3.conv3.*    | backbone.bottom_up.res3.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res4.0.conv1.*    | backbone.bottom_up.res4.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,512,1,1)       |\n",
      "| backbone.bottom_up.res4.0.conv2.*    | backbone.bottom_up.res4.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.0.conv3.*    | backbone.bottom_up.res4.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.0.shortcut.* | backbone.bottom_up.res4.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (1024,) (1024,) (1024,) (1024,) (1024,512,1,1)  |\n",
      "| backbone.bottom_up.res4.1.conv1.*    | backbone.bottom_up.res4.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.1.conv2.*    | backbone.bottom_up.res4.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.1.conv3.*    | backbone.bottom_up.res4.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.2.conv1.*    | backbone.bottom_up.res4.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.2.conv2.*    | backbone.bottom_up.res4.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.2.conv3.*    | backbone.bottom_up.res4.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.3.conv1.*    | backbone.bottom_up.res4.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.3.conv2.*    | backbone.bottom_up.res4.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.3.conv3.*    | backbone.bottom_up.res4.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.4.conv1.*    | backbone.bottom_up.res4.4.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.4.conv2.*    | backbone.bottom_up.res4.4.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.4.conv3.*    | backbone.bottom_up.res4.4.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.5.conv1.*    | backbone.bottom_up.res4.5.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.5.conv2.*    | backbone.bottom_up.res4.5.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.5.conv3.*    | backbone.bottom_up.res4.5.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res5.0.conv1.*    | backbone.bottom_up.res5.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,1024,1,1)      |\n",
      "| backbone.bottom_up.res5.0.conv2.*    | backbone.bottom_up.res5.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |\n",
      "| backbone.bottom_up.res5.0.conv3.*    | backbone.bottom_up.res5.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
      "| backbone.bottom_up.res5.0.shortcut.* | backbone.bottom_up.res5.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (2048,) (2048,) (2048,) (2048,) (2048,1024,1,1) |\n",
      "| backbone.bottom_up.res5.1.conv1.*    | backbone.bottom_up.res5.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |\n",
      "| backbone.bottom_up.res5.1.conv2.*    | backbone.bottom_up.res5.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |\n",
      "| backbone.bottom_up.res5.1.conv3.*    | backbone.bottom_up.res5.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
      "| backbone.bottom_up.res5.2.conv1.*    | backbone.bottom_up.res5.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |\n",
      "| backbone.bottom_up.res5.2.conv2.*    | backbone.bottom_up.res5.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |\n",
      "| backbone.bottom_up.res5.2.conv3.*    | backbone.bottom_up.res5.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
      "| backbone.bottom_up.stem.conv1.*      | backbone.bottom_up.stem.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}      | (64,) (64,) (64,) (64,) (64,3,7,7)              |\n",
      "| backbone.fpn_lateral2.*              | backbone.fpn_lateral2.{bias,weight}                                                                  | (256,) (256,256,1,1)                            |\n",
      "| backbone.fpn_lateral3.*              | backbone.fpn_lateral3.{bias,weight}                                                                  | (256,) (256,512,1,1)                            |\n",
      "| backbone.fpn_lateral4.*              | backbone.fpn_lateral4.{bias,weight}                                                                  | (256,) (256,1024,1,1)                           |\n",
      "| backbone.fpn_lateral5.*              | backbone.fpn_lateral5.{bias,weight}                                                                  | (256,) (256,2048,1,1)                           |\n",
      "| backbone.fpn_output2.*               | backbone.fpn_output2.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| backbone.fpn_output3.*               | backbone.fpn_output3.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| backbone.fpn_output4.*               | backbone.fpn_output4.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| backbone.fpn_output5.*               | backbone.fpn_output5.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| sem_seg_head.p2.0.*                  | sem_seg_head.p2.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p3.0.*                  | sem_seg_head.p3.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p4.0.*                  | sem_seg_head.p4.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p4.2.*                  | sem_seg_head.p4.2.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,128,3,3)                     |\n",
      "| sem_seg_head.p5.0.*                  | sem_seg_head.p5.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p5.2.*                  | sem_seg_head.p5.2.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,128,3,3)                     |\n",
      "| sem_seg_head.p5.4.*                  | sem_seg_head.p5.4.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,128,3,3)                     |\n",
      "| sem_seg_head.predictor.*             | sem_seg_head.predictor.{bias,weight}                                                                 | (17,) (17,128,1,1)                              |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/05 21:36:14 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(720, 720), max_size=2048, sample_style='choice')]\n",
      "\u001b[32m[07/05 21:36:14 d2.data.common]: \u001b[0mSerializing 7230 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[07/05 21:36:14 d2.data.common]: \u001b[0mSerialized dataset takes 2.25 MiB\n",
      "\u001b[32m[07/05 21:36:14 d2.evaluation.evaluator]: \u001b[0mStart inference on 7230 batches\n",
      "\u001b[32m[07/05 21:36:17 d2.evaluation.evaluator]: \u001b[0mInference done 28/7230. Dataloading: 0.0022 s/iter. Inference: 0.0356 s/iter. Eval: 0.0424 s/iter. Total: 0.0802 s/iter. ETA=0:09:37\n",
      "\u001b[32m[07/05 21:36:22 d2.evaluation.evaluator]: \u001b[0mInference done 93/7230. Dataloading: 0.0022 s/iter. Inference: 0.0353 s/iter. Eval: 0.0405 s/iter. Total: 0.0781 s/iter. ETA=0:09:17\n",
      "\u001b[32m[07/05 21:36:27 d2.evaluation.evaluator]: \u001b[0mInference done 159/7230. Dataloading: 0.0022 s/iter. Inference: 0.0352 s/iter. Eval: 0.0396 s/iter. Total: 0.0771 s/iter. ETA=0:09:05\n",
      "\u001b[32m[07/05 21:36:32 d2.evaluation.evaluator]: \u001b[0mInference done 226/7230. Dataloading: 0.0022 s/iter. Inference: 0.0352 s/iter. Eval: 0.0390 s/iter. Total: 0.0765 s/iter. ETA=0:08:55\n",
      "\u001b[32m[07/05 21:36:37 d2.evaluation.evaluator]: \u001b[0mInference done 293/7230. Dataloading: 0.0022 s/iter. Inference: 0.0352 s/iter. Eval: 0.0386 s/iter. Total: 0.0761 s/iter. ETA=0:08:48\n",
      "\u001b[32m[07/05 21:36:42 d2.evaluation.evaluator]: \u001b[0mInference done 360/7230. Dataloading: 0.0022 s/iter. Inference: 0.0352 s/iter. Eval: 0.0383 s/iter. Total: 0.0759 s/iter. ETA=0:08:41\n",
      "\u001b[32m[07/05 21:36:47 d2.evaluation.evaluator]: \u001b[0mInference done 426/7230. Dataloading: 0.0022 s/iter. Inference: 0.0353 s/iter. Eval: 0.0383 s/iter. Total: 0.0759 s/iter. ETA=0:08:36\n",
      "\u001b[32m[07/05 21:36:52 d2.evaluation.evaluator]: \u001b[0mInference done 494/7230. Dataloading: 0.0022 s/iter. Inference: 0.0353 s/iter. Eval: 0.0381 s/iter. Total: 0.0757 s/iter. ETA=0:08:29\n",
      "\u001b[32m[07/05 21:36:57 d2.evaluation.evaluator]: \u001b[0mInference done 560/7230. Dataloading: 0.0026 s/iter. Inference: 0.0353 s/iter. Eval: 0.0379 s/iter. Total: 0.0758 s/iter. ETA=0:08:25\n",
      "\u001b[32m[07/05 21:37:02 d2.evaluation.evaluator]: \u001b[0mInference done 628/7230. Dataloading: 0.0025 s/iter. Inference: 0.0353 s/iter. Eval: 0.0378 s/iter. Total: 0.0757 s/iter. ETA=0:08:19\n",
      "\u001b[32m[07/05 21:37:07 d2.evaluation.evaluator]: \u001b[0mInference done 696/7230. Dataloading: 0.0025 s/iter. Inference: 0.0353 s/iter. Eval: 0.0376 s/iter. Total: 0.0755 s/iter. ETA=0:08:13\n",
      "\u001b[32m[07/05 21:37:12 d2.evaluation.evaluator]: \u001b[0mInference done 763/7230. Dataloading: 0.0025 s/iter. Inference: 0.0353 s/iter. Eval: 0.0376 s/iter. Total: 0.0754 s/iter. ETA=0:08:07\n",
      "\u001b[32m[07/05 21:37:17 d2.evaluation.evaluator]: \u001b[0mInference done 831/7230. Dataloading: 0.0025 s/iter. Inference: 0.0353 s/iter. Eval: 0.0375 s/iter. Total: 0.0754 s/iter. ETA=0:08:02\n",
      "\u001b[32m[07/05 21:37:22 d2.evaluation.evaluator]: \u001b[0mInference done 898/7230. Dataloading: 0.0024 s/iter. Inference: 0.0353 s/iter. Eval: 0.0375 s/iter. Total: 0.0753 s/iter. ETA=0:07:57\n",
      "\u001b[32m[07/05 21:37:27 d2.evaluation.evaluator]: \u001b[0mInference done 964/7230. Dataloading: 0.0024 s/iter. Inference: 0.0353 s/iter. Eval: 0.0376 s/iter. Total: 0.0754 s/iter. ETA=0:07:52\n",
      "\u001b[32m[07/05 21:37:32 d2.evaluation.evaluator]: \u001b[0mInference done 1030/7230. Dataloading: 0.0024 s/iter. Inference: 0.0353 s/iter. Eval: 0.0376 s/iter. Total: 0.0755 s/iter. ETA=0:07:47\n",
      "\u001b[32m[07/05 21:37:37 d2.evaluation.evaluator]: \u001b[0mInference done 1097/7230. Dataloading: 0.0024 s/iter. Inference: 0.0354 s/iter. Eval: 0.0376 s/iter. Total: 0.0754 s/iter. ETA=0:07:42\n",
      "\u001b[32m[07/05 21:37:42 d2.evaluation.evaluator]: \u001b[0mInference done 1162/7230. Dataloading: 0.0024 s/iter. Inference: 0.0354 s/iter. Eval: 0.0377 s/iter. Total: 0.0756 s/iter. ETA=0:07:38\n",
      "\u001b[32m[07/05 21:37:47 d2.evaluation.evaluator]: \u001b[0mInference done 1228/7230. Dataloading: 0.0024 s/iter. Inference: 0.0354 s/iter. Eval: 0.0378 s/iter. Total: 0.0756 s/iter. ETA=0:07:33\n",
      "\u001b[32m[07/05 21:37:52 d2.evaluation.evaluator]: \u001b[0mInference done 1294/7230. Dataloading: 0.0024 s/iter. Inference: 0.0354 s/iter. Eval: 0.0378 s/iter. Total: 0.0757 s/iter. ETA=0:07:29\n",
      "\u001b[32m[07/05 21:37:57 d2.evaluation.evaluator]: \u001b[0mInference done 1360/7230. Dataloading: 0.0024 s/iter. Inference: 0.0354 s/iter. Eval: 0.0379 s/iter. Total: 0.0757 s/iter. ETA=0:07:24\n",
      "\u001b[32m[07/05 21:38:02 d2.evaluation.evaluator]: \u001b[0mInference done 1427/7230. Dataloading: 0.0024 s/iter. Inference: 0.0354 s/iter. Eval: 0.0379 s/iter. Total: 0.0757 s/iter. ETA=0:07:19\n",
      "\u001b[32m[07/05 21:38:07 d2.evaluation.evaluator]: \u001b[0mInference done 1493/7230. Dataloading: 0.0024 s/iter. Inference: 0.0354 s/iter. Eval: 0.0379 s/iter. Total: 0.0758 s/iter. ETA=0:07:14\n",
      "\u001b[32m[07/05 21:38:12 d2.evaluation.evaluator]: \u001b[0mInference done 1558/7230. Dataloading: 0.0024 s/iter. Inference: 0.0354 s/iter. Eval: 0.0380 s/iter. Total: 0.0758 s/iter. ETA=0:07:10\n",
      "\u001b[32m[07/05 21:38:17 d2.evaluation.evaluator]: \u001b[0mInference done 1623/7230. Dataloading: 0.0024 s/iter. Inference: 0.0354 s/iter. Eval: 0.0380 s/iter. Total: 0.0759 s/iter. ETA=0:07:05\n",
      "\u001b[32m[07/05 21:38:23 d2.evaluation.evaluator]: \u001b[0mInference done 1687/7230. Dataloading: 0.0024 s/iter. Inference: 0.0354 s/iter. Eval: 0.0381 s/iter. Total: 0.0760 s/iter. ETA=0:07:01\n",
      "\u001b[32m[07/05 21:38:28 d2.evaluation.evaluator]: \u001b[0mInference done 1752/7230. Dataloading: 0.0024 s/iter. Inference: 0.0354 s/iter. Eval: 0.0382 s/iter. Total: 0.0760 s/iter. ETA=0:06:56\n",
      "\u001b[32m[07/05 21:38:33 d2.evaluation.evaluator]: \u001b[0mInference done 1818/7230. Dataloading: 0.0023 s/iter. Inference: 0.0354 s/iter. Eval: 0.0382 s/iter. Total: 0.0760 s/iter. ETA=0:06:51\n",
      "\u001b[32m[07/05 21:38:38 d2.evaluation.evaluator]: \u001b[0mInference done 1882/7230. Dataloading: 0.0023 s/iter. Inference: 0.0354 s/iter. Eval: 0.0383 s/iter. Total: 0.0761 s/iter. ETA=0:06:47\n",
      "\u001b[32m[07/05 21:38:43 d2.evaluation.evaluator]: \u001b[0mInference done 1948/7230. Dataloading: 0.0023 s/iter. Inference: 0.0354 s/iter. Eval: 0.0383 s/iter. Total: 0.0762 s/iter. ETA=0:06:42\n",
      "\u001b[32m[07/05 21:38:48 d2.evaluation.evaluator]: \u001b[0mInference done 2014/7230. Dataloading: 0.0023 s/iter. Inference: 0.0354 s/iter. Eval: 0.0383 s/iter. Total: 0.0762 s/iter. ETA=0:06:37\n",
      "\u001b[32m[07/05 21:38:53 d2.evaluation.evaluator]: \u001b[0mInference done 2079/7230. Dataloading: 0.0023 s/iter. Inference: 0.0354 s/iter. Eval: 0.0384 s/iter. Total: 0.0762 s/iter. ETA=0:06:32\n",
      "\u001b[32m[07/05 21:38:58 d2.evaluation.evaluator]: \u001b[0mInference done 2144/7230. Dataloading: 0.0023 s/iter. Inference: 0.0354 s/iter. Eval: 0.0384 s/iter. Total: 0.0762 s/iter. ETA=0:06:27\n",
      "\u001b[32m[07/05 21:39:03 d2.evaluation.evaluator]: \u001b[0mInference done 2210/7230. Dataloading: 0.0023 s/iter. Inference: 0.0354 s/iter. Eval: 0.0384 s/iter. Total: 0.0763 s/iter. ETA=0:06:22\n",
      "\u001b[32m[07/05 21:39:08 d2.evaluation.evaluator]: \u001b[0mInference done 2275/7230. Dataloading: 0.0023 s/iter. Inference: 0.0354 s/iter. Eval: 0.0384 s/iter. Total: 0.0763 s/iter. ETA=0:06:17\n",
      "\u001b[32m[07/05 21:39:13 d2.evaluation.evaluator]: \u001b[0mInference done 2341/7230. Dataloading: 0.0023 s/iter. Inference: 0.0354 s/iter. Eval: 0.0384 s/iter. Total: 0.0763 s/iter. ETA=0:06:12\n",
      "\u001b[32m[07/05 21:39:18 d2.evaluation.evaluator]: \u001b[0mInference done 2407/7230. Dataloading: 0.0023 s/iter. Inference: 0.0354 s/iter. Eval: 0.0384 s/iter. Total: 0.0763 s/iter. ETA=0:06:07\n",
      "\u001b[32m[07/05 21:39:23 d2.evaluation.evaluator]: \u001b[0mInference done 2473/7230. Dataloading: 0.0023 s/iter. Inference: 0.0354 s/iter. Eval: 0.0384 s/iter. Total: 0.0763 s/iter. ETA=0:06:02\n",
      "\u001b[32m[07/05 21:39:28 d2.evaluation.evaluator]: \u001b[0mInference done 2539/7230. Dataloading: 0.0023 s/iter. Inference: 0.0354 s/iter. Eval: 0.0384 s/iter. Total: 0.0763 s/iter. ETA=0:05:57\n",
      "\u001b[32m[07/05 21:39:33 d2.evaluation.evaluator]: \u001b[0mInference done 2605/7230. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0384 s/iter. Total: 0.0763 s/iter. ETA=0:05:52\n",
      "\u001b[32m[07/05 21:39:38 d2.evaluation.evaluator]: \u001b[0mInference done 2671/7230. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0384 s/iter. Total: 0.0763 s/iter. ETA=0:05:47\n",
      "\u001b[32m[07/05 21:39:43 d2.evaluation.evaluator]: \u001b[0mInference done 2737/7230. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0384 s/iter. Total: 0.0763 s/iter. ETA=0:05:42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/05 21:39:48 d2.evaluation.evaluator]: \u001b[0mInference done 2803/7230. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0384 s/iter. Total: 0.0763 s/iter. ETA=0:05:37\n",
      "\u001b[32m[07/05 21:39:53 d2.evaluation.evaluator]: \u001b[0mInference done 2869/7230. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0384 s/iter. Total: 0.0763 s/iter. ETA=0:05:32\n",
      "\u001b[32m[07/05 21:39:58 d2.evaluation.evaluator]: \u001b[0mInference done 2935/7230. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0384 s/iter. Total: 0.0763 s/iter. ETA=0:05:27\n",
      "\u001b[32m[07/05 21:40:03 d2.evaluation.evaluator]: \u001b[0mInference done 3001/7230. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0384 s/iter. Total: 0.0763 s/iter. ETA=0:05:22\n",
      "\u001b[32m[07/05 21:40:08 d2.evaluation.evaluator]: \u001b[0mInference done 3067/7230. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0384 s/iter. Total: 0.0763 s/iter. ETA=0:05:17\n",
      "\u001b[32m[07/05 21:40:13 d2.evaluation.evaluator]: \u001b[0mInference done 3133/7230. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0384 s/iter. Total: 0.0763 s/iter. ETA=0:05:12\n",
      "\u001b[32m[07/05 21:40:18 d2.evaluation.evaluator]: \u001b[0mInference done 3199/7230. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0384 s/iter. Total: 0.0763 s/iter. ETA=0:05:07\n",
      "\u001b[32m[07/05 21:40:24 d2.evaluation.evaluator]: \u001b[0mInference done 3261/7230. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0385 s/iter. Total: 0.0764 s/iter. ETA=0:05:03\n",
      "\u001b[32m[07/05 21:40:29 d2.evaluation.evaluator]: \u001b[0mInference done 3288/7230. Dataloading: 0.0023 s/iter. Inference: 0.0356 s/iter. Eval: 0.0394 s/iter. Total: 0.0774 s/iter. ETA=0:05:05\n",
      "\u001b[32m[07/05 21:40:34 d2.evaluation.evaluator]: \u001b[0mInference done 3314/7230. Dataloading: 0.0023 s/iter. Inference: 0.0357 s/iter. Eval: 0.0403 s/iter. Total: 0.0783 s/iter. ETA=0:05:06\n",
      "\u001b[32m[07/05 21:40:39 d2.evaluation.evaluator]: \u001b[0mInference done 3340/7230. Dataloading: 0.0023 s/iter. Inference: 0.0357 s/iter. Eval: 0.0411 s/iter. Total: 0.0792 s/iter. ETA=0:05:08\n",
      "\u001b[32m[07/05 21:40:44 d2.evaluation.evaluator]: \u001b[0mInference done 3367/7230. Dataloading: 0.0023 s/iter. Inference: 0.0358 s/iter. Eval: 0.0419 s/iter. Total: 0.0801 s/iter. ETA=0:05:09\n",
      "\u001b[32m[07/05 21:40:49 d2.evaluation.evaluator]: \u001b[0mInference done 3394/7230. Dataloading: 0.0023 s/iter. Inference: 0.0359 s/iter. Eval: 0.0426 s/iter. Total: 0.0809 s/iter. ETA=0:05:10\n",
      "\u001b[32m[07/05 21:40:54 d2.evaluation.evaluator]: \u001b[0mInference done 3422/7230. Dataloading: 0.0023 s/iter. Inference: 0.0360 s/iter. Eval: 0.0434 s/iter. Total: 0.0818 s/iter. ETA=0:05:11\n",
      "\u001b[32m[07/05 21:40:59 d2.evaluation.evaluator]: \u001b[0mInference done 3447/7230. Dataloading: 0.0023 s/iter. Inference: 0.0361 s/iter. Eval: 0.0442 s/iter. Total: 0.0827 s/iter. ETA=0:05:12\n",
      "\u001b[32m[07/05 21:41:04 d2.evaluation.evaluator]: \u001b[0mInference done 3473/7230. Dataloading: 0.0023 s/iter. Inference: 0.0362 s/iter. Eval: 0.0450 s/iter. Total: 0.0835 s/iter. ETA=0:05:13\n",
      "\u001b[32m[07/05 21:41:10 d2.evaluation.evaluator]: \u001b[0mInference done 3499/7230. Dataloading: 0.0023 s/iter. Inference: 0.0362 s/iter. Eval: 0.0457 s/iter. Total: 0.0844 s/iter. ETA=0:05:14\n",
      "\u001b[32m[07/05 21:41:15 d2.evaluation.evaluator]: \u001b[0mInference done 3525/7230. Dataloading: 0.0023 s/iter. Inference: 0.0363 s/iter. Eval: 0.0465 s/iter. Total: 0.0852 s/iter. ETA=0:05:15\n",
      "\u001b[32m[07/05 21:41:20 d2.evaluation.evaluator]: \u001b[0mInference done 3552/7230. Dataloading: 0.0023 s/iter. Inference: 0.0364 s/iter. Eval: 0.0472 s/iter. Total: 0.0860 s/iter. ETA=0:05:16\n",
      "\u001b[32m[07/05 21:41:25 d2.evaluation.evaluator]: \u001b[0mInference done 3579/7230. Dataloading: 0.0023 s/iter. Inference: 0.0365 s/iter. Eval: 0.0479 s/iter. Total: 0.0868 s/iter. ETA=0:05:16\n",
      "\u001b[32m[07/05 21:41:30 d2.evaluation.evaluator]: \u001b[0mInference done 3605/7230. Dataloading: 0.0023 s/iter. Inference: 0.0365 s/iter. Eval: 0.0486 s/iter. Total: 0.0875 s/iter. ETA=0:05:17\n",
      "\u001b[32m[07/05 21:41:35 d2.evaluation.evaluator]: \u001b[0mInference done 3632/7230. Dataloading: 0.0023 s/iter. Inference: 0.0366 s/iter. Eval: 0.0493 s/iter. Total: 0.0883 s/iter. ETA=0:05:17\n",
      "\u001b[32m[07/05 21:41:40 d2.evaluation.evaluator]: \u001b[0mInference done 3658/7230. Dataloading: 0.0023 s/iter. Inference: 0.0367 s/iter. Eval: 0.0500 s/iter. Total: 0.0891 s/iter. ETA=0:05:18\n",
      "\u001b[32m[07/05 21:41:45 d2.evaluation.evaluator]: \u001b[0mInference done 3685/7230. Dataloading: 0.0023 s/iter. Inference: 0.0368 s/iter. Eval: 0.0506 s/iter. Total: 0.0898 s/iter. ETA=0:05:18\n",
      "\u001b[32m[07/05 21:41:50 d2.evaluation.evaluator]: \u001b[0mInference done 3711/7230. Dataloading: 0.0024 s/iter. Inference: 0.0368 s/iter. Eval: 0.0512 s/iter. Total: 0.0906 s/iter. ETA=0:05:18\n",
      "\u001b[32m[07/05 21:41:55 d2.evaluation.evaluator]: \u001b[0mInference done 3738/7230. Dataloading: 0.0024 s/iter. Inference: 0.0369 s/iter. Eval: 0.0519 s/iter. Total: 0.0912 s/iter. ETA=0:05:18\n",
      "\u001b[32m[07/05 21:42:00 d2.evaluation.evaluator]: \u001b[0mInference done 3764/7230. Dataloading: 0.0024 s/iter. Inference: 0.0370 s/iter. Eval: 0.0525 s/iter. Total: 0.0919 s/iter. ETA=0:05:18\n",
      "\u001b[32m[07/05 21:42:05 d2.evaluation.evaluator]: \u001b[0mInference done 3791/7230. Dataloading: 0.0024 s/iter. Inference: 0.0370 s/iter. Eval: 0.0531 s/iter. Total: 0.0926 s/iter. ETA=0:05:18\n",
      "\u001b[32m[07/05 21:42:10 d2.evaluation.evaluator]: \u001b[0mInference done 3817/7230. Dataloading: 0.0024 s/iter. Inference: 0.0371 s/iter. Eval: 0.0537 s/iter. Total: 0.0933 s/iter. ETA=0:05:18\n",
      "\u001b[32m[07/05 21:42:15 d2.evaluation.evaluator]: \u001b[0mInference done 3843/7230. Dataloading: 0.0024 s/iter. Inference: 0.0372 s/iter. Eval: 0.0544 s/iter. Total: 0.0940 s/iter. ETA=0:05:18\n",
      "\u001b[32m[07/05 21:42:20 d2.evaluation.evaluator]: \u001b[0mInference done 3869/7230. Dataloading: 0.0024 s/iter. Inference: 0.0372 s/iter. Eval: 0.0550 s/iter. Total: 0.0947 s/iter. ETA=0:05:18\n",
      "\u001b[32m[07/05 21:42:26 d2.evaluation.evaluator]: \u001b[0mInference done 3896/7230. Dataloading: 0.0024 s/iter. Inference: 0.0373 s/iter. Eval: 0.0556 s/iter. Total: 0.0953 s/iter. ETA=0:05:17\n",
      "\u001b[32m[07/05 21:42:31 d2.evaluation.evaluator]: \u001b[0mInference done 3924/7230. Dataloading: 0.0024 s/iter. Inference: 0.0374 s/iter. Eval: 0.0561 s/iter. Total: 0.0960 s/iter. ETA=0:05:17\n",
      "\u001b[32m[07/05 21:42:36 d2.evaluation.evaluator]: \u001b[0mInference done 3950/7230. Dataloading: 0.0024 s/iter. Inference: 0.0374 s/iter. Eval: 0.0567 s/iter. Total: 0.0966 s/iter. ETA=0:05:16\n",
      "\u001b[32m[07/05 21:42:41 d2.evaluation.evaluator]: \u001b[0mInference done 4004/7230. Dataloading: 0.0024 s/iter. Inference: 0.0374 s/iter. Eval: 0.0567 s/iter. Total: 0.0966 s/iter. ETA=0:05:11\n",
      "\u001b[32m[07/05 21:42:46 d2.evaluation.evaluator]: \u001b[0mInference done 4069/7230. Dataloading: 0.0024 s/iter. Inference: 0.0374 s/iter. Eval: 0.0564 s/iter. Total: 0.0963 s/iter. ETA=0:05:04\n",
      "\u001b[32m[07/05 21:42:51 d2.evaluation.evaluator]: \u001b[0mInference done 4134/7230. Dataloading: 0.0024 s/iter. Inference: 0.0374 s/iter. Eval: 0.0561 s/iter. Total: 0.0960 s/iter. ETA=0:04:57\n",
      "\u001b[32m[07/05 21:42:56 d2.evaluation.evaluator]: \u001b[0mInference done 4199/7230. Dataloading: 0.0024 s/iter. Inference: 0.0373 s/iter. Eval: 0.0559 s/iter. Total: 0.0957 s/iter. ETA=0:04:50\n",
      "\u001b[32m[07/05 21:43:01 d2.evaluation.evaluator]: \u001b[0mInference done 4264/7230. Dataloading: 0.0024 s/iter. Inference: 0.0373 s/iter. Eval: 0.0557 s/iter. Total: 0.0954 s/iter. ETA=0:04:42\n",
      "\u001b[32m[07/05 21:43:06 d2.evaluation.evaluator]: \u001b[0mInference done 4328/7230. Dataloading: 0.0024 s/iter. Inference: 0.0373 s/iter. Eval: 0.0554 s/iter. Total: 0.0952 s/iter. ETA=0:04:36\n",
      "\u001b[32m[07/05 21:43:11 d2.evaluation.evaluator]: \u001b[0mInference done 4392/7230. Dataloading: 0.0024 s/iter. Inference: 0.0372 s/iter. Eval: 0.0552 s/iter. Total: 0.0949 s/iter. ETA=0:04:29\n",
      "\u001b[32m[07/05 21:43:16 d2.evaluation.evaluator]: \u001b[0mInference done 4456/7230. Dataloading: 0.0024 s/iter. Inference: 0.0372 s/iter. Eval: 0.0550 s/iter. Total: 0.0947 s/iter. ETA=0:04:22\n",
      "\u001b[32m[07/05 21:43:21 d2.evaluation.evaluator]: \u001b[0mInference done 4521/7230. Dataloading: 0.0024 s/iter. Inference: 0.0372 s/iter. Eval: 0.0548 s/iter. Total: 0.0944 s/iter. ETA=0:04:15\n",
      "\u001b[32m[07/05 21:43:26 d2.evaluation.evaluator]: \u001b[0mInference done 4585/7230. Dataloading: 0.0024 s/iter. Inference: 0.0372 s/iter. Eval: 0.0546 s/iter. Total: 0.0942 s/iter. ETA=0:04:09\n",
      "\u001b[32m[07/05 21:43:31 d2.evaluation.evaluator]: \u001b[0mInference done 4649/7230. Dataloading: 0.0024 s/iter. Inference: 0.0371 s/iter. Eval: 0.0544 s/iter. Total: 0.0940 s/iter. ETA=0:04:02\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/05 21:43:36 d2.evaluation.evaluator]: \u001b[0mInference done 4713/7230. Dataloading: 0.0024 s/iter. Inference: 0.0371 s/iter. Eval: 0.0542 s/iter. Total: 0.0938 s/iter. ETA=0:03:56\n",
      "\u001b[32m[07/05 21:43:41 d2.evaluation.evaluator]: \u001b[0mInference done 4779/7230. Dataloading: 0.0024 s/iter. Inference: 0.0371 s/iter. Eval: 0.0540 s/iter. Total: 0.0935 s/iter. ETA=0:03:49\n",
      "\u001b[32m[07/05 21:43:46 d2.evaluation.evaluator]: \u001b[0mInference done 4846/7230. Dataloading: 0.0024 s/iter. Inference: 0.0371 s/iter. Eval: 0.0538 s/iter. Total: 0.0933 s/iter. ETA=0:03:42\n",
      "\u001b[32m[07/05 21:43:51 d2.evaluation.evaluator]: \u001b[0mInference done 4912/7230. Dataloading: 0.0024 s/iter. Inference: 0.0370 s/iter. Eval: 0.0536 s/iter. Total: 0.0931 s/iter. ETA=0:03:35\n",
      "\u001b[32m[07/05 21:43:56 d2.evaluation.evaluator]: \u001b[0mInference done 4978/7230. Dataloading: 0.0024 s/iter. Inference: 0.0370 s/iter. Eval: 0.0534 s/iter. Total: 0.0928 s/iter. ETA=0:03:29\n",
      "\u001b[32m[07/05 21:44:01 d2.evaluation.evaluator]: \u001b[0mInference done 5045/7230. Dataloading: 0.0024 s/iter. Inference: 0.0370 s/iter. Eval: 0.0532 s/iter. Total: 0.0926 s/iter. ETA=0:03:22\n",
      "\u001b[32m[07/05 21:44:06 d2.evaluation.evaluator]: \u001b[0mInference done 5111/7230. Dataloading: 0.0024 s/iter. Inference: 0.0370 s/iter. Eval: 0.0530 s/iter. Total: 0.0924 s/iter. ETA=0:03:15\n",
      "\u001b[32m[07/05 21:44:11 d2.evaluation.evaluator]: \u001b[0mInference done 5177/7230. Dataloading: 0.0024 s/iter. Inference: 0.0370 s/iter. Eval: 0.0528 s/iter. Total: 0.0922 s/iter. ETA=0:03:09\n",
      "\u001b[32m[07/05 21:44:17 d2.evaluation.evaluator]: \u001b[0mInference done 5243/7230. Dataloading: 0.0024 s/iter. Inference: 0.0369 s/iter. Eval: 0.0526 s/iter. Total: 0.0920 s/iter. ETA=0:03:02\n",
      "\u001b[32m[07/05 21:44:22 d2.evaluation.evaluator]: \u001b[0mInference done 5309/7230. Dataloading: 0.0024 s/iter. Inference: 0.0369 s/iter. Eval: 0.0524 s/iter. Total: 0.0918 s/iter. ETA=0:02:56\n",
      "\u001b[32m[07/05 21:44:27 d2.evaluation.evaluator]: \u001b[0mInference done 5375/7230. Dataloading: 0.0024 s/iter. Inference: 0.0369 s/iter. Eval: 0.0522 s/iter. Total: 0.0916 s/iter. ETA=0:02:49\n",
      "\u001b[32m[07/05 21:44:32 d2.evaluation.evaluator]: \u001b[0mInference done 5442/7230. Dataloading: 0.0024 s/iter. Inference: 0.0369 s/iter. Eval: 0.0521 s/iter. Total: 0.0914 s/iter. ETA=0:02:43\n",
      "\u001b[32m[07/05 21:44:37 d2.evaluation.evaluator]: \u001b[0mInference done 5508/7230. Dataloading: 0.0024 s/iter. Inference: 0.0369 s/iter. Eval: 0.0519 s/iter. Total: 0.0912 s/iter. ETA=0:02:37\n",
      "\u001b[32m[07/05 21:44:42 d2.evaluation.evaluator]: \u001b[0mInference done 5574/7230. Dataloading: 0.0024 s/iter. Inference: 0.0369 s/iter. Eval: 0.0517 s/iter. Total: 0.0910 s/iter. ETA=0:02:30\n",
      "\u001b[32m[07/05 21:44:47 d2.evaluation.evaluator]: \u001b[0mInference done 5640/7230. Dataloading: 0.0024 s/iter. Inference: 0.0368 s/iter. Eval: 0.0516 s/iter. Total: 0.0909 s/iter. ETA=0:02:24\n",
      "\u001b[32m[07/05 21:44:52 d2.evaluation.evaluator]: \u001b[0mInference done 5706/7230. Dataloading: 0.0024 s/iter. Inference: 0.0368 s/iter. Eval: 0.0514 s/iter. Total: 0.0907 s/iter. ETA=0:02:18\n",
      "\u001b[32m[07/05 21:44:57 d2.evaluation.evaluator]: \u001b[0mInference done 5772/7230. Dataloading: 0.0024 s/iter. Inference: 0.0368 s/iter. Eval: 0.0513 s/iter. Total: 0.0905 s/iter. ETA=0:02:12\n",
      "\u001b[32m[07/05 21:45:02 d2.evaluation.evaluator]: \u001b[0mInference done 5838/7230. Dataloading: 0.0024 s/iter. Inference: 0.0368 s/iter. Eval: 0.0511 s/iter. Total: 0.0904 s/iter. ETA=0:02:05\n",
      "\u001b[32m[07/05 21:45:07 d2.evaluation.evaluator]: \u001b[0mInference done 5905/7230. Dataloading: 0.0024 s/iter. Inference: 0.0368 s/iter. Eval: 0.0510 s/iter. Total: 0.0902 s/iter. ETA=0:01:59\n",
      "\u001b[32m[07/05 21:45:12 d2.evaluation.evaluator]: \u001b[0mInference done 5972/7230. Dataloading: 0.0024 s/iter. Inference: 0.0368 s/iter. Eval: 0.0508 s/iter. Total: 0.0901 s/iter. ETA=0:01:53\n",
      "\u001b[32m[07/05 21:45:17 d2.evaluation.evaluator]: \u001b[0mInference done 6037/7230. Dataloading: 0.0024 s/iter. Inference: 0.0368 s/iter. Eval: 0.0507 s/iter. Total: 0.0899 s/iter. ETA=0:01:47\n",
      "\u001b[32m[07/05 21:45:22 d2.evaluation.evaluator]: \u001b[0mInference done 6103/7230. Dataloading: 0.0024 s/iter. Inference: 0.0367 s/iter. Eval: 0.0506 s/iter. Total: 0.0898 s/iter. ETA=0:01:41\n",
      "\u001b[32m[07/05 21:45:27 d2.evaluation.evaluator]: \u001b[0mInference done 6169/7230. Dataloading: 0.0024 s/iter. Inference: 0.0367 s/iter. Eval: 0.0504 s/iter. Total: 0.0896 s/iter. ETA=0:01:35\n",
      "\u001b[32m[07/05 21:45:32 d2.evaluation.evaluator]: \u001b[0mInference done 6235/7230. Dataloading: 0.0024 s/iter. Inference: 0.0367 s/iter. Eval: 0.0503 s/iter. Total: 0.0895 s/iter. ETA=0:01:29\n",
      "\u001b[32m[07/05 21:45:37 d2.evaluation.evaluator]: \u001b[0mInference done 6301/7230. Dataloading: 0.0024 s/iter. Inference: 0.0367 s/iter. Eval: 0.0502 s/iter. Total: 0.0893 s/iter. ETA=0:01:23\n",
      "\u001b[32m[07/05 21:45:42 d2.evaluation.evaluator]: \u001b[0mInference done 6367/7230. Dataloading: 0.0024 s/iter. Inference: 0.0367 s/iter. Eval: 0.0501 s/iter. Total: 0.0892 s/iter. ETA=0:01:16\n",
      "\u001b[32m[07/05 21:45:47 d2.evaluation.evaluator]: \u001b[0mInference done 6433/7230. Dataloading: 0.0024 s/iter. Inference: 0.0367 s/iter. Eval: 0.0500 s/iter. Total: 0.0891 s/iter. ETA=0:01:11\n",
      "\u001b[32m[07/05 21:45:52 d2.evaluation.evaluator]: \u001b[0mInference done 6498/7230. Dataloading: 0.0024 s/iter. Inference: 0.0367 s/iter. Eval: 0.0498 s/iter. Total: 0.0890 s/iter. ETA=0:01:05\n",
      "\u001b[32m[07/05 21:45:57 d2.evaluation.evaluator]: \u001b[0mInference done 6565/7230. Dataloading: 0.0024 s/iter. Inference: 0.0367 s/iter. Eval: 0.0497 s/iter. Total: 0.0888 s/iter. ETA=0:00:59\n",
      "\u001b[32m[07/05 21:46:02 d2.evaluation.evaluator]: \u001b[0mInference done 6632/7230. Dataloading: 0.0024 s/iter. Inference: 0.0367 s/iter. Eval: 0.0496 s/iter. Total: 0.0887 s/iter. ETA=0:00:53\n",
      "\u001b[32m[07/05 21:46:08 d2.evaluation.evaluator]: \u001b[0mInference done 6699/7230. Dataloading: 0.0024 s/iter. Inference: 0.0366 s/iter. Eval: 0.0495 s/iter. Total: 0.0886 s/iter. ETA=0:00:47\n",
      "\u001b[32m[07/05 21:46:13 d2.evaluation.evaluator]: \u001b[0mInference done 6764/7230. Dataloading: 0.0024 s/iter. Inference: 0.0366 s/iter. Eval: 0.0494 s/iter. Total: 0.0885 s/iter. ETA=0:00:41\n",
      "\u001b[32m[07/05 21:46:18 d2.evaluation.evaluator]: \u001b[0mInference done 6828/7230. Dataloading: 0.0024 s/iter. Inference: 0.0366 s/iter. Eval: 0.0493 s/iter. Total: 0.0884 s/iter. ETA=0:00:35\n",
      "\u001b[32m[07/05 21:46:23 d2.evaluation.evaluator]: \u001b[0mInference done 6891/7230. Dataloading: 0.0024 s/iter. Inference: 0.0366 s/iter. Eval: 0.0492 s/iter. Total: 0.0883 s/iter. ETA=0:00:29\n",
      "\u001b[32m[07/05 21:46:28 d2.evaluation.evaluator]: \u001b[0mInference done 6954/7230. Dataloading: 0.0024 s/iter. Inference: 0.0366 s/iter. Eval: 0.0492 s/iter. Total: 0.0882 s/iter. ETA=0:00:24\n",
      "\u001b[32m[07/05 21:46:33 d2.evaluation.evaluator]: \u001b[0mInference done 7019/7230. Dataloading: 0.0024 s/iter. Inference: 0.0366 s/iter. Eval: 0.0491 s/iter. Total: 0.0881 s/iter. ETA=0:00:18\n",
      "\u001b[32m[07/05 21:46:38 d2.evaluation.evaluator]: \u001b[0mInference done 7084/7230. Dataloading: 0.0024 s/iter. Inference: 0.0366 s/iter. Eval: 0.0490 s/iter. Total: 0.0880 s/iter. ETA=0:00:12\n",
      "\u001b[32m[07/05 21:46:43 d2.evaluation.evaluator]: \u001b[0mInference done 7150/7230. Dataloading: 0.0024 s/iter. Inference: 0.0366 s/iter. Eval: 0.0489 s/iter. Total: 0.0879 s/iter. ETA=0:00:07\n",
      "\u001b[32m[07/05 21:46:48 d2.evaluation.evaluator]: \u001b[0mInference done 7217/7230. Dataloading: 0.0024 s/iter. Inference: 0.0366 s/iter. Eval: 0.0488 s/iter. Total: 0.0878 s/iter. ETA=0:00:01\n",
      "\u001b[32m[07/05 21:46:49 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:10:34.154497 (0.087772 s / iter per device, on 1 devices)\n",
      "\u001b[32m[07/05 21:46:49 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:04:24 (0.036565 s / iter per device, on 1 devices)\n",
      "\u001b[32m[07/05 21:46:50 d2.evaluation.sem_seg_evaluation]: \u001b[0mOrderedDict([('sem_seg', {'mIoU': 56.84485903343276, 'fwIoU': 81.3216115565641, 'IoU-Unlabeled': nan, 'IoU-Building': 73.81507043768084, 'IoU-Fence': 33.11620814018532, 'IoU-Pedestrian': 70.49008735030816, 'IoU-Pole': 53.061094270133616, 'IoU-Road': 95.82317298435179, 'IoU-SideWalk': 72.2737781691554, 'IoU-Vegetation': 72.33697329252966, 'IoU-Vehicles': 82.32304878663493, 'IoU-Wall': 57.197172042896064, 'IoU-TrafficSign': 57.8852033988575, 'IoU-Sky': 80.7696884783418, 'IoU-TrafficLight': 55.27492383388368, 'IoU-Terrain': 26.347524356771835, 'IoU-ConstructionVehicle': 56.63788013211336, 'IoU-workzone_object': 64.22115212807414, 'IoU-Detour': 14.78962576643879, 'mACC': 72.4448157333671, 'pACC': 89.18798190403521, 'ACC-Unlabeled': nan, 'ACC-Building': 95.65727944111252, 'ACC-Fence': 51.59529620710431, 'ACC-Pedestrian': 84.57179535560296, 'ACC-Pole': 62.4888250871716, 'ACC-Road': 97.59122704298565, 'ACC-SideWalk': 88.4176330373462, 'ACC-Vegetation': 83.84320565505463, 'ACC-Vehicles': 91.20888777841245, 'ACC-Wall': 64.05694567713783, 'ACC-TrafficSign': 67.67292327223021, 'ACC-Sky': 83.32414663905278, 'ACC-TrafficLight': 64.78702687509688, 'ACC-Terrain': 27.532336859333135, 'ACC-ConstructionVehicle': 94.23643823966336, 'ACC-workzone_object': 86.30291533928155, 'ACC-Detour': 15.830169227287586})])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/05 21:46:50 d2.engine.defaults]: \u001b[0mEvaluation results for combined_clear_both_val in csv format:\n",
      "\u001b[32m[07/05 21:46:50 d2.evaluation.testing]: \u001b[0mcopypaste: Task: sem_seg\n",
      "\u001b[32m[07/05 21:46:50 d2.evaluation.testing]: \u001b[0mcopypaste: mIoU,fwIoU,mACC,pACC\n",
      "\u001b[32m[07/05 21:46:50 d2.evaluation.testing]: \u001b[0mcopypaste: 56.8449,81.3216,72.4448,89.1880\n"
     ]
    }
   ],
   "source": [
    "trainer_both = Detectron2Trainer('combined_all_night_train', 'combined_clear_both_val', output_folder='./output_both_40k')\n",
    "trainer_both.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "80e56c8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/06 04:13:46 d2.engine.defaults]: \u001b[0mModel:\n",
      "SemanticSegmentor(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (sem_seg_head): SemSegFPNHead(\n",
      "    (p2): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "    )\n",
      "    (p3): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (1): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "    )\n",
      "    (p4): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (1): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      (2): Conv2d(\n",
      "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (3): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "    )\n",
      "    (p5): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (1): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      (2): Conv2d(\n",
      "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (3): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      (4): Conv2d(\n",
      "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (5): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "    )\n",
      "    (predictor): Conv2d(128, 17, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/06 04:13:46 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(720, 720), max_size=2048, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[07/06 04:13:46 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[07/06 04:13:46 d2.data.common]: \u001b[0mSerializing 4560 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[07/06 04:13:46 d2.data.common]: \u001b[0mSerialized dataset takes 1.68 MiB\n",
      "Last checkpoint: model_final.pth\n",
      "\u001b[32m[07/06 04:13:47 d2.checkpoint.c2_model_loading]: \u001b[0mFollowing weights matched with model:\n",
      "| Names in Model                       | Names in Checkpoint                                                                                  | Shapes                                          |\n",
      "|:-------------------------------------|:-----------------------------------------------------------------------------------------------------|:------------------------------------------------|\n",
      "| backbone.bottom_up.res2.0.conv1.*    | backbone.bottom_up.res2.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,1,1)             |\n",
      "| backbone.bottom_up.res2.0.conv2.*    | backbone.bottom_up.res2.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |\n",
      "| backbone.bottom_up.res2.0.conv3.*    | backbone.bottom_up.res2.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res2.0.shortcut.* | backbone.bottom_up.res2.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res2.1.conv1.*    | backbone.bottom_up.res2.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |\n",
      "| backbone.bottom_up.res2.1.conv2.*    | backbone.bottom_up.res2.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |\n",
      "| backbone.bottom_up.res2.1.conv3.*    | backbone.bottom_up.res2.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res2.2.conv1.*    | backbone.bottom_up.res2.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |\n",
      "| backbone.bottom_up.res2.2.conv2.*    | backbone.bottom_up.res2.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |\n",
      "| backbone.bottom_up.res2.2.conv3.*    | backbone.bottom_up.res2.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res3.0.conv1.*    | backbone.bottom_up.res3.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,256,1,1)       |\n",
      "| backbone.bottom_up.res3.0.conv2.*    | backbone.bottom_up.res3.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.0.conv3.*    | backbone.bottom_up.res3.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res3.0.shortcut.* | backbone.bottom_up.res3.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (512,) (512,) (512,) (512,) (512,256,1,1)       |\n",
      "| backbone.bottom_up.res3.1.conv1.*    | backbone.bottom_up.res3.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |\n",
      "| backbone.bottom_up.res3.1.conv2.*    | backbone.bottom_up.res3.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.1.conv3.*    | backbone.bottom_up.res3.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res3.2.conv1.*    | backbone.bottom_up.res3.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |\n",
      "| backbone.bottom_up.res3.2.conv2.*    | backbone.bottom_up.res3.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.2.conv3.*    | backbone.bottom_up.res3.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res3.3.conv1.*    | backbone.bottom_up.res3.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |\n",
      "| backbone.bottom_up.res3.3.conv2.*    | backbone.bottom_up.res3.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.3.conv3.*    | backbone.bottom_up.res3.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res4.0.conv1.*    | backbone.bottom_up.res4.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,512,1,1)       |\n",
      "| backbone.bottom_up.res4.0.conv2.*    | backbone.bottom_up.res4.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.0.conv3.*    | backbone.bottom_up.res4.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.0.shortcut.* | backbone.bottom_up.res4.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (1024,) (1024,) (1024,) (1024,) (1024,512,1,1)  |\n",
      "| backbone.bottom_up.res4.1.conv1.*    | backbone.bottom_up.res4.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.1.conv2.*    | backbone.bottom_up.res4.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.1.conv3.*    | backbone.bottom_up.res4.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.2.conv1.*    | backbone.bottom_up.res4.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.2.conv2.*    | backbone.bottom_up.res4.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.2.conv3.*    | backbone.bottom_up.res4.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.3.conv1.*    | backbone.bottom_up.res4.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.3.conv2.*    | backbone.bottom_up.res4.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.3.conv3.*    | backbone.bottom_up.res4.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.4.conv1.*    | backbone.bottom_up.res4.4.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.4.conv2.*    | backbone.bottom_up.res4.4.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.4.conv3.*    | backbone.bottom_up.res4.4.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.5.conv1.*    | backbone.bottom_up.res4.5.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.5.conv2.*    | backbone.bottom_up.res4.5.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.5.conv3.*    | backbone.bottom_up.res4.5.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res5.0.conv1.*    | backbone.bottom_up.res5.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,1024,1,1)      |\n",
      "| backbone.bottom_up.res5.0.conv2.*    | backbone.bottom_up.res5.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |\n",
      "| backbone.bottom_up.res5.0.conv3.*    | backbone.bottom_up.res5.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
      "| backbone.bottom_up.res5.0.shortcut.* | backbone.bottom_up.res5.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (2048,) (2048,) (2048,) (2048,) (2048,1024,1,1) |\n",
      "| backbone.bottom_up.res5.1.conv1.*    | backbone.bottom_up.res5.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |\n",
      "| backbone.bottom_up.res5.1.conv2.*    | backbone.bottom_up.res5.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |\n",
      "| backbone.bottom_up.res5.1.conv3.*    | backbone.bottom_up.res5.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
      "| backbone.bottom_up.res5.2.conv1.*    | backbone.bottom_up.res5.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |\n",
      "| backbone.bottom_up.res5.2.conv2.*    | backbone.bottom_up.res5.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |\n",
      "| backbone.bottom_up.res5.2.conv3.*    | backbone.bottom_up.res5.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
      "| backbone.bottom_up.stem.conv1.*      | backbone.bottom_up.stem.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}      | (64,) (64,) (64,) (64,) (64,3,7,7)              |\n",
      "| backbone.fpn_lateral2.*              | backbone.fpn_lateral2.{bias,weight}                                                                  | (256,) (256,256,1,1)                            |\n",
      "| backbone.fpn_lateral3.*              | backbone.fpn_lateral3.{bias,weight}                                                                  | (256,) (256,512,1,1)                            |\n",
      "| backbone.fpn_lateral4.*              | backbone.fpn_lateral4.{bias,weight}                                                                  | (256,) (256,1024,1,1)                           |\n",
      "| backbone.fpn_lateral5.*              | backbone.fpn_lateral5.{bias,weight}                                                                  | (256,) (256,2048,1,1)                           |\n",
      "| backbone.fpn_output2.*               | backbone.fpn_output2.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| backbone.fpn_output3.*               | backbone.fpn_output3.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| backbone.fpn_output4.*               | backbone.fpn_output4.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| backbone.fpn_output5.*               | backbone.fpn_output5.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| sem_seg_head.p2.0.*                  | sem_seg_head.p2.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p3.0.*                  | sem_seg_head.p3.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p4.0.*                  | sem_seg_head.p4.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p4.2.*                  | sem_seg_head.p4.2.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,128,3,3)                     |\n",
      "| sem_seg_head.p5.0.*                  | sem_seg_head.p5.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p5.2.*                  | sem_seg_head.p5.2.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,128,3,3)                     |\n",
      "| sem_seg_head.p5.4.*                  | sem_seg_head.p5.4.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,128,3,3)                     |\n",
      "| sem_seg_head.predictor.*             | sem_seg_head.predictor.{bias,weight}                                                                 | (17,) (17,128,1,1)                              |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/06 04:13:47 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(720, 720), max_size=2048, sample_style='choice')]\n",
      "\u001b[32m[07/06 04:13:47 d2.data.common]: \u001b[0mSerializing 2185 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[07/06 04:13:47 d2.data.common]: \u001b[0mSerialized dataset takes 0.81 MiB\n",
      "\u001b[32m[07/06 04:13:47 d2.evaluation.evaluator]: \u001b[0mStart inference on 2185 batches\n",
      "\u001b[32m[07/06 04:13:48 d2.evaluation.evaluator]: \u001b[0mInference done 11/2185. Dataloading: 0.0017 s/iter. Inference: 0.0349 s/iter. Eval: 0.0409 s/iter. Total: 0.0776 s/iter. ETA=0:02:48\n",
      "\u001b[32m[07/06 04:13:53 d2.evaluation.evaluator]: \u001b[0mInference done 79/2185. Dataloading: 0.0021 s/iter. Inference: 0.0348 s/iter. Eval: 0.0376 s/iter. Total: 0.0745 s/iter. ETA=0:02:36\n",
      "\u001b[32m[07/06 04:13:58 d2.evaluation.evaluator]: \u001b[0mInference done 147/2185. Dataloading: 0.0021 s/iter. Inference: 0.0348 s/iter. Eval: 0.0372 s/iter. Total: 0.0742 s/iter. ETA=0:02:31\n",
      "\u001b[32m[07/06 04:14:03 d2.evaluation.evaluator]: \u001b[0mInference done 213/2185. Dataloading: 0.0022 s/iter. Inference: 0.0348 s/iter. Eval: 0.0378 s/iter. Total: 0.0749 s/iter. ETA=0:02:27\n",
      "\u001b[32m[07/06 04:14:08 d2.evaluation.evaluator]: \u001b[0mInference done 279/2185. Dataloading: 0.0022 s/iter. Inference: 0.0349 s/iter. Eval: 0.0381 s/iter. Total: 0.0752 s/iter. ETA=0:02:23\n",
      "\u001b[32m[07/06 04:14:13 d2.evaluation.evaluator]: \u001b[0mInference done 345/2185. Dataloading: 0.0022 s/iter. Inference: 0.0349 s/iter. Eval: 0.0384 s/iter. Total: 0.0755 s/iter. ETA=0:02:18\n",
      "\u001b[32m[07/06 04:14:18 d2.evaluation.evaluator]: \u001b[0mInference done 411/2185. Dataloading: 0.0022 s/iter. Inference: 0.0349 s/iter. Eval: 0.0385 s/iter. Total: 0.0756 s/iter. ETA=0:02:14\n",
      "\u001b[32m[07/06 04:14:23 d2.evaluation.evaluator]: \u001b[0mInference done 478/2185. Dataloading: 0.0022 s/iter. Inference: 0.0349 s/iter. Eval: 0.0384 s/iter. Total: 0.0756 s/iter. ETA=0:02:09\n",
      "\u001b[32m[07/06 04:14:29 d2.evaluation.evaluator]: \u001b[0mInference done 545/2185. Dataloading: 0.0022 s/iter. Inference: 0.0350 s/iter. Eval: 0.0384 s/iter. Total: 0.0756 s/iter. ETA=0:02:03\n",
      "\u001b[32m[07/06 04:14:34 d2.evaluation.evaluator]: \u001b[0mInference done 612/2185. Dataloading: 0.0022 s/iter. Inference: 0.0350 s/iter. Eval: 0.0383 s/iter. Total: 0.0755 s/iter. ETA=0:01:58\n",
      "\u001b[32m[07/06 04:14:39 d2.evaluation.evaluator]: \u001b[0mInference done 678/2185. Dataloading: 0.0022 s/iter. Inference: 0.0350 s/iter. Eval: 0.0383 s/iter. Total: 0.0756 s/iter. ETA=0:01:53\n",
      "\u001b[32m[07/06 04:14:44 d2.evaluation.evaluator]: \u001b[0mInference done 745/2185. Dataloading: 0.0022 s/iter. Inference: 0.0350 s/iter. Eval: 0.0383 s/iter. Total: 0.0756 s/iter. ETA=0:01:48\n",
      "\u001b[32m[07/06 04:14:49 d2.evaluation.evaluator]: \u001b[0mInference done 810/2185. Dataloading: 0.0022 s/iter. Inference: 0.0351 s/iter. Eval: 0.0383 s/iter. Total: 0.0758 s/iter. ETA=0:01:44\n",
      "\u001b[32m[07/06 04:14:54 d2.evaluation.evaluator]: \u001b[0mInference done 877/2185. Dataloading: 0.0022 s/iter. Inference: 0.0352 s/iter. Eval: 0.0382 s/iter. Total: 0.0757 s/iter. ETA=0:01:39\n",
      "\u001b[32m[07/06 04:14:59 d2.evaluation.evaluator]: \u001b[0mInference done 944/2185. Dataloading: 0.0022 s/iter. Inference: 0.0352 s/iter. Eval: 0.0382 s/iter. Total: 0.0756 s/iter. ETA=0:01:33\n",
      "\u001b[32m[07/06 04:15:04 d2.evaluation.evaluator]: \u001b[0mInference done 1011/2185. Dataloading: 0.0022 s/iter. Inference: 0.0352 s/iter. Eval: 0.0381 s/iter. Total: 0.0756 s/iter. ETA=0:01:28\n",
      "\u001b[32m[07/06 04:15:09 d2.evaluation.evaluator]: \u001b[0mInference done 1078/2185. Dataloading: 0.0022 s/iter. Inference: 0.0352 s/iter. Eval: 0.0381 s/iter. Total: 0.0756 s/iter. ETA=0:01:23\n",
      "\u001b[32m[07/06 04:15:14 d2.evaluation.evaluator]: \u001b[0mInference done 1144/2185. Dataloading: 0.0022 s/iter. Inference: 0.0352 s/iter. Eval: 0.0382 s/iter. Total: 0.0757 s/iter. ETA=0:01:18\n",
      "\u001b[32m[07/06 04:15:19 d2.evaluation.evaluator]: \u001b[0mInference done 1209/2185. Dataloading: 0.0022 s/iter. Inference: 0.0352 s/iter. Eval: 0.0383 s/iter. Total: 0.0758 s/iter. ETA=0:01:13\n",
      "\u001b[32m[07/06 04:15:24 d2.evaluation.evaluator]: \u001b[0mInference done 1272/2185. Dataloading: 0.0022 s/iter. Inference: 0.0352 s/iter. Eval: 0.0385 s/iter. Total: 0.0760 s/iter. ETA=0:01:09\n",
      "\u001b[32m[07/06 04:15:29 d2.evaluation.evaluator]: \u001b[0mInference done 1336/2185. Dataloading: 0.0022 s/iter. Inference: 0.0352 s/iter. Eval: 0.0386 s/iter. Total: 0.0762 s/iter. ETA=0:01:04\n",
      "\u001b[32m[07/06 04:15:34 d2.evaluation.evaluator]: \u001b[0mInference done 1405/2185. Dataloading: 0.0022 s/iter. Inference: 0.0352 s/iter. Eval: 0.0385 s/iter. Total: 0.0760 s/iter. ETA=0:00:59\n",
      "\u001b[32m[07/06 04:15:39 d2.evaluation.evaluator]: \u001b[0mInference done 1474/2185. Dataloading: 0.0022 s/iter. Inference: 0.0352 s/iter. Eval: 0.0383 s/iter. Total: 0.0758 s/iter. ETA=0:00:53\n",
      "\u001b[32m[07/06 04:15:44 d2.evaluation.evaluator]: \u001b[0mInference done 1542/2185. Dataloading: 0.0022 s/iter. Inference: 0.0352 s/iter. Eval: 0.0382 s/iter. Total: 0.0758 s/iter. ETA=0:00:48\n",
      "\u001b[32m[07/06 04:15:49 d2.evaluation.evaluator]: \u001b[0mInference done 1609/2185. Dataloading: 0.0022 s/iter. Inference: 0.0352 s/iter. Eval: 0.0382 s/iter. Total: 0.0757 s/iter. ETA=0:00:43\n",
      "\u001b[32m[07/06 04:15:54 d2.evaluation.evaluator]: \u001b[0mInference done 1676/2185. Dataloading: 0.0022 s/iter. Inference: 0.0353 s/iter. Eval: 0.0381 s/iter. Total: 0.0757 s/iter. ETA=0:00:38\n",
      "\u001b[32m[07/06 04:15:59 d2.evaluation.evaluator]: \u001b[0mInference done 1743/2185. Dataloading: 0.0022 s/iter. Inference: 0.0353 s/iter. Eval: 0.0381 s/iter. Total: 0.0756 s/iter. ETA=0:00:33\n",
      "\u001b[32m[07/06 04:16:04 d2.evaluation.evaluator]: \u001b[0mInference done 1810/2185. Dataloading: 0.0022 s/iter. Inference: 0.0353 s/iter. Eval: 0.0380 s/iter. Total: 0.0756 s/iter. ETA=0:00:28\n",
      "\u001b[32m[07/06 04:16:09 d2.evaluation.evaluator]: \u001b[0mInference done 1877/2185. Dataloading: 0.0022 s/iter. Inference: 0.0353 s/iter. Eval: 0.0380 s/iter. Total: 0.0756 s/iter. ETA=0:00:23\n",
      "\u001b[32m[07/06 04:16:14 d2.evaluation.evaluator]: \u001b[0mInference done 1944/2185. Dataloading: 0.0023 s/iter. Inference: 0.0353 s/iter. Eval: 0.0380 s/iter. Total: 0.0756 s/iter. ETA=0:00:18\n",
      "\u001b[32m[07/06 04:16:19 d2.evaluation.evaluator]: \u001b[0mInference done 2010/2185. Dataloading: 0.0023 s/iter. Inference: 0.0353 s/iter. Eval: 0.0380 s/iter. Total: 0.0756 s/iter. ETA=0:00:13\n",
      "\u001b[32m[07/06 04:16:24 d2.evaluation.evaluator]: \u001b[0mInference done 2074/2185. Dataloading: 0.0023 s/iter. Inference: 0.0353 s/iter. Eval: 0.0381 s/iter. Total: 0.0757 s/iter. ETA=0:00:08\n",
      "\u001b[32m[07/06 04:16:29 d2.evaluation.evaluator]: \u001b[0mInference done 2141/2185. Dataloading: 0.0023 s/iter. Inference: 0.0353 s/iter. Eval: 0.0381 s/iter. Total: 0.0757 s/iter. ETA=0:00:03\n",
      "\u001b[32m[07/06 04:16:33 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:02:45.129949 (0.075748 s / iter per device, on 1 devices)\n",
      "\u001b[32m[07/06 04:16:33 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:01:16 (0.035313 s / iter per device, on 1 devices)\n",
      "\u001b[32m[07/06 04:16:33 d2.evaluation.sem_seg_evaluation]: \u001b[0mOrderedDict([('sem_seg', {'mIoU': 43.55543738322471, 'fwIoU': 59.94481251385007, 'IoU-Unlabeled': nan, 'IoU-Building': 43.75050965825139, 'IoU-Fence': 18.42902897370798, 'IoU-Pedestrian': 10.776665064213693, 'IoU-Pole': 42.02068580663671, 'IoU-Road': 90.81603532082674, 'IoU-SideWalk': 51.55972295488177, 'IoU-Vegetation': 47.4960528416038, 'IoU-Vehicles': 56.1401638417104, 'IoU-Wall': 42.57817218610018, 'IoU-TrafficSign': 47.88356252830046, 'IoU-Sky': 37.50555183564166, 'IoU-TrafficLight': 61.093640596017536, 'IoU-Terrain': 16.7654284336874, 'IoU-ConstructionVehicle': 63.942068354045034, 'IoU-workzone_object': 64.39499797847968, 'IoU-Detour': 1.7347117574908009, 'mACC': 59.39605901708005, 'pACC': 72.71568541628771, 'ACC-Unlabeled': nan, 'ACC-Building': 96.11931273577441, 'ACC-Fence': 22.806603624188195, 'ACC-Pedestrian': 65.68462943673877, 'ACC-Pole': 48.718627904922485, 'ACC-Road': 94.26693056238736, 'ACC-SideWalk': 71.15756942011483, 'ACC-Vegetation': 53.39214465121316, 'ACC-Vehicles': 84.20418375358972, 'ACC-Wall': 49.75632542628654, 'ACC-TrafficSign': 57.95869112810037, 'ACC-Sky': 37.819319043133795, 'ACC-TrafficLight': 73.03898426246077, 'ACC-Terrain': 18.081811940872903, 'ACC-ConstructionVehicle': 92.59337214326348, 'ACC-workzone_object': 82.90883188281386, 'ACC-Detour': 1.8296063574200703})])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/06 04:16:33 d2.engine.defaults]: \u001b[0mEvaluation results for carla_both_rain_val in csv format:\n",
      "\u001b[32m[07/06 04:16:33 d2.evaluation.testing]: \u001b[0mcopypaste: Task: sem_seg\n",
      "\u001b[32m[07/06 04:16:33 d2.evaluation.testing]: \u001b[0mcopypaste: mIoU,fwIoU,mACC,pACC\n",
      "\u001b[32m[07/06 04:16:33 d2.evaluation.testing]: \u001b[0mcopypaste: 43.5554,59.9448,59.3961,72.7157\n"
     ]
    }
   ],
   "source": [
    "trainer_both = Detectron2Trainer('combined_all_night_train', 'carla_both_rain_val', output_folder='./output_both_40k')\n",
    "trainer_both.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "423d15bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/06 04:16:34 d2.engine.defaults]: \u001b[0mModel:\n",
      "SemanticSegmentor(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (sem_seg_head): SemSegFPNHead(\n",
      "    (p2): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "    )\n",
      "    (p3): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (1): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "    )\n",
      "    (p4): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (1): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      (2): Conv2d(\n",
      "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (3): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "    )\n",
      "    (p5): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (1): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      (2): Conv2d(\n",
      "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (3): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      (4): Conv2d(\n",
      "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (5): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "    )\n",
      "    (predictor): Conv2d(128, 17, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/06 04:16:34 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(720, 720), max_size=2048, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[07/06 04:16:34 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[07/06 04:16:34 d2.data.common]: \u001b[0mSerializing 4560 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[07/06 04:16:34 d2.data.common]: \u001b[0mSerialized dataset takes 1.68 MiB\n",
      "Last checkpoint: model_final.pth\n",
      "\u001b[32m[07/06 04:16:34 d2.checkpoint.c2_model_loading]: \u001b[0mFollowing weights matched with model:\n",
      "| Names in Model                       | Names in Checkpoint                                                                                  | Shapes                                          |\n",
      "|:-------------------------------------|:-----------------------------------------------------------------------------------------------------|:------------------------------------------------|\n",
      "| backbone.bottom_up.res2.0.conv1.*    | backbone.bottom_up.res2.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,1,1)             |\n",
      "| backbone.bottom_up.res2.0.conv2.*    | backbone.bottom_up.res2.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |\n",
      "| backbone.bottom_up.res2.0.conv3.*    | backbone.bottom_up.res2.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res2.0.shortcut.* | backbone.bottom_up.res2.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res2.1.conv1.*    | backbone.bottom_up.res2.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |\n",
      "| backbone.bottom_up.res2.1.conv2.*    | backbone.bottom_up.res2.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |\n",
      "| backbone.bottom_up.res2.1.conv3.*    | backbone.bottom_up.res2.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res2.2.conv1.*    | backbone.bottom_up.res2.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |\n",
      "| backbone.bottom_up.res2.2.conv2.*    | backbone.bottom_up.res2.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |\n",
      "| backbone.bottom_up.res2.2.conv3.*    | backbone.bottom_up.res2.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res3.0.conv1.*    | backbone.bottom_up.res3.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,256,1,1)       |\n",
      "| backbone.bottom_up.res3.0.conv2.*    | backbone.bottom_up.res3.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.0.conv3.*    | backbone.bottom_up.res3.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res3.0.shortcut.* | backbone.bottom_up.res3.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (512,) (512,) (512,) (512,) (512,256,1,1)       |\n",
      "| backbone.bottom_up.res3.1.conv1.*    | backbone.bottom_up.res3.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |\n",
      "| backbone.bottom_up.res3.1.conv2.*    | backbone.bottom_up.res3.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.1.conv3.*    | backbone.bottom_up.res3.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res3.2.conv1.*    | backbone.bottom_up.res3.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |\n",
      "| backbone.bottom_up.res3.2.conv2.*    | backbone.bottom_up.res3.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.2.conv3.*    | backbone.bottom_up.res3.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res3.3.conv1.*    | backbone.bottom_up.res3.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |\n",
      "| backbone.bottom_up.res3.3.conv2.*    | backbone.bottom_up.res3.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.3.conv3.*    | backbone.bottom_up.res3.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res4.0.conv1.*    | backbone.bottom_up.res4.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,512,1,1)       |\n",
      "| backbone.bottom_up.res4.0.conv2.*    | backbone.bottom_up.res4.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.0.conv3.*    | backbone.bottom_up.res4.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.0.shortcut.* | backbone.bottom_up.res4.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (1024,) (1024,) (1024,) (1024,) (1024,512,1,1)  |\n",
      "| backbone.bottom_up.res4.1.conv1.*    | backbone.bottom_up.res4.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.1.conv2.*    | backbone.bottom_up.res4.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.1.conv3.*    | backbone.bottom_up.res4.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.2.conv1.*    | backbone.bottom_up.res4.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.2.conv2.*    | backbone.bottom_up.res4.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.2.conv3.*    | backbone.bottom_up.res4.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.3.conv1.*    | backbone.bottom_up.res4.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.3.conv2.*    | backbone.bottom_up.res4.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.3.conv3.*    | backbone.bottom_up.res4.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.4.conv1.*    | backbone.bottom_up.res4.4.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.4.conv2.*    | backbone.bottom_up.res4.4.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.4.conv3.*    | backbone.bottom_up.res4.4.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.5.conv1.*    | backbone.bottom_up.res4.5.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.5.conv2.*    | backbone.bottom_up.res4.5.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.5.conv3.*    | backbone.bottom_up.res4.5.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res5.0.conv1.*    | backbone.bottom_up.res5.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,1024,1,1)      |\n",
      "| backbone.bottom_up.res5.0.conv2.*    | backbone.bottom_up.res5.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |\n",
      "| backbone.bottom_up.res5.0.conv3.*    | backbone.bottom_up.res5.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
      "| backbone.bottom_up.res5.0.shortcut.* | backbone.bottom_up.res5.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (2048,) (2048,) (2048,) (2048,) (2048,1024,1,1) |\n",
      "| backbone.bottom_up.res5.1.conv1.*    | backbone.bottom_up.res5.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |\n",
      "| backbone.bottom_up.res5.1.conv2.*    | backbone.bottom_up.res5.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |\n",
      "| backbone.bottom_up.res5.1.conv3.*    | backbone.bottom_up.res5.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
      "| backbone.bottom_up.res5.2.conv1.*    | backbone.bottom_up.res5.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |\n",
      "| backbone.bottom_up.res5.2.conv2.*    | backbone.bottom_up.res5.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |\n",
      "| backbone.bottom_up.res5.2.conv3.*    | backbone.bottom_up.res5.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
      "| backbone.bottom_up.stem.conv1.*      | backbone.bottom_up.stem.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}      | (64,) (64,) (64,) (64,) (64,3,7,7)              |\n",
      "| backbone.fpn_lateral2.*              | backbone.fpn_lateral2.{bias,weight}                                                                  | (256,) (256,256,1,1)                            |\n",
      "| backbone.fpn_lateral3.*              | backbone.fpn_lateral3.{bias,weight}                                                                  | (256,) (256,512,1,1)                            |\n",
      "| backbone.fpn_lateral4.*              | backbone.fpn_lateral4.{bias,weight}                                                                  | (256,) (256,1024,1,1)                           |\n",
      "| backbone.fpn_lateral5.*              | backbone.fpn_lateral5.{bias,weight}                                                                  | (256,) (256,2048,1,1)                           |\n",
      "| backbone.fpn_output2.*               | backbone.fpn_output2.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| backbone.fpn_output3.*               | backbone.fpn_output3.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| backbone.fpn_output4.*               | backbone.fpn_output4.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| backbone.fpn_output5.*               | backbone.fpn_output5.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| sem_seg_head.p2.0.*                  | sem_seg_head.p2.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p3.0.*                  | sem_seg_head.p3.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p4.0.*                  | sem_seg_head.p4.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p4.2.*                  | sem_seg_head.p4.2.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,128,3,3)                     |\n",
      "| sem_seg_head.p5.0.*                  | sem_seg_head.p5.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p5.2.*                  | sem_seg_head.p5.2.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,128,3,3)                     |\n",
      "| sem_seg_head.p5.4.*                  | sem_seg_head.p5.4.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,128,3,3)                     |\n",
      "| sem_seg_head.predictor.*             | sem_seg_head.predictor.{bias,weight}                                                                 | (17,) (17,128,1,1)                              |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/06 04:16:34 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(720, 720), max_size=2048, sample_style='choice')]\n",
      "\u001b[32m[07/06 04:16:34 d2.data.common]: \u001b[0mSerializing 699 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[07/06 04:16:34 d2.data.common]: \u001b[0mSerialized dataset takes 0.24 MiB\n",
      "\u001b[32m[07/06 04:16:34 d2.evaluation.evaluator]: \u001b[0mStart inference on 699 batches\n",
      "\u001b[32m[07/06 04:16:37 d2.evaluation.evaluator]: \u001b[0mInference done 11/699. Dataloading: 0.0018 s/iter. Inference: 0.0470 s/iter. Eval: 0.1572 s/iter. Total: 0.2060 s/iter. ETA=0:02:21\n",
      "\u001b[32m[07/06 04:16:42 d2.evaluation.evaluator]: \u001b[0mInference done 37/699. Dataloading: 0.0020 s/iter. Inference: 0.0469 s/iter. Eval: 0.1525 s/iter. Total: 0.2015 s/iter. ETA=0:02:13\n",
      "\u001b[32m[07/06 04:16:47 d2.evaluation.evaluator]: \u001b[0mInference done 63/699. Dataloading: 0.0021 s/iter. Inference: 0.0469 s/iter. Eval: 0.1517 s/iter. Total: 0.2007 s/iter. ETA=0:02:07\n",
      "\u001b[32m[07/06 04:16:52 d2.evaluation.evaluator]: \u001b[0mInference done 89/699. Dataloading: 0.0021 s/iter. Inference: 0.0468 s/iter. Eval: 0.1500 s/iter. Total: 0.1991 s/iter. ETA=0:02:01\n",
      "\u001b[32m[07/06 04:16:57 d2.evaluation.evaluator]: \u001b[0mInference done 115/699. Dataloading: 0.0021 s/iter. Inference: 0.0468 s/iter. Eval: 0.1489 s/iter. Total: 0.1979 s/iter. ETA=0:01:55\n",
      "\u001b[32m[07/06 04:17:02 d2.evaluation.evaluator]: \u001b[0mInference done 142/699. Dataloading: 0.0021 s/iter. Inference: 0.0468 s/iter. Eval: 0.1475 s/iter. Total: 0.1965 s/iter. ETA=0:01:49\n",
      "\u001b[32m[07/06 04:17:07 d2.evaluation.evaluator]: \u001b[0mInference done 168/699. Dataloading: 0.0021 s/iter. Inference: 0.0468 s/iter. Eval: 0.1470 s/iter. Total: 0.1960 s/iter. ETA=0:01:44\n",
      "\u001b[32m[07/06 04:17:13 d2.evaluation.evaluator]: \u001b[0mInference done 193/699. Dataloading: 0.0021 s/iter. Inference: 0.0468 s/iter. Eval: 0.1485 s/iter. Total: 0.1974 s/iter. ETA=0:01:39\n",
      "\u001b[32m[07/06 04:17:18 d2.evaluation.evaluator]: \u001b[0mInference done 218/699. Dataloading: 0.0021 s/iter. Inference: 0.0468 s/iter. Eval: 0.1493 s/iter. Total: 0.1983 s/iter. ETA=0:01:35\n",
      "\u001b[32m[07/06 04:17:23 d2.evaluation.evaluator]: \u001b[0mInference done 243/699. Dataloading: 0.0021 s/iter. Inference: 0.0468 s/iter. Eval: 0.1499 s/iter. Total: 0.1989 s/iter. ETA=0:01:30\n",
      "\u001b[32m[07/06 04:17:28 d2.evaluation.evaluator]: \u001b[0mInference done 268/699. Dataloading: 0.0021 s/iter. Inference: 0.0468 s/iter. Eval: 0.1501 s/iter. Total: 0.1991 s/iter. ETA=0:01:25\n",
      "\u001b[32m[07/06 04:17:33 d2.evaluation.evaluator]: \u001b[0mInference done 293/699. Dataloading: 0.0021 s/iter. Inference: 0.0468 s/iter. Eval: 0.1502 s/iter. Total: 0.1992 s/iter. ETA=0:01:20\n",
      "\u001b[32m[07/06 04:17:38 d2.evaluation.evaluator]: \u001b[0mInference done 318/699. Dataloading: 0.0021 s/iter. Inference: 0.0468 s/iter. Eval: 0.1506 s/iter. Total: 0.1996 s/iter. ETA=0:01:16\n",
      "\u001b[32m[07/06 04:17:43 d2.evaluation.evaluator]: \u001b[0mInference done 343/699. Dataloading: 0.0021 s/iter. Inference: 0.0468 s/iter. Eval: 0.1511 s/iter. Total: 0.2001 s/iter. ETA=0:01:11\n",
      "\u001b[32m[07/06 04:17:48 d2.evaluation.evaluator]: \u001b[0mInference done 368/699. Dataloading: 0.0021 s/iter. Inference: 0.0468 s/iter. Eval: 0.1512 s/iter. Total: 0.2002 s/iter. ETA=0:01:06\n",
      "\u001b[32m[07/06 04:17:53 d2.evaluation.evaluator]: \u001b[0mInference done 393/699. Dataloading: 0.0021 s/iter. Inference: 0.0468 s/iter. Eval: 0.1515 s/iter. Total: 0.2005 s/iter. ETA=0:01:01\n",
      "\u001b[32m[07/06 04:17:58 d2.evaluation.evaluator]: \u001b[0mInference done 419/699. Dataloading: 0.0021 s/iter. Inference: 0.0468 s/iter. Eval: 0.1514 s/iter. Total: 0.2004 s/iter. ETA=0:00:56\n",
      "\u001b[32m[07/06 04:18:03 d2.evaluation.evaluator]: \u001b[0mInference done 444/699. Dataloading: 0.0021 s/iter. Inference: 0.0468 s/iter. Eval: 0.1514 s/iter. Total: 0.2004 s/iter. ETA=0:00:51\n",
      "\u001b[32m[07/06 04:18:09 d2.evaluation.evaluator]: \u001b[0mInference done 470/699. Dataloading: 0.0021 s/iter. Inference: 0.0468 s/iter. Eval: 0.1512 s/iter. Total: 0.2002 s/iter. ETA=0:00:45\n",
      "\u001b[32m[07/06 04:18:14 d2.evaluation.evaluator]: \u001b[0mInference done 495/699. Dataloading: 0.0021 s/iter. Inference: 0.0468 s/iter. Eval: 0.1513 s/iter. Total: 0.2003 s/iter. ETA=0:00:40\n",
      "\u001b[32m[07/06 04:18:19 d2.evaluation.evaluator]: \u001b[0mInference done 521/699. Dataloading: 0.0021 s/iter. Inference: 0.0468 s/iter. Eval: 0.1512 s/iter. Total: 0.2002 s/iter. ETA=0:00:35\n",
      "\u001b[32m[07/06 04:18:24 d2.evaluation.evaluator]: \u001b[0mInference done 547/699. Dataloading: 0.0021 s/iter. Inference: 0.0468 s/iter. Eval: 0.1512 s/iter. Total: 0.2002 s/iter. ETA=0:00:30\n",
      "\u001b[32m[07/06 04:18:29 d2.evaluation.evaluator]: \u001b[0mInference done 572/699. Dataloading: 0.0021 s/iter. Inference: 0.0468 s/iter. Eval: 0.1512 s/iter. Total: 0.2002 s/iter. ETA=0:00:25\n",
      "\u001b[32m[07/06 04:18:34 d2.evaluation.evaluator]: \u001b[0mInference done 597/699. Dataloading: 0.0021 s/iter. Inference: 0.0468 s/iter. Eval: 0.1513 s/iter. Total: 0.2003 s/iter. ETA=0:00:20\n",
      "\u001b[32m[07/06 04:18:39 d2.evaluation.evaluator]: \u001b[0mInference done 622/699. Dataloading: 0.0021 s/iter. Inference: 0.0468 s/iter. Eval: 0.1515 s/iter. Total: 0.2005 s/iter. ETA=0:00:15\n",
      "\u001b[32m[07/06 04:18:44 d2.evaluation.evaluator]: \u001b[0mInference done 648/699. Dataloading: 0.0021 s/iter. Inference: 0.0468 s/iter. Eval: 0.1514 s/iter. Total: 0.2004 s/iter. ETA=0:00:10\n",
      "\u001b[32m[07/06 04:18:49 d2.evaluation.evaluator]: \u001b[0mInference done 674/699. Dataloading: 0.0021 s/iter. Inference: 0.0468 s/iter. Eval: 0.1512 s/iter. Total: 0.2002 s/iter. ETA=0:00:05\n",
      "\u001b[32m[07/06 04:18:54 d2.evaluation.evaluator]: \u001b[0mInference done 699/699. Dataloading: 0.0021 s/iter. Inference: 0.0468 s/iter. Eval: 0.1513 s/iter. Total: 0.2003 s/iter. ETA=0:00:00\n",
      "\u001b[32m[07/06 04:18:55 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:02:19.101384 (0.200434 s / iter per device, on 1 devices)\n",
      "\u001b[32m[07/06 04:18:55 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:32 (0.046802 s / iter per device, on 1 devices)\n",
      "\u001b[32m[07/06 04:18:55 d2.evaluation.sem_seg_evaluation]: \u001b[0mOrderedDict([('sem_seg', {'mIoU': 60.814583340002336, 'fwIoU': 85.7080407726317, 'IoU-Unlabeled': nan, 'IoU-Building': 84.64569442435425, 'IoU-Fence': 41.43642452181284, 'IoU-Pedestrian': 68.54623225225644, 'IoU-Pole': 45.53918879356494, 'IoU-Road': 94.56329019863429, 'IoU-SideWalk': 72.24931235346288, 'IoU-Vegetation': 84.85526470473711, 'IoU-Vehicles': 87.19719431156746, 'IoU-Wall': 36.395339292655564, 'IoU-TrafficSign': 57.54211674823323, 'IoU-Sky': 83.90153382213192, 'IoU-TrafficLight': 45.47961201395894, 'IoU-Terrain': 49.052963322662976, 'IoU-ConstructionVehicle': nan, 'IoU-workzone_object': nan, 'IoU-Detour': nan, 'mACC': 75.55976652147038, 'pACC': 91.87851104228275, 'ACC-Unlabeled': nan, 'ACC-Building': 95.74043518630991, 'ACC-Fence': 50.29579401559619, 'ACC-Pedestrian': 86.4713398311357, 'ACC-Pole': 57.901690789425764, 'ACC-Road': 96.46353601076152, 'ACC-SideWalk': 83.30676791960431, 'ACC-Vegetation': 90.02312350233422, 'ACC-Vehicles': 92.18016291389887, 'ACC-Wall': 52.419601907697086, 'ACC-TrafficSign': 63.625967699023, 'ACC-Sky': 86.43663592647061, 'ACC-TrafficLight': 51.766384933973264, 'ACC-Terrain': 75.64552414288453, 'ACC-ConstructionVehicle': nan, 'ACC-workzone_object': nan, 'ACC-Detour': nan})])\n",
      "\u001b[32m[07/06 04:18:55 d2.engine.defaults]: \u001b[0mEvaluation results for cityscapes_rain_val in csv format:\n",
      "\u001b[32m[07/06 04:18:55 d2.evaluation.testing]: \u001b[0mcopypaste: Task: sem_seg\n",
      "\u001b[32m[07/06 04:18:55 d2.evaluation.testing]: \u001b[0mcopypaste: mIoU,fwIoU,mACC,pACC\n",
      "\u001b[32m[07/06 04:18:55 d2.evaluation.testing]: \u001b[0mcopypaste: 60.8146,85.7080,75.5598,91.8785\n"
     ]
    }
   ],
   "source": [
    "trainer_both = Detectron2Trainer('combined_all_night_train', 'cityscapes_rain_val', output_folder='./output_both_40k')\n",
    "trainer_both.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "23f0ec79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/06 04:18:55 d2.engine.defaults]: \u001b[0mModel:\n",
      "SemanticSegmentor(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (sem_seg_head): SemSegFPNHead(\n",
      "    (p2): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "    )\n",
      "    (p3): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (1): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "    )\n",
      "    (p4): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (1): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      (2): Conv2d(\n",
      "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (3): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "    )\n",
      "    (p5): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (1): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      (2): Conv2d(\n",
      "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (3): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      (4): Conv2d(\n",
      "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (5): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "    )\n",
      "    (predictor): Conv2d(128, 17, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/06 04:18:55 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(720, 720), max_size=2048, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[07/06 04:18:55 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[07/06 04:18:55 d2.data.common]: \u001b[0mSerializing 4560 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[07/06 04:18:55 d2.data.common]: \u001b[0mSerialized dataset takes 1.68 MiB\n",
      "Last checkpoint: model_final.pth\n",
      "\u001b[32m[07/06 04:18:56 d2.checkpoint.c2_model_loading]: \u001b[0mFollowing weights matched with model:\n",
      "| Names in Model                       | Names in Checkpoint                                                                                  | Shapes                                          |\n",
      "|:-------------------------------------|:-----------------------------------------------------------------------------------------------------|:------------------------------------------------|\n",
      "| backbone.bottom_up.res2.0.conv1.*    | backbone.bottom_up.res2.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,1,1)             |\n",
      "| backbone.bottom_up.res2.0.conv2.*    | backbone.bottom_up.res2.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |\n",
      "| backbone.bottom_up.res2.0.conv3.*    | backbone.bottom_up.res2.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res2.0.shortcut.* | backbone.bottom_up.res2.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res2.1.conv1.*    | backbone.bottom_up.res2.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |\n",
      "| backbone.bottom_up.res2.1.conv2.*    | backbone.bottom_up.res2.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |\n",
      "| backbone.bottom_up.res2.1.conv3.*    | backbone.bottom_up.res2.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res2.2.conv1.*    | backbone.bottom_up.res2.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |\n",
      "| backbone.bottom_up.res2.2.conv2.*    | backbone.bottom_up.res2.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |\n",
      "| backbone.bottom_up.res2.2.conv3.*    | backbone.bottom_up.res2.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res3.0.conv1.*    | backbone.bottom_up.res3.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,256,1,1)       |\n",
      "| backbone.bottom_up.res3.0.conv2.*    | backbone.bottom_up.res3.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.0.conv3.*    | backbone.bottom_up.res3.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res3.0.shortcut.* | backbone.bottom_up.res3.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (512,) (512,) (512,) (512,) (512,256,1,1)       |\n",
      "| backbone.bottom_up.res3.1.conv1.*    | backbone.bottom_up.res3.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |\n",
      "| backbone.bottom_up.res3.1.conv2.*    | backbone.bottom_up.res3.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.1.conv3.*    | backbone.bottom_up.res3.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res3.2.conv1.*    | backbone.bottom_up.res3.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |\n",
      "| backbone.bottom_up.res3.2.conv2.*    | backbone.bottom_up.res3.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.2.conv3.*    | backbone.bottom_up.res3.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res3.3.conv1.*    | backbone.bottom_up.res3.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |\n",
      "| backbone.bottom_up.res3.3.conv2.*    | backbone.bottom_up.res3.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.3.conv3.*    | backbone.bottom_up.res3.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res4.0.conv1.*    | backbone.bottom_up.res4.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,512,1,1)       |\n",
      "| backbone.bottom_up.res4.0.conv2.*    | backbone.bottom_up.res4.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.0.conv3.*    | backbone.bottom_up.res4.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.0.shortcut.* | backbone.bottom_up.res4.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (1024,) (1024,) (1024,) (1024,) (1024,512,1,1)  |\n",
      "| backbone.bottom_up.res4.1.conv1.*    | backbone.bottom_up.res4.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.1.conv2.*    | backbone.bottom_up.res4.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.1.conv3.*    | backbone.bottom_up.res4.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.2.conv1.*    | backbone.bottom_up.res4.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.2.conv2.*    | backbone.bottom_up.res4.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.2.conv3.*    | backbone.bottom_up.res4.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.3.conv1.*    | backbone.bottom_up.res4.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.3.conv2.*    | backbone.bottom_up.res4.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.3.conv3.*    | backbone.bottom_up.res4.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.4.conv1.*    | backbone.bottom_up.res4.4.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.4.conv2.*    | backbone.bottom_up.res4.4.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.4.conv3.*    | backbone.bottom_up.res4.4.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.5.conv1.*    | backbone.bottom_up.res4.5.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.5.conv2.*    | backbone.bottom_up.res4.5.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.5.conv3.*    | backbone.bottom_up.res4.5.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res5.0.conv1.*    | backbone.bottom_up.res5.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,1024,1,1)      |\n",
      "| backbone.bottom_up.res5.0.conv2.*    | backbone.bottom_up.res5.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |\n",
      "| backbone.bottom_up.res5.0.conv3.*    | backbone.bottom_up.res5.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
      "| backbone.bottom_up.res5.0.shortcut.* | backbone.bottom_up.res5.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (2048,) (2048,) (2048,) (2048,) (2048,1024,1,1) |\n",
      "| backbone.bottom_up.res5.1.conv1.*    | backbone.bottom_up.res5.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |\n",
      "| backbone.bottom_up.res5.1.conv2.*    | backbone.bottom_up.res5.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |\n",
      "| backbone.bottom_up.res5.1.conv3.*    | backbone.bottom_up.res5.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
      "| backbone.bottom_up.res5.2.conv1.*    | backbone.bottom_up.res5.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |\n",
      "| backbone.bottom_up.res5.2.conv2.*    | backbone.bottom_up.res5.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |\n",
      "| backbone.bottom_up.res5.2.conv3.*    | backbone.bottom_up.res5.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
      "| backbone.bottom_up.stem.conv1.*      | backbone.bottom_up.stem.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}      | (64,) (64,) (64,) (64,) (64,3,7,7)              |\n",
      "| backbone.fpn_lateral2.*              | backbone.fpn_lateral2.{bias,weight}                                                                  | (256,) (256,256,1,1)                            |\n",
      "| backbone.fpn_lateral3.*              | backbone.fpn_lateral3.{bias,weight}                                                                  | (256,) (256,512,1,1)                            |\n",
      "| backbone.fpn_lateral4.*              | backbone.fpn_lateral4.{bias,weight}                                                                  | (256,) (256,1024,1,1)                           |\n",
      "| backbone.fpn_lateral5.*              | backbone.fpn_lateral5.{bias,weight}                                                                  | (256,) (256,2048,1,1)                           |\n",
      "| backbone.fpn_output2.*               | backbone.fpn_output2.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| backbone.fpn_output3.*               | backbone.fpn_output3.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| backbone.fpn_output4.*               | backbone.fpn_output4.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| backbone.fpn_output5.*               | backbone.fpn_output5.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| sem_seg_head.p2.0.*                  | sem_seg_head.p2.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p3.0.*                  | sem_seg_head.p3.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p4.0.*                  | sem_seg_head.p4.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p4.2.*                  | sem_seg_head.p4.2.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,128,3,3)                     |\n",
      "| sem_seg_head.p5.0.*                  | sem_seg_head.p5.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p5.2.*                  | sem_seg_head.p5.2.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,128,3,3)                     |\n",
      "| sem_seg_head.p5.4.*                  | sem_seg_head.p5.4.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,128,3,3)                     |\n",
      "| sem_seg_head.predictor.*             | sem_seg_head.predictor.{bias,weight}                                                                 | (17,) (17,128,1,1)                              |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/06 04:18:56 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(720, 720), max_size=2048, sample_style='choice')]\n",
      "\u001b[32m[07/06 04:18:56 d2.data.common]: \u001b[0mSerializing 2884 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[07/06 04:18:56 d2.data.common]: \u001b[0mSerialized dataset takes 1.05 MiB\n",
      "\u001b[32m[07/06 04:18:56 d2.evaluation.evaluator]: \u001b[0mStart inference on 2884 batches\n",
      "\u001b[32m[07/06 04:18:59 d2.evaluation.evaluator]: \u001b[0mInference done 45/2884. Dataloading: 0.0021 s/iter. Inference: 0.0353 s/iter. Eval: 0.0401 s/iter. Total: 0.0775 s/iter. ETA=0:03:40\n",
      "\u001b[32m[07/06 04:19:05 d2.evaluation.evaluator]: \u001b[0mInference done 111/2884. Dataloading: 0.0022 s/iter. Inference: 0.0352 s/iter. Eval: 0.0394 s/iter. Total: 0.0768 s/iter. ETA=0:03:33\n",
      "\u001b[32m[07/06 04:19:10 d2.evaluation.evaluator]: \u001b[0mInference done 177/2884. Dataloading: 0.0022 s/iter. Inference: 0.0352 s/iter. Eval: 0.0390 s/iter. Total: 0.0765 s/iter. ETA=0:03:27\n",
      "\u001b[32m[07/06 04:19:15 d2.evaluation.evaluator]: \u001b[0mInference done 243/2884. Dataloading: 0.0022 s/iter. Inference: 0.0352 s/iter. Eval: 0.0390 s/iter. Total: 0.0765 s/iter. ETA=0:03:22\n",
      "\u001b[32m[07/06 04:19:20 d2.evaluation.evaluator]: \u001b[0mInference done 308/2884. Dataloading: 0.0022 s/iter. Inference: 0.0352 s/iter. Eval: 0.0391 s/iter. Total: 0.0766 s/iter. ETA=0:03:17\n",
      "\u001b[32m[07/06 04:19:25 d2.evaluation.evaluator]: \u001b[0mInference done 373/2884. Dataloading: 0.0022 s/iter. Inference: 0.0353 s/iter. Eval: 0.0393 s/iter. Total: 0.0768 s/iter. ETA=0:03:12\n",
      "\u001b[32m[07/06 04:19:30 d2.evaluation.evaluator]: \u001b[0mInference done 438/2884. Dataloading: 0.0022 s/iter. Inference: 0.0353 s/iter. Eval: 0.0394 s/iter. Total: 0.0769 s/iter. ETA=0:03:08\n",
      "\u001b[32m[07/06 04:19:35 d2.evaluation.evaluator]: \u001b[0mInference done 505/2884. Dataloading: 0.0022 s/iter. Inference: 0.0353 s/iter. Eval: 0.0391 s/iter. Total: 0.0767 s/iter. ETA=0:03:02\n",
      "\u001b[32m[07/06 04:19:40 d2.evaluation.evaluator]: \u001b[0mInference done 571/2884. Dataloading: 0.0022 s/iter. Inference: 0.0353 s/iter. Eval: 0.0390 s/iter. Total: 0.0766 s/iter. ETA=0:02:57\n",
      "\u001b[32m[07/06 04:19:45 d2.evaluation.evaluator]: \u001b[0mInference done 637/2884. Dataloading: 0.0022 s/iter. Inference: 0.0353 s/iter. Eval: 0.0390 s/iter. Total: 0.0766 s/iter. ETA=0:02:52\n",
      "\u001b[32m[07/06 04:19:50 d2.evaluation.evaluator]: \u001b[0mInference done 704/2884. Dataloading: 0.0022 s/iter. Inference: 0.0353 s/iter. Eval: 0.0388 s/iter. Total: 0.0765 s/iter. ETA=0:02:46\n",
      "\u001b[32m[07/06 04:19:55 d2.evaluation.evaluator]: \u001b[0mInference done 770/2884. Dataloading: 0.0022 s/iter. Inference: 0.0353 s/iter. Eval: 0.0388 s/iter. Total: 0.0764 s/iter. ETA=0:02:41\n",
      "\u001b[32m[07/06 04:20:00 d2.evaluation.evaluator]: \u001b[0mInference done 837/2884. Dataloading: 0.0022 s/iter. Inference: 0.0353 s/iter. Eval: 0.0387 s/iter. Total: 0.0763 s/iter. ETA=0:02:36\n",
      "\u001b[32m[07/06 04:20:05 d2.evaluation.evaluator]: \u001b[0mInference done 904/2884. Dataloading: 0.0022 s/iter. Inference: 0.0353 s/iter. Eval: 0.0386 s/iter. Total: 0.0762 s/iter. ETA=0:02:30\n",
      "\u001b[32m[07/06 04:20:10 d2.evaluation.evaluator]: \u001b[0mInference done 971/2884. Dataloading: 0.0022 s/iter. Inference: 0.0354 s/iter. Eval: 0.0385 s/iter. Total: 0.0762 s/iter. ETA=0:02:25\n",
      "\u001b[32m[07/06 04:20:15 d2.evaluation.evaluator]: \u001b[0mInference done 1038/2884. Dataloading: 0.0022 s/iter. Inference: 0.0354 s/iter. Eval: 0.0384 s/iter. Total: 0.0761 s/iter. ETA=0:02:20\n",
      "\u001b[32m[07/06 04:20:20 d2.evaluation.evaluator]: \u001b[0mInference done 1105/2884. Dataloading: 0.0023 s/iter. Inference: 0.0354 s/iter. Eval: 0.0383 s/iter. Total: 0.0760 s/iter. ETA=0:02:15\n",
      "\u001b[32m[07/06 04:20:25 d2.evaluation.evaluator]: \u001b[0mInference done 1172/2884. Dataloading: 0.0023 s/iter. Inference: 0.0354 s/iter. Eval: 0.0383 s/iter. Total: 0.0760 s/iter. ETA=0:02:10\n",
      "\u001b[32m[07/06 04:20:30 d2.evaluation.evaluator]: \u001b[0mInference done 1236/2884. Dataloading: 0.0023 s/iter. Inference: 0.0354 s/iter. Eval: 0.0384 s/iter. Total: 0.0761 s/iter. ETA=0:02:05\n",
      "\u001b[32m[07/06 04:20:35 d2.evaluation.evaluator]: \u001b[0mInference done 1301/2884. Dataloading: 0.0023 s/iter. Inference: 0.0354 s/iter. Eval: 0.0384 s/iter. Total: 0.0762 s/iter. ETA=0:02:00\n",
      "\u001b[32m[07/06 04:20:40 d2.evaluation.evaluator]: \u001b[0mInference done 1367/2884. Dataloading: 0.0023 s/iter. Inference: 0.0354 s/iter. Eval: 0.0384 s/iter. Total: 0.0762 s/iter. ETA=0:01:55\n",
      "\u001b[32m[07/06 04:20:45 d2.evaluation.evaluator]: \u001b[0mInference done 1436/2884. Dataloading: 0.0023 s/iter. Inference: 0.0354 s/iter. Eval: 0.0383 s/iter. Total: 0.0760 s/iter. ETA=0:01:50\n",
      "\u001b[32m[07/06 04:20:50 d2.evaluation.evaluator]: \u001b[0mInference done 1504/2884. Dataloading: 0.0023 s/iter. Inference: 0.0354 s/iter. Eval: 0.0382 s/iter. Total: 0.0759 s/iter. ETA=0:01:44\n",
      "\u001b[32m[07/06 04:20:55 d2.evaluation.evaluator]: \u001b[0mInference done 1571/2884. Dataloading: 0.0023 s/iter. Inference: 0.0354 s/iter. Eval: 0.0381 s/iter. Total: 0.0759 s/iter. ETA=0:01:39\n",
      "\u001b[32m[07/06 04:21:00 d2.evaluation.evaluator]: \u001b[0mInference done 1639/2884. Dataloading: 0.0023 s/iter. Inference: 0.0354 s/iter. Eval: 0.0381 s/iter. Total: 0.0758 s/iter. ETA=0:01:34\n",
      "\u001b[32m[07/06 04:21:05 d2.evaluation.evaluator]: \u001b[0mInference done 1707/2884. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0380 s/iter. Total: 0.0758 s/iter. ETA=0:01:29\n",
      "\u001b[32m[07/06 04:21:10 d2.evaluation.evaluator]: \u001b[0mInference done 1775/2884. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0379 s/iter. Total: 0.0757 s/iter. ETA=0:01:23\n",
      "\u001b[32m[07/06 04:21:15 d2.evaluation.evaluator]: \u001b[0mInference done 1843/2884. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0378 s/iter. Total: 0.0756 s/iter. ETA=0:01:18\n",
      "\u001b[32m[07/06 04:21:20 d2.evaluation.evaluator]: \u001b[0mInference done 1910/2884. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0378 s/iter. Total: 0.0756 s/iter. ETA=0:01:13\n",
      "\u001b[32m[07/06 04:21:25 d2.evaluation.evaluator]: \u001b[0mInference done 1977/2884. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0378 s/iter. Total: 0.0756 s/iter. ETA=0:01:08\n",
      "\u001b[32m[07/06 04:21:31 d2.evaluation.evaluator]: \u001b[0mInference done 2044/2884. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0378 s/iter. Total: 0.0756 s/iter. ETA=0:01:03\n",
      "\u001b[32m[07/06 04:21:36 d2.evaluation.evaluator]: \u001b[0mInference done 2111/2884. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0377 s/iter. Total: 0.0756 s/iter. ETA=0:00:58\n",
      "\u001b[32m[07/06 04:21:41 d2.evaluation.evaluator]: \u001b[0mInference done 2179/2884. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0377 s/iter. Total: 0.0755 s/iter. ETA=0:00:53\n",
      "\u001b[32m[07/06 04:21:46 d2.evaluation.evaluator]: \u001b[0mInference done 2209/2884. Dataloading: 0.0023 s/iter. Inference: 0.0356 s/iter. Eval: 0.0389 s/iter. Total: 0.0768 s/iter. ETA=0:00:51\n",
      "\u001b[32m[07/06 04:21:51 d2.evaluation.evaluator]: \u001b[0mInference done 2235/2884. Dataloading: 0.0023 s/iter. Inference: 0.0357 s/iter. Eval: 0.0402 s/iter. Total: 0.0782 s/iter. ETA=0:00:50\n",
      "\u001b[32m[07/06 04:21:56 d2.evaluation.evaluator]: \u001b[0mInference done 2261/2884. Dataloading: 0.0023 s/iter. Inference: 0.0358 s/iter. Eval: 0.0414 s/iter. Total: 0.0796 s/iter. ETA=0:00:49\n",
      "\u001b[32m[07/06 04:22:01 d2.evaluation.evaluator]: \u001b[0mInference done 2287/2884. Dataloading: 0.0023 s/iter. Inference: 0.0360 s/iter. Eval: 0.0426 s/iter. Total: 0.0809 s/iter. ETA=0:00:48\n",
      "\u001b[32m[07/06 04:22:06 d2.evaluation.evaluator]: \u001b[0mInference done 2314/2884. Dataloading: 0.0023 s/iter. Inference: 0.0361 s/iter. Eval: 0.0438 s/iter. Total: 0.0822 s/iter. ETA=0:00:46\n",
      "\u001b[32m[07/06 04:22:11 d2.evaluation.evaluator]: \u001b[0mInference done 2341/2884. Dataloading: 0.0022 s/iter. Inference: 0.0362 s/iter. Eval: 0.0449 s/iter. Total: 0.0834 s/iter. ETA=0:00:45\n",
      "\u001b[32m[07/06 04:22:16 d2.evaluation.evaluator]: \u001b[0mInference done 2366/2884. Dataloading: 0.0022 s/iter. Inference: 0.0363 s/iter. Eval: 0.0461 s/iter. Total: 0.0847 s/iter. ETA=0:00:43\n",
      "\u001b[32m[07/06 04:22:21 d2.evaluation.evaluator]: \u001b[0mInference done 2391/2884. Dataloading: 0.0022 s/iter. Inference: 0.0364 s/iter. Eval: 0.0472 s/iter. Total: 0.0860 s/iter. ETA=0:00:42\n",
      "\u001b[32m[07/06 04:22:27 d2.evaluation.evaluator]: \u001b[0mInference done 2416/2884. Dataloading: 0.0022 s/iter. Inference: 0.0365 s/iter. Eval: 0.0483 s/iter. Total: 0.0872 s/iter. ETA=0:00:40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/06 04:22:32 d2.evaluation.evaluator]: \u001b[0mInference done 2441/2884. Dataloading: 0.0022 s/iter. Inference: 0.0367 s/iter. Eval: 0.0494 s/iter. Total: 0.0884 s/iter. ETA=0:00:39\n",
      "\u001b[32m[07/06 04:22:37 d2.evaluation.evaluator]: \u001b[0mInference done 2466/2884. Dataloading: 0.0023 s/iter. Inference: 0.0368 s/iter. Eval: 0.0504 s/iter. Total: 0.0895 s/iter. ETA=0:00:37\n",
      "\u001b[32m[07/06 04:22:42 d2.evaluation.evaluator]: \u001b[0mInference done 2491/2884. Dataloading: 0.0023 s/iter. Inference: 0.0369 s/iter. Eval: 0.0514 s/iter. Total: 0.0907 s/iter. ETA=0:00:35\n",
      "\u001b[32m[07/06 04:22:47 d2.evaluation.evaluator]: \u001b[0mInference done 2516/2884. Dataloading: 0.0023 s/iter. Inference: 0.0370 s/iter. Eval: 0.0525 s/iter. Total: 0.0918 s/iter. ETA=0:00:33\n",
      "\u001b[32m[07/06 04:22:52 d2.evaluation.evaluator]: \u001b[0mInference done 2542/2884. Dataloading: 0.0023 s/iter. Inference: 0.0371 s/iter. Eval: 0.0535 s/iter. Total: 0.0929 s/iter. ETA=0:00:31\n",
      "\u001b[32m[07/06 04:22:57 d2.evaluation.evaluator]: \u001b[0mInference done 2566/2884. Dataloading: 0.0023 s/iter. Inference: 0.0371 s/iter. Eval: 0.0545 s/iter. Total: 0.0940 s/iter. ETA=0:00:29\n",
      "\u001b[32m[07/06 04:23:02 d2.evaluation.evaluator]: \u001b[0mInference done 2591/2884. Dataloading: 0.0023 s/iter. Inference: 0.0372 s/iter. Eval: 0.0554 s/iter. Total: 0.0950 s/iter. ETA=0:00:27\n",
      "\u001b[32m[07/06 04:23:07 d2.evaluation.evaluator]: \u001b[0mInference done 2616/2884. Dataloading: 0.0023 s/iter. Inference: 0.0373 s/iter. Eval: 0.0563 s/iter. Total: 0.0960 s/iter. ETA=0:00:25\n",
      "\u001b[32m[07/06 04:23:12 d2.evaluation.evaluator]: \u001b[0mInference done 2641/2884. Dataloading: 0.0023 s/iter. Inference: 0.0374 s/iter. Eval: 0.0573 s/iter. Total: 0.0970 s/iter. ETA=0:00:23\n",
      "\u001b[32m[07/06 04:23:17 d2.evaluation.evaluator]: \u001b[0mInference done 2667/2884. Dataloading: 0.0023 s/iter. Inference: 0.0375 s/iter. Eval: 0.0582 s/iter. Total: 0.0980 s/iter. ETA=0:00:21\n",
      "\u001b[32m[07/06 04:23:22 d2.evaluation.evaluator]: \u001b[0mInference done 2692/2884. Dataloading: 0.0023 s/iter. Inference: 0.0376 s/iter. Eval: 0.0591 s/iter. Total: 0.0990 s/iter. ETA=0:00:19\n",
      "\u001b[32m[07/06 04:23:28 d2.evaluation.evaluator]: \u001b[0mInference done 2718/2884. Dataloading: 0.0023 s/iter. Inference: 0.0377 s/iter. Eval: 0.0599 s/iter. Total: 0.1000 s/iter. ETA=0:00:16\n",
      "\u001b[32m[07/06 04:23:33 d2.evaluation.evaluator]: \u001b[0mInference done 2743/2884. Dataloading: 0.0023 s/iter. Inference: 0.0378 s/iter. Eval: 0.0608 s/iter. Total: 0.1009 s/iter. ETA=0:00:14\n",
      "\u001b[32m[07/06 04:23:38 d2.evaluation.evaluator]: \u001b[0mInference done 2768/2884. Dataloading: 0.0023 s/iter. Inference: 0.0379 s/iter. Eval: 0.0616 s/iter. Total: 0.1018 s/iter. ETA=0:00:11\n",
      "\u001b[32m[07/06 04:23:43 d2.evaluation.evaluator]: \u001b[0mInference done 2793/2884. Dataloading: 0.0023 s/iter. Inference: 0.0379 s/iter. Eval: 0.0625 s/iter. Total: 0.1027 s/iter. ETA=0:00:09\n",
      "\u001b[32m[07/06 04:23:48 d2.evaluation.evaluator]: \u001b[0mInference done 2817/2884. Dataloading: 0.0023 s/iter. Inference: 0.0380 s/iter. Eval: 0.0633 s/iter. Total: 0.1036 s/iter. ETA=0:00:06\n",
      "\u001b[32m[07/06 04:23:53 d2.evaluation.evaluator]: \u001b[0mInference done 2843/2884. Dataloading: 0.0023 s/iter. Inference: 0.0381 s/iter. Eval: 0.0641 s/iter. Total: 0.1045 s/iter. ETA=0:00:04\n",
      "\u001b[32m[07/06 04:23:58 d2.evaluation.evaluator]: \u001b[0mInference done 2868/2884. Dataloading: 0.0023 s/iter. Inference: 0.0382 s/iter. Eval: 0.0649 s/iter. Total: 0.1054 s/iter. ETA=0:00:01\n",
      "\u001b[32m[07/06 04:24:02 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:05:05.112456 (0.105979 s / iter per device, on 1 devices)\n",
      "\u001b[32m[07/06 04:24:02 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:01:50 (0.038212 s / iter per device, on 1 devices)\n",
      "\u001b[32m[07/06 04:24:02 d2.evaluation.sem_seg_evaluation]: \u001b[0mOrderedDict([('sem_seg', {'mIoU': 52.31738844349895, 'fwIoU': 69.09060706915815, 'IoU-Unlabeled': nan, 'IoU-Building': 56.741269840029, 'IoU-Fence': 29.876444810311913, 'IoU-Pedestrian': 60.14042575238514, 'IoU-Pole': 43.21585647459651, 'IoU-Road': 92.30922143999595, 'IoU-SideWalk': 60.34366948301684, 'IoU-Vegetation': 69.74153314668153, 'IoU-Vehicles': 75.93478559915455, 'IoU-Wall': 40.904500528333436, 'IoU-TrafficSign': 55.62583251419792, 'IoU-Sky': 42.50929767753491, 'IoU-TrafficLight': 53.39438851961776, 'IoU-Terrain': 26.2961486208916, 'IoU-ConstructionVehicle': 63.942068354045034, 'IoU-workzone_object': 64.36806057770026, 'IoU-Detour': 1.7347117574908009, 'mACC': 64.64037871861738, 'pACC': 80.59096127547075, 'ACC-Unlabeled': nan, 'ACC-Building': 95.93939719766293, 'ACC-Fence': 36.61701298194646, 'ACC-Pedestrian': 85.76368155772107, 'ACC-Pole': 51.65078623108895, 'ACC-Road': 95.15139882355066, 'ACC-SideWalk': 76.85500341039693, 'ACC-Vegetation': 75.71193973900235, 'ACC-Vehicles': 89.89719021237964, 'ACC-Wall': 50.37274379872072, 'ACC-TrafficSign': 62.580874076280004, 'ACC-Sky': 42.9631957562754, 'ACC-TrafficLight': 62.28834652310814, 'ACC-Terrain': 31.122678806247432, 'ACC-ConstructionVehicle': 92.59337214326348, 'ACC-workzone_object': 82.90883188281386, 'ACC-Detour': 1.8296063574200703})])\n",
      "\u001b[32m[07/06 04:24:02 d2.engine.defaults]: \u001b[0mEvaluation results for combined_both_rain_val in csv format:\n",
      "\u001b[32m[07/06 04:24:02 d2.evaluation.testing]: \u001b[0mcopypaste: Task: sem_seg\n",
      "\u001b[32m[07/06 04:24:02 d2.evaluation.testing]: \u001b[0mcopypaste: mIoU,fwIoU,mACC,pACC\n",
      "\u001b[32m[07/06 04:24:02 d2.evaluation.testing]: \u001b[0mcopypaste: 52.3174,69.0906,64.6404,80.5910\n"
     ]
    }
   ],
   "source": [
    "trainer_both = Detectron2Trainer('combined_all_night_train', 'combined_both_rain_val', output_folder='./output_both_40k')\n",
    "trainer_both.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "08d0896b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/05 22:13:49 d2.engine.defaults]: \u001b[0mModel:\n",
      "SemanticSegmentor(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (sem_seg_head): SemSegFPNHead(\n",
      "    (p2): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "    )\n",
      "    (p3): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (1): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "    )\n",
      "    (p4): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (1): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      (2): Conv2d(\n",
      "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (3): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "    )\n",
      "    (p5): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (1): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      (2): Conv2d(\n",
      "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (3): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      (4): Conv2d(\n",
      "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (5): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "    )\n",
      "    (predictor): Conv2d(128, 17, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/05 22:13:49 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(720, 720), max_size=2048, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[07/05 22:13:49 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[07/05 22:13:49 d2.data.common]: \u001b[0mSerializing 37734 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[07/05 22:13:49 d2.data.common]: \u001b[0mSerialized dataset takes 11.85 MiB\n",
      "Last checkpoint: model_final.pth\n",
      "\u001b[32m[07/05 22:13:50 d2.checkpoint.c2_model_loading]: \u001b[0mFollowing weights matched with model:\n",
      "| Names in Model                       | Names in Checkpoint                                                                                  | Shapes                                          |\n",
      "|:-------------------------------------|:-----------------------------------------------------------------------------------------------------|:------------------------------------------------|\n",
      "| backbone.bottom_up.res2.0.conv1.*    | backbone.bottom_up.res2.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,1,1)             |\n",
      "| backbone.bottom_up.res2.0.conv2.*    | backbone.bottom_up.res2.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |\n",
      "| backbone.bottom_up.res2.0.conv3.*    | backbone.bottom_up.res2.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res2.0.shortcut.* | backbone.bottom_up.res2.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res2.1.conv1.*    | backbone.bottom_up.res2.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |\n",
      "| backbone.bottom_up.res2.1.conv2.*    | backbone.bottom_up.res2.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |\n",
      "| backbone.bottom_up.res2.1.conv3.*    | backbone.bottom_up.res2.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res2.2.conv1.*    | backbone.bottom_up.res2.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |\n",
      "| backbone.bottom_up.res2.2.conv2.*    | backbone.bottom_up.res2.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |\n",
      "| backbone.bottom_up.res2.2.conv3.*    | backbone.bottom_up.res2.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res3.0.conv1.*    | backbone.bottom_up.res3.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,256,1,1)       |\n",
      "| backbone.bottom_up.res3.0.conv2.*    | backbone.bottom_up.res3.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.0.conv3.*    | backbone.bottom_up.res3.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res3.0.shortcut.* | backbone.bottom_up.res3.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (512,) (512,) (512,) (512,) (512,256,1,1)       |\n",
      "| backbone.bottom_up.res3.1.conv1.*    | backbone.bottom_up.res3.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |\n",
      "| backbone.bottom_up.res3.1.conv2.*    | backbone.bottom_up.res3.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.1.conv3.*    | backbone.bottom_up.res3.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res3.2.conv1.*    | backbone.bottom_up.res3.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |\n",
      "| backbone.bottom_up.res3.2.conv2.*    | backbone.bottom_up.res3.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.2.conv3.*    | backbone.bottom_up.res3.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res3.3.conv1.*    | backbone.bottom_up.res3.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |\n",
      "| backbone.bottom_up.res3.3.conv2.*    | backbone.bottom_up.res3.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.3.conv3.*    | backbone.bottom_up.res3.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res4.0.conv1.*    | backbone.bottom_up.res4.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,512,1,1)       |\n",
      "| backbone.bottom_up.res4.0.conv2.*    | backbone.bottom_up.res4.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.0.conv3.*    | backbone.bottom_up.res4.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.0.shortcut.* | backbone.bottom_up.res4.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (1024,) (1024,) (1024,) (1024,) (1024,512,1,1)  |\n",
      "| backbone.bottom_up.res4.1.conv1.*    | backbone.bottom_up.res4.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.1.conv2.*    | backbone.bottom_up.res4.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.1.conv3.*    | backbone.bottom_up.res4.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.2.conv1.*    | backbone.bottom_up.res4.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.2.conv2.*    | backbone.bottom_up.res4.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.2.conv3.*    | backbone.bottom_up.res4.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.3.conv1.*    | backbone.bottom_up.res4.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.3.conv2.*    | backbone.bottom_up.res4.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.3.conv3.*    | backbone.bottom_up.res4.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.4.conv1.*    | backbone.bottom_up.res4.4.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.4.conv2.*    | backbone.bottom_up.res4.4.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.4.conv3.*    | backbone.bottom_up.res4.4.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.5.conv1.*    | backbone.bottom_up.res4.5.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.5.conv2.*    | backbone.bottom_up.res4.5.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.5.conv3.*    | backbone.bottom_up.res4.5.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res5.0.conv1.*    | backbone.bottom_up.res5.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,1024,1,1)      |\n",
      "| backbone.bottom_up.res5.0.conv2.*    | backbone.bottom_up.res5.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |\n",
      "| backbone.bottom_up.res5.0.conv3.*    | backbone.bottom_up.res5.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
      "| backbone.bottom_up.res5.0.shortcut.* | backbone.bottom_up.res5.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (2048,) (2048,) (2048,) (2048,) (2048,1024,1,1) |\n",
      "| backbone.bottom_up.res5.1.conv1.*    | backbone.bottom_up.res5.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |\n",
      "| backbone.bottom_up.res5.1.conv2.*    | backbone.bottom_up.res5.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |\n",
      "| backbone.bottom_up.res5.1.conv3.*    | backbone.bottom_up.res5.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
      "| backbone.bottom_up.res5.2.conv1.*    | backbone.bottom_up.res5.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |\n",
      "| backbone.bottom_up.res5.2.conv2.*    | backbone.bottom_up.res5.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |\n",
      "| backbone.bottom_up.res5.2.conv3.*    | backbone.bottom_up.res5.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
      "| backbone.bottom_up.stem.conv1.*      | backbone.bottom_up.stem.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}      | (64,) (64,) (64,) (64,) (64,3,7,7)              |\n",
      "| backbone.fpn_lateral2.*              | backbone.fpn_lateral2.{bias,weight}                                                                  | (256,) (256,256,1,1)                            |\n",
      "| backbone.fpn_lateral3.*              | backbone.fpn_lateral3.{bias,weight}                                                                  | (256,) (256,512,1,1)                            |\n",
      "| backbone.fpn_lateral4.*              | backbone.fpn_lateral4.{bias,weight}                                                                  | (256,) (256,1024,1,1)                           |\n",
      "| backbone.fpn_lateral5.*              | backbone.fpn_lateral5.{bias,weight}                                                                  | (256,) (256,2048,1,1)                           |\n",
      "| backbone.fpn_output2.*               | backbone.fpn_output2.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| backbone.fpn_output3.*               | backbone.fpn_output3.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| backbone.fpn_output4.*               | backbone.fpn_output4.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| backbone.fpn_output5.*               | backbone.fpn_output5.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| sem_seg_head.p2.0.*                  | sem_seg_head.p2.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p3.0.*                  | sem_seg_head.p3.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p4.0.*                  | sem_seg_head.p4.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p4.2.*                  | sem_seg_head.p4.2.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,128,3,3)                     |\n",
      "| sem_seg_head.p5.0.*                  | sem_seg_head.p5.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p5.2.*                  | sem_seg_head.p5.2.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,128,3,3)                     |\n",
      "| sem_seg_head.p5.4.*                  | sem_seg_head.p5.4.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,128,3,3)                     |\n",
      "| sem_seg_head.predictor.*             | sem_seg_head.predictor.{bias,weight}                                                                 | (17,) (17,128,1,1)                              |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/05 22:13:50 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(720, 720), max_size=2048, sample_style='choice')]\n",
      "\u001b[32m[07/05 22:13:50 d2.data.common]: \u001b[0mSerializing 14460 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[07/05 22:13:50 d2.data.common]: \u001b[0mSerialized dataset takes 4.48 MiB\n",
      "\u001b[32m[07/05 22:13:50 d2.evaluation.evaluator]: \u001b[0mStart inference on 14460 batches\n",
      "\u001b[32m[07/05 22:13:51 d2.evaluation.evaluator]: \u001b[0mInference done 11/14460. Dataloading: 0.0017 s/iter. Inference: 0.0371 s/iter. Eval: 0.0419 s/iter. Total: 0.0808 s/iter. ETA=0:19:27\n",
      "\u001b[32m[07/05 22:13:56 d2.evaluation.evaluator]: \u001b[0mInference done 73/14460. Dataloading: 0.0021 s/iter. Inference: 0.0349 s/iter. Eval: 0.0437 s/iter. Total: 0.0808 s/iter. ETA=0:19:22\n",
      "\u001b[32m[07/05 22:14:01 d2.evaluation.evaluator]: \u001b[0mInference done 138/14460. Dataloading: 0.0021 s/iter. Inference: 0.0349 s/iter. Eval: 0.0420 s/iter. Total: 0.0790 s/iter. ETA=0:18:51\n",
      "\u001b[32m[07/05 22:14:06 d2.evaluation.evaluator]: \u001b[0mInference done 204/14460. Dataloading: 0.0021 s/iter. Inference: 0.0349 s/iter. Eval: 0.0409 s/iter. Total: 0.0780 s/iter. ETA=0:18:32\n",
      "\u001b[32m[07/05 22:14:11 d2.evaluation.evaluator]: \u001b[0mInference done 271/14460. Dataloading: 0.0021 s/iter. Inference: 0.0349 s/iter. Eval: 0.0403 s/iter. Total: 0.0774 s/iter. ETA=0:18:18\n",
      "\u001b[32m[07/05 22:14:16 d2.evaluation.evaluator]: \u001b[0mInference done 338/14460. Dataloading: 0.0021 s/iter. Inference: 0.0349 s/iter. Eval: 0.0399 s/iter. Total: 0.0771 s/iter. ETA=0:18:08\n",
      "\u001b[32m[07/05 22:14:21 d2.evaluation.evaluator]: \u001b[0mInference done 404/14460. Dataloading: 0.0021 s/iter. Inference: 0.0350 s/iter. Eval: 0.0397 s/iter. Total: 0.0769 s/iter. ETA=0:18:01\n",
      "\u001b[32m[07/05 22:14:26 d2.evaluation.evaluator]: \u001b[0mInference done 469/14460. Dataloading: 0.0022 s/iter. Inference: 0.0350 s/iter. Eval: 0.0398 s/iter. Total: 0.0770 s/iter. ETA=0:17:57\n",
      "\u001b[32m[07/05 22:14:31 d2.evaluation.evaluator]: \u001b[0mInference done 536/14460. Dataloading: 0.0022 s/iter. Inference: 0.0350 s/iter. Eval: 0.0396 s/iter. Total: 0.0768 s/iter. ETA=0:17:49\n",
      "\u001b[32m[07/05 22:14:36 d2.evaluation.evaluator]: \u001b[0mInference done 601/14460. Dataloading: 0.0022 s/iter. Inference: 0.0350 s/iter. Eval: 0.0396 s/iter. Total: 0.0769 s/iter. ETA=0:17:45\n",
      "\u001b[32m[07/05 22:14:41 d2.evaluation.evaluator]: \u001b[0mInference done 667/14460. Dataloading: 0.0022 s/iter. Inference: 0.0350 s/iter. Eval: 0.0395 s/iter. Total: 0.0768 s/iter. ETA=0:17:38\n",
      "\u001b[32m[07/05 22:14:46 d2.evaluation.evaluator]: \u001b[0mInference done 733/14460. Dataloading: 0.0022 s/iter. Inference: 0.0351 s/iter. Eval: 0.0394 s/iter. Total: 0.0768 s/iter. ETA=0:17:33\n",
      "\u001b[32m[07/05 22:14:51 d2.evaluation.evaluator]: \u001b[0mInference done 800/14460. Dataloading: 0.0022 s/iter. Inference: 0.0351 s/iter. Eval: 0.0392 s/iter. Total: 0.0766 s/iter. ETA=0:17:26\n",
      "\u001b[32m[07/05 22:14:56 d2.evaluation.evaluator]: \u001b[0mInference done 867/14460. Dataloading: 0.0022 s/iter. Inference: 0.0351 s/iter. Eval: 0.0391 s/iter. Total: 0.0765 s/iter. ETA=0:17:19\n",
      "\u001b[32m[07/05 22:15:02 d2.evaluation.evaluator]: \u001b[0mInference done 934/14460. Dataloading: 0.0022 s/iter. Inference: 0.0351 s/iter. Eval: 0.0390 s/iter. Total: 0.0764 s/iter. ETA=0:17:12\n",
      "\u001b[32m[07/05 22:15:07 d2.evaluation.evaluator]: \u001b[0mInference done 1002/14460. Dataloading: 0.0022 s/iter. Inference: 0.0351 s/iter. Eval: 0.0388 s/iter. Total: 0.0762 s/iter. ETA=0:17:05\n",
      "\u001b[32m[07/05 22:15:12 d2.evaluation.evaluator]: \u001b[0mInference done 1070/14460. Dataloading: 0.0022 s/iter. Inference: 0.0351 s/iter. Eval: 0.0387 s/iter. Total: 0.0761 s/iter. ETA=0:16:59\n",
      "\u001b[32m[07/05 22:15:17 d2.evaluation.evaluator]: \u001b[0mInference done 1136/14460. Dataloading: 0.0022 s/iter. Inference: 0.0352 s/iter. Eval: 0.0387 s/iter. Total: 0.0761 s/iter. ETA=0:16:54\n",
      "\u001b[32m[07/05 22:15:22 d2.evaluation.evaluator]: \u001b[0mInference done 1202/14460. Dataloading: 0.0022 s/iter. Inference: 0.0352 s/iter. Eval: 0.0387 s/iter. Total: 0.0762 s/iter. ETA=0:16:49\n",
      "\u001b[32m[07/05 22:15:27 d2.evaluation.evaluator]: \u001b[0mInference done 1267/14460. Dataloading: 0.0022 s/iter. Inference: 0.0352 s/iter. Eval: 0.0388 s/iter. Total: 0.0762 s/iter. ETA=0:16:45\n",
      "\u001b[32m[07/05 22:15:32 d2.evaluation.evaluator]: \u001b[0mInference done 1333/14460. Dataloading: 0.0022 s/iter. Inference: 0.0352 s/iter. Eval: 0.0387 s/iter. Total: 0.0762 s/iter. ETA=0:16:40\n",
      "\u001b[32m[07/05 22:15:37 d2.evaluation.evaluator]: \u001b[0mInference done 1399/14460. Dataloading: 0.0022 s/iter. Inference: 0.0352 s/iter. Eval: 0.0387 s/iter. Total: 0.0762 s/iter. ETA=0:16:35\n",
      "\u001b[32m[07/05 22:15:42 d2.evaluation.evaluator]: \u001b[0mInference done 1464/14460. Dataloading: 0.0022 s/iter. Inference: 0.0352 s/iter. Eval: 0.0387 s/iter. Total: 0.0763 s/iter. ETA=0:16:31\n",
      "\u001b[32m[07/05 22:15:47 d2.evaluation.evaluator]: \u001b[0mInference done 1530/14460. Dataloading: 0.0022 s/iter. Inference: 0.0352 s/iter. Eval: 0.0387 s/iter. Total: 0.0763 s/iter. ETA=0:16:26\n",
      "\u001b[32m[07/05 22:15:52 d2.evaluation.evaluator]: \u001b[0mInference done 1597/14460. Dataloading: 0.0022 s/iter. Inference: 0.0352 s/iter. Eval: 0.0387 s/iter. Total: 0.0762 s/iter. ETA=0:16:20\n",
      "\u001b[32m[07/05 22:15:57 d2.evaluation.evaluator]: \u001b[0mInference done 1664/14460. Dataloading: 0.0022 s/iter. Inference: 0.0353 s/iter. Eval: 0.0386 s/iter. Total: 0.0762 s/iter. ETA=0:16:14\n",
      "\u001b[32m[07/05 22:16:02 d2.evaluation.evaluator]: \u001b[0mInference done 1729/14460. Dataloading: 0.0022 s/iter. Inference: 0.0353 s/iter. Eval: 0.0387 s/iter. Total: 0.0762 s/iter. ETA=0:16:10\n",
      "\u001b[32m[07/05 22:16:07 d2.evaluation.evaluator]: \u001b[0mInference done 1795/14460. Dataloading: 0.0022 s/iter. Inference: 0.0353 s/iter. Eval: 0.0387 s/iter. Total: 0.0762 s/iter. ETA=0:16:05\n",
      "\u001b[32m[07/05 22:16:12 d2.evaluation.evaluator]: \u001b[0mInference done 1859/14460. Dataloading: 0.0022 s/iter. Inference: 0.0353 s/iter. Eval: 0.0387 s/iter. Total: 0.0763 s/iter. ETA=0:16:01\n",
      "\u001b[32m[07/05 22:16:17 d2.evaluation.evaluator]: \u001b[0mInference done 1924/14460. Dataloading: 0.0022 s/iter. Inference: 0.0353 s/iter. Eval: 0.0388 s/iter. Total: 0.0764 s/iter. ETA=0:15:57\n",
      "\u001b[32m[07/05 22:16:22 d2.evaluation.evaluator]: \u001b[0mInference done 1988/14460. Dataloading: 0.0022 s/iter. Inference: 0.0353 s/iter. Eval: 0.0388 s/iter. Total: 0.0764 s/iter. ETA=0:15:53\n",
      "\u001b[32m[07/05 22:16:27 d2.evaluation.evaluator]: \u001b[0mInference done 2053/14460. Dataloading: 0.0022 s/iter. Inference: 0.0353 s/iter. Eval: 0.0389 s/iter. Total: 0.0765 s/iter. ETA=0:15:48\n",
      "\u001b[32m[07/05 22:16:32 d2.evaluation.evaluator]: \u001b[0mInference done 2118/14460. Dataloading: 0.0022 s/iter. Inference: 0.0353 s/iter. Eval: 0.0389 s/iter. Total: 0.0765 s/iter. ETA=0:15:44\n",
      "\u001b[32m[07/05 22:16:37 d2.evaluation.evaluator]: \u001b[0mInference done 2184/14460. Dataloading: 0.0022 s/iter. Inference: 0.0353 s/iter. Eval: 0.0389 s/iter. Total: 0.0765 s/iter. ETA=0:15:39\n",
      "\u001b[32m[07/05 22:16:42 d2.evaluation.evaluator]: \u001b[0mInference done 2249/14460. Dataloading: 0.0022 s/iter. Inference: 0.0353 s/iter. Eval: 0.0389 s/iter. Total: 0.0766 s/iter. ETA=0:15:34\n",
      "\u001b[32m[07/05 22:16:47 d2.evaluation.evaluator]: \u001b[0mInference done 2315/14460. Dataloading: 0.0022 s/iter. Inference: 0.0353 s/iter. Eval: 0.0389 s/iter. Total: 0.0766 s/iter. ETA=0:15:29\n",
      "\u001b[32m[07/05 22:16:52 d2.evaluation.evaluator]: \u001b[0mInference done 2381/14460. Dataloading: 0.0022 s/iter. Inference: 0.0353 s/iter. Eval: 0.0389 s/iter. Total: 0.0766 s/iter. ETA=0:15:24\n",
      "\u001b[32m[07/05 22:16:57 d2.evaluation.evaluator]: \u001b[0mInference done 2445/14460. Dataloading: 0.0022 s/iter. Inference: 0.0353 s/iter. Eval: 0.0389 s/iter. Total: 0.0766 s/iter. ETA=0:15:20\n",
      "\u001b[32m[07/05 22:17:03 d2.evaluation.evaluator]: \u001b[0mInference done 2510/14460. Dataloading: 0.0022 s/iter. Inference: 0.0353 s/iter. Eval: 0.0390 s/iter. Total: 0.0766 s/iter. ETA=0:15:15\n",
      "\u001b[32m[07/05 22:17:08 d2.evaluation.evaluator]: \u001b[0mInference done 2575/14460. Dataloading: 0.0023 s/iter. Inference: 0.0353 s/iter. Eval: 0.0390 s/iter. Total: 0.0767 s/iter. ETA=0:15:11\n",
      "\u001b[32m[07/05 22:17:13 d2.evaluation.evaluator]: \u001b[0mInference done 2639/14460. Dataloading: 0.0023 s/iter. Inference: 0.0354 s/iter. Eval: 0.0390 s/iter. Total: 0.0767 s/iter. ETA=0:15:06\n",
      "\u001b[32m[07/05 22:17:18 d2.evaluation.evaluator]: \u001b[0mInference done 2704/14460. Dataloading: 0.0023 s/iter. Inference: 0.0354 s/iter. Eval: 0.0390 s/iter. Total: 0.0767 s/iter. ETA=0:15:01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/05 22:17:23 d2.evaluation.evaluator]: \u001b[0mInference done 2769/14460. Dataloading: 0.0023 s/iter. Inference: 0.0354 s/iter. Eval: 0.0390 s/iter. Total: 0.0767 s/iter. ETA=0:14:57\n",
      "\u001b[32m[07/05 22:17:28 d2.evaluation.evaluator]: \u001b[0mInference done 2837/14460. Dataloading: 0.0023 s/iter. Inference: 0.0354 s/iter. Eval: 0.0390 s/iter. Total: 0.0767 s/iter. ETA=0:14:51\n",
      "\u001b[32m[07/05 22:17:33 d2.evaluation.evaluator]: \u001b[0mInference done 2902/14460. Dataloading: 0.0023 s/iter. Inference: 0.0354 s/iter. Eval: 0.0390 s/iter. Total: 0.0767 s/iter. ETA=0:14:46\n",
      "\u001b[32m[07/05 22:17:38 d2.evaluation.evaluator]: \u001b[0mInference done 2968/14460. Dataloading: 0.0023 s/iter. Inference: 0.0354 s/iter. Eval: 0.0390 s/iter. Total: 0.0767 s/iter. ETA=0:14:41\n",
      "\u001b[32m[07/05 22:17:43 d2.evaluation.evaluator]: \u001b[0mInference done 3033/14460. Dataloading: 0.0023 s/iter. Inference: 0.0354 s/iter. Eval: 0.0390 s/iter. Total: 0.0767 s/iter. ETA=0:14:36\n",
      "\u001b[32m[07/05 22:17:48 d2.evaluation.evaluator]: \u001b[0mInference done 3097/14460. Dataloading: 0.0023 s/iter. Inference: 0.0354 s/iter. Eval: 0.0390 s/iter. Total: 0.0767 s/iter. ETA=0:14:32\n",
      "\u001b[32m[07/05 22:17:53 d2.evaluation.evaluator]: \u001b[0mInference done 3162/14460. Dataloading: 0.0023 s/iter. Inference: 0.0354 s/iter. Eval: 0.0390 s/iter. Total: 0.0768 s/iter. ETA=0:14:27\n",
      "\u001b[32m[07/05 22:17:58 d2.evaluation.evaluator]: \u001b[0mInference done 3228/14460. Dataloading: 0.0023 s/iter. Inference: 0.0354 s/iter. Eval: 0.0390 s/iter. Total: 0.0768 s/iter. ETA=0:14:22\n",
      "\u001b[32m[07/05 22:18:03 d2.evaluation.evaluator]: \u001b[0mInference done 3292/14460. Dataloading: 0.0023 s/iter. Inference: 0.0354 s/iter. Eval: 0.0390 s/iter. Total: 0.0768 s/iter. ETA=0:14:17\n",
      "\u001b[32m[07/05 22:18:08 d2.evaluation.evaluator]: \u001b[0mInference done 3355/14460. Dataloading: 0.0023 s/iter. Inference: 0.0354 s/iter. Eval: 0.0391 s/iter. Total: 0.0768 s/iter. ETA=0:14:13\n",
      "\u001b[32m[07/05 22:18:13 d2.evaluation.evaluator]: \u001b[0mInference done 3416/14460. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0391 s/iter. Total: 0.0769 s/iter. ETA=0:14:09\n",
      "\u001b[32m[07/05 22:18:18 d2.evaluation.evaluator]: \u001b[0mInference done 3483/14460. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0391 s/iter. Total: 0.0769 s/iter. ETA=0:14:04\n",
      "\u001b[32m[07/05 22:18:23 d2.evaluation.evaluator]: \u001b[0mInference done 3549/14460. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0391 s/iter. Total: 0.0769 s/iter. ETA=0:13:59\n",
      "\u001b[32m[07/05 22:18:28 d2.evaluation.evaluator]: \u001b[0mInference done 3613/14460. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0391 s/iter. Total: 0.0769 s/iter. ETA=0:13:54\n",
      "\u001b[32m[07/05 22:18:33 d2.evaluation.evaluator]: \u001b[0mInference done 3677/14460. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0391 s/iter. Total: 0.0770 s/iter. ETA=0:13:49\n",
      "\u001b[32m[07/05 22:18:38 d2.evaluation.evaluator]: \u001b[0mInference done 3738/14460. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0392 s/iter. Total: 0.0771 s/iter. ETA=0:13:46\n",
      "\u001b[32m[07/05 22:18:43 d2.evaluation.evaluator]: \u001b[0mInference done 3803/14460. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0392 s/iter. Total: 0.0771 s/iter. ETA=0:13:41\n",
      "\u001b[32m[07/05 22:18:48 d2.evaluation.evaluator]: \u001b[0mInference done 3867/14460. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0393 s/iter. Total: 0.0771 s/iter. ETA=0:13:36\n",
      "\u001b[32m[07/05 22:18:53 d2.evaluation.evaluator]: \u001b[0mInference done 3932/14460. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0393 s/iter. Total: 0.0771 s/iter. ETA=0:13:31\n",
      "\u001b[32m[07/05 22:18:58 d2.evaluation.evaluator]: \u001b[0mInference done 3997/14460. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0393 s/iter. Total: 0.0771 s/iter. ETA=0:13:26\n",
      "\u001b[32m[07/05 22:19:03 d2.evaluation.evaluator]: \u001b[0mInference done 4063/14460. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0393 s/iter. Total: 0.0771 s/iter. ETA=0:13:21\n",
      "\u001b[32m[07/05 22:19:09 d2.evaluation.evaluator]: \u001b[0mInference done 4129/14460. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0393 s/iter. Total: 0.0771 s/iter. ETA=0:13:16\n",
      "\u001b[32m[07/05 22:19:14 d2.evaluation.evaluator]: \u001b[0mInference done 4194/14460. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0393 s/iter. Total: 0.0771 s/iter. ETA=0:13:11\n",
      "\u001b[32m[07/05 22:19:19 d2.evaluation.evaluator]: \u001b[0mInference done 4259/14460. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0392 s/iter. Total: 0.0771 s/iter. ETA=0:13:06\n",
      "\u001b[32m[07/05 22:19:24 d2.evaluation.evaluator]: \u001b[0mInference done 4324/14460. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0392 s/iter. Total: 0.0771 s/iter. ETA=0:13:01\n",
      "\u001b[32m[07/05 22:19:29 d2.evaluation.evaluator]: \u001b[0mInference done 4390/14460. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0392 s/iter. Total: 0.0771 s/iter. ETA=0:12:56\n",
      "\u001b[32m[07/05 22:19:34 d2.evaluation.evaluator]: \u001b[0mInference done 4457/14460. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0392 s/iter. Total: 0.0771 s/iter. ETA=0:12:50\n",
      "\u001b[32m[07/05 22:19:39 d2.evaluation.evaluator]: \u001b[0mInference done 4523/14460. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0392 s/iter. Total: 0.0770 s/iter. ETA=0:12:45\n",
      "\u001b[32m[07/05 22:19:44 d2.evaluation.evaluator]: \u001b[0mInference done 4590/14460. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0392 s/iter. Total: 0.0770 s/iter. ETA=0:12:40\n",
      "\u001b[32m[07/05 22:19:49 d2.evaluation.evaluator]: \u001b[0mInference done 4656/14460. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0391 s/iter. Total: 0.0770 s/iter. ETA=0:12:34\n",
      "\u001b[32m[07/05 22:19:54 d2.evaluation.evaluator]: \u001b[0mInference done 4722/14460. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0391 s/iter. Total: 0.0770 s/iter. ETA=0:12:29\n",
      "\u001b[32m[07/05 22:19:59 d2.evaluation.evaluator]: \u001b[0mInference done 4788/14460. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0391 s/iter. Total: 0.0770 s/iter. ETA=0:12:24\n",
      "\u001b[32m[07/05 22:20:04 d2.evaluation.evaluator]: \u001b[0mInference done 4854/14460. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0391 s/iter. Total: 0.0770 s/iter. ETA=0:12:19\n",
      "\u001b[32m[07/05 22:20:09 d2.evaluation.evaluator]: \u001b[0mInference done 4920/14460. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0391 s/iter. Total: 0.0770 s/iter. ETA=0:12:14\n",
      "\u001b[32m[07/05 22:20:14 d2.evaluation.evaluator]: \u001b[0mInference done 4986/14460. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0391 s/iter. Total: 0.0770 s/iter. ETA=0:12:09\n",
      "\u001b[32m[07/05 22:20:19 d2.evaluation.evaluator]: \u001b[0mInference done 5052/14460. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0391 s/iter. Total: 0.0770 s/iter. ETA=0:12:04\n",
      "\u001b[32m[07/05 22:20:24 d2.evaluation.evaluator]: \u001b[0mInference done 5118/14460. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0391 s/iter. Total: 0.0770 s/iter. ETA=0:11:58\n",
      "\u001b[32m[07/05 22:20:29 d2.evaluation.evaluator]: \u001b[0mInference done 5184/14460. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0391 s/iter. Total: 0.0770 s/iter. ETA=0:11:53\n",
      "\u001b[32m[07/05 22:20:34 d2.evaluation.evaluator]: \u001b[0mInference done 5250/14460. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0391 s/iter. Total: 0.0770 s/iter. ETA=0:11:48\n",
      "\u001b[32m[07/05 22:20:39 d2.evaluation.evaluator]: \u001b[0mInference done 5315/14460. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0391 s/iter. Total: 0.0770 s/iter. ETA=0:11:43\n",
      "\u001b[32m[07/05 22:20:44 d2.evaluation.evaluator]: \u001b[0mInference done 5381/14460. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0390 s/iter. Total: 0.0770 s/iter. ETA=0:11:38\n",
      "\u001b[32m[07/05 22:20:49 d2.evaluation.evaluator]: \u001b[0mInference done 5446/14460. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0390 s/iter. Total: 0.0770 s/iter. ETA=0:11:33\n",
      "\u001b[32m[07/05 22:20:54 d2.evaluation.evaluator]: \u001b[0mInference done 5512/14460. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0390 s/iter. Total: 0.0770 s/iter. ETA=0:11:28\n",
      "\u001b[32m[07/05 22:20:59 d2.evaluation.evaluator]: \u001b[0mInference done 5579/14460. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0390 s/iter. Total: 0.0769 s/iter. ETA=0:11:23\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/05 22:21:04 d2.evaluation.evaluator]: \u001b[0mInference done 5645/14460. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0390 s/iter. Total: 0.0769 s/iter. ETA=0:11:18\n",
      "\u001b[32m[07/05 22:21:09 d2.evaluation.evaluator]: \u001b[0mInference done 5712/14460. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0390 s/iter. Total: 0.0769 s/iter. ETA=0:11:12\n",
      "\u001b[32m[07/05 22:21:14 d2.evaluation.evaluator]: \u001b[0mInference done 5778/14460. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0390 s/iter. Total: 0.0769 s/iter. ETA=0:11:07\n",
      "\u001b[32m[07/05 22:21:19 d2.evaluation.evaluator]: \u001b[0mInference done 5844/14460. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0390 s/iter. Total: 0.0769 s/iter. ETA=0:11:02\n",
      "\u001b[32m[07/05 22:21:25 d2.evaluation.evaluator]: \u001b[0mInference done 5910/14460. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0390 s/iter. Total: 0.0769 s/iter. ETA=0:10:57\n",
      "\u001b[32m[07/05 22:21:30 d2.evaluation.evaluator]: \u001b[0mInference done 5976/14460. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0389 s/iter. Total: 0.0769 s/iter. ETA=0:10:52\n",
      "\u001b[32m[07/05 22:21:35 d2.evaluation.evaluator]: \u001b[0mInference done 6042/14460. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0389 s/iter. Total: 0.0769 s/iter. ETA=0:10:47\n",
      "\u001b[32m[07/05 22:21:40 d2.evaluation.evaluator]: \u001b[0mInference done 6108/14460. Dataloading: 0.0023 s/iter. Inference: 0.0356 s/iter. Eval: 0.0389 s/iter. Total: 0.0769 s/iter. ETA=0:10:41\n",
      "\u001b[32m[07/05 22:21:45 d2.evaluation.evaluator]: \u001b[0mInference done 6175/14460. Dataloading: 0.0023 s/iter. Inference: 0.0356 s/iter. Eval: 0.0389 s/iter. Total: 0.0769 s/iter. ETA=0:10:36\n",
      "\u001b[32m[07/05 22:21:50 d2.evaluation.evaluator]: \u001b[0mInference done 6241/14460. Dataloading: 0.0023 s/iter. Inference: 0.0356 s/iter. Eval: 0.0389 s/iter. Total: 0.0768 s/iter. ETA=0:10:31\n",
      "\u001b[32m[07/05 22:21:55 d2.evaluation.evaluator]: \u001b[0mInference done 6307/14460. Dataloading: 0.0023 s/iter. Inference: 0.0356 s/iter. Eval: 0.0389 s/iter. Total: 0.0768 s/iter. ETA=0:10:26\n",
      "\u001b[32m[07/05 22:22:00 d2.evaluation.evaluator]: \u001b[0mInference done 6373/14460. Dataloading: 0.0023 s/iter. Inference: 0.0356 s/iter. Eval: 0.0389 s/iter. Total: 0.0768 s/iter. ETA=0:10:21\n",
      "\u001b[32m[07/05 22:22:05 d2.evaluation.evaluator]: \u001b[0mInference done 6439/14460. Dataloading: 0.0023 s/iter. Inference: 0.0356 s/iter. Eval: 0.0389 s/iter. Total: 0.0768 s/iter. ETA=0:10:16\n",
      "\u001b[32m[07/05 22:22:10 d2.evaluation.evaluator]: \u001b[0mInference done 6505/14460. Dataloading: 0.0023 s/iter. Inference: 0.0356 s/iter. Eval: 0.0389 s/iter. Total: 0.0768 s/iter. ETA=0:10:11\n",
      "\u001b[32m[07/05 22:22:15 d2.evaluation.evaluator]: \u001b[0mInference done 6538/14460. Dataloading: 0.0023 s/iter. Inference: 0.0356 s/iter. Eval: 0.0393 s/iter. Total: 0.0772 s/iter. ETA=0:10:11\n",
      "\u001b[32m[07/05 22:22:20 d2.evaluation.evaluator]: \u001b[0mInference done 6565/14460. Dataloading: 0.0023 s/iter. Inference: 0.0356 s/iter. Eval: 0.0397 s/iter. Total: 0.0777 s/iter. ETA=0:10:13\n",
      "\u001b[32m[07/05 22:22:25 d2.evaluation.evaluator]: \u001b[0mInference done 6591/14460. Dataloading: 0.0023 s/iter. Inference: 0.0357 s/iter. Eval: 0.0401 s/iter. Total: 0.0782 s/iter. ETA=0:10:15\n",
      "\u001b[32m[07/05 22:22:30 d2.evaluation.evaluator]: \u001b[0mInference done 6617/14460. Dataloading: 0.0023 s/iter. Inference: 0.0357 s/iter. Eval: 0.0405 s/iter. Total: 0.0786 s/iter. ETA=0:10:16\n",
      "\u001b[32m[07/05 22:22:35 d2.evaluation.evaluator]: \u001b[0mInference done 6643/14460. Dataloading: 0.0023 s/iter. Inference: 0.0358 s/iter. Eval: 0.0409 s/iter. Total: 0.0791 s/iter. ETA=0:10:18\n",
      "\u001b[32m[07/05 22:22:41 d2.evaluation.evaluator]: \u001b[0mInference done 6669/14460. Dataloading: 0.0023 s/iter. Inference: 0.0358 s/iter. Eval: 0.0413 s/iter. Total: 0.0795 s/iter. ETA=0:10:19\n",
      "\u001b[32m[07/05 22:22:46 d2.evaluation.evaluator]: \u001b[0mInference done 6696/14460. Dataloading: 0.0023 s/iter. Inference: 0.0359 s/iter. Eval: 0.0417 s/iter. Total: 0.0800 s/iter. ETA=0:10:20\n",
      "\u001b[32m[07/05 22:22:51 d2.evaluation.evaluator]: \u001b[0mInference done 6724/14460. Dataloading: 0.0023 s/iter. Inference: 0.0359 s/iter. Eval: 0.0421 s/iter. Total: 0.0804 s/iter. ETA=0:10:22\n",
      "\u001b[32m[07/05 22:22:56 d2.evaluation.evaluator]: \u001b[0mInference done 6751/14460. Dataloading: 0.0023 s/iter. Inference: 0.0359 s/iter. Eval: 0.0425 s/iter. Total: 0.0809 s/iter. ETA=0:10:23\n",
      "\u001b[32m[07/05 22:23:01 d2.evaluation.evaluator]: \u001b[0mInference done 6780/14460. Dataloading: 0.0023 s/iter. Inference: 0.0360 s/iter. Eval: 0.0429 s/iter. Total: 0.0812 s/iter. ETA=0:10:23\n",
      "\u001b[32m[07/05 22:23:06 d2.evaluation.evaluator]: \u001b[0mInference done 6808/14460. Dataloading: 0.0023 s/iter. Inference: 0.0360 s/iter. Eval: 0.0433 s/iter. Total: 0.0817 s/iter. ETA=0:10:24\n",
      "\u001b[32m[07/05 22:23:11 d2.evaluation.evaluator]: \u001b[0mInference done 6836/14460. Dataloading: 0.0023 s/iter. Inference: 0.0361 s/iter. Eval: 0.0436 s/iter. Total: 0.0821 s/iter. ETA=0:10:25\n",
      "\u001b[32m[07/05 22:23:16 d2.evaluation.evaluator]: \u001b[0mInference done 6862/14460. Dataloading: 0.0023 s/iter. Inference: 0.0361 s/iter. Eval: 0.0440 s/iter. Total: 0.0825 s/iter. ETA=0:10:26\n",
      "\u001b[32m[07/05 22:23:21 d2.evaluation.evaluator]: \u001b[0mInference done 6887/14460. Dataloading: 0.0023 s/iter. Inference: 0.0361 s/iter. Eval: 0.0444 s/iter. Total: 0.0829 s/iter. ETA=0:10:28\n",
      "\u001b[32m[07/05 22:23:26 d2.evaluation.evaluator]: \u001b[0mInference done 6913/14460. Dataloading: 0.0023 s/iter. Inference: 0.0362 s/iter. Eval: 0.0448 s/iter. Total: 0.0834 s/iter. ETA=0:10:29\n",
      "\u001b[32m[07/05 22:23:32 d2.evaluation.evaluator]: \u001b[0mInference done 6939/14460. Dataloading: 0.0023 s/iter. Inference: 0.0362 s/iter. Eval: 0.0452 s/iter. Total: 0.0838 s/iter. ETA=0:10:30\n",
      "\u001b[32m[07/05 22:23:37 d2.evaluation.evaluator]: \u001b[0mInference done 6965/14460. Dataloading: 0.0023 s/iter. Inference: 0.0363 s/iter. Eval: 0.0456 s/iter. Total: 0.0842 s/iter. ETA=0:10:31\n",
      "\u001b[32m[07/05 22:23:42 d2.evaluation.evaluator]: \u001b[0mInference done 6991/14460. Dataloading: 0.0023 s/iter. Inference: 0.0363 s/iter. Eval: 0.0459 s/iter. Total: 0.0846 s/iter. ETA=0:10:32\n",
      "\u001b[32m[07/05 22:23:47 d2.evaluation.evaluator]: \u001b[0mInference done 7017/14460. Dataloading: 0.0023 s/iter. Inference: 0.0363 s/iter. Eval: 0.0463 s/iter. Total: 0.0850 s/iter. ETA=0:10:32\n",
      "\u001b[32m[07/05 22:23:52 d2.evaluation.evaluator]: \u001b[0mInference done 7044/14460. Dataloading: 0.0023 s/iter. Inference: 0.0364 s/iter. Eval: 0.0467 s/iter. Total: 0.0854 s/iter. ETA=0:10:33\n",
      "\u001b[32m[07/05 22:23:57 d2.evaluation.evaluator]: \u001b[0mInference done 7071/14460. Dataloading: 0.0023 s/iter. Inference: 0.0364 s/iter. Eval: 0.0470 s/iter. Total: 0.0858 s/iter. ETA=0:10:34\n",
      "\u001b[32m[07/05 22:24:02 d2.evaluation.evaluator]: \u001b[0mInference done 7098/14460. Dataloading: 0.0023 s/iter. Inference: 0.0365 s/iter. Eval: 0.0474 s/iter. Total: 0.0862 s/iter. ETA=0:10:34\n",
      "\u001b[32m[07/05 22:24:07 d2.evaluation.evaluator]: \u001b[0mInference done 7125/14460. Dataloading: 0.0023 s/iter. Inference: 0.0365 s/iter. Eval: 0.0477 s/iter. Total: 0.0866 s/iter. ETA=0:10:35\n",
      "\u001b[32m[07/05 22:24:12 d2.evaluation.evaluator]: \u001b[0mInference done 7150/14460. Dataloading: 0.0023 s/iter. Inference: 0.0365 s/iter. Eval: 0.0481 s/iter. Total: 0.0870 s/iter. ETA=0:10:36\n",
      "\u001b[32m[07/05 22:24:18 d2.evaluation.evaluator]: \u001b[0mInference done 7176/14460. Dataloading: 0.0023 s/iter. Inference: 0.0366 s/iter. Eval: 0.0485 s/iter. Total: 0.0874 s/iter. ETA=0:10:36\n",
      "\u001b[32m[07/05 22:24:23 d2.evaluation.evaluator]: \u001b[0mInference done 7202/14460. Dataloading: 0.0023 s/iter. Inference: 0.0366 s/iter. Eval: 0.0488 s/iter. Total: 0.0878 s/iter. ETA=0:10:37\n",
      "\u001b[32m[07/05 22:24:28 d2.evaluation.evaluator]: \u001b[0mInference done 7229/14460. Dataloading: 0.0023 s/iter. Inference: 0.0366 s/iter. Eval: 0.0492 s/iter. Total: 0.0882 s/iter. ETA=0:10:37\n",
      "\u001b[32m[07/05 22:24:33 d2.evaluation.evaluator]: \u001b[0mInference done 7254/14460. Dataloading: 0.0023 s/iter. Inference: 0.0367 s/iter. Eval: 0.0495 s/iter. Total: 0.0886 s/iter. ETA=0:10:38\n",
      "\u001b[32m[07/05 22:24:38 d2.evaluation.evaluator]: \u001b[0mInference done 7280/14460. Dataloading: 0.0023 s/iter. Inference: 0.0367 s/iter. Eval: 0.0499 s/iter. Total: 0.0890 s/iter. ETA=0:10:39\n",
      "\u001b[32m[07/05 22:24:43 d2.evaluation.evaluator]: \u001b[0mInference done 7305/14460. Dataloading: 0.0023 s/iter. Inference: 0.0368 s/iter. Eval: 0.0502 s/iter. Total: 0.0894 s/iter. ETA=0:10:39\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/05 22:24:48 d2.evaluation.evaluator]: \u001b[0mInference done 7331/14460. Dataloading: 0.0023 s/iter. Inference: 0.0368 s/iter. Eval: 0.0506 s/iter. Total: 0.0898 s/iter. ETA=0:10:40\n",
      "\u001b[32m[07/05 22:24:54 d2.evaluation.evaluator]: \u001b[0mInference done 7357/14460. Dataloading: 0.0023 s/iter. Inference: 0.0369 s/iter. Eval: 0.0509 s/iter. Total: 0.0902 s/iter. ETA=0:10:40\n",
      "\u001b[32m[07/05 22:24:59 d2.evaluation.evaluator]: \u001b[0mInference done 7383/14460. Dataloading: 0.0023 s/iter. Inference: 0.0369 s/iter. Eval: 0.0512 s/iter. Total: 0.0905 s/iter. ETA=0:10:40\n",
      "\u001b[32m[07/05 22:25:04 d2.evaluation.evaluator]: \u001b[0mInference done 7409/14460. Dataloading: 0.0023 s/iter. Inference: 0.0369 s/iter. Eval: 0.0516 s/iter. Total: 0.0909 s/iter. ETA=0:10:40\n",
      "\u001b[32m[07/05 22:25:09 d2.evaluation.evaluator]: \u001b[0mInference done 7436/14460. Dataloading: 0.0023 s/iter. Inference: 0.0370 s/iter. Eval: 0.0519 s/iter. Total: 0.0913 s/iter. ETA=0:10:40\n",
      "\u001b[32m[07/05 22:25:14 d2.evaluation.evaluator]: \u001b[0mInference done 7464/14460. Dataloading: 0.0023 s/iter. Inference: 0.0370 s/iter. Eval: 0.0522 s/iter. Total: 0.0916 s/iter. ETA=0:10:40\n",
      "\u001b[32m[07/05 22:25:19 d2.evaluation.evaluator]: \u001b[0mInference done 7490/14460. Dataloading: 0.0023 s/iter. Inference: 0.0370 s/iter. Eval: 0.0525 s/iter. Total: 0.0920 s/iter. ETA=0:10:41\n",
      "\u001b[32m[07/05 22:25:24 d2.evaluation.evaluator]: \u001b[0mInference done 7516/14460. Dataloading: 0.0023 s/iter. Inference: 0.0371 s/iter. Eval: 0.0529 s/iter. Total: 0.0923 s/iter. ETA=0:10:41\n",
      "\u001b[32m[07/05 22:25:29 d2.evaluation.evaluator]: \u001b[0mInference done 7542/14460. Dataloading: 0.0023 s/iter. Inference: 0.0371 s/iter. Eval: 0.0532 s/iter. Total: 0.0927 s/iter. ETA=0:10:41\n",
      "\u001b[32m[07/05 22:25:34 d2.evaluation.evaluator]: \u001b[0mInference done 7569/14460. Dataloading: 0.0023 s/iter. Inference: 0.0371 s/iter. Eval: 0.0535 s/iter. Total: 0.0931 s/iter. ETA=0:10:41\n",
      "\u001b[32m[07/05 22:25:40 d2.evaluation.evaluator]: \u001b[0mInference done 7596/14460. Dataloading: 0.0023 s/iter. Inference: 0.0372 s/iter. Eval: 0.0538 s/iter. Total: 0.0934 s/iter. ETA=0:10:41\n",
      "\u001b[32m[07/05 22:25:45 d2.evaluation.evaluator]: \u001b[0mInference done 7621/14460. Dataloading: 0.0023 s/iter. Inference: 0.0372 s/iter. Eval: 0.0542 s/iter. Total: 0.0938 s/iter. ETA=0:10:41\n",
      "\u001b[32m[07/05 22:25:50 d2.evaluation.evaluator]: \u001b[0mInference done 7647/14460. Dataloading: 0.0023 s/iter. Inference: 0.0372 s/iter. Eval: 0.0545 s/iter. Total: 0.0941 s/iter. ETA=0:10:41\n",
      "\u001b[32m[07/05 22:25:55 d2.evaluation.evaluator]: \u001b[0mInference done 7673/14460. Dataloading: 0.0023 s/iter. Inference: 0.0373 s/iter. Eval: 0.0548 s/iter. Total: 0.0944 s/iter. ETA=0:10:41\n",
      "\u001b[32m[07/05 22:26:00 d2.evaluation.evaluator]: \u001b[0mInference done 7699/14460. Dataloading: 0.0023 s/iter. Inference: 0.0373 s/iter. Eval: 0.0551 s/iter. Total: 0.0948 s/iter. ETA=0:10:40\n",
      "\u001b[32m[07/05 22:26:05 d2.evaluation.evaluator]: \u001b[0mInference done 7725/14460. Dataloading: 0.0023 s/iter. Inference: 0.0373 s/iter. Eval: 0.0554 s/iter. Total: 0.0951 s/iter. ETA=0:10:40\n",
      "\u001b[32m[07/05 22:26:10 d2.evaluation.evaluator]: \u001b[0mInference done 7751/14460. Dataloading: 0.0023 s/iter. Inference: 0.0374 s/iter. Eval: 0.0557 s/iter. Total: 0.0955 s/iter. ETA=0:10:40\n",
      "\u001b[32m[07/05 22:26:15 d2.evaluation.evaluator]: \u001b[0mInference done 7777/14460. Dataloading: 0.0023 s/iter. Inference: 0.0374 s/iter. Eval: 0.0560 s/iter. Total: 0.0958 s/iter. ETA=0:10:40\n",
      "\u001b[32m[07/05 22:26:20 d2.evaluation.evaluator]: \u001b[0mInference done 7804/14460. Dataloading: 0.0023 s/iter. Inference: 0.0374 s/iter. Eval: 0.0563 s/iter. Total: 0.0961 s/iter. ETA=0:10:39\n",
      "\u001b[32m[07/05 22:26:26 d2.evaluation.evaluator]: \u001b[0mInference done 7831/14460. Dataloading: 0.0023 s/iter. Inference: 0.0375 s/iter. Eval: 0.0566 s/iter. Total: 0.0965 s/iter. ETA=0:10:39\n",
      "\u001b[32m[07/05 22:26:31 d2.evaluation.evaluator]: \u001b[0mInference done 7858/14460. Dataloading: 0.0023 s/iter. Inference: 0.0375 s/iter. Eval: 0.0569 s/iter. Total: 0.0968 s/iter. ETA=0:10:38\n",
      "\u001b[32m[07/05 22:26:36 d2.evaluation.evaluator]: \u001b[0mInference done 7884/14460. Dataloading: 0.0023 s/iter. Inference: 0.0375 s/iter. Eval: 0.0572 s/iter. Total: 0.0971 s/iter. ETA=0:10:38\n",
      "\u001b[32m[07/05 22:26:41 d2.evaluation.evaluator]: \u001b[0mInference done 7909/14460. Dataloading: 0.0023 s/iter. Inference: 0.0375 s/iter. Eval: 0.0575 s/iter. Total: 0.0974 s/iter. ETA=0:10:38\n",
      "\u001b[32m[07/05 22:26:46 d2.evaluation.evaluator]: \u001b[0mInference done 7965/14460. Dataloading: 0.0023 s/iter. Inference: 0.0375 s/iter. Eval: 0.0574 s/iter. Total: 0.0974 s/iter. ETA=0:10:32\n",
      "\u001b[32m[07/05 22:26:51 d2.evaluation.evaluator]: \u001b[0mInference done 8030/14460. Dataloading: 0.0023 s/iter. Inference: 0.0375 s/iter. Eval: 0.0573 s/iter. Total: 0.0972 s/iter. ETA=0:10:25\n",
      "\u001b[32m[07/05 22:26:56 d2.evaluation.evaluator]: \u001b[0mInference done 8095/14460. Dataloading: 0.0023 s/iter. Inference: 0.0375 s/iter. Eval: 0.0572 s/iter. Total: 0.0971 s/iter. ETA=0:10:17\n",
      "\u001b[32m[07/05 22:27:01 d2.evaluation.evaluator]: \u001b[0mInference done 8159/14460. Dataloading: 0.0023 s/iter. Inference: 0.0375 s/iter. Eval: 0.0570 s/iter. Total: 0.0969 s/iter. ETA=0:10:10\n",
      "\u001b[32m[07/05 22:27:06 d2.evaluation.evaluator]: \u001b[0mInference done 8224/14460. Dataloading: 0.0023 s/iter. Inference: 0.0375 s/iter. Eval: 0.0569 s/iter. Total: 0.0968 s/iter. ETA=0:10:03\n",
      "\u001b[32m[07/05 22:27:11 d2.evaluation.evaluator]: \u001b[0mInference done 8288/14460. Dataloading: 0.0023 s/iter. Inference: 0.0374 s/iter. Eval: 0.0568 s/iter. Total: 0.0966 s/iter. ETA=0:09:56\n",
      "\u001b[32m[07/05 22:27:16 d2.evaluation.evaluator]: \u001b[0mInference done 8353/14460. Dataloading: 0.0023 s/iter. Inference: 0.0374 s/iter. Eval: 0.0566 s/iter. Total: 0.0965 s/iter. ETA=0:09:49\n",
      "\u001b[32m[07/05 22:27:21 d2.evaluation.evaluator]: \u001b[0mInference done 8420/14460. Dataloading: 0.0023 s/iter. Inference: 0.0374 s/iter. Eval: 0.0565 s/iter. Total: 0.0963 s/iter. ETA=0:09:41\n",
      "\u001b[32m[07/05 22:27:26 d2.evaluation.evaluator]: \u001b[0mInference done 8485/14460. Dataloading: 0.0023 s/iter. Inference: 0.0374 s/iter. Eval: 0.0564 s/iter. Total: 0.0962 s/iter. ETA=0:09:34\n",
      "\u001b[32m[07/05 22:27:31 d2.evaluation.evaluator]: \u001b[0mInference done 8550/14460. Dataloading: 0.0023 s/iter. Inference: 0.0374 s/iter. Eval: 0.0562 s/iter. Total: 0.0960 s/iter. ETA=0:09:27\n",
      "\u001b[32m[07/05 22:27:36 d2.evaluation.evaluator]: \u001b[0mInference done 8614/14460. Dataloading: 0.0023 s/iter. Inference: 0.0374 s/iter. Eval: 0.0561 s/iter. Total: 0.0959 s/iter. ETA=0:09:20\n",
      "\u001b[32m[07/05 22:27:41 d2.evaluation.evaluator]: \u001b[0mInference done 8678/14460. Dataloading: 0.0023 s/iter. Inference: 0.0374 s/iter. Eval: 0.0560 s/iter. Total: 0.0958 s/iter. ETA=0:09:13\n",
      "\u001b[32m[07/05 22:27:46 d2.evaluation.evaluator]: \u001b[0mInference done 8741/14460. Dataloading: 0.0023 s/iter. Inference: 0.0373 s/iter. Eval: 0.0559 s/iter. Total: 0.0957 s/iter. ETA=0:09:07\n",
      "\u001b[32m[07/05 22:27:51 d2.evaluation.evaluator]: \u001b[0mInference done 8804/14460. Dataloading: 0.0023 s/iter. Inference: 0.0373 s/iter. Eval: 0.0558 s/iter. Total: 0.0955 s/iter. ETA=0:09:00\n",
      "\u001b[32m[07/05 22:27:56 d2.evaluation.evaluator]: \u001b[0mInference done 8867/14460. Dataloading: 0.0023 s/iter. Inference: 0.0373 s/iter. Eval: 0.0557 s/iter. Total: 0.0954 s/iter. ETA=0:08:53\n",
      "\u001b[32m[07/05 22:28:01 d2.evaluation.evaluator]: \u001b[0mInference done 8930/14460. Dataloading: 0.0023 s/iter. Inference: 0.0373 s/iter. Eval: 0.0556 s/iter. Total: 0.0953 s/iter. ETA=0:08:47\n",
      "\u001b[32m[07/05 22:28:06 d2.evaluation.evaluator]: \u001b[0mInference done 8994/14460. Dataloading: 0.0023 s/iter. Inference: 0.0373 s/iter. Eval: 0.0555 s/iter. Total: 0.0952 s/iter. ETA=0:08:40\n",
      "\u001b[32m[07/05 22:28:11 d2.evaluation.evaluator]: \u001b[0mInference done 9057/14460. Dataloading: 0.0023 s/iter. Inference: 0.0373 s/iter. Eval: 0.0554 s/iter. Total: 0.0951 s/iter. ETA=0:08:33\n",
      "\u001b[32m[07/05 22:28:16 d2.evaluation.evaluator]: \u001b[0mInference done 9120/14460. Dataloading: 0.0023 s/iter. Inference: 0.0373 s/iter. Eval: 0.0553 s/iter. Total: 0.0950 s/iter. ETA=0:08:27\n",
      "\u001b[32m[07/05 22:28:21 d2.evaluation.evaluator]: \u001b[0mInference done 9183/14460. Dataloading: 0.0023 s/iter. Inference: 0.0372 s/iter. Eval: 0.0552 s/iter. Total: 0.0949 s/iter. ETA=0:08:20\n",
      "\u001b[32m[07/05 22:28:26 d2.evaluation.evaluator]: \u001b[0mInference done 9246/14460. Dataloading: 0.0023 s/iter. Inference: 0.0372 s/iter. Eval: 0.0551 s/iter. Total: 0.0948 s/iter. ETA=0:08:14\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/05 22:28:32 d2.evaluation.evaluator]: \u001b[0mInference done 9309/14460. Dataloading: 0.0023 s/iter. Inference: 0.0372 s/iter. Eval: 0.0550 s/iter. Total: 0.0947 s/iter. ETA=0:08:07\n",
      "\u001b[32m[07/05 22:28:37 d2.evaluation.evaluator]: \u001b[0mInference done 9371/14460. Dataloading: 0.0023 s/iter. Inference: 0.0372 s/iter. Eval: 0.0550 s/iter. Total: 0.0946 s/iter. ETA=0:08:01\n",
      "\u001b[32m[07/05 22:28:42 d2.evaluation.evaluator]: \u001b[0mInference done 9433/14460. Dataloading: 0.0023 s/iter. Inference: 0.0372 s/iter. Eval: 0.0549 s/iter. Total: 0.0945 s/iter. ETA=0:07:55\n",
      "\u001b[32m[07/05 22:28:47 d2.evaluation.evaluator]: \u001b[0mInference done 9498/14460. Dataloading: 0.0023 s/iter. Inference: 0.0372 s/iter. Eval: 0.0548 s/iter. Total: 0.0944 s/iter. ETA=0:07:48\n",
      "\u001b[32m[07/05 22:28:52 d2.evaluation.evaluator]: \u001b[0mInference done 9564/14460. Dataloading: 0.0023 s/iter. Inference: 0.0372 s/iter. Eval: 0.0547 s/iter. Total: 0.0943 s/iter. ETA=0:07:41\n",
      "\u001b[32m[07/05 22:28:57 d2.evaluation.evaluator]: \u001b[0mInference done 9630/14460. Dataloading: 0.0023 s/iter. Inference: 0.0372 s/iter. Eval: 0.0545 s/iter. Total: 0.0941 s/iter. ETA=0:07:34\n",
      "\u001b[32m[07/05 22:29:02 d2.evaluation.evaluator]: \u001b[0mInference done 9696/14460. Dataloading: 0.0023 s/iter. Inference: 0.0372 s/iter. Eval: 0.0544 s/iter. Total: 0.0940 s/iter. ETA=0:07:27\n",
      "\u001b[32m[07/05 22:29:07 d2.evaluation.evaluator]: \u001b[0mInference done 9760/14460. Dataloading: 0.0023 s/iter. Inference: 0.0371 s/iter. Eval: 0.0543 s/iter. Total: 0.0939 s/iter. ETA=0:07:21\n",
      "\u001b[32m[07/05 22:29:12 d2.evaluation.evaluator]: \u001b[0mInference done 9826/14460. Dataloading: 0.0023 s/iter. Inference: 0.0371 s/iter. Eval: 0.0542 s/iter. Total: 0.0938 s/iter. ETA=0:07:14\n",
      "\u001b[32m[07/05 22:29:17 d2.evaluation.evaluator]: \u001b[0mInference done 9890/14460. Dataloading: 0.0023 s/iter. Inference: 0.0371 s/iter. Eval: 0.0541 s/iter. Total: 0.0937 s/iter. ETA=0:07:08\n",
      "\u001b[32m[07/05 22:29:22 d2.evaluation.evaluator]: \u001b[0mInference done 9955/14460. Dataloading: 0.0023 s/iter. Inference: 0.0371 s/iter. Eval: 0.0541 s/iter. Total: 0.0936 s/iter. ETA=0:07:01\n",
      "\u001b[32m[07/05 22:29:27 d2.evaluation.evaluator]: \u001b[0mInference done 10021/14460. Dataloading: 0.0023 s/iter. Inference: 0.0371 s/iter. Eval: 0.0540 s/iter. Total: 0.0935 s/iter. ETA=0:06:54\n",
      "\u001b[32m[07/05 22:29:32 d2.evaluation.evaluator]: \u001b[0mInference done 10086/14460. Dataloading: 0.0023 s/iter. Inference: 0.0371 s/iter. Eval: 0.0539 s/iter. Total: 0.0934 s/iter. ETA=0:06:48\n",
      "\u001b[32m[07/05 22:29:37 d2.evaluation.evaluator]: \u001b[0mInference done 10150/14460. Dataloading: 0.0023 s/iter. Inference: 0.0371 s/iter. Eval: 0.0538 s/iter. Total: 0.0933 s/iter. ETA=0:06:42\n",
      "\u001b[32m[07/05 22:29:42 d2.evaluation.evaluator]: \u001b[0mInference done 10216/14460. Dataloading: 0.0024 s/iter. Inference: 0.0371 s/iter. Eval: 0.0537 s/iter. Total: 0.0932 s/iter. ETA=0:06:35\n",
      "\u001b[32m[07/05 22:29:47 d2.evaluation.evaluator]: \u001b[0mInference done 10281/14460. Dataloading: 0.0024 s/iter. Inference: 0.0371 s/iter. Eval: 0.0536 s/iter. Total: 0.0931 s/iter. ETA=0:06:28\n",
      "\u001b[32m[07/05 22:29:52 d2.evaluation.evaluator]: \u001b[0mInference done 10346/14460. Dataloading: 0.0024 s/iter. Inference: 0.0371 s/iter. Eval: 0.0535 s/iter. Total: 0.0930 s/iter. ETA=0:06:22\n",
      "\u001b[32m[07/05 22:29:57 d2.evaluation.evaluator]: \u001b[0mInference done 10411/14460. Dataloading: 0.0024 s/iter. Inference: 0.0370 s/iter. Eval: 0.0534 s/iter. Total: 0.0929 s/iter. ETA=0:06:16\n",
      "\u001b[32m[07/05 22:30:02 d2.evaluation.evaluator]: \u001b[0mInference done 10475/14460. Dataloading: 0.0024 s/iter. Inference: 0.0370 s/iter. Eval: 0.0533 s/iter. Total: 0.0928 s/iter. ETA=0:06:09\n",
      "\u001b[32m[07/05 22:30:07 d2.evaluation.evaluator]: \u001b[0mInference done 10540/14460. Dataloading: 0.0024 s/iter. Inference: 0.0370 s/iter. Eval: 0.0532 s/iter. Total: 0.0927 s/iter. ETA=0:06:03\n",
      "\u001b[32m[07/05 22:30:12 d2.evaluation.evaluator]: \u001b[0mInference done 10605/14460. Dataloading: 0.0024 s/iter. Inference: 0.0370 s/iter. Eval: 0.0532 s/iter. Total: 0.0926 s/iter. ETA=0:05:56\n",
      "\u001b[32m[07/05 22:30:17 d2.evaluation.evaluator]: \u001b[0mInference done 10669/14460. Dataloading: 0.0024 s/iter. Inference: 0.0370 s/iter. Eval: 0.0531 s/iter. Total: 0.0925 s/iter. ETA=0:05:50\n",
      "\u001b[32m[07/05 22:30:22 d2.evaluation.evaluator]: \u001b[0mInference done 10734/14460. Dataloading: 0.0024 s/iter. Inference: 0.0370 s/iter. Eval: 0.0530 s/iter. Total: 0.0924 s/iter. ETA=0:05:44\n",
      "\u001b[32m[07/05 22:30:27 d2.evaluation.evaluator]: \u001b[0mInference done 10800/14460. Dataloading: 0.0024 s/iter. Inference: 0.0370 s/iter. Eval: 0.0529 s/iter. Total: 0.0923 s/iter. ETA=0:05:37\n",
      "\u001b[32m[07/05 22:30:32 d2.evaluation.evaluator]: \u001b[0mInference done 10867/14460. Dataloading: 0.0024 s/iter. Inference: 0.0370 s/iter. Eval: 0.0528 s/iter. Total: 0.0922 s/iter. ETA=0:05:31\n",
      "\u001b[32m[07/05 22:30:37 d2.evaluation.evaluator]: \u001b[0mInference done 10934/14460. Dataloading: 0.0024 s/iter. Inference: 0.0370 s/iter. Eval: 0.0527 s/iter. Total: 0.0921 s/iter. ETA=0:05:24\n",
      "\u001b[32m[07/05 22:30:42 d2.evaluation.evaluator]: \u001b[0mInference done 11000/14460. Dataloading: 0.0024 s/iter. Inference: 0.0370 s/iter. Eval: 0.0526 s/iter. Total: 0.0920 s/iter. ETA=0:05:18\n",
      "\u001b[32m[07/05 22:30:47 d2.evaluation.evaluator]: \u001b[0mInference done 11067/14460. Dataloading: 0.0024 s/iter. Inference: 0.0370 s/iter. Eval: 0.0525 s/iter. Total: 0.0919 s/iter. ETA=0:05:11\n",
      "\u001b[32m[07/05 22:30:53 d2.evaluation.evaluator]: \u001b[0mInference done 11134/14460. Dataloading: 0.0024 s/iter. Inference: 0.0369 s/iter. Eval: 0.0525 s/iter. Total: 0.0918 s/iter. ETA=0:05:05\n",
      "\u001b[32m[07/05 22:30:58 d2.evaluation.evaluator]: \u001b[0mInference done 11201/14460. Dataloading: 0.0024 s/iter. Inference: 0.0369 s/iter. Eval: 0.0524 s/iter. Total: 0.0917 s/iter. ETA=0:04:58\n",
      "\u001b[32m[07/05 22:31:03 d2.evaluation.evaluator]: \u001b[0mInference done 11267/14460. Dataloading: 0.0024 s/iter. Inference: 0.0369 s/iter. Eval: 0.0523 s/iter. Total: 0.0916 s/iter. ETA=0:04:52\n",
      "\u001b[32m[07/05 22:31:08 d2.evaluation.evaluator]: \u001b[0mInference done 11334/14460. Dataloading: 0.0024 s/iter. Inference: 0.0369 s/iter. Eval: 0.0522 s/iter. Total: 0.0915 s/iter. ETA=0:04:46\n",
      "\u001b[32m[07/05 22:31:13 d2.evaluation.evaluator]: \u001b[0mInference done 11400/14460. Dataloading: 0.0024 s/iter. Inference: 0.0369 s/iter. Eval: 0.0521 s/iter. Total: 0.0915 s/iter. ETA=0:04:39\n",
      "\u001b[32m[07/05 22:31:18 d2.evaluation.evaluator]: \u001b[0mInference done 11466/14460. Dataloading: 0.0024 s/iter. Inference: 0.0369 s/iter. Eval: 0.0520 s/iter. Total: 0.0914 s/iter. ETA=0:04:33\n",
      "\u001b[32m[07/05 22:31:23 d2.evaluation.evaluator]: \u001b[0mInference done 11534/14460. Dataloading: 0.0024 s/iter. Inference: 0.0369 s/iter. Eval: 0.0519 s/iter. Total: 0.0913 s/iter. ETA=0:04:27\n",
      "\u001b[32m[07/05 22:31:28 d2.evaluation.evaluator]: \u001b[0mInference done 11600/14460. Dataloading: 0.0024 s/iter. Inference: 0.0369 s/iter. Eval: 0.0519 s/iter. Total: 0.0912 s/iter. ETA=0:04:20\n",
      "\u001b[32m[07/05 22:31:33 d2.evaluation.evaluator]: \u001b[0mInference done 11667/14460. Dataloading: 0.0024 s/iter. Inference: 0.0369 s/iter. Eval: 0.0518 s/iter. Total: 0.0911 s/iter. ETA=0:04:14\n",
      "\u001b[32m[07/05 22:31:38 d2.evaluation.evaluator]: \u001b[0mInference done 11734/14460. Dataloading: 0.0024 s/iter. Inference: 0.0369 s/iter. Eval: 0.0517 s/iter. Total: 0.0910 s/iter. ETA=0:04:08\n",
      "\u001b[32m[07/05 22:31:43 d2.evaluation.evaluator]: \u001b[0mInference done 11801/14460. Dataloading: 0.0024 s/iter. Inference: 0.0369 s/iter. Eval: 0.0516 s/iter. Total: 0.0909 s/iter. ETA=0:04:01\n",
      "\u001b[32m[07/05 22:31:48 d2.evaluation.evaluator]: \u001b[0mInference done 11868/14460. Dataloading: 0.0024 s/iter. Inference: 0.0369 s/iter. Eval: 0.0515 s/iter. Total: 0.0908 s/iter. ETA=0:03:55\n",
      "\u001b[32m[07/05 22:31:53 d2.evaluation.evaluator]: \u001b[0mInference done 11935/14460. Dataloading: 0.0024 s/iter. Inference: 0.0368 s/iter. Eval: 0.0514 s/iter. Total: 0.0907 s/iter. ETA=0:03:49\n",
      "\u001b[32m[07/05 22:31:58 d2.evaluation.evaluator]: \u001b[0mInference done 11998/14460. Dataloading: 0.0024 s/iter. Inference: 0.0369 s/iter. Eval: 0.0514 s/iter. Total: 0.0907 s/iter. ETA=0:03:43\n",
      "\u001b[32m[07/05 22:32:03 d2.evaluation.evaluator]: \u001b[0mInference done 12063/14460. Dataloading: 0.0024 s/iter. Inference: 0.0369 s/iter. Eval: 0.0513 s/iter. Total: 0.0906 s/iter. ETA=0:03:37\n",
      "\u001b[32m[07/05 22:32:08 d2.evaluation.evaluator]: \u001b[0mInference done 12129/14460. Dataloading: 0.0024 s/iter. Inference: 0.0368 s/iter. Eval: 0.0512 s/iter. Total: 0.0905 s/iter. ETA=0:03:31\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/05 22:32:13 d2.evaluation.evaluator]: \u001b[0mInference done 12195/14460. Dataloading: 0.0024 s/iter. Inference: 0.0368 s/iter. Eval: 0.0512 s/iter. Total: 0.0904 s/iter. ETA=0:03:24\n",
      "\u001b[32m[07/05 22:32:18 d2.evaluation.evaluator]: \u001b[0mInference done 12261/14460. Dataloading: 0.0024 s/iter. Inference: 0.0368 s/iter. Eval: 0.0511 s/iter. Total: 0.0904 s/iter. ETA=0:03:18\n",
      "\u001b[32m[07/05 22:32:23 d2.evaluation.evaluator]: \u001b[0mInference done 12327/14460. Dataloading: 0.0024 s/iter. Inference: 0.0368 s/iter. Eval: 0.0510 s/iter. Total: 0.0903 s/iter. ETA=0:03:12\n",
      "\u001b[32m[07/05 22:32:28 d2.evaluation.evaluator]: \u001b[0mInference done 12394/14460. Dataloading: 0.0024 s/iter. Inference: 0.0368 s/iter. Eval: 0.0510 s/iter. Total: 0.0902 s/iter. ETA=0:03:06\n",
      "\u001b[32m[07/05 22:32:33 d2.evaluation.evaluator]: \u001b[0mInference done 12460/14460. Dataloading: 0.0024 s/iter. Inference: 0.0368 s/iter. Eval: 0.0509 s/iter. Total: 0.0901 s/iter. ETA=0:03:00\n",
      "\u001b[32m[07/05 22:32:38 d2.evaluation.evaluator]: \u001b[0mInference done 12525/14460. Dataloading: 0.0024 s/iter. Inference: 0.0368 s/iter. Eval: 0.0508 s/iter. Total: 0.0901 s/iter. ETA=0:02:54\n",
      "\u001b[32m[07/05 22:32:43 d2.evaluation.evaluator]: \u001b[0mInference done 12591/14460. Dataloading: 0.0024 s/iter. Inference: 0.0368 s/iter. Eval: 0.0508 s/iter. Total: 0.0900 s/iter. ETA=0:02:48\n",
      "\u001b[32m[07/05 22:32:48 d2.evaluation.evaluator]: \u001b[0mInference done 12657/14460. Dataloading: 0.0024 s/iter. Inference: 0.0368 s/iter. Eval: 0.0507 s/iter. Total: 0.0899 s/iter. ETA=0:02:42\n",
      "\u001b[32m[07/05 22:32:53 d2.evaluation.evaluator]: \u001b[0mInference done 12721/14460. Dataloading: 0.0024 s/iter. Inference: 0.0368 s/iter. Eval: 0.0507 s/iter. Total: 0.0899 s/iter. ETA=0:02:36\n",
      "\u001b[32m[07/05 22:32:58 d2.evaluation.evaluator]: \u001b[0mInference done 12786/14460. Dataloading: 0.0024 s/iter. Inference: 0.0368 s/iter. Eval: 0.0506 s/iter. Total: 0.0898 s/iter. ETA=0:02:30\n",
      "\u001b[32m[07/05 22:33:04 d2.evaluation.evaluator]: \u001b[0mInference done 12851/14460. Dataloading: 0.0024 s/iter. Inference: 0.0368 s/iter. Eval: 0.0505 s/iter. Total: 0.0898 s/iter. ETA=0:02:24\n",
      "\u001b[32m[07/05 22:33:09 d2.evaluation.evaluator]: \u001b[0mInference done 12915/14460. Dataloading: 0.0024 s/iter. Inference: 0.0368 s/iter. Eval: 0.0505 s/iter. Total: 0.0897 s/iter. ETA=0:02:18\n",
      "\u001b[32m[07/05 22:33:14 d2.evaluation.evaluator]: \u001b[0mInference done 12979/14460. Dataloading: 0.0024 s/iter. Inference: 0.0368 s/iter. Eval: 0.0504 s/iter. Total: 0.0896 s/iter. ETA=0:02:12\n",
      "\u001b[32m[07/05 22:33:19 d2.evaluation.evaluator]: \u001b[0mInference done 13044/14460. Dataloading: 0.0024 s/iter. Inference: 0.0368 s/iter. Eval: 0.0504 s/iter. Total: 0.0896 s/iter. ETA=0:02:06\n",
      "\u001b[32m[07/05 22:33:24 d2.evaluation.evaluator]: \u001b[0mInference done 13110/14460. Dataloading: 0.0024 s/iter. Inference: 0.0367 s/iter. Eval: 0.0503 s/iter. Total: 0.0895 s/iter. ETA=0:02:00\n",
      "\u001b[32m[07/05 22:33:29 d2.evaluation.evaluator]: \u001b[0mInference done 13175/14460. Dataloading: 0.0024 s/iter. Inference: 0.0367 s/iter. Eval: 0.0503 s/iter. Total: 0.0895 s/iter. ETA=0:01:54\n",
      "\u001b[32m[07/05 22:33:34 d2.evaluation.evaluator]: \u001b[0mInference done 13240/14460. Dataloading: 0.0024 s/iter. Inference: 0.0367 s/iter. Eval: 0.0502 s/iter. Total: 0.0894 s/iter. ETA=0:01:49\n",
      "\u001b[32m[07/05 22:33:39 d2.evaluation.evaluator]: \u001b[0mInference done 13305/14460. Dataloading: 0.0024 s/iter. Inference: 0.0367 s/iter. Eval: 0.0502 s/iter. Total: 0.0893 s/iter. ETA=0:01:43\n",
      "\u001b[32m[07/05 22:33:44 d2.evaluation.evaluator]: \u001b[0mInference done 13370/14460. Dataloading: 0.0024 s/iter. Inference: 0.0367 s/iter. Eval: 0.0501 s/iter. Total: 0.0893 s/iter. ETA=0:01:37\n",
      "\u001b[32m[07/05 22:33:49 d2.evaluation.evaluator]: \u001b[0mInference done 13434/14460. Dataloading: 0.0024 s/iter. Inference: 0.0367 s/iter. Eval: 0.0501 s/iter. Total: 0.0892 s/iter. ETA=0:01:31\n",
      "\u001b[32m[07/05 22:33:54 d2.evaluation.evaluator]: \u001b[0mInference done 13498/14460. Dataloading: 0.0024 s/iter. Inference: 0.0367 s/iter. Eval: 0.0500 s/iter. Total: 0.0892 s/iter. ETA=0:01:25\n",
      "\u001b[32m[07/05 22:33:59 d2.evaluation.evaluator]: \u001b[0mInference done 13562/14460. Dataloading: 0.0024 s/iter. Inference: 0.0367 s/iter. Eval: 0.0500 s/iter. Total: 0.0891 s/iter. ETA=0:01:20\n",
      "\u001b[32m[07/05 22:34:04 d2.evaluation.evaluator]: \u001b[0mInference done 13626/14460. Dataloading: 0.0024 s/iter. Inference: 0.0367 s/iter. Eval: 0.0499 s/iter. Total: 0.0891 s/iter. ETA=0:01:14\n",
      "\u001b[32m[07/05 22:34:09 d2.evaluation.evaluator]: \u001b[0mInference done 13690/14460. Dataloading: 0.0024 s/iter. Inference: 0.0367 s/iter. Eval: 0.0499 s/iter. Total: 0.0890 s/iter. ETA=0:01:08\n",
      "\u001b[32m[07/05 22:34:14 d2.evaluation.evaluator]: \u001b[0mInference done 13753/14460. Dataloading: 0.0024 s/iter. Inference: 0.0367 s/iter. Eval: 0.0499 s/iter. Total: 0.0890 s/iter. ETA=0:01:02\n",
      "\u001b[32m[07/05 22:34:19 d2.evaluation.evaluator]: \u001b[0mInference done 13816/14460. Dataloading: 0.0024 s/iter. Inference: 0.0367 s/iter. Eval: 0.0498 s/iter. Total: 0.0889 s/iter. ETA=0:00:57\n",
      "\u001b[32m[07/05 22:34:24 d2.evaluation.evaluator]: \u001b[0mInference done 13877/14460. Dataloading: 0.0024 s/iter. Inference: 0.0367 s/iter. Eval: 0.0498 s/iter. Total: 0.0889 s/iter. ETA=0:00:51\n",
      "\u001b[32m[07/05 22:34:29 d2.evaluation.evaluator]: \u001b[0mInference done 13943/14460. Dataloading: 0.0024 s/iter. Inference: 0.0367 s/iter. Eval: 0.0497 s/iter. Total: 0.0889 s/iter. ETA=0:00:45\n",
      "\u001b[32m[07/05 22:34:34 d2.evaluation.evaluator]: \u001b[0mInference done 14008/14460. Dataloading: 0.0024 s/iter. Inference: 0.0367 s/iter. Eval: 0.0497 s/iter. Total: 0.0888 s/iter. ETA=0:00:40\n",
      "\u001b[32m[07/05 22:34:39 d2.evaluation.evaluator]: \u001b[0mInference done 14072/14460. Dataloading: 0.0024 s/iter. Inference: 0.0367 s/iter. Eval: 0.0497 s/iter. Total: 0.0888 s/iter. ETA=0:00:34\n",
      "\u001b[32m[07/05 22:34:44 d2.evaluation.evaluator]: \u001b[0mInference done 14137/14460. Dataloading: 0.0024 s/iter. Inference: 0.0367 s/iter. Eval: 0.0496 s/iter. Total: 0.0887 s/iter. ETA=0:00:28\n",
      "\u001b[32m[07/05 22:34:49 d2.evaluation.evaluator]: \u001b[0mInference done 14202/14460. Dataloading: 0.0024 s/iter. Inference: 0.0367 s/iter. Eval: 0.0496 s/iter. Total: 0.0887 s/iter. ETA=0:00:22\n",
      "\u001b[32m[07/05 22:34:54 d2.evaluation.evaluator]: \u001b[0mInference done 14266/14460. Dataloading: 0.0024 s/iter. Inference: 0.0366 s/iter. Eval: 0.0495 s/iter. Total: 0.0886 s/iter. ETA=0:00:17\n",
      "\u001b[32m[07/05 22:34:59 d2.evaluation.evaluator]: \u001b[0mInference done 14334/14460. Dataloading: 0.0024 s/iter. Inference: 0.0366 s/iter. Eval: 0.0495 s/iter. Total: 0.0885 s/iter. ETA=0:00:11\n",
      "\u001b[32m[07/05 22:35:04 d2.evaluation.evaluator]: \u001b[0mInference done 14401/14460. Dataloading: 0.0024 s/iter. Inference: 0.0366 s/iter. Eval: 0.0494 s/iter. Total: 0.0885 s/iter. ETA=0:00:05\n",
      "\u001b[32m[07/05 22:35:09 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:21:18.279608 (0.088432 s / iter per device, on 1 devices)\n",
      "\u001b[32m[07/05 22:35:09 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:08:49 (0.036632 s / iter per device, on 1 devices)\n",
      "\u001b[32m[07/05 22:35:11 d2.evaluation.sem_seg_evaluation]: \u001b[0mOrderedDict([('sem_seg', {'mIoU': 57.373962412497804, 'fwIoU': 82.66305498153986, 'IoU-Unlabeled': nan, 'IoU-Building': 77.993219766944, 'IoU-Fence': 31.77960612201226, 'IoU-Pedestrian': 71.02204708074348, 'IoU-Pole': 52.971897204963206, 'IoU-Road': 95.5866320365371, 'IoU-SideWalk': 70.78720896052103, 'IoU-Vegetation': 72.05380549819847, 'IoU-Vehicles': 83.46687908060395, 'IoU-Wall': 56.31784427013006, 'IoU-TrafficSign': 58.28732123566357, 'IoU-Sky': 84.89646155619597, 'IoU-TrafficLight': 58.12707660486816, 'IoU-Terrain': 24.44226382238454, 'IoU-ConstructionVehicle': 56.10233574354492, 'IoU-workzone_object': 66.41778825824619, 'IoU-Detour': 15.104973770905794, 'mACC': 72.6368594385374, 'pACC': 90.09976704678824, 'ACC-Unlabeled': nan, 'ACC-Building': 95.12893358528687, 'ACC-Fence': 52.34829496584621, 'ACC-Pedestrian': 84.32163251825011, 'ACC-Pole': 62.29406134822235, 'ACC-Road': 97.70065532422947, 'ACC-SideWalk': 85.56229728612573, 'ACC-Vegetation': 82.4611282242156, 'ACC-Vehicles': 91.46592696096825, 'ACC-Wall': 62.59500911651372, 'ACC-TrafficSign': 67.794748142962, 'ACC-Sky': 90.091692788157, 'ACC-TrafficLight': 67.64196965958016, 'ACC-Terrain': 25.474894880300408, 'ACC-ConstructionVehicle': 94.49825766654332, 'ACC-workzone_object': 86.26595525562556, 'ACC-Detour': 16.54429329377153})])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/05 22:35:11 d2.engine.defaults]: \u001b[0mEvaluation results for combined_all_night_val in csv format:\n",
      "\u001b[32m[07/05 22:35:11 d2.evaluation.testing]: \u001b[0mcopypaste: Task: sem_seg\n",
      "\u001b[32m[07/05 22:35:11 d2.evaluation.testing]: \u001b[0mcopypaste: mIoU,fwIoU,mACC,pACC\n",
      "\u001b[32m[07/05 22:35:11 d2.evaluation.testing]: \u001b[0mcopypaste: 57.3740,82.6631,72.6369,90.0998\n"
     ]
    }
   ],
   "source": [
    "trainer_both = Detectron2Trainer('combined_all_night_train', 'combined_all_night_val', output_folder='./output_both_40k')\n",
    "trainer_both.test()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fca1518",
   "metadata": {
    "id": "eCcw0VZ-Bzig"
   },
   "source": [
    "## 3. Model trained on all with carla night"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "9baa8d09",
   "metadata": {
    "id": "AhoGPVnKHiMw"
   },
   "outputs": [],
   "source": [
    "#trainer_all = Detectron2Trainer('combined_all_night_train', 'carla_rain_val', output_folder='./output_part_night_40k')\n",
    "#trainer_all.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "024cd308",
   "metadata": {
    "id": "67qzQSBbJK3G"
   },
   "outputs": [],
   "source": [
    "#trainer_all = Detectron2Trainer('combined_all_night_train', 'carla_night_rain_val', output_folder='./output_part_night_40k')\n",
    "#trainer_all.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "46a29dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainer_all = Detectron2Trainer('combined_all_night_train', 'cityscapes_rain_val', output_folder='./output_part_night_40k')\n",
    "#trainer_all.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "28a5c0dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainer_all = Detectron2Trainer('combined_all_night_train', 'cityscapes_clear_val', output_folder='./output_part_night_40k')\n",
    "#trainer_all.test()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f3745d",
   "metadata": {
    "id": "8BPrv2unBu_5",
    "tags": []
   },
   "source": [
    "## 2. Model trained on all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "2dcafb64",
   "metadata": {
    "id": "07d49a7f"
   },
   "outputs": [],
   "source": [
    "# trainer_all = Detectron2Trainer('combined_all_train', 'combined_all_val', output_folder='./output_combined_all_40k')\n",
    "# trainer_all.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "5c4a5332",
   "metadata": {
    "id": "5LBmVarGBljx"
   },
   "outputs": [],
   "source": [
    "# trainer_all = Detectron2Trainer('combined_all_train', 'combined_clear_val', output_folder='./output_combined_all_40k')\n",
    "# trainer_all.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "9ba149ab",
   "metadata": {
    "id": "qyXzC8KvEBHx"
   },
   "outputs": [],
   "source": [
    "# trainer_all = Detectron2Trainer('combined_all_train', 'combined_rain_val', output_folder='./output_combined_all_40k')\n",
    "# trainer_all.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "1eea3f94",
   "metadata": {
    "id": "AhoGPVnKHiMw"
   },
   "outputs": [],
   "source": [
    "# trainer_all = Detectron2Trainer('combined_all_train', 'carla_rain_val', output_folder='./output_combined_all_40k')\n",
    "# trainer_all.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "659b4030",
   "metadata": {
    "id": "67qzQSBbJK3G"
   },
   "outputs": [],
   "source": [
    "# trainer_all = Detectron2Trainer('combined_all_train', 'cityscapes_rain_val', output_folder='./output_combined_all_40k')\n",
    "# trainer_all.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "403e77f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer_all = Detectron2Trainer('combined_all_train', 'carla_clear_val', output_folder='./output_combined_all_40k')\n",
    "# trainer_all.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "aea3e23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer_all = Detectron2Trainer('combined_all_train', 'carla_night_rain_val', output_folder='./output_combined_all_40k')\n",
    "# trainer_all.test()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9367dd3b",
   "metadata": {
    "id": "eCcw0VZ-Bzig"
   },
   "source": [
    "## 1. Model trained on clear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "8aa5cac1",
   "metadata": {
    "id": "PlZ3ag3oEJoE"
   },
   "outputs": [],
   "source": [
    "#trainer_clear = Detectron2Trainer('combined_clear_train', 'combined_all_val', output_folder='./output_combined_clear_20k')\n",
    "#trainer_clear.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "2797baa4",
   "metadata": {
    "id": "Pca4DugyR6wJ"
   },
   "outputs": [],
   "source": [
    "#trainer_clear = Detectron2Trainer('combined_clear_train', 'combined_clear_val', output_folder='./output_combined_clear_20k')\n",
    "#trainer_clear.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "fe2e6053",
   "metadata": {
    "id": "RHbt_C-U0bzO"
   },
   "outputs": [],
   "source": [
    "#trainer_clear = Detectron2Trainer('combined_clear_train', 'combined_rain_val', output_folder='./output_combined_clear_20k')\n",
    "#trainer_clear.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "08aed8a8",
   "metadata": {
    "id": "AM8SDAduEQc0"
   },
   "outputs": [],
   "source": [
    "#trainer_clear = Detectron2Trainer('combined_clear_train', 'carla_rain_val', output_folder='./output_combined_clear_20k')\n",
    "#trainer_clear.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "e7d1f01e",
   "metadata": {
    "id": "C4geX49UE2Kn"
   },
   "outputs": [],
   "source": [
    "#trainer_clear = Detectron2Trainer('combined_clear_train', 'cityscapes_rain_val', output_folder='./output_combined_clear_20k')\n",
    "#trainer_clear.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "63f9b37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainer_clear = Detectron2Trainer('combined_clear_train', 'carla_clear_val', output_folder='./output_combined_clear_20k')\n",
    "#trainer_clear.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "72c3f667",
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainer_clear = Detectron2Trainer('combined_clear_train', 'carla_night_rain_val', output_folder='./output_combined_clear_20k')\n",
    "#trainer_clear.test()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "KVqmnxQOn4Nm"
   ],
   "name": "detectron2_trainer.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
