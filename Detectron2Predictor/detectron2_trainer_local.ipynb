{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "34e6eddb",
   "metadata": {
    "id": "-4OJq6c4oPqR"
   },
   "source": [
    "# Google Colab initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8fad179",
   "metadata": {
    "id": "7150dd93"
   },
   "outputs": [],
   "source": [
    "# !pip install pyyaml==5.1\n",
    "\n",
    "# import torch\n",
    "# TORCH_VERSION = \".\".join(torch.__version__.split(\".\")[:2])\n",
    "# CUDA_VERSION = torch.__version__.split(\"+\")[-1]\n",
    "# print(\"torch: \", TORCH_VERSION, \"; cuda: \", CUDA_VERSION)\n",
    "# # Install detectron2 that matches the above pytorch version\n",
    "# # See https://detectron2.readthedocs.io/tutorials/install.html for instructions\n",
    "# !pip install detectron2 -f https://dl.fbaipublicfiles.com/detectron2/wheels/$CUDA_VERSION/torch$TORCH_VERSION/index.html > /dev/null \n",
    "# # If there is not yet a detectron2 release that matches the given torch + CUDA version, you need to install a different pytorch.\n",
    "\n",
    "# exit(0)  # After installation, you may need to \"restart runtime\" in Colab. This line can also restart runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "684d6e40",
   "metadata": {
    "id": "868f1a31-1da7-479c-9bd0-35eabef2ad1d"
   },
   "outputs": [],
   "source": [
    "GOOGLE_COLAB = False\n",
    "# GOOGLE_COLAB = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "990c9aee",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1301,
     "status": "ok",
     "timestamp": 1650750032069,
     "user": {
      "displayName": "Tũn Tũn",
      "userId": "10147808466179585969"
     },
     "user_tz": 240
    },
    "id": "73d376c0",
    "outputId": "b5338b24-a47e-44f6-8740-afaef44df672"
   },
   "outputs": [],
   "source": [
    "if GOOGLE_COLAB == True:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fdab6dd6",
   "metadata": {
    "id": "T1wp5irN5qw9"
   },
   "outputs": [],
   "source": [
    "# if GOOGLE_COLAB == True:\n",
    "#     !ls '/content/drive/MyDrive/18744/data/Cityscapes/'\n",
    "\n",
    "#     !mkdir '/content/data/'\n",
    "#     !mkdir '/content/data/Cityscapes/'\n",
    "\n",
    "#     !unzip -n '/content/drive/MyDrive/18744/data/Cityscapes/gtFine_trainvaltest.zip' -d '/content/data/Cityscapes/' > /dev/null\n",
    "#     !unzip -n '/content/drive/MyDrive/18744/data/Cityscapes/leftImg8bit_trainvaltest.zip' -d '/content/data/Cityscapes/' > /dev/null\n",
    "#     !tar -xf '/content/drive/MyDrive/18744/data/Cityscapes/mapped_labels.tar' --skip-old-files --directory '/content/data/Cityscapes/'\n",
    "\n",
    "#     ##################################################\n",
    "\n",
    "#     !ls '/content/drive/MyDrive/18744/data/Carla/packaging/'\n",
    "\n",
    "#     !mkdir '/content/data/'\n",
    "#     !mkdir '/content/data/Carla/'\n",
    "#     !mkdir '/content/data/Carla/packaging/'\n",
    "\n",
    "#     !unzip -n '/content/drive/MyDrive/18744/data/Carla/packaging/package2.zip' -d '/content/data/Carla/packaging/' > /dev/null\n",
    "#     !unzip -n '/content/drive/MyDrive/18744/data/Carla/packaging/package3.zip' -d '/content/data/Carla/packaging/' > /dev/null\n",
    "#     !unzip -n '/content/drive/MyDrive/18744/data/Carla/packaging/package4.zip' -d '/content/data/Carla/packaging/' > /dev/null\n",
    "#     !unzip -n '/content/drive/MyDrive/18744/data/Carla/packaging/package5.zip' -d '/content/data/Carla/packaging/' > /dev/null\n",
    "#     !unzip -n '/content/drive/MyDrive/18744/data/Carla/packaging/package6.zip' -d '/content/data/Carla/packaging/' > /dev/null\n",
    "#     !unzip -n '/content/drive/MyDrive/18744/data/Carla/packaging/package7.zip' -d '/content/data/Carla/packaging/' > /dev/null\n",
    "#     !unzip -n '/content/drive/MyDrive/18744/data/Carla/packaging/package8.zip' -d '/content/data/Carla/packaging/' > /dev/null\n",
    "#     !unzip -n '/content/drive/MyDrive/18744/data/Carla/packaging/package9.zip' -d '/content/data/Carla/packaging/' > /dev/null\n",
    "#     !tar -xf '/content/drive/MyDrive/18744/data/Carla/packaging/semantic_train.tar' --skip-old-files --directory '/content/data/Carla/packaging/'\n",
    "\n",
    "#     ##################################################\n",
    "\n",
    "#     !ls '/content/drive/MyDrive/18744/data/CarlaNight/night_packaging/'\n",
    "\n",
    "#     !mkdir '/content/data/'\n",
    "#     !mkdir '/content/data/CarlaNight/'\n",
    "#     !mkdir '/content/data/CarlaNight/night_packaging/'\n",
    "    \n",
    "#     !tar -xf '/content/drive/MyDrive/18744/data/CarlaNight/night_packaging/package10.tar' --skip-old-files --directory '/content/data/CarlaNight/night_packaging/'\n",
    "#     !tar -xf '/content/drive/MyDrive/18744/data/CarlaNight/night_packaging/package11.tar' --skip-old-files --directory '/content/data/CarlaNight/night_packaging/'\n",
    "\n",
    "#     ##################################################\n",
    "\n",
    "#     !ls '/content/drive/MyDrive/18744/data/RainAddition/train/'\n",
    "\n",
    "#     !mkdir '/content/data/'\n",
    "#     !mkdir '/content/data/RainAddition/'\n",
    "#     !mkdir '/content/data/RainAddition/train/'\n",
    "\n",
    "#     !tar -xf '/content/drive/MyDrive/18744/data/RainAddition/train/1.tar' --skip-old-files --directory '/content/data/RainAddition/train/'\n",
    "#     !tar -xf '/content/drive/MyDrive/18744/data/RainAddition/train/2.tar' --skip-old-files --directory '/content/data/RainAddition/train/'\n",
    "#     !tar -xf '/content/drive/MyDrive/18744/data/RainAddition/train/3.tar' --skip-old-files --directory '/content/data/RainAddition/train/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d1b4bf2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1650750032070,
     "user": {
      "displayName": "Tũn Tũn",
      "userId": "10147808466179585969"
     },
     "user_tz": 240
    },
    "id": "2854f46b",
    "outputId": "88560d5b-3976-4d4a-96a0-baf4c1024b23"
   },
   "outputs": [],
   "source": [
    "if GOOGLE_COLAB == True:\n",
    "    !ls '/content/drive/MyDrive/18744/data/'\n",
    "    %cd '/content/drive/MyDrive/18744/Robust-Vision-in-Rain/Detectron2Predictor/'\n",
    "    !ls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50cf16c0",
   "metadata": {
    "id": "vOI__nJ2oiYZ"
   },
   "source": [
    "# Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4dbc1b08",
   "metadata": {
    "id": "78860d72-d62b-442a-aac9-b7499a37d343"
   },
   "outputs": [],
   "source": [
    "main_dir = './'\n",
    "#data_dir = '/home/tunx404/Miscellaneous/data/' # Local Jupyter\n",
    "data_dir = '/home/gregory/Documents/RainPerception/'\n",
    "data_dir = '/home/gregory/Documents/RainPerception/RainRemoval/Copied/generated_tests/'\n",
    "data_dir = '/home/gregory/Documents/RainPerception/RainRemoval/Copied/generated_test_both/'\n",
    "\n",
    "if GOOGLE_COLAB == True:\n",
    "    # data_dir = '/content/drive/MyDrive/18744/data/'\n",
    "    data_dir = '/content/data/'\n",
    "    \n",
    "DEBUG = False\n",
    "DEBUG = True\n",
    "\n",
    "EVAL_LEVEL_LIST = ['H', 'M', 'S']\n",
    "EVAL_LEVEL_LIST = ['S']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0d8aa54",
   "metadata": {
    "id": "7dfd639d-5b7a-4280-9689-32aa4d40a9cd"
   },
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "795067b5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4214,
     "status": "ok",
     "timestamp": 1650750036279,
     "user": {
      "displayName": "Tũn Tũn",
      "userId": "10147808466179585969"
     },
     "user_tz": 240
    },
    "id": "11d2a715-8cb4-4df1-9ef7-00b18f834f32",
    "outputId": "8d20260c-67f9-4bb2-d49d-fbbb01996099"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train images: 0\n",
      "Number of val images:   0\n"
     ]
    }
   ],
   "source": [
    "##################################################\n",
    "# Local libraries\n",
    "\n",
    "from detectron2_predictor import Detectron2Predictor\n",
    "from detectron2_trainer import Detectron2Trainer\n",
    "from detectron2_dataset import Detectron2CustomDataset\n",
    "from utilities import create_file_list, imshow_jupyter\n",
    "from datasets import get_carla_file_list, get_carla_dicts, get_cityscapes_file_list, get_cityscapes_dicts\n",
    "from datasets import convert_carla, convert_cityscapes\n",
    "\n",
    "##################################################\n",
    "# Libraries\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "import os, json, cv2, random\n",
    "\n",
    "##################################################\n",
    "# Detectron2\n",
    "\n",
    "import detectron2\n",
    "\n",
    "from detectron2.utils.logger import setup_logger\n",
    "setup_logger()\n",
    "\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import DatasetCatalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "267cbca6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.7.6 (default, May 29 2020, 16:22:44) \n",
      "[GCC 5.4.0 20160609]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a981d8b",
   "metadata": {
    "id": "WG-v-IBXo7e7"
   },
   "source": [
    "# Image lists & dicts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56d2d19b",
   "metadata": {
    "id": "bJEp7LRapA9e"
   },
   "source": [
    "## Carla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "07f6bd58",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 234,
     "status": "ok",
     "timestamp": 1650750036503,
     "user": {
      "displayName": "Tũn Tũn",
      "userId": "10147808466179585969"
     },
     "user_tz": 240
    },
    "id": "5ae5b712-4f0f-4c81-91f2-6b704a73b2d9",
    "outputId": "0228aa52-81e4-48ea-b5b4-d5ee6463449a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images: 1089\n",
      "Number of images: 1089\n"
     ]
    }
   ],
   "source": [
    "data_carla_dir = data_dir + 'Carla/packaging/'\n",
    "\n",
    "# Dir structure:\n",
    "# <data_carla_dir>\n",
    "#     packages2\n",
    "#     packages3\n",
    "#     ...\n",
    "\n",
    "#data_carla_train_file_list = get_carla_file_list(data_carla_dir, packages=['package2', 'package3', 'package4', 'package5', 'package6', 'package7', 'package9', 'carla_data_day_2'], levels=EVAL_LEVEL_LIST)\n",
    "#data_carla_val_file_list = get_carla_file_list(data_carla_dir, packages=['package8', 'carla_data_day_1'], levels=EVAL_LEVEL_LIST)\n",
    "\n",
    "# data_carla_train_file_list = get_carla_file_list(data_carla_dir, packages=['package2'], levels=['H', 'M', 'S'])\n",
    "# data_carla_val_file_list = get_carla_file_list(data_carla_dir, packages=['package8'], levels=['H', 'M', 'S'])\n",
    "\n",
    "data_carla_train_file_list = get_carla_file_list(data_carla_dir, packages=['test'], levels=EVAL_LEVEL_LIST)\n",
    "data_carla_val_file_list = get_carla_file_list(data_carla_dir, packages=['test'], levels=EVAL_LEVEL_LIST)\n",
    "\n",
    "# # Toy example\n",
    "# data_carla_train_file_list = data_carla_train_file_list[:10]\n",
    "# data_carla_val_file_list = data_carla_val_file_list[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fb06988e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_carla_dir = data_dir + 'RainRemoval/CarlaDerained/'\n",
    "\n",
    "# # Dir structure:\n",
    "# # <data_carla_dir>\n",
    "# #     packages2\n",
    "# #     packages3\n",
    "# #     ...\n",
    "\n",
    "# data_carla_train_file_list = get_carla_file_list(data_carla_dir, packages=['package8'], levels=EVAL_LEVEL_LIST)\n",
    "# data_carla_val_file_list = get_carla_file_list(data_carla_dir, packages=['package8'], levels=EVAL_LEVEL_LIST)\n",
    "\n",
    "# # # Toy example\n",
    "# # data_carla_train_file_list = data_carla_train_file_list[:10]\n",
    "# # data_carla_val_file_list = data_carla_val_file_list[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8800419b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1221,
     "status": "ok",
     "timestamp": 1650750037718,
     "user": {
      "displayName": "Tũn Tũn",
      "userId": "10147808466179585969"
     },
     "user_tz": 240
    },
    "id": "e7ff3fc8-60ad-4f66-8081-26b25a515d8c",
    "outputId": "a51d5273-c290-4071-8351-a2a4192f6944"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n",
      "Carla clear\n",
      "{'file_name': '/home/gregory/Documents/RainPerception/RainRemoval/Copied/generated_test_both/Carla/packaging/test/1647661109.8690557_clear.png', 'height': 720, 'width': 1280, 'image_id': '1647661109.8690557_clear', 'sem_seg_file_name': '/home/gregory/Documents/RainPerception/RainRemoval/Copied/generated_test_both/Carla/packaging/test/1647661109.8690557_semantic_train.png'}\n",
      "{'file_name': '/home/gregory/Documents/RainPerception/RainRemoval/Copied/generated_test_both/Carla/packaging/test/1647661123.9885252_clear.png', 'height': 720, 'width': 1280, 'image_id': '1647661123.9885252_clear', 'sem_seg_file_name': '/home/gregory/Documents/RainPerception/RainRemoval/Copied/generated_test_both/Carla/packaging/test/1647661123.9885252_semantic_train.png'}\n",
      "{'file_name': '/home/gregory/Documents/RainPerception/RainRemoval/Copied/generated_test_both/Carla/packaging/test/1647661174.6142457_clear.png', 'height': 720, 'width': 1280, 'image_id': '1647661174.6142457_clear', 'sem_seg_file_name': '/home/gregory/Documents/RainPerception/RainRemoval/Copied/generated_test_both/Carla/packaging/test/1647661174.6142457_semantic_train.png'}\n",
      "{'file_name': '/home/gregory/Documents/RainPerception/RainRemoval/Copied/generated_test_both/Carla/packaging/test/1647661196.5949862_clear.png', 'height': 720, 'width': 1280, 'image_id': '1647661196.5949862_clear', 'sem_seg_file_name': '/home/gregory/Documents/RainPerception/RainRemoval/Copied/generated_test_both/Carla/packaging/test/1647661196.5949862_semantic_train.png'}\n",
      "1089\n",
      "1089\n",
      "\n",
      "**************************************************\n",
      "Carla rain\n",
      "{'file_name': '/home/gregory/Documents/RainPerception/RainRemoval/Copied/generated_test_both/Carla/packaging/test/1647661109.8690557_rain_S.png', 'height': 720, 'width': 1280, 'image_id': '1647661109.8690557_rain', 'sem_seg_file_name': '/home/gregory/Documents/RainPerception/RainRemoval/Copied/generated_test_both/Carla/packaging/test/1647661109.8690557_semantic_train.png'}\n",
      "{'file_name': '/home/gregory/Documents/RainPerception/RainRemoval/Copied/generated_test_both/Carla/packaging/test/1647661123.9885252_rain_S.png', 'height': 720, 'width': 1280, 'image_id': '1647661123.9885252_rain', 'sem_seg_file_name': '/home/gregory/Documents/RainPerception/RainRemoval/Copied/generated_test_both/Carla/packaging/test/1647661123.9885252_semantic_train.png'}\n",
      "{'file_name': '/home/gregory/Documents/RainPerception/RainRemoval/Copied/generated_test_both/Carla/packaging/test/1647661174.6142457_rain_S.png', 'height': 720, 'width': 1280, 'image_id': '1647661174.6142457_rain', 'sem_seg_file_name': '/home/gregory/Documents/RainPerception/RainRemoval/Copied/generated_test_both/Carla/packaging/test/1647661174.6142457_semantic_train.png'}\n",
      "{'file_name': '/home/gregory/Documents/RainPerception/RainRemoval/Copied/generated_test_both/Carla/packaging/test/1647661196.5949862_rain_S.png', 'height': 720, 'width': 1280, 'image_id': '1647661196.5949862_rain', 'sem_seg_file_name': '/home/gregory/Documents/RainPerception/RainRemoval/Copied/generated_test_both/Carla/packaging/test/1647661196.5949862_semantic_train.png'}\n",
      "1089\n",
      "1089\n",
      "\n",
      "**************************************************\n",
      "Carla all\n",
      "{'file_name': '/home/gregory/Documents/RainPerception/RainRemoval/Copied/generated_test_both/Carla/packaging/test/1647661109.8690557_clear.png', 'height': 720, 'width': 1280, 'image_id': '1647661109.8690557_clear', 'sem_seg_file_name': '/home/gregory/Documents/RainPerception/RainRemoval/Copied/generated_test_both/Carla/packaging/test/1647661109.8690557_semantic_train.png'}\n",
      "{'file_name': '/home/gregory/Documents/RainPerception/RainRemoval/Copied/generated_test_both/Carla/packaging/test/1647661109.8690557_rain_S.png', 'height': 720, 'width': 1280, 'image_id': '1647661109.8690557_rain', 'sem_seg_file_name': '/home/gregory/Documents/RainPerception/RainRemoval/Copied/generated_test_both/Carla/packaging/test/1647661109.8690557_semantic_train.png'}\n",
      "{'file_name': '/home/gregory/Documents/RainPerception/RainRemoval/Copied/generated_test_both/Carla/packaging/test/1647661123.9885252_clear.png', 'height': 720, 'width': 1280, 'image_id': '1647661123.9885252_clear', 'sem_seg_file_name': '/home/gregory/Documents/RainPerception/RainRemoval/Copied/generated_test_both/Carla/packaging/test/1647661123.9885252_semantic_train.png'}\n",
      "{'file_name': '/home/gregory/Documents/RainPerception/RainRemoval/Copied/generated_test_both/Carla/packaging/test/1647661123.9885252_rain_S.png', 'height': 720, 'width': 1280, 'image_id': '1647661123.9885252_rain', 'sem_seg_file_name': '/home/gregory/Documents/RainPerception/RainRemoval/Copied/generated_test_both/Carla/packaging/test/1647661123.9885252_semantic_train.png'}\n",
      "2178\n",
      "2178\n"
     ]
    }
   ],
   "source": [
    "print('**************************************************')\n",
    "print('Carla clear')\n",
    "\n",
    "def get_carla_clear_train_dicts():\n",
    "    return get_carla_dicts(data_carla_train_file_list, data_carla_dir, clear=True, rain=False)\n",
    "\n",
    "def get_carla_clear_val_dicts():\n",
    "    return get_carla_dicts(data_carla_val_file_list, data_carla_dir, clear=True, rain=False)\n",
    "\n",
    "if DEBUG == True:\n",
    "    for dict in get_carla_clear_train_dicts()[:4]:\n",
    "        print(dict)\n",
    "    \n",
    "print(len(get_carla_clear_train_dicts())) # 2990\n",
    "print(len(get_carla_clear_val_dicts()))   # 1173\n",
    "\n",
    "print('\\n**************************************************')\n",
    "print('Carla rain')\n",
    "\n",
    "def get_carla_rain_train_dicts():\n",
    "    return get_carla_dicts(data_carla_train_file_list, data_carla_dir, clear=False, rain=True)\n",
    "\n",
    "def get_carla_rain_val_dicts():\n",
    "    return get_carla_dicts(data_carla_val_file_list, data_carla_dir, clear=False, rain=True)\n",
    "\n",
    "if DEBUG == True:\n",
    "    for dict in get_carla_rain_val_dicts()[:4]:\n",
    "        print(dict)\n",
    "    \n",
    "print(len(get_carla_rain_train_dicts())) # 2990\n",
    "print(len(get_carla_rain_val_dicts()))   # 1173\n",
    "\n",
    "print('\\n**************************************************')\n",
    "print('Carla all')\n",
    "\n",
    "def get_carla_all_train_dicts():\n",
    "    return get_carla_dicts(data_carla_train_file_list, data_carla_dir, clear=True, rain=True)\n",
    "\n",
    "def get_carla_all_val_dicts():\n",
    "    return get_carla_dicts(data_carla_val_file_list, data_carla_dir, clear=True, rain=True)\n",
    "\n",
    "if DEBUG == True:\n",
    "    for dict in get_carla_all_val_dicts()[:4]:\n",
    "        print(dict)\n",
    "    \n",
    "print(len(get_carla_all_train_dicts())) # 2990*2 = 5980\n",
    "print(len(get_carla_all_val_dicts()))   # 1173*2 = 2346"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb72f010",
   "metadata": {
    "id": "cdea5e2a-78f6-477c-8a07-31ad4eb7f753"
   },
   "source": [
    "## Carla night"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e22eb94c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1650750037719,
     "user": {
      "displayName": "Tũn Tũn",
      "userId": "10147808466179585969"
     },
     "user_tz": 240
    },
    "id": "200e99e5-062a-49c7-bfac-9c47e86464a2",
    "outputId": "e8fa2703-52f4-4a8c-f964-ec040a49e2c6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images: 1102\n",
      "Number of images: 1102\n"
     ]
    }
   ],
   "source": [
    "data_carla_night_dir = data_dir + 'CarlaNight/night_packaging/'\n",
    "\n",
    "# Dir structure:\n",
    "# <data_carla_night_dir>\n",
    "#     packages10\n",
    "#     packages11\n",
    "#     ...\n",
    "\n",
    "#data_carla_night_train_file_list = get_carla_file_list(data_carla_night_dir, packages=['package10', 'carla_data_night_1', 'carla_data_night_3', 'carla_data_night_4'], levels=EVAL_LEVEL_LIST)\n",
    "#data_carla_night_val_file_list = get_carla_file_list(data_carla_night_dir, packages=['package11', 'carla_data_night_2'], levels=EVAL_LEVEL_LIST)\n",
    "\n",
    "# data_carla_night_train_file_list = get_carla_file_list(data_carla_night_dir, packages=['carla_data_pennstate_night_1'], levels=['H', 'M', 'S'])\n",
    "# data_carla_night_val_file_list = get_carla_file_list(data_carla_night_dir, packages=['package11'], levels=['H', 'M', 'S'])\n",
    "\n",
    "data_carla_night_train_file_list = get_carla_file_list(data_carla_night_dir, packages=['test'], levels=EVAL_LEVEL_LIST)\n",
    "data_carla_night_val_file_list = get_carla_file_list(data_carla_night_dir, packages=['test'], levels=EVAL_LEVEL_LIST)\n",
    "\n",
    "# # Toy example\n",
    "# data_carla_night_train_file_list = data_carla_night_train_file_list[:10]\n",
    "# data_carla_night_val_file_list = data_carla_night_val_file_list[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9cac6bdf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 623,
     "status": "ok",
     "timestamp": 1650750038336,
     "user": {
      "displayName": "Tũn Tũn",
      "userId": "10147808466179585969"
     },
     "user_tz": 240
    },
    "id": "94f8319d-9a96-4c21-b142-f95f87226731",
    "outputId": "67bb9551-c439-4f9f-ed20-abe1cbf15f56"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n",
      "Carla night clear\n",
      "{'file_name': '/home/gregory/Documents/RainPerception/RainRemoval/Copied/generated_test_both/CarlaNight/night_packaging/test/1650004480.8757513_clear.png', 'height': 720, 'width': 1280, 'image_id': '1650004480.8757513_clear', 'sem_seg_file_name': '/home/gregory/Documents/RainPerception/RainRemoval/Copied/generated_test_both/CarlaNight/night_packaging/test/1650004480.8757513_semantic_train.png'}\n",
      "{'file_name': '/home/gregory/Documents/RainPerception/RainRemoval/Copied/generated_test_both/CarlaNight/night_packaging/test/1650004499.1453662_clear.png', 'height': 720, 'width': 1280, 'image_id': '1650004499.1453662_clear', 'sem_seg_file_name': '/home/gregory/Documents/RainPerception/RainRemoval/Copied/generated_test_both/CarlaNight/night_packaging/test/1650004499.1453662_semantic_train.png'}\n",
      "{'file_name': '/home/gregory/Documents/RainPerception/RainRemoval/Copied/generated_test_both/CarlaNight/night_packaging/test/1650004508.3163974_clear.png', 'height': 720, 'width': 1280, 'image_id': '1650004508.3163974_clear', 'sem_seg_file_name': '/home/gregory/Documents/RainPerception/RainRemoval/Copied/generated_test_both/CarlaNight/night_packaging/test/1650004508.3163974_semantic_train.png'}\n",
      "{'file_name': '/home/gregory/Documents/RainPerception/RainRemoval/Copied/generated_test_both/CarlaNight/night_packaging/test/1650004545.0858083_clear.png', 'height': 720, 'width': 1280, 'image_id': '1650004545.0858083_clear', 'sem_seg_file_name': '/home/gregory/Documents/RainPerception/RainRemoval/Copied/generated_test_both/CarlaNight/night_packaging/test/1650004545.0858083_semantic_train.png'}\n",
      "1102\n",
      "1102\n",
      "\n",
      "**************************************************\n",
      "Carla night rain\n",
      "{'file_name': '/home/gregory/Documents/RainPerception/RainRemoval/Copied/generated_test_both/CarlaNight/night_packaging/test/1650004480.8757513_rain_S.png', 'height': 720, 'width': 1280, 'image_id': '1650004480.8757513_rain', 'sem_seg_file_name': '/home/gregory/Documents/RainPerception/RainRemoval/Copied/generated_test_both/CarlaNight/night_packaging/test/1650004480.8757513_semantic_train.png'}\n",
      "{'file_name': '/home/gregory/Documents/RainPerception/RainRemoval/Copied/generated_test_both/CarlaNight/night_packaging/test/1650004499.1453662_rain_S.png', 'height': 720, 'width': 1280, 'image_id': '1650004499.1453662_rain', 'sem_seg_file_name': '/home/gregory/Documents/RainPerception/RainRemoval/Copied/generated_test_both/CarlaNight/night_packaging/test/1650004499.1453662_semantic_train.png'}\n",
      "{'file_name': '/home/gregory/Documents/RainPerception/RainRemoval/Copied/generated_test_both/CarlaNight/night_packaging/test/1650004508.3163974_rain_S.png', 'height': 720, 'width': 1280, 'image_id': '1650004508.3163974_rain', 'sem_seg_file_name': '/home/gregory/Documents/RainPerception/RainRemoval/Copied/generated_test_both/CarlaNight/night_packaging/test/1650004508.3163974_semantic_train.png'}\n",
      "{'file_name': '/home/gregory/Documents/RainPerception/RainRemoval/Copied/generated_test_both/CarlaNight/night_packaging/test/1650004545.0858083_rain_S.png', 'height': 720, 'width': 1280, 'image_id': '1650004545.0858083_rain', 'sem_seg_file_name': '/home/gregory/Documents/RainPerception/RainRemoval/Copied/generated_test_both/CarlaNight/night_packaging/test/1650004545.0858083_semantic_train.png'}\n",
      "1102\n",
      "1102\n",
      "\n",
      "**************************************************\n",
      "Carla night all\n",
      "{'file_name': '/home/gregory/Documents/RainPerception/RainRemoval/Copied/generated_test_both/CarlaNight/night_packaging/test/1650004480.8757513_clear.png', 'height': 720, 'width': 1280, 'image_id': '1650004480.8757513_clear', 'sem_seg_file_name': '/home/gregory/Documents/RainPerception/RainRemoval/Copied/generated_test_both/CarlaNight/night_packaging/test/1650004480.8757513_semantic_train.png'}\n",
      "{'file_name': '/home/gregory/Documents/RainPerception/RainRemoval/Copied/generated_test_both/CarlaNight/night_packaging/test/1650004480.8757513_rain_S.png', 'height': 720, 'width': 1280, 'image_id': '1650004480.8757513_rain', 'sem_seg_file_name': '/home/gregory/Documents/RainPerception/RainRemoval/Copied/generated_test_both/CarlaNight/night_packaging/test/1650004480.8757513_semantic_train.png'}\n",
      "{'file_name': '/home/gregory/Documents/RainPerception/RainRemoval/Copied/generated_test_both/CarlaNight/night_packaging/test/1650004499.1453662_clear.png', 'height': 720, 'width': 1280, 'image_id': '1650004499.1453662_clear', 'sem_seg_file_name': '/home/gregory/Documents/RainPerception/RainRemoval/Copied/generated_test_both/CarlaNight/night_packaging/test/1650004499.1453662_semantic_train.png'}\n",
      "{'file_name': '/home/gregory/Documents/RainPerception/RainRemoval/Copied/generated_test_both/CarlaNight/night_packaging/test/1650004499.1453662_rain_S.png', 'height': 720, 'width': 1280, 'image_id': '1650004499.1453662_rain', 'sem_seg_file_name': '/home/gregory/Documents/RainPerception/RainRemoval/Copied/generated_test_both/CarlaNight/night_packaging/test/1650004499.1453662_semantic_train.png'}\n",
      "2204\n",
      "2204\n"
     ]
    }
   ],
   "source": [
    "print('**************************************************')\n",
    "print('Carla night clear')\n",
    "\n",
    "def get_carla_night_clear_train_dicts():\n",
    "    return get_carla_dicts(data_carla_night_train_file_list, data_carla_night_dir, clear=True, rain=False)\n",
    "\n",
    "def get_carla_night_clear_val_dicts():\n",
    "    return get_carla_dicts(data_carla_night_val_file_list, data_carla_night_dir, clear=True, rain=False)\n",
    "\n",
    "def get_carla_night_clear_val_dicts_sub():\n",
    "    return get_carla_night_clear_val_dicts()[:1000]\n",
    "\n",
    "if DEBUG == True:\n",
    "    for dict in get_carla_night_clear_val_dicts()[:4]:\n",
    "        print(dict)\n",
    "    \n",
    "print(len(get_carla_night_clear_train_dicts())) # 2842\n",
    "print(len(get_carla_night_clear_val_dicts()))   # 2974\n",
    "\n",
    "print('\\n**************************************************')\n",
    "print('Carla night rain')\n",
    "\n",
    "def get_carla_night_rain_train_dicts():\n",
    "    return get_carla_dicts(data_carla_night_train_file_list, data_carla_night_dir, clear=False, rain=True)\n",
    "\n",
    "def get_carla_night_rain_val_dicts():\n",
    "    return get_carla_dicts(data_carla_night_val_file_list, data_carla_night_dir, clear=False, rain=True)\n",
    "\n",
    "if DEBUG == True:\n",
    "    for dict in get_carla_night_rain_val_dicts()[:4]:\n",
    "        print(dict)\n",
    "    \n",
    "print(len(get_carla_night_rain_train_dicts())) # 2842\n",
    "print(len(get_carla_night_rain_val_dicts()))   # 2974\n",
    "\n",
    "print('\\n**************************************************')\n",
    "print('Carla night all')\n",
    "\n",
    "def get_carla_night_all_train_dicts():\n",
    "    return get_carla_dicts(data_carla_night_train_file_list, data_carla_night_dir, clear=True, rain=True)\n",
    "\n",
    "def get_carla_night_all_val_dicts():\n",
    "    return get_carla_dicts(data_carla_night_val_file_list, data_carla_night_dir, clear=True, rain=True)\n",
    "\n",
    "def get_carla_night_all_val_dicts_sub():\n",
    "    return get_carla_night_clear_val_dicts()[:1000] + get_carla_night_rain_val_dicts()[:1000]\n",
    "\n",
    "if DEBUG == True:\n",
    "    for dict in get_carla_night_all_val_dicts()[:4]:\n",
    "        print(dict)\n",
    "    \n",
    "print(len(get_carla_night_all_train_dicts())) # 2842*2 = 5684\n",
    "print(len(get_carla_night_all_val_dicts()))   # 2974*2 = 5948"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6ebc3b8",
   "metadata": {
    "id": "CEjETjkApDCI"
   },
   "source": [
    "## Cityscapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aae44f95",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1650750038337,
     "user": {
      "displayName": "Tũn Tũn",
      "userId": "10147808466179585969"
     },
     "user_tz": 240
    },
    "id": "959352e0-9de4-478e-8a51-f6ca3fa1bb3b",
    "outputId": "295d485e-3887-4f44-fdce-9e9e01724772"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of cities: 5\n",
      "Number of images: 95\n",
      "Number of images: 699\n"
     ]
    }
   ],
   "source": [
    "data_dir_cityscapes = data_dir + 'Cityscapes/leftImg8bit/train/'\n",
    "data_dir_cityscapes = data_dir + 'original/'\n",
    "# data_dir_rain_addition = data_dir + 'RainAddition/train/'\n",
    "data_dir_rain_addition = data_dir + 'RainRemoval/RainAddition/'\n",
    "data_dir_rain_addition = data_dir + 'city/'\n",
    "anno_dir_cityscapes = data_dir + 'Cityscapes/gtFine/train/'\n",
    "# anno_dir_cityscapes = data_dir + 'Cityscapes/mapped_labels/train/'\n",
    "anno_dir_cityscapes = data_dir + 'labels/'\n",
    "\n",
    "city_name_list, _ = create_file_list(data_dir_cityscapes)\n",
    "print(f'Number of cities: {len(city_name_list)}')\n",
    "\n",
    "#data_cityscapes_train_file_list = get_cityscapes_file_list(data_dir_cityscapes, cities=city_name_list[:13])\n",
    "#data_cityscapes_val_file_list   = get_cityscapes_file_list(data_dir_cityscapes, cities=city_name_list[13:])\n",
    "\n",
    "data_cityscapes_train_file_list = get_cityscapes_file_list(data_dir_cityscapes, cities=['ulm'])\n",
    "data_cityscapes_val_file_list   = get_cityscapes_file_list(data_dir_cityscapes, cities=city_name_list)\n",
    "\n",
    "# # Toy example\n",
    "# data_cityscapes_train_file_list = data_cityscapes_train_file_list[:10]\n",
    "# data_cityscapes_val_file_list = data_cityscapes_val_file_list[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a6b5166b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_dir_cityscapes = data_dir + 'RainRemoval/RainAddition/'\n",
    "# # data_dir_rain_addition = data_dir + 'RainAddition/train/'\n",
    "# data_dir_rain_addition = data_dir + 'RainRemoval/RainAddition/'\n",
    "# # anno_dir_cityscapes = data_dir + 'Cityscapes/gtFine/train/'\n",
    "# anno_dir_cityscapes = data_dir + 'Cityscapes/mapped_labels/train/'\n",
    "\n",
    "# city_name_list, _ = create_file_list(data_dir_cityscapes)\n",
    "# print(f'Number of cities: {len(city_name_list)}')\n",
    "\n",
    "# data_cityscapes_train_file_list = get_cityscapes_file_list(data_dir_cityscapes, cities=city_name_list)\n",
    "# data_cityscapes_val_file_list   = get_cityscapes_file_list(data_dir_cityscapes, cities=city_name_list)\n",
    "\n",
    "# # # Toy example\n",
    "# # data_cityscapes_train_file_list = data_cityscapes_train_file_list[:10]\n",
    "# # data_cityscapes_val_file_list = data_cityscapes_val_file_list[:10\n",
    "\n",
    "# def get_cityscapes_dicts(file_list, data_dir_main, data_dir_rain, anno_dir, clear=True, rain=True, levels=[]):\n",
    "#     dicts = []\n",
    "    \n",
    "#     # for file in file_list:\n",
    "#     for index, file in enumerate(file_list):\n",
    "#         file_name, city = file\n",
    "\n",
    "#         image_clear_path = os.path.join(data_dir_main, city, file_name)\n",
    "        \n",
    "#         file_name_split = file_name.split('_')\n",
    "        \n",
    "#         level = file_name_split[3][0]\n",
    "        \n",
    "#         # anno_name = file_name_split[0] + '_' + file_name_split[1] + '_' + file_name_split[2] + '_gtFine_labelIds.png' # Default\n",
    "#         image_id = file_name_split[0] + '_' + file_name_split[1] + '_' + file_name_split[2]\n",
    "#         anno_name = image_id + '_train.png' # Mapped\n",
    "#         image_semantic_path = os.path.join(anno_dir, city, anno_name)\n",
    "        \n",
    "#         if level in levels:\n",
    "#             if clear == True:\n",
    "#                 record = {}\n",
    "#                 record['file_name'] = image_clear_path\n",
    "#                 record['height'] = 1024 # shape[0]\n",
    "#                 record['width'] = 2048 # shape[1]\n",
    "#                 record['image_id'] = image_id + '_clear'\n",
    "#                 record['sem_seg_file_name'] = image_semantic_path\n",
    "#                 dicts.append(record)\n",
    "\n",
    "#             if rain == True:\n",
    "#                 image_rain_name = image_id + '_' + level + '.png'\n",
    "#                 image_rain_path = os.path.join(data_dir_rain, city, image_rain_name)\n",
    "\n",
    "#                 record = {}\n",
    "#                 record['file_name'] = image_rain_path\n",
    "#                 record['height'] = 1024\n",
    "#                 record['width'] = 2048\n",
    "#                 record['image_id'] = image_id + '_rain'\n",
    "#                 record['sem_seg_file_name'] = image_semantic_path\n",
    "#                 dicts.append(record)\n",
    "#     return dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5129bee9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 244,
     "status": "ok",
     "timestamp": 1650750038571,
     "user": {
      "displayName": "Tũn Tũn",
      "userId": "10147808466179585969"
     },
     "user_tz": 240
    },
    "id": "e964bcb7-123a-4a4a-975b-d3b7554551d7",
    "outputId": "7f378cd1-36fa-4078-dba3-71451602ec1d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n",
      "Cityscapes clear\n",
      "{'file_name': '/home/gregory/Documents/RainPerception/RainRemoval/Copied/generated_test_both/original/stuttgart/stuttgart_000000_000019_leftImg8bit.png', 'height': 1024, 'width': 2048, 'image_id': 'stuttgart_000000_000019_clear', 'sem_seg_file_name': '/home/gregory/Documents/RainPerception/RainRemoval/Copied/generated_test_both/labels/stuttgart/stuttgart_000000_000019_train.png'}\n",
      "{'file_name': '/home/gregory/Documents/RainPerception/RainRemoval/Copied/generated_test_both/original/stuttgart/stuttgart_000001_000019_leftImg8bit.png', 'height': 1024, 'width': 2048, 'image_id': 'stuttgart_000001_000019_clear', 'sem_seg_file_name': '/home/gregory/Documents/RainPerception/RainRemoval/Copied/generated_test_both/labels/stuttgart/stuttgart_000001_000019_train.png'}\n",
      "{'file_name': '/home/gregory/Documents/RainPerception/RainRemoval/Copied/generated_test_both/original/stuttgart/stuttgart_000002_000019_leftImg8bit.png', 'height': 1024, 'width': 2048, 'image_id': 'stuttgart_000002_000019_clear', 'sem_seg_file_name': '/home/gregory/Documents/RainPerception/RainRemoval/Copied/generated_test_both/labels/stuttgart/stuttgart_000002_000019_train.png'}\n",
      "{'file_name': '/home/gregory/Documents/RainPerception/RainRemoval/Copied/generated_test_both/original/stuttgart/stuttgart_000003_000019_leftImg8bit.png', 'height': 1024, 'width': 2048, 'image_id': 'stuttgart_000003_000019_clear', 'sem_seg_file_name': '/home/gregory/Documents/RainPerception/RainRemoval/Copied/generated_test_both/labels/stuttgart/stuttgart_000003_000019_train.png'}\n",
      "95\n",
      "699\n",
      "\n",
      "**************************************************\n",
      "Cityscapes rain\n",
      "{'file_name': '/home/gregory/Documents/RainPerception/RainRemoval/Copied/generated_test_both/city/stuttgart/stuttgart_000000_000019_S.png', 'height': 1024, 'width': 2048, 'image_id': 'stuttgart_000000_000019_rain', 'sem_seg_file_name': '/home/gregory/Documents/RainPerception/RainRemoval/Copied/generated_test_both/labels/stuttgart/stuttgart_000000_000019_train.png'}\n",
      "{'file_name': '/home/gregory/Documents/RainPerception/RainRemoval/Copied/generated_test_both/city/stuttgart/stuttgart_000001_000019_S.png', 'height': 1024, 'width': 2048, 'image_id': 'stuttgart_000001_000019_rain', 'sem_seg_file_name': '/home/gregory/Documents/RainPerception/RainRemoval/Copied/generated_test_both/labels/stuttgart/stuttgart_000001_000019_train.png'}\n",
      "{'file_name': '/home/gregory/Documents/RainPerception/RainRemoval/Copied/generated_test_both/city/stuttgart/stuttgart_000002_000019_S.png', 'height': 1024, 'width': 2048, 'image_id': 'stuttgart_000002_000019_rain', 'sem_seg_file_name': '/home/gregory/Documents/RainPerception/RainRemoval/Copied/generated_test_both/labels/stuttgart/stuttgart_000002_000019_train.png'}\n",
      "{'file_name': '/home/gregory/Documents/RainPerception/RainRemoval/Copied/generated_test_both/city/stuttgart/stuttgart_000003_000019_S.png', 'height': 1024, 'width': 2048, 'image_id': 'stuttgart_000003_000019_rain', 'sem_seg_file_name': '/home/gregory/Documents/RainPerception/RainRemoval/Copied/generated_test_both/labels/stuttgart/stuttgart_000003_000019_train.png'}\n",
      "95\n",
      "699\n",
      "\n",
      "**************************************************\n",
      "Cityscapes all\n",
      "{'file_name': '/home/gregory/Documents/RainPerception/RainRemoval/Copied/generated_test_both/original/stuttgart/stuttgart_000000_000019_leftImg8bit.png', 'height': 1024, 'width': 2048, 'image_id': 'stuttgart_000000_000019_clear', 'sem_seg_file_name': '/home/gregory/Documents/RainPerception/RainRemoval/Copied/generated_test_both/labels/stuttgart/stuttgart_000000_000019_train.png'}\n",
      "{'file_name': '/home/gregory/Documents/RainPerception/RainRemoval/Copied/generated_test_both/city/stuttgart/stuttgart_000000_000019_S.png', 'height': 1024, 'width': 2048, 'image_id': 'stuttgart_000000_000019_rain', 'sem_seg_file_name': '/home/gregory/Documents/RainPerception/RainRemoval/Copied/generated_test_both/labels/stuttgart/stuttgart_000000_000019_train.png'}\n",
      "{'file_name': '/home/gregory/Documents/RainPerception/RainRemoval/Copied/generated_test_both/original/stuttgart/stuttgart_000001_000019_leftImg8bit.png', 'height': 1024, 'width': 2048, 'image_id': 'stuttgart_000001_000019_clear', 'sem_seg_file_name': '/home/gregory/Documents/RainPerception/RainRemoval/Copied/generated_test_both/labels/stuttgart/stuttgart_000001_000019_train.png'}\n",
      "{'file_name': '/home/gregory/Documents/RainPerception/RainRemoval/Copied/generated_test_both/city/stuttgart/stuttgart_000001_000019_S.png', 'height': 1024, 'width': 2048, 'image_id': 'stuttgart_000001_000019_rain', 'sem_seg_file_name': '/home/gregory/Documents/RainPerception/RainRemoval/Copied/generated_test_both/labels/stuttgart/stuttgart_000001_000019_train.png'}\n",
      "190\n",
      "1398\n"
     ]
    }
   ],
   "source": [
    "print('**************************************************')\n",
    "print('Cityscapes clear')\n",
    "\n",
    "def get_cityscapes_clear_train_dicts():\n",
    "    return get_cityscapes_dicts(data_cityscapes_train_file_list, data_dir_cityscapes, data_dir_rain_addition, anno_dir_cityscapes, clear=True, rain=False, levels=EVAL_LEVEL_LIST)\n",
    "\n",
    "def get_cityscapes_clear_val_dicts():\n",
    "    return get_cityscapes_dicts(data_cityscapes_val_file_list, data_dir_cityscapes, data_dir_rain_addition, anno_dir_cityscapes, clear=True, rain=False, levels=EVAL_LEVEL_LIST)\n",
    "\n",
    "if DEBUG == True:\n",
    "    for dict in get_cityscapes_clear_val_dicts()[:4]:\n",
    "        print(dict)\n",
    "    \n",
    "print(len(get_cityscapes_clear_train_dicts())) # 2276\n",
    "print(len(get_cityscapes_clear_val_dicts()))   # 699\n",
    "\n",
    "print('\\n**************************************************')\n",
    "print('Cityscapes rain')\n",
    "\n",
    "def get_cityscapes_rain_train_dicts():\n",
    "    return get_cityscapes_dicts(data_cityscapes_train_file_list, data_dir_cityscapes, data_dir_rain_addition, anno_dir_cityscapes, clear=False, rain=True, levels=EVAL_LEVEL_LIST)\n",
    "\n",
    "def get_cityscapes_rain_val_dicts():\n",
    "    # return get_cityscapes_dicts(data_cityscapes_val_file_list, data_dir_cityscapes, data_dir_rain_addition, anno_dir_cityscapes, clear=False, rain=True, levels=['H', 'M', 'S'])\n",
    "    return get_cityscapes_dicts(data_cityscapes_val_file_list, data_dir_cityscapes, data_dir_rain_addition, anno_dir_cityscapes, clear=False, rain=True, levels=EVAL_LEVEL_LIST)\n",
    "\n",
    "if DEBUG == True:\n",
    "    for dict in get_cityscapes_rain_val_dicts()[:4]:\n",
    "        print(dict)\n",
    "    \n",
    "print(len(get_cityscapes_rain_train_dicts())) # 2276\n",
    "print(len(get_cityscapes_rain_val_dicts()))   # 699\n",
    "\n",
    "print('\\n**************************************************')\n",
    "print('Cityscapes all')\n",
    "\n",
    "def get_cityscapes_all_train_dicts():\n",
    "    return get_cityscapes_dicts(data_cityscapes_train_file_list, data_dir_cityscapes, data_dir_rain_addition, anno_dir_cityscapes, clear=True, rain=True, levels=EVAL_LEVEL_LIST)\n",
    "\n",
    "def get_cityscapes_all_val_dicts():\n",
    "    return get_cityscapes_dicts(data_cityscapes_val_file_list, data_dir_cityscapes, data_dir_rain_addition, anno_dir_cityscapes, clear=True, rain=True, levels=EVAL_LEVEL_LIST)\n",
    "\n",
    "if DEBUG == True:\n",
    "    for dict in get_cityscapes_all_val_dicts()[:4]:\n",
    "        print(dict)\n",
    "\n",
    "print(len(get_cityscapes_all_train_dicts())) # 2276*2 = 4552\n",
    "print(len(get_cityscapes_all_val_dicts()))   # 699*2  = 1398"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c822457",
   "metadata": {
    "id": "0gefPQJF9bmn"
   },
   "source": [
    "## Combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0caf40ba",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 631,
     "status": "ok",
     "timestamp": 1650750039196,
     "user": {
      "displayName": "Tũn Tũn",
      "userId": "10147808466179585969"
     },
     "user_tz": 240
    },
    "id": "8wECyKDe9bCj",
    "outputId": "383538b1-c424-4e39-a8c2-07eed27bf439"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n",
      "Combined clear\n",
      "{'file_name': '/home/gregory/Documents/RainPerception/RainRemoval/Copied/generated_test_both/Carla/packaging/test/1647661109.8690557_clear.png', 'height': 720, 'width': 1280, 'image_id': '1647661109.8690557_clear', 'sem_seg_file_name': '/home/gregory/Documents/RainPerception/RainRemoval/Copied/generated_test_both/Carla/packaging/test/1647661109.8690557_semantic_train.png'}\n",
      "{'file_name': '/home/gregory/Documents/RainPerception/RainRemoval/Copied/generated_test_both/Carla/packaging/test/1647661123.9885252_clear.png', 'height': 720, 'width': 1280, 'image_id': '1647661123.9885252_clear', 'sem_seg_file_name': '/home/gregory/Documents/RainPerception/RainRemoval/Copied/generated_test_both/Carla/packaging/test/1647661123.9885252_semantic_train.png'}\n",
      "{'file_name': '/home/gregory/Documents/RainPerception/RainRemoval/Copied/generated_test_both/Carla/packaging/test/1647661174.6142457_clear.png', 'height': 720, 'width': 1280, 'image_id': '1647661174.6142457_clear', 'sem_seg_file_name': '/home/gregory/Documents/RainPerception/RainRemoval/Copied/generated_test_both/Carla/packaging/test/1647661174.6142457_semantic_train.png'}\n",
      "{'file_name': '/home/gregory/Documents/RainPerception/RainRemoval/Copied/generated_test_both/Carla/packaging/test/1647661196.5949862_clear.png', 'height': 720, 'width': 1280, 'image_id': '1647661196.5949862_clear', 'sem_seg_file_name': '/home/gregory/Documents/RainPerception/RainRemoval/Copied/generated_test_both/Carla/packaging/test/1647661196.5949862_semantic_train.png'}\n",
      "{'file_name': '/home/gregory/Documents/RainPerception/RainRemoval/Copied/generated_test_both/original/ulm/ulm_000091_000019_leftImg8bit.png', 'height': 1024, 'width': 2048, 'image_id': 'ulm_000091_000019_clear', 'sem_seg_file_name': '/home/gregory/Documents/RainPerception/RainRemoval/Copied/generated_test_both/labels/ulm/ulm_000091_000019_train.png'}\n",
      "{'file_name': '/home/gregory/Documents/RainPerception/RainRemoval/Copied/generated_test_both/original/ulm/ulm_000092_000019_leftImg8bit.png', 'height': 1024, 'width': 2048, 'image_id': 'ulm_000092_000019_clear', 'sem_seg_file_name': '/home/gregory/Documents/RainPerception/RainRemoval/Copied/generated_test_both/labels/ulm/ulm_000092_000019_train.png'}\n",
      "{'file_name': '/home/gregory/Documents/RainPerception/RainRemoval/Copied/generated_test_both/original/ulm/ulm_000093_000019_leftImg8bit.png', 'height': 1024, 'width': 2048, 'image_id': 'ulm_000093_000019_clear', 'sem_seg_file_name': '/home/gregory/Documents/RainPerception/RainRemoval/Copied/generated_test_both/labels/ulm/ulm_000093_000019_train.png'}\n",
      "{'file_name': '/home/gregory/Documents/RainPerception/RainRemoval/Copied/generated_test_both/original/ulm/ulm_000094_000019_leftImg8bit.png', 'height': 1024, 'width': 2048, 'image_id': 'ulm_000094_000019_clear', 'sem_seg_file_name': '/home/gregory/Documents/RainPerception/RainRemoval/Copied/generated_test_both/labels/ulm/ulm_000094_000019_train.png'}\n",
      "1184\n",
      "1788\n",
      "\n",
      "**************************************************\n",
      "Combined rain\n",
      "{'file_name': '/home/gregory/Documents/RainPerception/RainRemoval/Copied/generated_test_both/Carla/packaging/test/1647661109.8690557_rain_S.png', 'height': 720, 'width': 1280, 'image_id': '1647661109.8690557_rain', 'sem_seg_file_name': '/home/gregory/Documents/RainPerception/RainRemoval/Copied/generated_test_both/Carla/packaging/test/1647661109.8690557_semantic_train.png'}\n",
      "{'file_name': '/home/gregory/Documents/RainPerception/RainRemoval/Copied/generated_test_both/Carla/packaging/test/1647661123.9885252_rain_S.png', 'height': 720, 'width': 1280, 'image_id': '1647661123.9885252_rain', 'sem_seg_file_name': '/home/gregory/Documents/RainPerception/RainRemoval/Copied/generated_test_both/Carla/packaging/test/1647661123.9885252_semantic_train.png'}\n",
      "{'file_name': '/home/gregory/Documents/RainPerception/RainRemoval/Copied/generated_test_both/Carla/packaging/test/1647661174.6142457_rain_S.png', 'height': 720, 'width': 1280, 'image_id': '1647661174.6142457_rain', 'sem_seg_file_name': '/home/gregory/Documents/RainPerception/RainRemoval/Copied/generated_test_both/Carla/packaging/test/1647661174.6142457_semantic_train.png'}\n",
      "{'file_name': '/home/gregory/Documents/RainPerception/RainRemoval/Copied/generated_test_both/Carla/packaging/test/1647661196.5949862_rain_S.png', 'height': 720, 'width': 1280, 'image_id': '1647661196.5949862_rain', 'sem_seg_file_name': '/home/gregory/Documents/RainPerception/RainRemoval/Copied/generated_test_both/Carla/packaging/test/1647661196.5949862_semantic_train.png'}\n",
      "{'file_name': '/home/gregory/Documents/RainPerception/RainRemoval/Copied/generated_test_both/city/ulm/ulm_000091_000019_S.png', 'height': 1024, 'width': 2048, 'image_id': 'ulm_000091_000019_rain', 'sem_seg_file_name': '/home/gregory/Documents/RainPerception/RainRemoval/Copied/generated_test_both/labels/ulm/ulm_000091_000019_train.png'}\n",
      "{'file_name': '/home/gregory/Documents/RainPerception/RainRemoval/Copied/generated_test_both/city/ulm/ulm_000092_000019_S.png', 'height': 1024, 'width': 2048, 'image_id': 'ulm_000092_000019_rain', 'sem_seg_file_name': '/home/gregory/Documents/RainPerception/RainRemoval/Copied/generated_test_both/labels/ulm/ulm_000092_000019_train.png'}\n",
      "{'file_name': '/home/gregory/Documents/RainPerception/RainRemoval/Copied/generated_test_both/city/ulm/ulm_000093_000019_S.png', 'height': 1024, 'width': 2048, 'image_id': 'ulm_000093_000019_rain', 'sem_seg_file_name': '/home/gregory/Documents/RainPerception/RainRemoval/Copied/generated_test_both/labels/ulm/ulm_000093_000019_train.png'}\n",
      "{'file_name': '/home/gregory/Documents/RainPerception/RainRemoval/Copied/generated_test_both/city/ulm/ulm_000094_000019_S.png', 'height': 1024, 'width': 2048, 'image_id': 'ulm_000094_000019_rain', 'sem_seg_file_name': '/home/gregory/Documents/RainPerception/RainRemoval/Copied/generated_test_both/labels/ulm/ulm_000094_000019_train.png'}\n",
      "1184\n",
      "1788\n",
      "\n",
      "**************************************************\n",
      "Combined all\n",
      "{'file_name': '/home/gregory/Documents/RainPerception/RainRemoval/Copied/generated_test_both/Carla/packaging/test/1647661109.8690557_clear.png', 'height': 720, 'width': 1280, 'image_id': '1647661109.8690557_clear', 'sem_seg_file_name': '/home/gregory/Documents/RainPerception/RainRemoval/Copied/generated_test_both/Carla/packaging/test/1647661109.8690557_semantic_train.png'}\n",
      "{'file_name': '/home/gregory/Documents/RainPerception/RainRemoval/Copied/generated_test_both/Carla/packaging/test/1647661109.8690557_rain_S.png', 'height': 720, 'width': 1280, 'image_id': '1647661109.8690557_rain', 'sem_seg_file_name': '/home/gregory/Documents/RainPerception/RainRemoval/Copied/generated_test_both/Carla/packaging/test/1647661109.8690557_semantic_train.png'}\n",
      "{'file_name': '/home/gregory/Documents/RainPerception/RainRemoval/Copied/generated_test_both/Carla/packaging/test/1647661123.9885252_clear.png', 'height': 720, 'width': 1280, 'image_id': '1647661123.9885252_clear', 'sem_seg_file_name': '/home/gregory/Documents/RainPerception/RainRemoval/Copied/generated_test_both/Carla/packaging/test/1647661123.9885252_semantic_train.png'}\n",
      "{'file_name': '/home/gregory/Documents/RainPerception/RainRemoval/Copied/generated_test_both/Carla/packaging/test/1647661123.9885252_rain_S.png', 'height': 720, 'width': 1280, 'image_id': '1647661123.9885252_rain', 'sem_seg_file_name': '/home/gregory/Documents/RainPerception/RainRemoval/Copied/generated_test_both/Carla/packaging/test/1647661123.9885252_semantic_train.png'}\n",
      "{'file_name': '/home/gregory/Documents/RainPerception/RainRemoval/Copied/generated_test_both/original/ulm/ulm_000093_000019_leftImg8bit.png', 'height': 1024, 'width': 2048, 'image_id': 'ulm_000093_000019_clear', 'sem_seg_file_name': '/home/gregory/Documents/RainPerception/RainRemoval/Copied/generated_test_both/labels/ulm/ulm_000093_000019_train.png'}\n",
      "{'file_name': '/home/gregory/Documents/RainPerception/RainRemoval/Copied/generated_test_both/city/ulm/ulm_000093_000019_S.png', 'height': 1024, 'width': 2048, 'image_id': 'ulm_000093_000019_rain', 'sem_seg_file_name': '/home/gregory/Documents/RainPerception/RainRemoval/Copied/generated_test_both/labels/ulm/ulm_000093_000019_train.png'}\n",
      "{'file_name': '/home/gregory/Documents/RainPerception/RainRemoval/Copied/generated_test_both/original/ulm/ulm_000094_000019_leftImg8bit.png', 'height': 1024, 'width': 2048, 'image_id': 'ulm_000094_000019_clear', 'sem_seg_file_name': '/home/gregory/Documents/RainPerception/RainRemoval/Copied/generated_test_both/labels/ulm/ulm_000094_000019_train.png'}\n",
      "{'file_name': '/home/gregory/Documents/RainPerception/RainRemoval/Copied/generated_test_both/city/ulm/ulm_000094_000019_S.png', 'height': 1024, 'width': 2048, 'image_id': 'ulm_000094_000019_rain', 'sem_seg_file_name': '/home/gregory/Documents/RainPerception/RainRemoval/Copied/generated_test_both/labels/ulm/ulm_000094_000019_train.png'}\n",
      "2368\n",
      "3576\n",
      "\n",
      "**************************************************\n",
      "Combined all night\n",
      "{'file_name': '/home/gregory/Documents/RainPerception/RainRemoval/Copied/generated_test_both/Carla/packaging/test/1647661109.8690557_clear.png', 'height': 720, 'width': 1280, 'image_id': '1647661109.8690557_clear', 'sem_seg_file_name': '/home/gregory/Documents/RainPerception/RainRemoval/Copied/generated_test_both/Carla/packaging/test/1647661109.8690557_semantic_train.png'}\n",
      "{'file_name': '/home/gregory/Documents/RainPerception/RainRemoval/Copied/generated_test_both/Carla/packaging/test/1647661109.8690557_rain_S.png', 'height': 720, 'width': 1280, 'image_id': '1647661109.8690557_rain', 'sem_seg_file_name': '/home/gregory/Documents/RainPerception/RainRemoval/Copied/generated_test_both/Carla/packaging/test/1647661109.8690557_semantic_train.png'}\n",
      "{'file_name': '/home/gregory/Documents/RainPerception/RainRemoval/Copied/generated_test_both/Carla/packaging/test/1647661123.9885252_clear.png', 'height': 720, 'width': 1280, 'image_id': '1647661123.9885252_clear', 'sem_seg_file_name': '/home/gregory/Documents/RainPerception/RainRemoval/Copied/generated_test_both/Carla/packaging/test/1647661123.9885252_semantic_train.png'}\n",
      "{'file_name': '/home/gregory/Documents/RainPerception/RainRemoval/Copied/generated_test_both/Carla/packaging/test/1647661123.9885252_rain_S.png', 'height': 720, 'width': 1280, 'image_id': '1647661123.9885252_rain', 'sem_seg_file_name': '/home/gregory/Documents/RainPerception/RainRemoval/Copied/generated_test_both/Carla/packaging/test/1647661123.9885252_semantic_train.png'}\n",
      "{'file_name': '/home/gregory/Documents/RainPerception/RainRemoval/Copied/generated_test_both/CarlaNight/night_packaging/test/1656198969.8900688_clear.png', 'height': 720, 'width': 1280, 'image_id': '1656198969.8900688_clear', 'sem_seg_file_name': '/home/gregory/Documents/RainPerception/RainRemoval/Copied/generated_test_both/CarlaNight/night_packaging/test/1656198969.8900688_semantic_train.png'}\n",
      "{'file_name': '/home/gregory/Documents/RainPerception/RainRemoval/Copied/generated_test_both/CarlaNight/night_packaging/test/1656198969.8900688_rain_S.png', 'height': 720, 'width': 1280, 'image_id': '1656198969.8900688_rain', 'sem_seg_file_name': '/home/gregory/Documents/RainPerception/RainRemoval/Copied/generated_test_both/CarlaNight/night_packaging/test/1656198969.8900688_semantic_train.png'}\n",
      "{'file_name': '/home/gregory/Documents/RainPerception/RainRemoval/Copied/generated_test_both/CarlaNight/night_packaging/test/1656198980.7042713_clear.png', 'height': 720, 'width': 1280, 'image_id': '1656198980.7042713_clear', 'sem_seg_file_name': '/home/gregory/Documents/RainPerception/RainRemoval/Copied/generated_test_both/CarlaNight/night_packaging/test/1656198980.7042713_semantic_train.png'}\n",
      "{'file_name': '/home/gregory/Documents/RainPerception/RainRemoval/Copied/generated_test_both/CarlaNight/night_packaging/test/1656198980.7042713_rain_S.png', 'height': 720, 'width': 1280, 'image_id': '1656198980.7042713_rain', 'sem_seg_file_name': '/home/gregory/Documents/RainPerception/RainRemoval/Copied/generated_test_both/CarlaNight/night_packaging/test/1656198980.7042713_semantic_train.png'}\n",
      "4572\n",
      "5780\n",
      "\n",
      "**************************************************\n",
      "Others\n"
     ]
    }
   ],
   "source": [
    "print('**************************************************')\n",
    "print('Combined clear')\n",
    "\n",
    "def get_combined_clear_train_dicts():\n",
    "    return get_carla_clear_train_dicts() + get_cityscapes_clear_train_dicts()\n",
    "\n",
    "def get_combined_clear_val_dicts():\n",
    "    return get_carla_clear_val_dicts() + get_cityscapes_clear_val_dicts()\n",
    "\n",
    "if DEBUG == True:\n",
    "    for dict in get_combined_clear_train_dicts()[:4]:\n",
    "        print(dict)\n",
    "    for dict in get_combined_clear_train_dicts()[-4:]:\n",
    "        print(dict)\n",
    "    \n",
    "print(len(get_combined_clear_train_dicts())) # 2990 + 2276 = 5266\n",
    "print(len(get_combined_clear_val_dicts()))   # 1173 + 699  = 1872\n",
    "\n",
    "print('\\n**************************************************')\n",
    "print('Combined rain')\n",
    "\n",
    "def get_combined_rain_train_dicts():\n",
    "    return get_carla_rain_train_dicts() + get_cityscapes_rain_train_dicts()\n",
    "\n",
    "def get_combined_rain_val_dicts():\n",
    "    return get_carla_rain_val_dicts() + get_cityscapes_rain_val_dicts()\n",
    "\n",
    "if DEBUG == True:\n",
    "    for dict in get_combined_rain_train_dicts()[:4]:\n",
    "        print(dict)\n",
    "    for dict in get_combined_rain_train_dicts()[-4:]:\n",
    "        print(dict)\n",
    "    \n",
    "print(len(get_combined_rain_train_dicts())) # 2990 + 2276 = 5266\n",
    "print(len(get_combined_rain_val_dicts()))   # 1173 + 699  = 1872\n",
    "\n",
    "print('\\n**************************************************')\n",
    "print('Combined all')\n",
    "\n",
    "def get_combined_all_train_dicts():\n",
    "    return get_carla_all_train_dicts() + get_cityscapes_all_train_dicts()\n",
    "\n",
    "def get_combined_all_val_dicts():\n",
    "    return get_carla_all_val_dicts() + get_cityscapes_all_val_dicts()\n",
    "\n",
    "if DEBUG == True:\n",
    "    for dict in get_combined_all_train_dicts()[:4]:\n",
    "        print(dict)\n",
    "    for dict in get_combined_all_train_dicts()[-4:]:\n",
    "        print(dict)\n",
    "\n",
    "print(len(get_combined_all_train_dicts())) # 5266*2 = 10532\n",
    "print(len(get_combined_all_val_dicts()))   # 1872*2 = 3744\n",
    "\n",
    "print('\\n**************************************************')\n",
    "print('Combined all night')\n",
    "\n",
    "def get_combined_clear_both_train_dicts():\n",
    "    return get_combined_clear_train_dicts() + get_carla_night_clear_train_dicts()\n",
    "\n",
    "def get_combined_clear_both_val_dicts():\n",
    "    return get_combined_clear_val_dicts() + get_carla_night_clear_val_dicts()\n",
    "\n",
    "def get_combined_all_night_train_dicts():\n",
    "    return get_combined_all_train_dicts() + get_carla_night_all_train_dicts()\n",
    "\n",
    "def get_combined_all_night_val_dicts():\n",
    "    return get_combined_all_val_dicts() + get_carla_night_all_val_dicts()\n",
    "\n",
    "if DEBUG == True:\n",
    "    for dict in get_combined_all_night_train_dicts()[:4]:\n",
    "        print(dict)\n",
    "    for dict in get_combined_all_night_val_dicts()[-4:]:\n",
    "        print(dict)\n",
    "\n",
    "print(len(get_combined_all_night_train_dicts())) # 10532 + 5684 = 16216\n",
    "print(len(get_combined_all_night_val_dicts()))   # 3744  + 5948 = 9692\n",
    "\n",
    "\n",
    "print('\\n**************************************************')\n",
    "print('Others')\n",
    "def get_carla_both_clear_val_dicts():\n",
    "    return get_carla_clear_val_dicts() + get_carla_night_clear_val_dicts()\n",
    "\n",
    "def get_carla_both_rain_val_dicts():\n",
    "    return get_carla_rain_val_dicts() + get_carla_night_rain_val_dicts()\n",
    "\n",
    "def get_combined_both_rain_val_dicts():\n",
    "    return get_carla_both_rain_val_dicts() + get_cityscapes_rain_val_dicts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7173710",
   "metadata": {
    "id": "KVqmnxQOn4Nm"
   },
   "source": [
    "# Convert labels to train IDs\n",
    "Execute only once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a785cab8",
   "metadata": {
    "id": "d467859a-d17d-481f-aa6f-553a513bdfc7"
   },
   "outputs": [],
   "source": [
    "# %cd '/home/tunx404/Miscellaneous/data/Cityscapes/mapped_labels/train/'\n",
    "# for city_name in city_name_list:\n",
    "#     !mkdir $city_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d3317c56",
   "metadata": {
    "id": "80ddac12"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 699/699 [00:00<00:00, 125462.96it/s]\n"
     ]
    }
   ],
   "source": [
    "# convert_carla(data_carla_train_file_list, data_carla_dir)\n",
    "# convert_carla(data_carla_val_file_list, data_carla_dir)\n",
    "\n",
    "# convert_carla(data_carla_night_train_file_list, data_carla_night_dir)\n",
    "# convert_carla(data_carla_night_val_file_list, data_carla_night_dir)\n",
    "\n",
    "#convert_cityscapes(data_cityscapes_train_file_list, anno_dir_cityscapes, output_dir='/home/gregory/Documents/RainPerception/Cityscapes/gtFine/train/')\n",
    "#convert_cityscapes(data_cityscapes_val_file_list, anno_dir_cityscapes, output_dir='/home/gregory/Documents/RainPerception/Cityscapes/gtFine/val/')\n",
    "\n",
    "convert_cityscapes(data_cityscapes_val_file_list, anno_dir_cityscapes, output_dir=data_dir+'labels/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01b58218",
   "metadata": {
    "id": "25818909"
   },
   "source": [
    "# Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "27cd5899",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 588,
     "status": "ok",
     "timestamp": 1650750039781,
     "user": {
      "displayName": "Tũn Tũn",
      "userId": "10147808466179585969"
     },
     "user_tz": 240
    },
    "id": "33d9e8dd",
    "outputId": "90ce465b-86ec-4a75-a9a9-cfc4affb6a48"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n",
      "Carla clear dataset\n",
      "Number of train images: 1089\n",
      "Number of val images:   1089\n",
      "\n",
      "Carla rain dataset\n",
      "Number of train images: 1089\n",
      "Number of val images:   1089\n",
      "\n",
      "Carla all dataset\n",
      "Number of train images: 1089\n",
      "Number of val images:   2178\n",
      "\n",
      "**************************************************\n",
      "Carla night clear dataset\n",
      "Number of train images: 1102\n",
      "Number of val images:   1102\n",
      "\n",
      "Carla night rain dataset\n",
      "Number of train images: 1102\n",
      "Number of val images:   1102\n",
      "\n",
      "Carla night all dataset\n",
      "Number of train images: 2204\n",
      "Number of val images:   2204\n",
      "\n",
      "**************************************************\n",
      "Cityscapes clear dataset\n",
      "Number of train images: 95\n",
      "Number of val images:   699\n",
      "\n",
      "Cityscapes rain dataset\n",
      "Number of train images: 95\n",
      "Number of val images:   699\n",
      "\n",
      "Cityscapes day dataset\n",
      "Number of train images: 190\n",
      "Number of val images:   1398\n",
      "\n",
      "**************************************************\n",
      "Combined clear dataset\n",
      "Number of train images: 1184\n",
      "Number of val images:   1788\n",
      "\n",
      "Combined rain dataset\n",
      "Number of train images: 1184\n",
      "Number of val images:   1788\n",
      "\n",
      "Combined all dataset\n",
      "Number of train images: 2368\n",
      "Number of val images:   3576\n",
      "\n",
      "**************************************************\n",
      "Combined all night dataset (rain+clear, day+night)\n",
      "Number of train images: 4572\n",
      "Number of val images:   5780\n",
      "\n",
      "Combined clear both dataset\n",
      "Number of train images: 2286\n",
      "Number of val images:   2890\n",
      "\n",
      "Combined rain both dataset\n",
      "Number of train images: 2286\n",
      "Number of val images:   2890\n",
      "\n",
      "**************************************************\n",
      "Number of train images: 2286\n",
      "Number of val images:   2191\n",
      "Number of train images: 2286\n",
      "Number of val images:   2191\n",
      "Number of train images: 2286\n",
      "Number of val images:   2890\n"
     ]
    }
   ],
   "source": [
    "DatasetCatalog.clear()\n",
    "\n",
    "print('**************************************************')\n",
    "\n",
    "print('Carla clear dataset')\n",
    "carla_clear_dataset = Detectron2CustomDataset('carla_clear_train', 'carla_clear_val', get_carla_clear_train_dicts, get_carla_clear_val_dicts)\n",
    "# carla_clear_dataset.visualize_dataset(num_samples=4, size=(20, 10), show_original=True)\n",
    "            \n",
    "print('\\nCarla rain dataset')\n",
    "carla_rain_dataset = Detectron2CustomDataset('carla_rain_train', 'carla_rain_val', get_carla_rain_train_dicts, get_carla_rain_val_dicts)\n",
    "# carla_rain_dataset.visualize_dataset(num_samples=1, size=(20, 10), show_original=True)\n",
    "\n",
    "print('\\nCarla all dataset')\n",
    "carla_day_dataset = Detectron2CustomDataset('carla_rain_train_2', 'carla_day_val', get_carla_rain_train_dicts, get_carla_all_val_dicts)\n",
    "\n",
    "# print('\\nCarla derained dataset')\n",
    "# carla_derained_dataset = Detectron2CustomDataset('carla_derained_train', 'carla_derained_val', get_carla_rain_train_dicts, get_carla_derained_val_dicts)\n",
    "# # carla_rain_dataset.visualize_dataset(num_samples=1, size=(20, 10), show_original=True)\n",
    "\n",
    "##################################################\n",
    "\n",
    "print('\\n**************************************************')\n",
    "\n",
    "print('Carla night clear dataset')\n",
    "carla_night_clear_dataset = Detectron2CustomDataset('carla_night_clear_train', 'carla_night_clear_val', get_carla_night_clear_train_dicts, get_carla_night_clear_val_dicts)\n",
    "# carla_night_clear_dataset.visualize_dataset(num_samples=1, size=(20, 10), show_original=True)\n",
    "            \n",
    "print('\\nCarla night rain dataset')\n",
    "carla_night_rain_dataset = Detectron2CustomDataset('carla_night_rain_train', 'carla_night_rain_val', get_carla_night_rain_train_dicts, get_carla_night_rain_val_dicts)\n",
    "# carla_night_rain_dataset.visualize_dataset(num_samples=1, size=(20, 10), show_original=True)\n",
    "\n",
    "print('\\nCarla night all dataset')\n",
    "carla_night_all_dataset = Detectron2CustomDataset('carla_night_all_train', 'carla_night_all_val', get_carla_night_all_train_dicts, get_carla_night_all_val_dicts)\n",
    "# carla_night_all_dataset.visualize_dataset(num_samples=1, size=(20, 10), show_original=True)\n",
    "\n",
    "##################################################\n",
    "\n",
    "print('\\n**************************************************')\n",
    "\n",
    "print('Cityscapes clear dataset')\n",
    "cityscapes_clear_dataset = Detectron2CustomDataset('cityscapes_clear_train', 'cityscapes_clear_val', get_cityscapes_clear_train_dicts, get_cityscapes_clear_val_dicts)\n",
    "# cityscapes_clear_dataset.visualize_dataset(num_samples=10, size=(20, 10), show_original=True)\n",
    "\n",
    "print('\\nCityscapes rain dataset')\n",
    "cityscapes_rain_dataset = Detectron2CustomDataset('cityscapes_rain_train', 'cityscapes_rain_val', get_cityscapes_rain_train_dicts, get_cityscapes_rain_val_dicts)\n",
    "# cityscapes_rain_dataset.visualize_dataset(num_samples=1, size=(20, 10), show_original=True)\n",
    "\n",
    "print('\\nCityscapes day dataset')\n",
    "cityscapes_day_dataset = Detectron2CustomDataset('cityscapes_day_train', 'cityscapes_day_val', get_cityscapes_all_train_dicts, get_cityscapes_all_val_dicts)\n",
    "\n",
    "##################################################\n",
    "\n",
    "print('\\n**************************************************')\n",
    "            \n",
    "print('Combined clear dataset')\n",
    "combined_clear_dataset = Detectron2CustomDataset('combined_clear_train', 'combined_clear_val', get_combined_clear_train_dicts, get_combined_clear_val_dicts)\n",
    "# combined_clear_dataset.visualize_dataset(num_samples=1, size=(20, 10), show_original=True)\n",
    "            \n",
    "print('\\nCombined rain dataset')\n",
    "combined_rain_dataset = Detectron2CustomDataset('combined_rain_train', 'combined_rain_val', get_combined_rain_train_dicts, get_combined_rain_val_dicts)\n",
    "# combined_rain_dataset.visualize_dataset(num_samples=1, size=(20, 10), show_original=True)\n",
    "            \n",
    "print('\\nCombined all dataset')\n",
    "combined_all_dataset = Detectron2CustomDataset('combined_all_train', 'combined_all_val', get_combined_all_train_dicts, get_combined_all_val_dicts)\n",
    "# combined_all_dataset.visualize_dataset(num_samples=1, size=(20, 10), show_original=True)\n",
    "\n",
    "##################################################\n",
    "\n",
    "print('\\n**************************************************')\n",
    "            \n",
    "print('Combined all night dataset (rain+clear, day+night)')\n",
    "combined_all_night_dataset = Detectron2CustomDataset('combined_all_night_train', 'combined_all_night_val', get_combined_all_night_train_dicts, get_combined_all_night_val_dicts)\n",
    "# combined_all_dataset.visualize_dataset(num_samples=20, size=(20, 10), show_original=True)\n",
    "\n",
    "print('\\nCombined clear both dataset')\n",
    "combined_clear_both_dataset = Detectron2CustomDataset('combined_clear_both_train', 'combined_clear_both_val', get_combined_clear_both_train_dicts, get_combined_clear_both_val_dicts)\n",
    "# combined_all_dataset.visualize_dataset(num_samples=20, size=(20, 10), show_original=True)\n",
    "\n",
    "print('\\nCombined rain both dataset')\n",
    "combined_rain_both_dataset = Detectron2CustomDataset('combined_rain_both_train', 'combined_rain_both_val', get_combined_clear_both_train_dicts, get_combined_clear_both_val_dicts)\n",
    "# combined_all_dataset.visualize_dataset(num_samples=20, size=(20, 10), show_original=True)\n",
    "\n",
    "print('\\n**************************************************')\n",
    "carla_both_clear_dataset = Detectron2CustomDataset('combined_rain_both_train2', 'carla_both_clear_val', get_combined_clear_both_train_dicts, get_carla_both_clear_val_dicts)\n",
    "\n",
    "carla_both_rain_dataset = Detectron2CustomDataset('combined_rain_both_train3', 'carla_both_rain_val', get_combined_clear_both_train_dicts, get_carla_both_rain_val_dicts)\n",
    "\n",
    "combined_both_rain_dataset = Detectron2CustomDataset('combined_rain_both_train4', 'combined_both_rain_val', get_combined_clear_both_train_dicts, get_combined_both_rain_val_dicts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d1d838d",
   "metadata": {
    "id": "l0TtWq0-DxjT"
   },
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8cda77fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import os\n",
    "#os.environ['CUDA_VISIBLE_DEVICES'] = '0, 1'\n",
    "#os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
    "#print(os.environ['CUDA_VISIBLE_DEVICES'])\n",
    "#print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "76a6100e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6bd2452e",
    "outputId": "6b55e451-4d71-4cef-94a4-680b0b443221"
   },
   "outputs": [],
   "source": [
    "#trainer_all = Detectron2Trainer('combined_all_night_train', 'combined_all_night_val', output_folder='./output_part_night_40k')\n",
    "#trainer_all.load()\n",
    "#trainer_all.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ef085596",
   "metadata": {
    "id": "mPFpcmeBIxQQ"
   },
   "outputs": [],
   "source": [
    "#trainer_clear = Detectron2Trainer('cityscapes_clear_train', 'cityscapes_clear_val', output_folder='./output_combined_all_40k')\n",
    "#trainer_clear.load()\n",
    "#detectron2.engine.launch(trainer_clear.train, 3)\n",
    "#trainer_clear.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4e4a5c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainer_clear.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5fb7936d",
   "metadata": {
    "id": "39c385b8"
   },
   "outputs": [],
   "source": [
    "# %load_ext tensorboard\n",
    "# %tensorboard --logdir output_all_40k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "53a3227e",
   "metadata": {
    "id": "aVfRixZjJS_a"
   },
   "outputs": [],
   "source": [
    "# %load_ext tensorboard\n",
    "# %tensorboard --logdir output_clear_20k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "43236661",
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainer_all = Detectron2Trainer('carla_night_all_train', 'carla_night_all_val', output_folder='./output_test_night_40k')\n",
    "#trainer_all.load()\n",
    "#trainer_all.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "065008d1",
   "metadata": {},
   "source": [
    "## Models for Construction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f731fb42",
   "metadata": {},
   "source": [
    "### -3. Day Clear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b9bd2377",
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainer_all = Detectron2Trainer('combined_clear_train', 'combined_clear_val', output_folder='./output_day_clear_40k')\n",
    "#trainer_all.load()\n",
    "#trainer_all.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3c67313",
   "metadata": {},
   "source": [
    "### -2. Night Clear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7dab72c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainer_all = Detectron2Trainer('carla_night_clear_train', 'carla_night_clear_val', output_folder='./output_night_clear_40k')\n",
    "#trainer_all.load()\n",
    "#trainer_all.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d6e5ca3",
   "metadata": {},
   "source": [
    "### -1. Day and Night Clear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "99f3d6bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainer_all = Detectron2Trainer('combined_clear_both_train', 'combined_clear_both_val', output_folder='./output_both_clear_40k') # Actually has both day and night\n",
    "#trainer_all.load()\n",
    "#trainer_all.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8926ed79",
   "metadata": {},
   "source": [
    "### 1. Day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1cc2fc38",
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainer_all = Detectron2Trainer('combined_all_train', 'combined_all_val', output_folder='./output_day_40k')\n",
    "#trainer_all.load()\n",
    "#trainer_all.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "604a2c13",
   "metadata": {},
   "source": [
    "### 2. Night"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "43312109",
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainer_all = Detectron2Trainer('carla_night_all_train', 'carla_night_all_val', output_folder='./output_night_40k')\n",
    "#trainer_all.load()\n",
    "#trainer_all.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f86e255",
   "metadata": {},
   "source": [
    "### 3. Day and Night"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d6eafb86",
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainer_all = Detectron2Trainer('combined_all_night_train', 'combined_all_night_val', output_folder='./output_both_40k') # Actually has both day and night\n",
    "#trainer_all.load()\n",
    "#trainer_all.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c17fe47",
   "metadata": {
    "id": "t5iO65WNDzRa"
   },
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48b19e0f",
   "metadata": {},
   "source": [
    "## Models for Construction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef56ace8",
   "metadata": {},
   "source": [
    "### 1. Day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5c747434",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/06 02:26:51 d2.engine.defaults]: \u001b[0mModel:\n",
      "SemanticSegmentor(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (sem_seg_head): SemSegFPNHead(\n",
      "    (p2): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "    )\n",
      "    (p3): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (1): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "    )\n",
      "    (p4): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (1): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      (2): Conv2d(\n",
      "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (3): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "    )\n",
      "    (p5): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (1): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      (2): Conv2d(\n",
      "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (3): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      (4): Conv2d(\n",
      "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (5): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "    )\n",
      "    (predictor): Conv2d(128, 17, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/06 02:26:51 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(720, 720), max_size=2048, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[07/06 02:26:51 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[07/06 02:26:51 d2.data.common]: \u001b[0mSerializing 3353 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[07/06 02:26:51 d2.data.common]: \u001b[0mSerialized dataset takes 1.18 MiB\n",
      "Last checkpoint: model_final.pth\n",
      "\u001b[32m[07/06 02:26:51 d2.checkpoint.c2_model_loading]: \u001b[0mFollowing weights matched with model:\n",
      "| Names in Model                       | Names in Checkpoint                                                                                  | Shapes                                          |\n",
      "|:-------------------------------------|:-----------------------------------------------------------------------------------------------------|:------------------------------------------------|\n",
      "| backbone.bottom_up.res2.0.conv1.*    | backbone.bottom_up.res2.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,1,1)             |\n",
      "| backbone.bottom_up.res2.0.conv2.*    | backbone.bottom_up.res2.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |\n",
      "| backbone.bottom_up.res2.0.conv3.*    | backbone.bottom_up.res2.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res2.0.shortcut.* | backbone.bottom_up.res2.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res2.1.conv1.*    | backbone.bottom_up.res2.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |\n",
      "| backbone.bottom_up.res2.1.conv2.*    | backbone.bottom_up.res2.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |\n",
      "| backbone.bottom_up.res2.1.conv3.*    | backbone.bottom_up.res2.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res2.2.conv1.*    | backbone.bottom_up.res2.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |\n",
      "| backbone.bottom_up.res2.2.conv2.*    | backbone.bottom_up.res2.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |\n",
      "| backbone.bottom_up.res2.2.conv3.*    | backbone.bottom_up.res2.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res3.0.conv1.*    | backbone.bottom_up.res3.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,256,1,1)       |\n",
      "| backbone.bottom_up.res3.0.conv2.*    | backbone.bottom_up.res3.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.0.conv3.*    | backbone.bottom_up.res3.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res3.0.shortcut.* | backbone.bottom_up.res3.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (512,) (512,) (512,) (512,) (512,256,1,1)       |\n",
      "| backbone.bottom_up.res3.1.conv1.*    | backbone.bottom_up.res3.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |\n",
      "| backbone.bottom_up.res3.1.conv2.*    | backbone.bottom_up.res3.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.1.conv3.*    | backbone.bottom_up.res3.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res3.2.conv1.*    | backbone.bottom_up.res3.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |\n",
      "| backbone.bottom_up.res3.2.conv2.*    | backbone.bottom_up.res3.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.2.conv3.*    | backbone.bottom_up.res3.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res3.3.conv1.*    | backbone.bottom_up.res3.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |\n",
      "| backbone.bottom_up.res3.3.conv2.*    | backbone.bottom_up.res3.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.3.conv3.*    | backbone.bottom_up.res3.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res4.0.conv1.*    | backbone.bottom_up.res4.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,512,1,1)       |\n",
      "| backbone.bottom_up.res4.0.conv2.*    | backbone.bottom_up.res4.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.0.conv3.*    | backbone.bottom_up.res4.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.0.shortcut.* | backbone.bottom_up.res4.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (1024,) (1024,) (1024,) (1024,) (1024,512,1,1)  |\n",
      "| backbone.bottom_up.res4.1.conv1.*    | backbone.bottom_up.res4.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.1.conv2.*    | backbone.bottom_up.res4.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.1.conv3.*    | backbone.bottom_up.res4.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.2.conv1.*    | backbone.bottom_up.res4.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.2.conv2.*    | backbone.bottom_up.res4.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.2.conv3.*    | backbone.bottom_up.res4.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.3.conv1.*    | backbone.bottom_up.res4.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.3.conv2.*    | backbone.bottom_up.res4.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.3.conv3.*    | backbone.bottom_up.res4.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.4.conv1.*    | backbone.bottom_up.res4.4.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.4.conv2.*    | backbone.bottom_up.res4.4.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.4.conv3.*    | backbone.bottom_up.res4.4.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.5.conv1.*    | backbone.bottom_up.res4.5.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.5.conv2.*    | backbone.bottom_up.res4.5.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.5.conv3.*    | backbone.bottom_up.res4.5.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res5.0.conv1.*    | backbone.bottom_up.res5.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,1024,1,1)      |\n",
      "| backbone.bottom_up.res5.0.conv2.*    | backbone.bottom_up.res5.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |\n",
      "| backbone.bottom_up.res5.0.conv3.*    | backbone.bottom_up.res5.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
      "| backbone.bottom_up.res5.0.shortcut.* | backbone.bottom_up.res5.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (2048,) (2048,) (2048,) (2048,) (2048,1024,1,1) |\n",
      "| backbone.bottom_up.res5.1.conv1.*    | backbone.bottom_up.res5.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |\n",
      "| backbone.bottom_up.res5.1.conv2.*    | backbone.bottom_up.res5.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |\n",
      "| backbone.bottom_up.res5.1.conv3.*    | backbone.bottom_up.res5.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
      "| backbone.bottom_up.res5.2.conv1.*    | backbone.bottom_up.res5.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |\n",
      "| backbone.bottom_up.res5.2.conv2.*    | backbone.bottom_up.res5.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |\n",
      "| backbone.bottom_up.res5.2.conv3.*    | backbone.bottom_up.res5.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
      "| backbone.bottom_up.stem.conv1.*      | backbone.bottom_up.stem.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}      | (64,) (64,) (64,) (64,) (64,3,7,7)              |\n",
      "| backbone.fpn_lateral2.*              | backbone.fpn_lateral2.{bias,weight}                                                                  | (256,) (256,256,1,1)                            |\n",
      "| backbone.fpn_lateral3.*              | backbone.fpn_lateral3.{bias,weight}                                                                  | (256,) (256,512,1,1)                            |\n",
      "| backbone.fpn_lateral4.*              | backbone.fpn_lateral4.{bias,weight}                                                                  | (256,) (256,1024,1,1)                           |\n",
      "| backbone.fpn_lateral5.*              | backbone.fpn_lateral5.{bias,weight}                                                                  | (256,) (256,2048,1,1)                           |\n",
      "| backbone.fpn_output2.*               | backbone.fpn_output2.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| backbone.fpn_output3.*               | backbone.fpn_output3.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| backbone.fpn_output4.*               | backbone.fpn_output4.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| backbone.fpn_output5.*               | backbone.fpn_output5.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| sem_seg_head.p2.0.*                  | sem_seg_head.p2.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p3.0.*                  | sem_seg_head.p3.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p4.0.*                  | sem_seg_head.p4.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p4.2.*                  | sem_seg_head.p4.2.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,128,3,3)                     |\n",
      "| sem_seg_head.p5.0.*                  | sem_seg_head.p5.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p5.2.*                  | sem_seg_head.p5.2.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,128,3,3)                     |\n",
      "| sem_seg_head.p5.4.*                  | sem_seg_head.p5.4.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,128,3,3)                     |\n",
      "| sem_seg_head.predictor.*             | sem_seg_head.predictor.{bias,weight}                                                                 | (17,) (17,128,1,1)                              |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/06 02:26:51 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(720, 720), max_size=2048, sample_style='choice')]\n",
      "\u001b[32m[07/06 02:26:51 d2.data.common]: \u001b[0mSerializing 3258 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[07/06 02:26:51 d2.data.common]: \u001b[0mSerialized dataset takes 1.15 MiB\n",
      "\u001b[32m[07/06 02:26:51 d2.evaluation.evaluator]: \u001b[0mStart inference on 3258 batches\n",
      "\u001b[32m[07/06 02:26:53 d2.evaluation.evaluator]: \u001b[0mInference done 11/3258. Dataloading: 0.0019 s/iter. Inference: 0.0357 s/iter. Eval: 0.0420 s/iter. Total: 0.0796 s/iter. ETA=0:04:18\n",
      "\u001b[32m[07/06 02:26:58 d2.evaluation.evaluator]: \u001b[0mInference done 76/3258. Dataloading: 0.0021 s/iter. Inference: 0.0348 s/iter. Eval: 0.0406 s/iter. Total: 0.0775 s/iter. ETA=0:04:06\n",
      "\u001b[32m[07/06 02:27:03 d2.evaluation.evaluator]: \u001b[0mInference done 143/3258. Dataloading: 0.0021 s/iter. Inference: 0.0348 s/iter. Eval: 0.0394 s/iter. Total: 0.0764 s/iter. ETA=0:03:57\n",
      "\u001b[32m[07/06 02:27:08 d2.evaluation.evaluator]: \u001b[0mInference done 210/3258. Dataloading: 0.0021 s/iter. Inference: 0.0348 s/iter. Eval: 0.0390 s/iter. Total: 0.0760 s/iter. ETA=0:03:51\n",
      "\u001b[32m[07/06 02:27:13 d2.evaluation.evaluator]: \u001b[0mInference done 277/3258. Dataloading: 0.0021 s/iter. Inference: 0.0348 s/iter. Eval: 0.0389 s/iter. Total: 0.0759 s/iter. ETA=0:03:46\n",
      "\u001b[32m[07/06 02:27:18 d2.evaluation.evaluator]: \u001b[0mInference done 344/3258. Dataloading: 0.0021 s/iter. Inference: 0.0348 s/iter. Eval: 0.0387 s/iter. Total: 0.0758 s/iter. ETA=0:03:40\n",
      "\u001b[32m[07/06 02:27:23 d2.evaluation.evaluator]: \u001b[0mInference done 411/3258. Dataloading: 0.0021 s/iter. Inference: 0.0349 s/iter. Eval: 0.0385 s/iter. Total: 0.0756 s/iter. ETA=0:03:35\n",
      "\u001b[32m[07/06 02:27:28 d2.evaluation.evaluator]: \u001b[0mInference done 479/3258. Dataloading: 0.0021 s/iter. Inference: 0.0349 s/iter. Eval: 0.0383 s/iter. Total: 0.0754 s/iter. ETA=0:03:29\n",
      "\u001b[32m[07/06 02:27:33 d2.evaluation.evaluator]: \u001b[0mInference done 546/3258. Dataloading: 0.0021 s/iter. Inference: 0.0349 s/iter. Eval: 0.0382 s/iter. Total: 0.0753 s/iter. ETA=0:03:24\n",
      "\u001b[32m[07/06 02:27:38 d2.evaluation.evaluator]: \u001b[0mInference done 613/3258. Dataloading: 0.0021 s/iter. Inference: 0.0350 s/iter. Eval: 0.0381 s/iter. Total: 0.0753 s/iter. ETA=0:03:19\n",
      "\u001b[32m[07/06 02:27:43 d2.evaluation.evaluator]: \u001b[0mInference done 679/3258. Dataloading: 0.0021 s/iter. Inference: 0.0350 s/iter. Eval: 0.0382 s/iter. Total: 0.0754 s/iter. ETA=0:03:14\n",
      "\u001b[32m[07/06 02:27:48 d2.evaluation.evaluator]: \u001b[0mInference done 743/3258. Dataloading: 0.0021 s/iter. Inference: 0.0351 s/iter. Eval: 0.0383 s/iter. Total: 0.0756 s/iter. ETA=0:03:10\n",
      "\u001b[32m[07/06 02:27:53 d2.evaluation.evaluator]: \u001b[0mInference done 810/3258. Dataloading: 0.0021 s/iter. Inference: 0.0351 s/iter. Eval: 0.0382 s/iter. Total: 0.0756 s/iter. ETA=0:03:05\n",
      "\u001b[32m[07/06 02:27:58 d2.evaluation.evaluator]: \u001b[0mInference done 876/3258. Dataloading: 0.0021 s/iter. Inference: 0.0351 s/iter. Eval: 0.0383 s/iter. Total: 0.0756 s/iter. ETA=0:03:00\n",
      "\u001b[32m[07/06 02:28:03 d2.evaluation.evaluator]: \u001b[0mInference done 942/3258. Dataloading: 0.0021 s/iter. Inference: 0.0352 s/iter. Eval: 0.0383 s/iter. Total: 0.0757 s/iter. ETA=0:02:55\n",
      "\u001b[32m[07/06 02:28:08 d2.evaluation.evaluator]: \u001b[0mInference done 1008/3258. Dataloading: 0.0021 s/iter. Inference: 0.0352 s/iter. Eval: 0.0383 s/iter. Total: 0.0757 s/iter. ETA=0:02:50\n",
      "\u001b[32m[07/06 02:28:13 d2.evaluation.evaluator]: \u001b[0mInference done 1074/3258. Dataloading: 0.0021 s/iter. Inference: 0.0352 s/iter. Eval: 0.0384 s/iter. Total: 0.0757 s/iter. ETA=0:02:45\n",
      "\u001b[32m[07/06 02:28:18 d2.evaluation.evaluator]: \u001b[0mInference done 1139/3258. Dataloading: 0.0021 s/iter. Inference: 0.0352 s/iter. Eval: 0.0385 s/iter. Total: 0.0759 s/iter. ETA=0:02:40\n",
      "\u001b[32m[07/06 02:28:23 d2.evaluation.evaluator]: \u001b[0mInference done 1205/3258. Dataloading: 0.0021 s/iter. Inference: 0.0352 s/iter. Eval: 0.0385 s/iter. Total: 0.0759 s/iter. ETA=0:02:35\n",
      "\u001b[32m[07/06 02:28:28 d2.evaluation.evaluator]: \u001b[0mInference done 1271/3258. Dataloading: 0.0021 s/iter. Inference: 0.0352 s/iter. Eval: 0.0385 s/iter. Total: 0.0759 s/iter. ETA=0:02:30\n",
      "\u001b[32m[07/06 02:28:33 d2.evaluation.evaluator]: \u001b[0mInference done 1336/3258. Dataloading: 0.0021 s/iter. Inference: 0.0352 s/iter. Eval: 0.0386 s/iter. Total: 0.0760 s/iter. ETA=0:02:26\n",
      "\u001b[32m[07/06 02:28:38 d2.evaluation.evaluator]: \u001b[0mInference done 1404/3258. Dataloading: 0.0021 s/iter. Inference: 0.0352 s/iter. Eval: 0.0385 s/iter. Total: 0.0760 s/iter. ETA=0:02:20\n",
      "\u001b[32m[07/06 02:28:43 d2.evaluation.evaluator]: \u001b[0mInference done 1469/3258. Dataloading: 0.0021 s/iter. Inference: 0.0352 s/iter. Eval: 0.0386 s/iter. Total: 0.0760 s/iter. ETA=0:02:15\n",
      "\u001b[32m[07/06 02:28:48 d2.evaluation.evaluator]: \u001b[0mInference done 1533/3258. Dataloading: 0.0021 s/iter. Inference: 0.0352 s/iter. Eval: 0.0387 s/iter. Total: 0.0761 s/iter. ETA=0:02:11\n",
      "\u001b[32m[07/06 02:28:53 d2.evaluation.evaluator]: \u001b[0mInference done 1598/3258. Dataloading: 0.0022 s/iter. Inference: 0.0352 s/iter. Eval: 0.0387 s/iter. Total: 0.0762 s/iter. ETA=0:02:06\n",
      "\u001b[32m[07/06 02:28:58 d2.evaluation.evaluator]: \u001b[0mInference done 1663/3258. Dataloading: 0.0022 s/iter. Inference: 0.0352 s/iter. Eval: 0.0388 s/iter. Total: 0.0762 s/iter. ETA=0:02:01\n",
      "\u001b[32m[07/06 02:29:03 d2.evaluation.evaluator]: \u001b[0mInference done 1727/3258. Dataloading: 0.0022 s/iter. Inference: 0.0352 s/iter. Eval: 0.0388 s/iter. Total: 0.0763 s/iter. ETA=0:01:56\n",
      "\u001b[32m[07/06 02:29:08 d2.evaluation.evaluator]: \u001b[0mInference done 1792/3258. Dataloading: 0.0022 s/iter. Inference: 0.0352 s/iter. Eval: 0.0389 s/iter. Total: 0.0763 s/iter. ETA=0:01:51\n",
      "\u001b[32m[07/06 02:29:14 d2.evaluation.evaluator]: \u001b[0mInference done 1856/3258. Dataloading: 0.0022 s/iter. Inference: 0.0352 s/iter. Eval: 0.0390 s/iter. Total: 0.0764 s/iter. ETA=0:01:47\n",
      "\u001b[32m[07/06 02:29:19 d2.evaluation.evaluator]: \u001b[0mInference done 1921/3258. Dataloading: 0.0022 s/iter. Inference: 0.0353 s/iter. Eval: 0.0390 s/iter. Total: 0.0765 s/iter. ETA=0:01:42\n",
      "\u001b[32m[07/06 02:29:24 d2.evaluation.evaluator]: \u001b[0mInference done 1986/3258. Dataloading: 0.0022 s/iter. Inference: 0.0353 s/iter. Eval: 0.0390 s/iter. Total: 0.0765 s/iter. ETA=0:01:37\n",
      "\u001b[32m[07/06 02:29:29 d2.evaluation.evaluator]: \u001b[0mInference done 2052/3258. Dataloading: 0.0022 s/iter. Inference: 0.0353 s/iter. Eval: 0.0390 s/iter. Total: 0.0765 s/iter. ETA=0:01:32\n",
      "\u001b[32m[07/06 02:29:34 d2.evaluation.evaluator]: \u001b[0mInference done 2118/3258. Dataloading: 0.0022 s/iter. Inference: 0.0353 s/iter. Eval: 0.0390 s/iter. Total: 0.0765 s/iter. ETA=0:01:27\n",
      "\u001b[32m[07/06 02:29:39 d2.evaluation.evaluator]: \u001b[0mInference done 2185/3258. Dataloading: 0.0022 s/iter. Inference: 0.0353 s/iter. Eval: 0.0389 s/iter. Total: 0.0765 s/iter. ETA=0:01:22\n",
      "\u001b[32m[07/06 02:29:44 d2.evaluation.evaluator]: \u001b[0mInference done 2251/3258. Dataloading: 0.0022 s/iter. Inference: 0.0353 s/iter. Eval: 0.0389 s/iter. Total: 0.0765 s/iter. ETA=0:01:16\n",
      "\u001b[32m[07/06 02:29:49 d2.evaluation.evaluator]: \u001b[0mInference done 2317/3258. Dataloading: 0.0022 s/iter. Inference: 0.0353 s/iter. Eval: 0.0389 s/iter. Total: 0.0764 s/iter. ETA=0:01:11\n",
      "\u001b[32m[07/06 02:29:54 d2.evaluation.evaluator]: \u001b[0mInference done 2383/3258. Dataloading: 0.0022 s/iter. Inference: 0.0353 s/iter. Eval: 0.0389 s/iter. Total: 0.0764 s/iter. ETA=0:01:06\n",
      "\u001b[32m[07/06 02:29:59 d2.evaluation.evaluator]: \u001b[0mInference done 2449/3258. Dataloading: 0.0022 s/iter. Inference: 0.0353 s/iter. Eval: 0.0389 s/iter. Total: 0.0764 s/iter. ETA=0:01:01\n",
      "\u001b[32m[07/06 02:30:04 d2.evaluation.evaluator]: \u001b[0mInference done 2515/3258. Dataloading: 0.0022 s/iter. Inference: 0.0353 s/iter. Eval: 0.0389 s/iter. Total: 0.0764 s/iter. ETA=0:00:56\n",
      "\u001b[32m[07/06 02:30:09 d2.evaluation.evaluator]: \u001b[0mInference done 2582/3258. Dataloading: 0.0022 s/iter. Inference: 0.0353 s/iter. Eval: 0.0389 s/iter. Total: 0.0764 s/iter. ETA=0:00:51\n",
      "\u001b[32m[07/06 02:30:14 d2.evaluation.evaluator]: \u001b[0mInference done 2648/3258. Dataloading: 0.0022 s/iter. Inference: 0.0353 s/iter. Eval: 0.0389 s/iter. Total: 0.0764 s/iter. ETA=0:00:46\n",
      "\u001b[32m[07/06 02:30:19 d2.evaluation.evaluator]: \u001b[0mInference done 2714/3258. Dataloading: 0.0021 s/iter. Inference: 0.0353 s/iter. Eval: 0.0389 s/iter. Total: 0.0764 s/iter. ETA=0:00:41\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/06 02:30:24 d2.evaluation.evaluator]: \u001b[0mInference done 2780/3258. Dataloading: 0.0021 s/iter. Inference: 0.0353 s/iter. Eval: 0.0388 s/iter. Total: 0.0764 s/iter. ETA=0:00:36\n",
      "\u001b[32m[07/06 02:30:29 d2.evaluation.evaluator]: \u001b[0mInference done 2846/3258. Dataloading: 0.0021 s/iter. Inference: 0.0353 s/iter. Eval: 0.0388 s/iter. Total: 0.0764 s/iter. ETA=0:00:31\n",
      "\u001b[32m[07/06 02:30:34 d2.evaluation.evaluator]: \u001b[0mInference done 2912/3258. Dataloading: 0.0021 s/iter. Inference: 0.0353 s/iter. Eval: 0.0388 s/iter. Total: 0.0764 s/iter. ETA=0:00:26\n",
      "\u001b[32m[07/06 02:30:39 d2.evaluation.evaluator]: \u001b[0mInference done 2979/3258. Dataloading: 0.0021 s/iter. Inference: 0.0353 s/iter. Eval: 0.0388 s/iter. Total: 0.0764 s/iter. ETA=0:00:21\n",
      "\u001b[32m[07/06 02:30:44 d2.evaluation.evaluator]: \u001b[0mInference done 3045/3258. Dataloading: 0.0021 s/iter. Inference: 0.0353 s/iter. Eval: 0.0388 s/iter. Total: 0.0763 s/iter. ETA=0:00:16\n",
      "\u001b[32m[07/06 02:30:49 d2.evaluation.evaluator]: \u001b[0mInference done 3111/3258. Dataloading: 0.0021 s/iter. Inference: 0.0353 s/iter. Eval: 0.0388 s/iter. Total: 0.0763 s/iter. ETA=0:00:11\n",
      "\u001b[32m[07/06 02:30:54 d2.evaluation.evaluator]: \u001b[0mInference done 3177/3258. Dataloading: 0.0021 s/iter. Inference: 0.0353 s/iter. Eval: 0.0388 s/iter. Total: 0.0763 s/iter. ETA=0:00:06\n",
      "\u001b[32m[07/06 02:30:59 d2.evaluation.evaluator]: \u001b[0mInference done 3243/3258. Dataloading: 0.0021 s/iter. Inference: 0.0353 s/iter. Eval: 0.0388 s/iter. Total: 0.0763 s/iter. ETA=0:00:01\n",
      "\u001b[32m[07/06 02:31:00 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:04:08.353856 (0.076346 s / iter per device, on 1 devices)\n",
      "\u001b[32m[07/06 02:31:00 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:01:54 (0.035337 s / iter per device, on 1 devices)\n",
      "\u001b[32m[07/06 02:31:01 d2.evaluation.sem_seg_evaluation]: \u001b[0mOrderedDict([('sem_seg', {'mIoU': 73.50159882283094, 'fwIoU': 94.02298990720715, 'IoU-Unlabeled': nan, 'IoU-Building': 92.59199314979914, 'IoU-Fence': 41.15782995241916, 'IoU-Pedestrian': 48.3030270328603, 'IoU-Pole': 61.24756784844111, 'IoU-Road': 99.05825961719658, 'IoU-SideWalk': 90.29031204670675, 'IoU-Vegetation': 83.74333470933537, 'IoU-Vehicles': 88.85925984392507, 'IoU-Wall': 87.14789245570347, 'IoU-TrafficSign': 53.344493082271896, 'IoU-Sky': 97.17420278182577, 'IoU-TrafficLight': 72.71533217228861, 'IoU-Terrain': 76.0035183872367, 'IoU-ConstructionVehicle': 89.35891906676986, 'IoU-workzone_object': 78.43676377456663, 'IoU-Detour': 16.59287524394862, 'mACC': 80.09492981464578, 'pACC': 96.7674432892396, 'ACC-Unlabeled': nan, 'ACC-Building': 96.8521458172517, 'ACC-Fence': 56.23869872535492, 'ACC-Pedestrian': 61.23269363659004, 'ACC-Pole': 70.91802288875546, 'ACC-Road': 99.5048219496301, 'ACC-SideWalk': 95.27519248537753, 'ACC-Vegetation': 92.86950551111792, 'ACC-Vehicles': 91.22293374533719, 'ACC-Wall': 93.55363488452964, 'ACC-TrafficSign': 62.1733449119414, 'ACC-Sky': 98.44969510259465, 'ACC-TrafficLight': 82.30801013760171, 'ACC-Terrain': 81.85752681817767, 'ACC-ConstructionVehicle': 94.82027482504448, 'ACC-workzone_object': 86.49405804767032, 'ACC-Detour': 17.748317547357924})])\n",
      "\u001b[32m[07/06 02:31:01 d2.engine.defaults]: \u001b[0mEvaluation results for carla_clear_val in csv format:\n",
      "\u001b[32m[07/06 02:31:01 d2.evaluation.testing]: \u001b[0mcopypaste: Task: sem_seg\n",
      "\u001b[32m[07/06 02:31:01 d2.evaluation.testing]: \u001b[0mcopypaste: mIoU,fwIoU,mACC,pACC\n",
      "\u001b[32m[07/06 02:31:01 d2.evaluation.testing]: \u001b[0mcopypaste: 73.5016,94.0230,80.0949,96.7674\n"
     ]
    }
   ],
   "source": [
    "trainer_day = Detectron2Trainer('combined_clear_train', 'carla_clear_val', output_folder='./output_day_clear_40k')\n",
    "trainer_day.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b3ae9fe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/06 02:31:01 d2.engine.defaults]: \u001b[0mModel:\n",
      "SemanticSegmentor(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (sem_seg_head): SemSegFPNHead(\n",
      "    (p2): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "    )\n",
      "    (p3): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (1): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "    )\n",
      "    (p4): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (1): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      (2): Conv2d(\n",
      "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (3): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "    )\n",
      "    (p5): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (1): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      (2): Conv2d(\n",
      "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (3): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      (4): Conv2d(\n",
      "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (5): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "    )\n",
      "    (predictor): Conv2d(128, 17, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/06 02:31:01 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(720, 720), max_size=2048, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[07/06 02:31:01 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[07/06 02:31:01 d2.data.common]: \u001b[0mSerializing 3353 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[07/06 02:31:01 d2.data.common]: \u001b[0mSerialized dataset takes 1.18 MiB\n",
      "Last checkpoint: model_final.pth\n",
      "\u001b[32m[07/06 02:31:02 d2.checkpoint.c2_model_loading]: \u001b[0mFollowing weights matched with model:\n",
      "| Names in Model                       | Names in Checkpoint                                                                                  | Shapes                                          |\n",
      "|:-------------------------------------|:-----------------------------------------------------------------------------------------------------|:------------------------------------------------|\n",
      "| backbone.bottom_up.res2.0.conv1.*    | backbone.bottom_up.res2.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,1,1)             |\n",
      "| backbone.bottom_up.res2.0.conv2.*    | backbone.bottom_up.res2.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |\n",
      "| backbone.bottom_up.res2.0.conv3.*    | backbone.bottom_up.res2.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res2.0.shortcut.* | backbone.bottom_up.res2.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res2.1.conv1.*    | backbone.bottom_up.res2.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |\n",
      "| backbone.bottom_up.res2.1.conv2.*    | backbone.bottom_up.res2.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |\n",
      "| backbone.bottom_up.res2.1.conv3.*    | backbone.bottom_up.res2.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res2.2.conv1.*    | backbone.bottom_up.res2.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |\n",
      "| backbone.bottom_up.res2.2.conv2.*    | backbone.bottom_up.res2.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |\n",
      "| backbone.bottom_up.res2.2.conv3.*    | backbone.bottom_up.res2.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res3.0.conv1.*    | backbone.bottom_up.res3.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,256,1,1)       |\n",
      "| backbone.bottom_up.res3.0.conv2.*    | backbone.bottom_up.res3.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.0.conv3.*    | backbone.bottom_up.res3.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res3.0.shortcut.* | backbone.bottom_up.res3.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (512,) (512,) (512,) (512,) (512,256,1,1)       |\n",
      "| backbone.bottom_up.res3.1.conv1.*    | backbone.bottom_up.res3.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |\n",
      "| backbone.bottom_up.res3.1.conv2.*    | backbone.bottom_up.res3.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.1.conv3.*    | backbone.bottom_up.res3.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res3.2.conv1.*    | backbone.bottom_up.res3.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |\n",
      "| backbone.bottom_up.res3.2.conv2.*    | backbone.bottom_up.res3.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.2.conv3.*    | backbone.bottom_up.res3.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res3.3.conv1.*    | backbone.bottom_up.res3.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |\n",
      "| backbone.bottom_up.res3.3.conv2.*    | backbone.bottom_up.res3.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.3.conv3.*    | backbone.bottom_up.res3.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res4.0.conv1.*    | backbone.bottom_up.res4.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,512,1,1)       |\n",
      "| backbone.bottom_up.res4.0.conv2.*    | backbone.bottom_up.res4.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.0.conv3.*    | backbone.bottom_up.res4.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.0.shortcut.* | backbone.bottom_up.res4.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (1024,) (1024,) (1024,) (1024,) (1024,512,1,1)  |\n",
      "| backbone.bottom_up.res4.1.conv1.*    | backbone.bottom_up.res4.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.1.conv2.*    | backbone.bottom_up.res4.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.1.conv3.*    | backbone.bottom_up.res4.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.2.conv1.*    | backbone.bottom_up.res4.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.2.conv2.*    | backbone.bottom_up.res4.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.2.conv3.*    | backbone.bottom_up.res4.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.3.conv1.*    | backbone.bottom_up.res4.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.3.conv2.*    | backbone.bottom_up.res4.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.3.conv3.*    | backbone.bottom_up.res4.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.4.conv1.*    | backbone.bottom_up.res4.4.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.4.conv2.*    | backbone.bottom_up.res4.4.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.4.conv3.*    | backbone.bottom_up.res4.4.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.5.conv1.*    | backbone.bottom_up.res4.5.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.5.conv2.*    | backbone.bottom_up.res4.5.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.5.conv3.*    | backbone.bottom_up.res4.5.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res5.0.conv1.*    | backbone.bottom_up.res5.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,1024,1,1)      |\n",
      "| backbone.bottom_up.res5.0.conv2.*    | backbone.bottom_up.res5.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |\n",
      "| backbone.bottom_up.res5.0.conv3.*    | backbone.bottom_up.res5.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
      "| backbone.bottom_up.res5.0.shortcut.* | backbone.bottom_up.res5.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (2048,) (2048,) (2048,) (2048,) (2048,1024,1,1) |\n",
      "| backbone.bottom_up.res5.1.conv1.*    | backbone.bottom_up.res5.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |\n",
      "| backbone.bottom_up.res5.1.conv2.*    | backbone.bottom_up.res5.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |\n",
      "| backbone.bottom_up.res5.1.conv3.*    | backbone.bottom_up.res5.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
      "| backbone.bottom_up.res5.2.conv1.*    | backbone.bottom_up.res5.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |\n",
      "| backbone.bottom_up.res5.2.conv2.*    | backbone.bottom_up.res5.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |\n",
      "| backbone.bottom_up.res5.2.conv3.*    | backbone.bottom_up.res5.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
      "| backbone.bottom_up.stem.conv1.*      | backbone.bottom_up.stem.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}      | (64,) (64,) (64,) (64,) (64,3,7,7)              |\n",
      "| backbone.fpn_lateral2.*              | backbone.fpn_lateral2.{bias,weight}                                                                  | (256,) (256,256,1,1)                            |\n",
      "| backbone.fpn_lateral3.*              | backbone.fpn_lateral3.{bias,weight}                                                                  | (256,) (256,512,1,1)                            |\n",
      "| backbone.fpn_lateral4.*              | backbone.fpn_lateral4.{bias,weight}                                                                  | (256,) (256,1024,1,1)                           |\n",
      "| backbone.fpn_lateral5.*              | backbone.fpn_lateral5.{bias,weight}                                                                  | (256,) (256,2048,1,1)                           |\n",
      "| backbone.fpn_output2.*               | backbone.fpn_output2.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| backbone.fpn_output3.*               | backbone.fpn_output3.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| backbone.fpn_output4.*               | backbone.fpn_output4.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| backbone.fpn_output5.*               | backbone.fpn_output5.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| sem_seg_head.p2.0.*                  | sem_seg_head.p2.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p3.0.*                  | sem_seg_head.p3.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p4.0.*                  | sem_seg_head.p4.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p4.2.*                  | sem_seg_head.p4.2.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,128,3,3)                     |\n",
      "| sem_seg_head.p5.0.*                  | sem_seg_head.p5.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p5.2.*                  | sem_seg_head.p5.2.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,128,3,3)                     |\n",
      "| sem_seg_head.p5.4.*                  | sem_seg_head.p5.4.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,128,3,3)                     |\n",
      "| sem_seg_head.predictor.*             | sem_seg_head.predictor.{bias,weight}                                                                 | (17,) (17,128,1,1)                              |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/06 02:31:02 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(720, 720), max_size=2048, sample_style='choice')]\n",
      "\u001b[32m[07/06 02:31:02 d2.data.common]: \u001b[0mSerializing 699 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[07/06 02:31:02 d2.data.common]: \u001b[0mSerialized dataset takes 0.24 MiB\n",
      "\u001b[32m[07/06 02:31:02 d2.evaluation.evaluator]: \u001b[0mStart inference on 699 batches\n",
      "\u001b[32m[07/06 02:31:05 d2.evaluation.evaluator]: \u001b[0mInference done 11/699. Dataloading: 0.0016 s/iter. Inference: 0.0468 s/iter. Eval: 0.1509 s/iter. Total: 0.1993 s/iter. ETA=0:02:17\n",
      "\u001b[32m[07/06 02:31:10 d2.evaluation.evaluator]: \u001b[0mInference done 36/699. Dataloading: 0.0020 s/iter. Inference: 0.0469 s/iter. Eval: 0.1542 s/iter. Total: 0.2032 s/iter. ETA=0:02:14\n",
      "\u001b[32m[07/06 02:31:15 d2.evaluation.evaluator]: \u001b[0mInference done 61/699. Dataloading: 0.0020 s/iter. Inference: 0.0468 s/iter. Eval: 0.1535 s/iter. Total: 0.2025 s/iter. ETA=0:02:09\n",
      "\u001b[32m[07/06 02:31:20 d2.evaluation.evaluator]: \u001b[0mInference done 87/699. Dataloading: 0.0020 s/iter. Inference: 0.0468 s/iter. Eval: 0.1526 s/iter. Total: 0.2016 s/iter. ETA=0:02:03\n",
      "\u001b[32m[07/06 02:31:25 d2.evaluation.evaluator]: \u001b[0mInference done 113/699. Dataloading: 0.0020 s/iter. Inference: 0.0468 s/iter. Eval: 0.1512 s/iter. Total: 0.2001 s/iter. ETA=0:01:57\n",
      "\u001b[32m[07/06 02:31:30 d2.evaluation.evaluator]: \u001b[0mInference done 140/699. Dataloading: 0.0020 s/iter. Inference: 0.0468 s/iter. Eval: 0.1495 s/iter. Total: 0.1984 s/iter. ETA=0:01:50\n",
      "\u001b[32m[07/06 02:31:35 d2.evaluation.evaluator]: \u001b[0mInference done 167/699. Dataloading: 0.0021 s/iter. Inference: 0.0468 s/iter. Eval: 0.1485 s/iter. Total: 0.1974 s/iter. ETA=0:01:45\n",
      "\u001b[32m[07/06 02:31:41 d2.evaluation.evaluator]: \u001b[0mInference done 192/699. Dataloading: 0.0020 s/iter. Inference: 0.0468 s/iter. Eval: 0.1499 s/iter. Total: 0.1988 s/iter. ETA=0:01:40\n",
      "\u001b[32m[07/06 02:31:46 d2.evaluation.evaluator]: \u001b[0mInference done 217/699. Dataloading: 0.0021 s/iter. Inference: 0.0468 s/iter. Eval: 0.1506 s/iter. Total: 0.1995 s/iter. ETA=0:01:36\n",
      "\u001b[32m[07/06 02:31:51 d2.evaluation.evaluator]: \u001b[0mInference done 242/699. Dataloading: 0.0020 s/iter. Inference: 0.0468 s/iter. Eval: 0.1510 s/iter. Total: 0.2000 s/iter. ETA=0:01:31\n",
      "\u001b[32m[07/06 02:31:56 d2.evaluation.evaluator]: \u001b[0mInference done 268/699. Dataloading: 0.0020 s/iter. Inference: 0.0468 s/iter. Eval: 0.1510 s/iter. Total: 0.1999 s/iter. ETA=0:01:26\n",
      "\u001b[32m[07/06 02:32:01 d2.evaluation.evaluator]: \u001b[0mInference done 294/699. Dataloading: 0.0020 s/iter. Inference: 0.0468 s/iter. Eval: 0.1504 s/iter. Total: 0.1994 s/iter. ETA=0:01:20\n",
      "\u001b[32m[07/06 02:32:06 d2.evaluation.evaluator]: \u001b[0mInference done 319/699. Dataloading: 0.0021 s/iter. Inference: 0.0468 s/iter. Eval: 0.1508 s/iter. Total: 0.1997 s/iter. ETA=0:01:15\n",
      "\u001b[32m[07/06 02:32:11 d2.evaluation.evaluator]: \u001b[0mInference done 344/699. Dataloading: 0.0021 s/iter. Inference: 0.0468 s/iter. Eval: 0.1510 s/iter. Total: 0.2000 s/iter. ETA=0:01:10\n",
      "\u001b[32m[07/06 02:32:16 d2.evaluation.evaluator]: \u001b[0mInference done 369/699. Dataloading: 0.0021 s/iter. Inference: 0.0468 s/iter. Eval: 0.1512 s/iter. Total: 0.2001 s/iter. ETA=0:01:06\n",
      "\u001b[32m[07/06 02:32:21 d2.evaluation.evaluator]: \u001b[0mInference done 394/699. Dataloading: 0.0021 s/iter. Inference: 0.0468 s/iter. Eval: 0.1515 s/iter. Total: 0.2005 s/iter. ETA=0:01:01\n",
      "\u001b[32m[07/06 02:32:26 d2.evaluation.evaluator]: \u001b[0mInference done 419/699. Dataloading: 0.0021 s/iter. Inference: 0.0468 s/iter. Eval: 0.1518 s/iter. Total: 0.2007 s/iter. ETA=0:00:56\n",
      "\u001b[32m[07/06 02:32:31 d2.evaluation.evaluator]: \u001b[0mInference done 444/699. Dataloading: 0.0021 s/iter. Inference: 0.0468 s/iter. Eval: 0.1517 s/iter. Total: 0.2007 s/iter. ETA=0:00:51\n",
      "\u001b[32m[07/06 02:32:37 d2.evaluation.evaluator]: \u001b[0mInference done 470/699. Dataloading: 0.0021 s/iter. Inference: 0.0468 s/iter. Eval: 0.1515 s/iter. Total: 0.2005 s/iter. ETA=0:00:45\n",
      "\u001b[32m[07/06 02:32:42 d2.evaluation.evaluator]: \u001b[0mInference done 495/699. Dataloading: 0.0021 s/iter. Inference: 0.0468 s/iter. Eval: 0.1517 s/iter. Total: 0.2007 s/iter. ETA=0:00:40\n",
      "\u001b[32m[07/06 02:32:47 d2.evaluation.evaluator]: \u001b[0mInference done 520/699. Dataloading: 0.0021 s/iter. Inference: 0.0468 s/iter. Eval: 0.1517 s/iter. Total: 0.2007 s/iter. ETA=0:00:35\n",
      "\u001b[32m[07/06 02:32:52 d2.evaluation.evaluator]: \u001b[0mInference done 545/699. Dataloading: 0.0021 s/iter. Inference: 0.0468 s/iter. Eval: 0.1517 s/iter. Total: 0.2007 s/iter. ETA=0:00:30\n",
      "\u001b[32m[07/06 02:32:57 d2.evaluation.evaluator]: \u001b[0mInference done 570/699. Dataloading: 0.0021 s/iter. Inference: 0.0468 s/iter. Eval: 0.1519 s/iter. Total: 0.2009 s/iter. ETA=0:00:25\n",
      "\u001b[32m[07/06 02:33:02 d2.evaluation.evaluator]: \u001b[0mInference done 595/699. Dataloading: 0.0021 s/iter. Inference: 0.0468 s/iter. Eval: 0.1521 s/iter. Total: 0.2012 s/iter. ETA=0:00:20\n",
      "\u001b[32m[07/06 02:33:07 d2.evaluation.evaluator]: \u001b[0mInference done 620/699. Dataloading: 0.0021 s/iter. Inference: 0.0468 s/iter. Eval: 0.1523 s/iter. Total: 0.2013 s/iter. ETA=0:00:15\n",
      "\u001b[32m[07/06 02:33:12 d2.evaluation.evaluator]: \u001b[0mInference done 645/699. Dataloading: 0.0022 s/iter. Inference: 0.0468 s/iter. Eval: 0.1523 s/iter. Total: 0.2013 s/iter. ETA=0:00:10\n",
      "\u001b[32m[07/06 02:33:17 d2.evaluation.evaluator]: \u001b[0mInference done 670/699. Dataloading: 0.0022 s/iter. Inference: 0.0468 s/iter. Eval: 0.1522 s/iter. Total: 0.2013 s/iter. ETA=0:00:05\n",
      "\u001b[32m[07/06 02:33:22 d2.evaluation.evaluator]: \u001b[0mInference done 695/699. Dataloading: 0.0022 s/iter. Inference: 0.0468 s/iter. Eval: 0.1524 s/iter. Total: 0.2014 s/iter. ETA=0:00:00\n",
      "\u001b[32m[07/06 02:33:23 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:02:19.889770 (0.201570 s / iter per device, on 1 devices)\n",
      "\u001b[32m[07/06 02:33:23 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:32 (0.046794 s / iter per device, on 1 devices)\n",
      "\u001b[32m[07/06 02:33:23 d2.evaluation.sem_seg_evaluation]: \u001b[0mOrderedDict([('sem_seg', {'mIoU': 63.91313047828757, 'fwIoU': 90.58613522554636, 'IoU-Unlabeled': nan, 'IoU-Building': 91.02126913429149, 'IoU-Fence': 53.96293842613608, 'IoU-Pedestrian': 78.64707362272159, 'IoU-Pole': 52.622963663530896, 'IoU-Road': 96.54026389269522, 'IoU-SideWalk': 78.30018902076496, 'IoU-Vegetation': 90.88046375578767, 'IoU-Vehicles': 90.62882551076521, 'IoU-Wall': 48.86347492298621, 'IoU-TrafficSign': 65.55087750297089, 'IoU-Sky': 94.42227581775778, 'IoU-TrafficLight': 55.95171637323219, 'IoU-Terrain': 61.3046255306734, 'IoU-ConstructionVehicle': nan, 'IoU-workzone_object': nan, 'IoU-Detour': nan, 'mACC': 82.01262997221012, 'pACC': 94.85749597038267, 'ACC-Unlabeled': nan, 'ACC-Building': 95.5394158600754, 'ACC-Fence': 71.33184459605006, 'ACC-Pedestrian': 88.37031849764793, 'ACC-Pole': 66.93821463549658, 'ACC-Road': 98.65190598625875, 'ACC-SideWalk': 85.46025998839019, 'ACC-Vegetation': 96.074450832703, 'ACC-Vehicles': 94.93661420875729, 'ACC-Wall': 59.391966239098984, 'ACC-TrafficSign': 74.88658607575167, 'ACC-Sky': 97.40921531861079, 'ACC-TrafficLight': 65.50545111121163, 'ACC-Terrain': 71.66794628867936, 'ACC-ConstructionVehicle': nan, 'ACC-workzone_object': nan, 'ACC-Detour': nan})])\n",
      "\u001b[32m[07/06 02:33:23 d2.engine.defaults]: \u001b[0mEvaluation results for cityscapes_clear_val in csv format:\n",
      "\u001b[32m[07/06 02:33:23 d2.evaluation.testing]: \u001b[0mcopypaste: Task: sem_seg\n",
      "\u001b[32m[07/06 02:33:23 d2.evaluation.testing]: \u001b[0mcopypaste: mIoU,fwIoU,mACC,pACC\n",
      "\u001b[32m[07/06 02:33:23 d2.evaluation.testing]: \u001b[0mcopypaste: 63.9131,90.5861,82.0126,94.8575\n"
     ]
    }
   ],
   "source": [
    "trainer_day = Detectron2Trainer('combined_clear_train', 'cityscapes_clear_val', output_folder='./output_day_clear_40k')\n",
    "trainer_day.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7bded1a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/06 02:33:24 d2.engine.defaults]: \u001b[0mModel:\n",
      "SemanticSegmentor(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (sem_seg_head): SemSegFPNHead(\n",
      "    (p2): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "    )\n",
      "    (p3): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (1): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "    )\n",
      "    (p4): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (1): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      (2): Conv2d(\n",
      "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (3): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "    )\n",
      "    (p5): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (1): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      (2): Conv2d(\n",
      "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (3): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      (4): Conv2d(\n",
      "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (5): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "    )\n",
      "    (predictor): Conv2d(128, 17, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/06 02:33:24 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(720, 720), max_size=2048, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[07/06 02:33:24 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[07/06 02:33:24 d2.data.common]: \u001b[0mSerializing 3353 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[07/06 02:33:24 d2.data.common]: \u001b[0mSerialized dataset takes 1.18 MiB\n",
      "Last checkpoint: model_final.pth\n",
      "\u001b[32m[07/06 02:33:24 d2.checkpoint.c2_model_loading]: \u001b[0mFollowing weights matched with model:\n",
      "| Names in Model                       | Names in Checkpoint                                                                                  | Shapes                                          |\n",
      "|:-------------------------------------|:-----------------------------------------------------------------------------------------------------|:------------------------------------------------|\n",
      "| backbone.bottom_up.res2.0.conv1.*    | backbone.bottom_up.res2.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,1,1)             |\n",
      "| backbone.bottom_up.res2.0.conv2.*    | backbone.bottom_up.res2.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |\n",
      "| backbone.bottom_up.res2.0.conv3.*    | backbone.bottom_up.res2.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res2.0.shortcut.* | backbone.bottom_up.res2.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res2.1.conv1.*    | backbone.bottom_up.res2.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |\n",
      "| backbone.bottom_up.res2.1.conv2.*    | backbone.bottom_up.res2.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |\n",
      "| backbone.bottom_up.res2.1.conv3.*    | backbone.bottom_up.res2.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res2.2.conv1.*    | backbone.bottom_up.res2.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |\n",
      "| backbone.bottom_up.res2.2.conv2.*    | backbone.bottom_up.res2.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |\n",
      "| backbone.bottom_up.res2.2.conv3.*    | backbone.bottom_up.res2.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res3.0.conv1.*    | backbone.bottom_up.res3.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,256,1,1)       |\n",
      "| backbone.bottom_up.res3.0.conv2.*    | backbone.bottom_up.res3.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.0.conv3.*    | backbone.bottom_up.res3.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res3.0.shortcut.* | backbone.bottom_up.res3.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (512,) (512,) (512,) (512,) (512,256,1,1)       |\n",
      "| backbone.bottom_up.res3.1.conv1.*    | backbone.bottom_up.res3.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |\n",
      "| backbone.bottom_up.res3.1.conv2.*    | backbone.bottom_up.res3.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.1.conv3.*    | backbone.bottom_up.res3.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res3.2.conv1.*    | backbone.bottom_up.res3.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |\n",
      "| backbone.bottom_up.res3.2.conv2.*    | backbone.bottom_up.res3.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.2.conv3.*    | backbone.bottom_up.res3.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res3.3.conv1.*    | backbone.bottom_up.res3.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |\n",
      "| backbone.bottom_up.res3.3.conv2.*    | backbone.bottom_up.res3.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.3.conv3.*    | backbone.bottom_up.res3.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res4.0.conv1.*    | backbone.bottom_up.res4.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,512,1,1)       |\n",
      "| backbone.bottom_up.res4.0.conv2.*    | backbone.bottom_up.res4.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.0.conv3.*    | backbone.bottom_up.res4.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.0.shortcut.* | backbone.bottom_up.res4.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (1024,) (1024,) (1024,) (1024,) (1024,512,1,1)  |\n",
      "| backbone.bottom_up.res4.1.conv1.*    | backbone.bottom_up.res4.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.1.conv2.*    | backbone.bottom_up.res4.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.1.conv3.*    | backbone.bottom_up.res4.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.2.conv1.*    | backbone.bottom_up.res4.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.2.conv2.*    | backbone.bottom_up.res4.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.2.conv3.*    | backbone.bottom_up.res4.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.3.conv1.*    | backbone.bottom_up.res4.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.3.conv2.*    | backbone.bottom_up.res4.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.3.conv3.*    | backbone.bottom_up.res4.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.4.conv1.*    | backbone.bottom_up.res4.4.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.4.conv2.*    | backbone.bottom_up.res4.4.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.4.conv3.*    | backbone.bottom_up.res4.4.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.5.conv1.*    | backbone.bottom_up.res4.5.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.5.conv2.*    | backbone.bottom_up.res4.5.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.5.conv3.*    | backbone.bottom_up.res4.5.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res5.0.conv1.*    | backbone.bottom_up.res5.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,1024,1,1)      |\n",
      "| backbone.bottom_up.res5.0.conv2.*    | backbone.bottom_up.res5.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |\n",
      "| backbone.bottom_up.res5.0.conv3.*    | backbone.bottom_up.res5.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
      "| backbone.bottom_up.res5.0.shortcut.* | backbone.bottom_up.res5.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (2048,) (2048,) (2048,) (2048,) (2048,1024,1,1) |\n",
      "| backbone.bottom_up.res5.1.conv1.*    | backbone.bottom_up.res5.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |\n",
      "| backbone.bottom_up.res5.1.conv2.*    | backbone.bottom_up.res5.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |\n",
      "| backbone.bottom_up.res5.1.conv3.*    | backbone.bottom_up.res5.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
      "| backbone.bottom_up.res5.2.conv1.*    | backbone.bottom_up.res5.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |\n",
      "| backbone.bottom_up.res5.2.conv2.*    | backbone.bottom_up.res5.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |\n",
      "| backbone.bottom_up.res5.2.conv3.*    | backbone.bottom_up.res5.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
      "| backbone.bottom_up.stem.conv1.*      | backbone.bottom_up.stem.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}      | (64,) (64,) (64,) (64,) (64,3,7,7)              |\n",
      "| backbone.fpn_lateral2.*              | backbone.fpn_lateral2.{bias,weight}                                                                  | (256,) (256,256,1,1)                            |\n",
      "| backbone.fpn_lateral3.*              | backbone.fpn_lateral3.{bias,weight}                                                                  | (256,) (256,512,1,1)                            |\n",
      "| backbone.fpn_lateral4.*              | backbone.fpn_lateral4.{bias,weight}                                                                  | (256,) (256,1024,1,1)                           |\n",
      "| backbone.fpn_lateral5.*              | backbone.fpn_lateral5.{bias,weight}                                                                  | (256,) (256,2048,1,1)                           |\n",
      "| backbone.fpn_output2.*               | backbone.fpn_output2.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| backbone.fpn_output3.*               | backbone.fpn_output3.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| backbone.fpn_output4.*               | backbone.fpn_output4.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| backbone.fpn_output5.*               | backbone.fpn_output5.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| sem_seg_head.p2.0.*                  | sem_seg_head.p2.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p3.0.*                  | sem_seg_head.p3.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p4.0.*                  | sem_seg_head.p4.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p4.2.*                  | sem_seg_head.p4.2.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,128,3,3)                     |\n",
      "| sem_seg_head.p5.0.*                  | sem_seg_head.p5.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p5.2.*                  | sem_seg_head.p5.2.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,128,3,3)                     |\n",
      "| sem_seg_head.p5.4.*                  | sem_seg_head.p5.4.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,128,3,3)                     |\n",
      "| sem_seg_head.predictor.*             | sem_seg_head.predictor.{bias,weight}                                                                 | (17,) (17,128,1,1)                              |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/06 02:33:24 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(720, 720), max_size=2048, sample_style='choice')]\n",
      "\u001b[32m[07/06 02:33:24 d2.data.common]: \u001b[0mSerializing 3957 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[07/06 02:33:24 d2.data.common]: \u001b[0mSerialized dataset takes 1.39 MiB\n",
      "\u001b[32m[07/06 02:33:24 d2.evaluation.evaluator]: \u001b[0mStart inference on 3957 batches\n",
      "\u001b[32m[07/06 02:33:27 d2.evaluation.evaluator]: \u001b[0mInference done 34/3957. Dataloading: 0.0022 s/iter. Inference: 0.0355 s/iter. Eval: 0.0443 s/iter. Total: 0.0820 s/iter. ETA=0:05:21\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_46992/2648711927.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtrainer_day\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDetectron2Trainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'combined_clear_train'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'combined_clear_val'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_folder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'./output_day_clear_40k'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrainer_day\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/RainPerception/Robust-Vision-in-Rain/Detectron2Predictor/detectron2_trainer.py\u001b[0m in \u001b[0;36mtest\u001b[0;34m(self, output_folder, last_checkpoint)\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_predictor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_checkpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSemSegEvaluator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mval_dataset_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'inference'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredictor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/RainPerception/detectron2/detectron2/engine/defaults.py\u001b[0m in \u001b[0;36mtest\u001b[0;34m(cls, cfg, model, evaluators)\u001b[0m\n\u001b[1;32m    615\u001b[0m                     \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdataset_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    616\u001b[0m                     \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 617\u001b[0;31m             \u001b[0mresults_i\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minference_on_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    618\u001b[0m             \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdataset_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults_i\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcomm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_main_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/RainPerception/detectron2/detectron2/evaluation/evaluator.py\u001b[0m in \u001b[0;36minference_on_dataset\u001b[0;34m(model, data_loader, evaluator)\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m             \u001b[0mstart_eval_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mperf_counter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m             \u001b[0mevaluator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    165\u001b[0m             \u001b[0mtotal_eval_time\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mperf_counter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_eval_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/RainPerception/detectron2/detectron2/evaluation/sem_seg_evaluation.py\u001b[0m in \u001b[0;36mprocess\u001b[0;34m(self, inputs, outputs)\u001b[0m\n\u001b[1;32m    114\u001b[0m             ).reshape(self._conf_matrix.shape)\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_predictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode_json_sem_seg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"file_name\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/RainPerception/detectron2/detectron2/evaluation/sem_seg_evaluation.py\u001b[0m in \u001b[0;36mencode_json_sem_seg\u001b[0;34m(self, sem_seg, input_file_name)\u001b[0m\n\u001b[1;32m    191\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m                 \u001b[0mdataset_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m             \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msem_seg\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m             \u001b[0mmask_rle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmask_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"F\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m             \u001b[0mmask_rle\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"counts\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmask_rle\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"counts\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer_day = Detectron2Trainer('combined_clear_train', 'combined_clear_val', output_folder='./output_day_clear_40k')\n",
    "trainer_day.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "604a9cc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/06 03:29:11 d2.engine.defaults]: \u001b[0mModel:\n",
      "SemanticSegmentor(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (sem_seg_head): SemSegFPNHead(\n",
      "    (p2): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "    )\n",
      "    (p3): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (1): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "    )\n",
      "    (p4): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (1): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      (2): Conv2d(\n",
      "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (3): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "    )\n",
      "    (p5): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (1): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      (2): Conv2d(\n",
      "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (3): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      (4): Conv2d(\n",
      "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (5): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "    )\n",
      "    (predictor): Conv2d(128, 17, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/06 03:29:11 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(720, 720), max_size=2048, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[07/06 03:29:11 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[07/06 03:29:11 d2.data.common]: \u001b[0mSerializing 1176 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[07/06 03:29:11 d2.data.common]: \u001b[0mSerialized dataset takes 0.41 MiB\n",
      "Last checkpoint: model_final.pth\n",
      "\u001b[32m[07/06 03:29:12 d2.checkpoint.c2_model_loading]: \u001b[0mFollowing weights matched with model:\n",
      "| Names in Model                       | Names in Checkpoint                                                                                  | Shapes                                          |\n",
      "|:-------------------------------------|:-----------------------------------------------------------------------------------------------------|:------------------------------------------------|\n",
      "| backbone.bottom_up.res2.0.conv1.*    | backbone.bottom_up.res2.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,1,1)             |\n",
      "| backbone.bottom_up.res2.0.conv2.*    | backbone.bottom_up.res2.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |\n",
      "| backbone.bottom_up.res2.0.conv3.*    | backbone.bottom_up.res2.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res2.0.shortcut.* | backbone.bottom_up.res2.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res2.1.conv1.*    | backbone.bottom_up.res2.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |\n",
      "| backbone.bottom_up.res2.1.conv2.*    | backbone.bottom_up.res2.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |\n",
      "| backbone.bottom_up.res2.1.conv3.*    | backbone.bottom_up.res2.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res2.2.conv1.*    | backbone.bottom_up.res2.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |\n",
      "| backbone.bottom_up.res2.2.conv2.*    | backbone.bottom_up.res2.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |\n",
      "| backbone.bottom_up.res2.2.conv3.*    | backbone.bottom_up.res2.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res3.0.conv1.*    | backbone.bottom_up.res3.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,256,1,1)       |\n",
      "| backbone.bottom_up.res3.0.conv2.*    | backbone.bottom_up.res3.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.0.conv3.*    | backbone.bottom_up.res3.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res3.0.shortcut.* | backbone.bottom_up.res3.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (512,) (512,) (512,) (512,) (512,256,1,1)       |\n",
      "| backbone.bottom_up.res3.1.conv1.*    | backbone.bottom_up.res3.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |\n",
      "| backbone.bottom_up.res3.1.conv2.*    | backbone.bottom_up.res3.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.1.conv3.*    | backbone.bottom_up.res3.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res3.2.conv1.*    | backbone.bottom_up.res3.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |\n",
      "| backbone.bottom_up.res3.2.conv2.*    | backbone.bottom_up.res3.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.2.conv3.*    | backbone.bottom_up.res3.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res3.3.conv1.*    | backbone.bottom_up.res3.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |\n",
      "| backbone.bottom_up.res3.3.conv2.*    | backbone.bottom_up.res3.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.3.conv3.*    | backbone.bottom_up.res3.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res4.0.conv1.*    | backbone.bottom_up.res4.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,512,1,1)       |\n",
      "| backbone.bottom_up.res4.0.conv2.*    | backbone.bottom_up.res4.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.0.conv3.*    | backbone.bottom_up.res4.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.0.shortcut.* | backbone.bottom_up.res4.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (1024,) (1024,) (1024,) (1024,) (1024,512,1,1)  |\n",
      "| backbone.bottom_up.res4.1.conv1.*    | backbone.bottom_up.res4.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.1.conv2.*    | backbone.bottom_up.res4.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.1.conv3.*    | backbone.bottom_up.res4.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.2.conv1.*    | backbone.bottom_up.res4.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.2.conv2.*    | backbone.bottom_up.res4.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.2.conv3.*    | backbone.bottom_up.res4.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.3.conv1.*    | backbone.bottom_up.res4.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.3.conv2.*    | backbone.bottom_up.res4.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.3.conv3.*    | backbone.bottom_up.res4.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.4.conv1.*    | backbone.bottom_up.res4.4.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.4.conv2.*    | backbone.bottom_up.res4.4.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.4.conv3.*    | backbone.bottom_up.res4.4.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.5.conv1.*    | backbone.bottom_up.res4.5.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.5.conv2.*    | backbone.bottom_up.res4.5.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.5.conv3.*    | backbone.bottom_up.res4.5.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res5.0.conv1.*    | backbone.bottom_up.res5.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,1024,1,1)      |\n",
      "| backbone.bottom_up.res5.0.conv2.*    | backbone.bottom_up.res5.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |\n",
      "| backbone.bottom_up.res5.0.conv3.*    | backbone.bottom_up.res5.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
      "| backbone.bottom_up.res5.0.shortcut.* | backbone.bottom_up.res5.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (2048,) (2048,) (2048,) (2048,) (2048,1024,1,1) |\n",
      "| backbone.bottom_up.res5.1.conv1.*    | backbone.bottom_up.res5.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |\n",
      "| backbone.bottom_up.res5.1.conv2.*    | backbone.bottom_up.res5.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |\n",
      "| backbone.bottom_up.res5.1.conv3.*    | backbone.bottom_up.res5.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
      "| backbone.bottom_up.res5.2.conv1.*    | backbone.bottom_up.res5.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |\n",
      "| backbone.bottom_up.res5.2.conv2.*    | backbone.bottom_up.res5.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |\n",
      "| backbone.bottom_up.res5.2.conv3.*    | backbone.bottom_up.res5.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
      "| backbone.bottom_up.stem.conv1.*      | backbone.bottom_up.stem.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}      | (64,) (64,) (64,) (64,) (64,3,7,7)              |\n",
      "| backbone.fpn_lateral2.*              | backbone.fpn_lateral2.{bias,weight}                                                                  | (256,) (256,256,1,1)                            |\n",
      "| backbone.fpn_lateral3.*              | backbone.fpn_lateral3.{bias,weight}                                                                  | (256,) (256,512,1,1)                            |\n",
      "| backbone.fpn_lateral4.*              | backbone.fpn_lateral4.{bias,weight}                                                                  | (256,) (256,1024,1,1)                           |\n",
      "| backbone.fpn_lateral5.*              | backbone.fpn_lateral5.{bias,weight}                                                                  | (256,) (256,2048,1,1)                           |\n",
      "| backbone.fpn_output2.*               | backbone.fpn_output2.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| backbone.fpn_output3.*               | backbone.fpn_output3.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| backbone.fpn_output4.*               | backbone.fpn_output4.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| backbone.fpn_output5.*               | backbone.fpn_output5.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| sem_seg_head.p2.0.*                  | sem_seg_head.p2.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p3.0.*                  | sem_seg_head.p3.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p4.0.*                  | sem_seg_head.p4.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p4.2.*                  | sem_seg_head.p4.2.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,128,3,3)                     |\n",
      "| sem_seg_head.p5.0.*                  | sem_seg_head.p5.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p5.2.*                  | sem_seg_head.p5.2.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,128,3,3)                     |\n",
      "| sem_seg_head.p5.4.*                  | sem_seg_head.p5.4.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,128,3,3)                     |\n",
      "| sem_seg_head.predictor.*             | sem_seg_head.predictor.{bias,weight}                                                                 | (17,) (17,128,1,1)                              |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/06 03:29:12 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(720, 720), max_size=2048, sample_style='choice')]\n",
      "\u001b[32m[07/06 03:29:12 d2.data.common]: \u001b[0mSerializing 1081 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[07/06 03:29:12 d2.data.common]: \u001b[0mSerialized dataset takes 0.38 MiB\n",
      "\u001b[32m[07/06 03:29:12 d2.evaluation.evaluator]: \u001b[0mStart inference on 1081 batches\n",
      "\u001b[32m[07/06 03:29:13 d2.evaluation.evaluator]: \u001b[0mInference done 11/1081. Dataloading: 0.0016 s/iter. Inference: 0.0353 s/iter. Eval: 0.0426 s/iter. Total: 0.0795 s/iter. ETA=0:01:25\n",
      "\u001b[32m[07/06 03:29:18 d2.evaluation.evaluator]: \u001b[0mInference done 78/1081. Dataloading: 0.0020 s/iter. Inference: 0.0349 s/iter. Eval: 0.0386 s/iter. Total: 0.0756 s/iter. ETA=0:01:15\n",
      "\u001b[32m[07/06 03:29:23 d2.evaluation.evaluator]: \u001b[0mInference done 145/1081. Dataloading: 0.0021 s/iter. Inference: 0.0349 s/iter. Eval: 0.0382 s/iter. Total: 0.0753 s/iter. ETA=0:01:10\n",
      "\u001b[32m[07/06 03:29:28 d2.evaluation.evaluator]: \u001b[0mInference done 212/1081. Dataloading: 0.0021 s/iter. Inference: 0.0349 s/iter. Eval: 0.0382 s/iter. Total: 0.0753 s/iter. ETA=0:01:05\n",
      "\u001b[32m[07/06 03:29:33 d2.evaluation.evaluator]: \u001b[0mInference done 277/1081. Dataloading: 0.0021 s/iter. Inference: 0.0350 s/iter. Eval: 0.0387 s/iter. Total: 0.0758 s/iter. ETA=0:01:00\n",
      "\u001b[32m[07/06 03:29:38 d2.evaluation.evaluator]: \u001b[0mInference done 342/1081. Dataloading: 0.0021 s/iter. Inference: 0.0350 s/iter. Eval: 0.0390 s/iter. Total: 0.0761 s/iter. ETA=0:00:56\n",
      "\u001b[32m[07/06 03:29:43 d2.evaluation.evaluator]: \u001b[0mInference done 408/1081. Dataloading: 0.0021 s/iter. Inference: 0.0350 s/iter. Eval: 0.0390 s/iter. Total: 0.0763 s/iter. ETA=0:00:51\n",
      "\u001b[32m[07/06 03:29:48 d2.evaluation.evaluator]: \u001b[0mInference done 473/1081. Dataloading: 0.0021 s/iter. Inference: 0.0350 s/iter. Eval: 0.0392 s/iter. Total: 0.0764 s/iter. ETA=0:00:46\n",
      "\u001b[32m[07/06 03:29:53 d2.evaluation.evaluator]: \u001b[0mInference done 538/1081. Dataloading: 0.0022 s/iter. Inference: 0.0350 s/iter. Eval: 0.0392 s/iter. Total: 0.0765 s/iter. ETA=0:00:41\n",
      "\u001b[32m[07/06 03:29:58 d2.evaluation.evaluator]: \u001b[0mInference done 604/1081. Dataloading: 0.0022 s/iter. Inference: 0.0351 s/iter. Eval: 0.0392 s/iter. Total: 0.0765 s/iter. ETA=0:00:36\n",
      "\u001b[32m[07/06 03:30:03 d2.evaluation.evaluator]: \u001b[0mInference done 669/1081. Dataloading: 0.0022 s/iter. Inference: 0.0351 s/iter. Eval: 0.0393 s/iter. Total: 0.0766 s/iter. ETA=0:00:31\n",
      "\u001b[32m[07/06 03:30:08 d2.evaluation.evaluator]: \u001b[0mInference done 733/1081. Dataloading: 0.0023 s/iter. Inference: 0.0351 s/iter. Eval: 0.0393 s/iter. Total: 0.0768 s/iter. ETA=0:00:26\n",
      "\u001b[32m[07/06 03:30:13 d2.evaluation.evaluator]: \u001b[0mInference done 799/1081. Dataloading: 0.0023 s/iter. Inference: 0.0351 s/iter. Eval: 0.0393 s/iter. Total: 0.0768 s/iter. ETA=0:00:21\n",
      "\u001b[32m[07/06 03:30:18 d2.evaluation.evaluator]: \u001b[0mInference done 865/1081. Dataloading: 0.0023 s/iter. Inference: 0.0351 s/iter. Eval: 0.0393 s/iter. Total: 0.0768 s/iter. ETA=0:00:16\n",
      "\u001b[32m[07/06 03:30:23 d2.evaluation.evaluator]: \u001b[0mInference done 931/1081. Dataloading: 0.0023 s/iter. Inference: 0.0351 s/iter. Eval: 0.0392 s/iter. Total: 0.0767 s/iter. ETA=0:00:11\n",
      "\u001b[32m[07/06 03:30:28 d2.evaluation.evaluator]: \u001b[0mInference done 996/1081. Dataloading: 0.0023 s/iter. Inference: 0.0351 s/iter. Eval: 0.0393 s/iter. Total: 0.0768 s/iter. ETA=0:00:06\n",
      "\u001b[32m[07/06 03:30:34 d2.evaluation.evaluator]: \u001b[0mInference done 1062/1081. Dataloading: 0.0023 s/iter. Inference: 0.0352 s/iter. Eval: 0.0393 s/iter. Total: 0.0768 s/iter. ETA=0:00:01\n",
      "\u001b[32m[07/06 03:30:35 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:01:22.740144 (0.076896 s / iter per device, on 1 devices)\n",
      "\u001b[32m[07/06 03:30:35 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:37 (0.035171 s / iter per device, on 1 devices)\n",
      "\u001b[32m[07/06 03:30:35 d2.evaluation.sem_seg_evaluation]: \u001b[0mOrderedDict([('sem_seg', {'mIoU': 60.782390522192095, 'fwIoU': 86.39222099521021, 'IoU-Unlabeled': nan, 'IoU-Building': 82.00768838030547, 'IoU-Fence': 23.980245597737664, 'IoU-Pedestrian': 24.67731618097914, 'IoU-Pole': 45.354827775170406, 'IoU-Road': 96.92406593746054, 'IoU-SideWalk': 75.57696318915517, 'IoU-Vegetation': 72.8918690396316, 'IoU-Vehicles': 83.86934153835871, 'IoU-Wall': 63.21148783764416, 'IoU-TrafficSign': 48.12156891583644, 'IoU-Sky': 87.33018545445951, 'IoU-TrafficLight': 68.84062771588401, 'IoU-Terrain': 51.70566552997561, 'IoU-ConstructionVehicle': 82.6088477731545, 'IoU-workzone_object': 65.41754748932074, 'IoU-Detour': 0.0, 'mACC': 70.80357335047619, 'pACC': 92.29566764739894, 'ACC-Unlabeled': nan, 'ACC-Building': 96.73244395769464, 'ACC-Fence': 30.359504579066886, 'ACC-Pedestrian': 66.0056205175486, 'ACC-Pole': 51.673934908049446, 'ACC-Road': 97.83298639755849, 'ACC-SideWalk': 88.91156192504427, 'ACC-Vegetation': 81.12245398929755, 'ACC-Vehicles': 88.00484257450542, 'ACC-Wall': 80.61274821938967, 'ACC-TrafficSign': 60.39929851361776, 'ACC-Sky': 88.67969731206688, 'ACC-TrafficLight': 79.12514446596153, 'ACC-Terrain': 61.941751305462404, 'ACC-ConstructionVehicle': 86.8761766796154, 'ACC-workzone_object': 74.57900826273995, 'ACC-Detour': 0.0})])\n",
      "\u001b[32m[07/06 03:30:35 d2.engine.defaults]: \u001b[0mEvaluation results for carla_rain_val in csv format:\n",
      "\u001b[32m[07/06 03:30:35 d2.evaluation.testing]: \u001b[0mcopypaste: Task: sem_seg\n",
      "\u001b[32m[07/06 03:30:35 d2.evaluation.testing]: \u001b[0mcopypaste: mIoU,fwIoU,mACC,pACC\n",
      "\u001b[32m[07/06 03:30:35 d2.evaluation.testing]: \u001b[0mcopypaste: 60.7824,86.3922,70.8036,92.2957\n"
     ]
    }
   ],
   "source": [
    "trainer_day = Detectron2Trainer('combined_clear_train', 'carla_rain_val', output_folder='./output_day_clear_40k')\n",
    "trainer_day.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "96f7b0e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/06 03:30:36 d2.engine.defaults]: \u001b[0mModel:\n",
      "SemanticSegmentor(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (sem_seg_head): SemSegFPNHead(\n",
      "    (p2): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "    )\n",
      "    (p3): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (1): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "    )\n",
      "    (p4): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (1): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      (2): Conv2d(\n",
      "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (3): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "    )\n",
      "    (p5): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (1): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      (2): Conv2d(\n",
      "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (3): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      (4): Conv2d(\n",
      "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (5): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "    )\n",
      "    (predictor): Conv2d(128, 17, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/06 03:30:36 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(720, 720), max_size=2048, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[07/06 03:30:36 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[07/06 03:30:36 d2.data.common]: \u001b[0mSerializing 1176 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[07/06 03:30:36 d2.data.common]: \u001b[0mSerialized dataset takes 0.41 MiB\n",
      "Last checkpoint: model_final.pth\n",
      "\u001b[32m[07/06 03:30:36 d2.checkpoint.c2_model_loading]: \u001b[0mFollowing weights matched with model:\n",
      "| Names in Model                       | Names in Checkpoint                                                                                  | Shapes                                          |\n",
      "|:-------------------------------------|:-----------------------------------------------------------------------------------------------------|:------------------------------------------------|\n",
      "| backbone.bottom_up.res2.0.conv1.*    | backbone.bottom_up.res2.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,1,1)             |\n",
      "| backbone.bottom_up.res2.0.conv2.*    | backbone.bottom_up.res2.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |\n",
      "| backbone.bottom_up.res2.0.conv3.*    | backbone.bottom_up.res2.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res2.0.shortcut.* | backbone.bottom_up.res2.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res2.1.conv1.*    | backbone.bottom_up.res2.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |\n",
      "| backbone.bottom_up.res2.1.conv2.*    | backbone.bottom_up.res2.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |\n",
      "| backbone.bottom_up.res2.1.conv3.*    | backbone.bottom_up.res2.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res2.2.conv1.*    | backbone.bottom_up.res2.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |\n",
      "| backbone.bottom_up.res2.2.conv2.*    | backbone.bottom_up.res2.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |\n",
      "| backbone.bottom_up.res2.2.conv3.*    | backbone.bottom_up.res2.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res3.0.conv1.*    | backbone.bottom_up.res3.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,256,1,1)       |\n",
      "| backbone.bottom_up.res3.0.conv2.*    | backbone.bottom_up.res3.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.0.conv3.*    | backbone.bottom_up.res3.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res3.0.shortcut.* | backbone.bottom_up.res3.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (512,) (512,) (512,) (512,) (512,256,1,1)       |\n",
      "| backbone.bottom_up.res3.1.conv1.*    | backbone.bottom_up.res3.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |\n",
      "| backbone.bottom_up.res3.1.conv2.*    | backbone.bottom_up.res3.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.1.conv3.*    | backbone.bottom_up.res3.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res3.2.conv1.*    | backbone.bottom_up.res3.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |\n",
      "| backbone.bottom_up.res3.2.conv2.*    | backbone.bottom_up.res3.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.2.conv3.*    | backbone.bottom_up.res3.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res3.3.conv1.*    | backbone.bottom_up.res3.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |\n",
      "| backbone.bottom_up.res3.3.conv2.*    | backbone.bottom_up.res3.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.3.conv3.*    | backbone.bottom_up.res3.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res4.0.conv1.*    | backbone.bottom_up.res4.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,512,1,1)       |\n",
      "| backbone.bottom_up.res4.0.conv2.*    | backbone.bottom_up.res4.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.0.conv3.*    | backbone.bottom_up.res4.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.0.shortcut.* | backbone.bottom_up.res4.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (1024,) (1024,) (1024,) (1024,) (1024,512,1,1)  |\n",
      "| backbone.bottom_up.res4.1.conv1.*    | backbone.bottom_up.res4.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.1.conv2.*    | backbone.bottom_up.res4.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.1.conv3.*    | backbone.bottom_up.res4.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.2.conv1.*    | backbone.bottom_up.res4.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.2.conv2.*    | backbone.bottom_up.res4.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.2.conv3.*    | backbone.bottom_up.res4.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.3.conv1.*    | backbone.bottom_up.res4.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.3.conv2.*    | backbone.bottom_up.res4.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.3.conv3.*    | backbone.bottom_up.res4.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.4.conv1.*    | backbone.bottom_up.res4.4.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.4.conv2.*    | backbone.bottom_up.res4.4.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.4.conv3.*    | backbone.bottom_up.res4.4.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.5.conv1.*    | backbone.bottom_up.res4.5.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.5.conv2.*    | backbone.bottom_up.res4.5.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.5.conv3.*    | backbone.bottom_up.res4.5.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res5.0.conv1.*    | backbone.bottom_up.res5.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,1024,1,1)      |\n",
      "| backbone.bottom_up.res5.0.conv2.*    | backbone.bottom_up.res5.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |\n",
      "| backbone.bottom_up.res5.0.conv3.*    | backbone.bottom_up.res5.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
      "| backbone.bottom_up.res5.0.shortcut.* | backbone.bottom_up.res5.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (2048,) (2048,) (2048,) (2048,) (2048,1024,1,1) |\n",
      "| backbone.bottom_up.res5.1.conv1.*    | backbone.bottom_up.res5.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |\n",
      "| backbone.bottom_up.res5.1.conv2.*    | backbone.bottom_up.res5.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |\n",
      "| backbone.bottom_up.res5.1.conv3.*    | backbone.bottom_up.res5.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
      "| backbone.bottom_up.res5.2.conv1.*    | backbone.bottom_up.res5.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |\n",
      "| backbone.bottom_up.res5.2.conv2.*    | backbone.bottom_up.res5.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |\n",
      "| backbone.bottom_up.res5.2.conv3.*    | backbone.bottom_up.res5.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
      "| backbone.bottom_up.stem.conv1.*      | backbone.bottom_up.stem.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}      | (64,) (64,) (64,) (64,) (64,3,7,7)              |\n",
      "| backbone.fpn_lateral2.*              | backbone.fpn_lateral2.{bias,weight}                                                                  | (256,) (256,256,1,1)                            |\n",
      "| backbone.fpn_lateral3.*              | backbone.fpn_lateral3.{bias,weight}                                                                  | (256,) (256,512,1,1)                            |\n",
      "| backbone.fpn_lateral4.*              | backbone.fpn_lateral4.{bias,weight}                                                                  | (256,) (256,1024,1,1)                           |\n",
      "| backbone.fpn_lateral5.*              | backbone.fpn_lateral5.{bias,weight}                                                                  | (256,) (256,2048,1,1)                           |\n",
      "| backbone.fpn_output2.*               | backbone.fpn_output2.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| backbone.fpn_output3.*               | backbone.fpn_output3.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| backbone.fpn_output4.*               | backbone.fpn_output4.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| backbone.fpn_output5.*               | backbone.fpn_output5.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| sem_seg_head.p2.0.*                  | sem_seg_head.p2.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p3.0.*                  | sem_seg_head.p3.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p4.0.*                  | sem_seg_head.p4.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p4.2.*                  | sem_seg_head.p4.2.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,128,3,3)                     |\n",
      "| sem_seg_head.p5.0.*                  | sem_seg_head.p5.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p5.2.*                  | sem_seg_head.p5.2.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,128,3,3)                     |\n",
      "| sem_seg_head.p5.4.*                  | sem_seg_head.p5.4.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,128,3,3)                     |\n",
      "| sem_seg_head.predictor.*             | sem_seg_head.predictor.{bias,weight}                                                                 | (17,) (17,128,1,1)                              |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/06 03:30:36 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(720, 720), max_size=2048, sample_style='choice')]\n",
      "\u001b[32m[07/06 03:30:36 d2.data.common]: \u001b[0mSerializing 699 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[07/06 03:30:36 d2.data.common]: \u001b[0mSerialized dataset takes 0.23 MiB\n",
      "\u001b[32m[07/06 03:30:36 d2.evaluation.evaluator]: \u001b[0mStart inference on 699 batches\n",
      "\u001b[32m[07/06 03:30:39 d2.evaluation.evaluator]: \u001b[0mInference done 11/699. Dataloading: 0.0017 s/iter. Inference: 0.0470 s/iter. Eval: 0.1530 s/iter. Total: 0.2017 s/iter. ETA=0:02:18\n",
      "\u001b[32m[07/06 03:30:44 d2.evaluation.evaluator]: \u001b[0mInference done 37/699. Dataloading: 0.0021 s/iter. Inference: 0.0469 s/iter. Eval: 0.1504 s/iter. Total: 0.1996 s/iter. ETA=0:02:12\n",
      "\u001b[32m[07/06 03:30:49 d2.evaluation.evaluator]: \u001b[0mInference done 62/699. Dataloading: 0.0021 s/iter. Inference: 0.0469 s/iter. Eval: 0.1506 s/iter. Total: 0.1998 s/iter. ETA=0:02:07\n",
      "\u001b[32m[07/06 03:30:54 d2.evaluation.evaluator]: \u001b[0mInference done 88/699. Dataloading: 0.0021 s/iter. Inference: 0.0469 s/iter. Eval: 0.1489 s/iter. Total: 0.1980 s/iter. ETA=0:02:00\n",
      "\u001b[32m[07/06 03:30:59 d2.evaluation.evaluator]: \u001b[0mInference done 115/699. Dataloading: 0.0021 s/iter. Inference: 0.0469 s/iter. Eval: 0.1467 s/iter. Total: 0.1958 s/iter. ETA=0:01:54\n",
      "\u001b[32m[07/06 03:31:04 d2.evaluation.evaluator]: \u001b[0mInference done 142/699. Dataloading: 0.0021 s/iter. Inference: 0.0469 s/iter. Eval: 0.1451 s/iter. Total: 0.1941 s/iter. ETA=0:01:48\n",
      "\u001b[32m[07/06 03:31:09 d2.evaluation.evaluator]: \u001b[0mInference done 169/699. Dataloading: 0.0021 s/iter. Inference: 0.0467 s/iter. Eval: 0.1442 s/iter. Total: 0.1931 s/iter. ETA=0:01:42\n",
      "\u001b[32m[07/06 03:31:14 d2.evaluation.evaluator]: \u001b[0mInference done 194/699. Dataloading: 0.0021 s/iter. Inference: 0.0467 s/iter. Eval: 0.1456 s/iter. Total: 0.1945 s/iter. ETA=0:01:38\n",
      "\u001b[32m[07/06 03:31:19 d2.evaluation.evaluator]: \u001b[0mInference done 219/699. Dataloading: 0.0021 s/iter. Inference: 0.0467 s/iter. Eval: 0.1466 s/iter. Total: 0.1955 s/iter. ETA=0:01:33\n",
      "\u001b[32m[07/06 03:31:24 d2.evaluation.evaluator]: \u001b[0mInference done 245/699. Dataloading: 0.0021 s/iter. Inference: 0.0467 s/iter. Eval: 0.1468 s/iter. Total: 0.1957 s/iter. ETA=0:01:28\n",
      "\u001b[32m[07/06 03:31:30 d2.evaluation.evaluator]: \u001b[0mInference done 271/699. Dataloading: 0.0021 s/iter. Inference: 0.0467 s/iter. Eval: 0.1470 s/iter. Total: 0.1959 s/iter. ETA=0:01:23\n",
      "\u001b[32m[07/06 03:31:35 d2.evaluation.evaluator]: \u001b[0mInference done 297/699. Dataloading: 0.0021 s/iter. Inference: 0.0467 s/iter. Eval: 0.1471 s/iter. Total: 0.1960 s/iter. ETA=0:01:18\n",
      "\u001b[32m[07/06 03:31:40 d2.evaluation.evaluator]: \u001b[0mInference done 323/699. Dataloading: 0.0021 s/iter. Inference: 0.0467 s/iter. Eval: 0.1470 s/iter. Total: 0.1959 s/iter. ETA=0:01:13\n",
      "\u001b[32m[07/06 03:31:45 d2.evaluation.evaluator]: \u001b[0mInference done 349/699. Dataloading: 0.0021 s/iter. Inference: 0.0467 s/iter. Eval: 0.1472 s/iter. Total: 0.1960 s/iter. ETA=0:01:08\n",
      "\u001b[32m[07/06 03:31:50 d2.evaluation.evaluator]: \u001b[0mInference done 375/699. Dataloading: 0.0021 s/iter. Inference: 0.0467 s/iter. Eval: 0.1474 s/iter. Total: 0.1963 s/iter. ETA=0:01:03\n",
      "\u001b[32m[07/06 03:31:55 d2.evaluation.evaluator]: \u001b[0mInference done 400/699. Dataloading: 0.0021 s/iter. Inference: 0.0467 s/iter. Eval: 0.1478 s/iter. Total: 0.1967 s/iter. ETA=0:00:58\n",
      "\u001b[32m[07/06 03:32:00 d2.evaluation.evaluator]: \u001b[0mInference done 426/699. Dataloading: 0.0021 s/iter. Inference: 0.0467 s/iter. Eval: 0.1480 s/iter. Total: 0.1969 s/iter. ETA=0:00:53\n",
      "\u001b[32m[07/06 03:32:05 d2.evaluation.evaluator]: \u001b[0mInference done 452/699. Dataloading: 0.0021 s/iter. Inference: 0.0467 s/iter. Eval: 0.1478 s/iter. Total: 0.1967 s/iter. ETA=0:00:48\n",
      "\u001b[32m[07/06 03:32:11 d2.evaluation.evaluator]: \u001b[0mInference done 479/699. Dataloading: 0.0021 s/iter. Inference: 0.0467 s/iter. Eval: 0.1473 s/iter. Total: 0.1963 s/iter. ETA=0:00:43\n",
      "\u001b[32m[07/06 03:32:16 d2.evaluation.evaluator]: \u001b[0mInference done 505/699. Dataloading: 0.0021 s/iter. Inference: 0.0467 s/iter. Eval: 0.1474 s/iter. Total: 0.1963 s/iter. ETA=0:00:38\n",
      "\u001b[32m[07/06 03:32:21 d2.evaluation.evaluator]: \u001b[0mInference done 531/699. Dataloading: 0.0021 s/iter. Inference: 0.0467 s/iter. Eval: 0.1473 s/iter. Total: 0.1962 s/iter. ETA=0:00:32\n",
      "\u001b[32m[07/06 03:32:26 d2.evaluation.evaluator]: \u001b[0mInference done 557/699. Dataloading: 0.0021 s/iter. Inference: 0.0467 s/iter. Eval: 0.1472 s/iter. Total: 0.1961 s/iter. ETA=0:00:27\n",
      "\u001b[32m[07/06 03:32:31 d2.evaluation.evaluator]: \u001b[0mInference done 583/699. Dataloading: 0.0021 s/iter. Inference: 0.0467 s/iter. Eval: 0.1473 s/iter. Total: 0.1962 s/iter. ETA=0:00:22\n",
      "\u001b[32m[07/06 03:32:36 d2.evaluation.evaluator]: \u001b[0mInference done 609/699. Dataloading: 0.0021 s/iter. Inference: 0.0467 s/iter. Eval: 0.1474 s/iter. Total: 0.1963 s/iter. ETA=0:00:17\n",
      "\u001b[32m[07/06 03:32:41 d2.evaluation.evaluator]: \u001b[0mInference done 635/699. Dataloading: 0.0021 s/iter. Inference: 0.0467 s/iter. Eval: 0.1475 s/iter. Total: 0.1964 s/iter. ETA=0:00:12\n",
      "\u001b[32m[07/06 03:32:46 d2.evaluation.evaluator]: \u001b[0mInference done 661/699. Dataloading: 0.0021 s/iter. Inference: 0.0467 s/iter. Eval: 0.1474 s/iter. Total: 0.1963 s/iter. ETA=0:00:07\n",
      "\u001b[32m[07/06 03:32:51 d2.evaluation.evaluator]: \u001b[0mInference done 687/699. Dataloading: 0.0021 s/iter. Inference: 0.0467 s/iter. Eval: 0.1474 s/iter. Total: 0.1963 s/iter. ETA=0:00:02\n",
      "\u001b[32m[07/06 03:32:54 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:02:16.401972 (0.196545 s / iter per device, on 1 devices)\n",
      "\u001b[32m[07/06 03:32:54 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:32 (0.046731 s / iter per device, on 1 devices)\n",
      "\u001b[32m[07/06 03:32:54 d2.evaluation.sem_seg_evaluation]: \u001b[0mOrderedDict([('sem_seg', {'mIoU': 56.73016122708587, 'fwIoU': 84.32250106786894, 'IoU-Unlabeled': nan, 'IoU-Building': 81.33642727579495, 'IoU-Fence': 41.88404854680119, 'IoU-Pedestrian': 71.09721003303277, 'IoU-Pole': 44.976748900747396, 'IoU-Road': 94.92799923385024, 'IoU-SideWalk': 71.7089316503013, 'IoU-Vegetation': 80.53040286287113, 'IoU-Vehicles': 86.34138207675134, 'IoU-Wall': 32.0236780844832, 'IoU-TrafficSign': 58.407017364803885, 'IoU-Sky': 84.29985501380426, 'IoU-TrafficLight': 48.482926724524106, 'IoU-Terrain': 54.935790638522306, 'IoU-ConstructionVehicle': nan, 'IoU-workzone_object': nan, 'IoU-Detour': nan, 'mACC': 74.8323010450807, 'pACC': 91.06547140805176, 'ACC-Unlabeled': nan, 'ACC-Building': 96.67855394958005, 'ACC-Fence': 51.187572441368815, 'ACC-Pedestrian': 86.27566039994836, 'ACC-Pole': 54.283467306967715, 'ACC-Road': 96.7499613632782, 'ACC-SideWalk': 82.59501339371171, 'ACC-Vegetation': 84.46880248344027, 'ACC-Vehicles': 91.70853752290617, 'ACC-Wall': 51.95117439432529, 'ACC-TrafficSign': 64.29413605720174, 'ACC-Sky': 87.29132376072309, 'ACC-TrafficLight': 55.362228654552716, 'ACC-Terrain': 69.97348185804483, 'ACC-ConstructionVehicle': nan, 'ACC-workzone_object': nan, 'ACC-Detour': nan})])\n",
      "\u001b[32m[07/06 03:32:54 d2.engine.defaults]: \u001b[0mEvaluation results for cityscapes_rain_val in csv format:\n",
      "\u001b[32m[07/06 03:32:54 d2.evaluation.testing]: \u001b[0mcopypaste: Task: sem_seg\n",
      "\u001b[32m[07/06 03:32:54 d2.evaluation.testing]: \u001b[0mcopypaste: mIoU,fwIoU,mACC,pACC\n",
      "\u001b[32m[07/06 03:32:54 d2.evaluation.testing]: \u001b[0mcopypaste: 56.7302,84.3225,74.8323,91.0655\n"
     ]
    }
   ],
   "source": [
    "trainer_day = Detectron2Trainer('combined_clear_train', 'cityscapes_rain_val', output_folder='./output_day_clear_40k')\n",
    "trainer_day.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0018b32b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/06 03:32:54 d2.engine.defaults]: \u001b[0mModel:\n",
      "SemanticSegmentor(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (sem_seg_head): SemSegFPNHead(\n",
      "    (p2): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "    )\n",
      "    (p3): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (1): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "    )\n",
      "    (p4): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (1): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      (2): Conv2d(\n",
      "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (3): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "    )\n",
      "    (p5): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (1): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      (2): Conv2d(\n",
      "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (3): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      (4): Conv2d(\n",
      "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (5): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "    )\n",
      "    (predictor): Conv2d(128, 17, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/06 03:32:54 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(720, 720), max_size=2048, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[07/06 03:32:54 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[07/06 03:32:54 d2.data.common]: \u001b[0mSerializing 1176 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[07/06 03:32:54 d2.data.common]: \u001b[0mSerialized dataset takes 0.41 MiB\n",
      "Last checkpoint: model_final.pth\n",
      "\u001b[32m[07/06 03:32:55 d2.checkpoint.c2_model_loading]: \u001b[0mFollowing weights matched with model:\n",
      "| Names in Model                       | Names in Checkpoint                                                                                  | Shapes                                          |\n",
      "|:-------------------------------------|:-----------------------------------------------------------------------------------------------------|:------------------------------------------------|\n",
      "| backbone.bottom_up.res2.0.conv1.*    | backbone.bottom_up.res2.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,1,1)             |\n",
      "| backbone.bottom_up.res2.0.conv2.*    | backbone.bottom_up.res2.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |\n",
      "| backbone.bottom_up.res2.0.conv3.*    | backbone.bottom_up.res2.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res2.0.shortcut.* | backbone.bottom_up.res2.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res2.1.conv1.*    | backbone.bottom_up.res2.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |\n",
      "| backbone.bottom_up.res2.1.conv2.*    | backbone.bottom_up.res2.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |\n",
      "| backbone.bottom_up.res2.1.conv3.*    | backbone.bottom_up.res2.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res2.2.conv1.*    | backbone.bottom_up.res2.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |\n",
      "| backbone.bottom_up.res2.2.conv2.*    | backbone.bottom_up.res2.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |\n",
      "| backbone.bottom_up.res2.2.conv3.*    | backbone.bottom_up.res2.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res3.0.conv1.*    | backbone.bottom_up.res3.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,256,1,1)       |\n",
      "| backbone.bottom_up.res3.0.conv2.*    | backbone.bottom_up.res3.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.0.conv3.*    | backbone.bottom_up.res3.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res3.0.shortcut.* | backbone.bottom_up.res3.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (512,) (512,) (512,) (512,) (512,256,1,1)       |\n",
      "| backbone.bottom_up.res3.1.conv1.*    | backbone.bottom_up.res3.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |\n",
      "| backbone.bottom_up.res3.1.conv2.*    | backbone.bottom_up.res3.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.1.conv3.*    | backbone.bottom_up.res3.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res3.2.conv1.*    | backbone.bottom_up.res3.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |\n",
      "| backbone.bottom_up.res3.2.conv2.*    | backbone.bottom_up.res3.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.2.conv3.*    | backbone.bottom_up.res3.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res3.3.conv1.*    | backbone.bottom_up.res3.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |\n",
      "| backbone.bottom_up.res3.3.conv2.*    | backbone.bottom_up.res3.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.3.conv3.*    | backbone.bottom_up.res3.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res4.0.conv1.*    | backbone.bottom_up.res4.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,512,1,1)       |\n",
      "| backbone.bottom_up.res4.0.conv2.*    | backbone.bottom_up.res4.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.0.conv3.*    | backbone.bottom_up.res4.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.0.shortcut.* | backbone.bottom_up.res4.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (1024,) (1024,) (1024,) (1024,) (1024,512,1,1)  |\n",
      "| backbone.bottom_up.res4.1.conv1.*    | backbone.bottom_up.res4.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.1.conv2.*    | backbone.bottom_up.res4.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.1.conv3.*    | backbone.bottom_up.res4.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.2.conv1.*    | backbone.bottom_up.res4.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.2.conv2.*    | backbone.bottom_up.res4.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.2.conv3.*    | backbone.bottom_up.res4.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.3.conv1.*    | backbone.bottom_up.res4.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.3.conv2.*    | backbone.bottom_up.res4.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.3.conv3.*    | backbone.bottom_up.res4.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.4.conv1.*    | backbone.bottom_up.res4.4.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.4.conv2.*    | backbone.bottom_up.res4.4.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.4.conv3.*    | backbone.bottom_up.res4.4.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.5.conv1.*    | backbone.bottom_up.res4.5.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.5.conv2.*    | backbone.bottom_up.res4.5.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.5.conv3.*    | backbone.bottom_up.res4.5.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res5.0.conv1.*    | backbone.bottom_up.res5.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,1024,1,1)      |\n",
      "| backbone.bottom_up.res5.0.conv2.*    | backbone.bottom_up.res5.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |\n",
      "| backbone.bottom_up.res5.0.conv3.*    | backbone.bottom_up.res5.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
      "| backbone.bottom_up.res5.0.shortcut.* | backbone.bottom_up.res5.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (2048,) (2048,) (2048,) (2048,) (2048,1024,1,1) |\n",
      "| backbone.bottom_up.res5.1.conv1.*    | backbone.bottom_up.res5.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |\n",
      "| backbone.bottom_up.res5.1.conv2.*    | backbone.bottom_up.res5.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |\n",
      "| backbone.bottom_up.res5.1.conv3.*    | backbone.bottom_up.res5.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
      "| backbone.bottom_up.res5.2.conv1.*    | backbone.bottom_up.res5.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |\n",
      "| backbone.bottom_up.res5.2.conv2.*    | backbone.bottom_up.res5.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |\n",
      "| backbone.bottom_up.res5.2.conv3.*    | backbone.bottom_up.res5.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
      "| backbone.bottom_up.stem.conv1.*      | backbone.bottom_up.stem.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}      | (64,) (64,) (64,) (64,) (64,3,7,7)              |\n",
      "| backbone.fpn_lateral2.*              | backbone.fpn_lateral2.{bias,weight}                                                                  | (256,) (256,256,1,1)                            |\n",
      "| backbone.fpn_lateral3.*              | backbone.fpn_lateral3.{bias,weight}                                                                  | (256,) (256,512,1,1)                            |\n",
      "| backbone.fpn_lateral4.*              | backbone.fpn_lateral4.{bias,weight}                                                                  | (256,) (256,1024,1,1)                           |\n",
      "| backbone.fpn_lateral5.*              | backbone.fpn_lateral5.{bias,weight}                                                                  | (256,) (256,2048,1,1)                           |\n",
      "| backbone.fpn_output2.*               | backbone.fpn_output2.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| backbone.fpn_output3.*               | backbone.fpn_output3.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| backbone.fpn_output4.*               | backbone.fpn_output4.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| backbone.fpn_output5.*               | backbone.fpn_output5.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| sem_seg_head.p2.0.*                  | sem_seg_head.p2.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p3.0.*                  | sem_seg_head.p3.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p4.0.*                  | sem_seg_head.p4.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p4.2.*                  | sem_seg_head.p4.2.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,128,3,3)                     |\n",
      "| sem_seg_head.p5.0.*                  | sem_seg_head.p5.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p5.2.*                  | sem_seg_head.p5.2.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,128,3,3)                     |\n",
      "| sem_seg_head.p5.4.*                  | sem_seg_head.p5.4.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,128,3,3)                     |\n",
      "| sem_seg_head.predictor.*             | sem_seg_head.predictor.{bias,weight}                                                                 | (17,) (17,128,1,1)                              |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/06 03:32:55 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(720, 720), max_size=2048, sample_style='choice')]\n",
      "\u001b[32m[07/06 03:32:55 d2.data.common]: \u001b[0mSerializing 1780 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[07/06 03:32:55 d2.data.common]: \u001b[0mSerialized dataset takes 0.61 MiB\n",
      "\u001b[32m[07/06 03:32:55 d2.evaluation.evaluator]: \u001b[0mStart inference on 1780 batches\n",
      "\u001b[32m[07/06 03:32:56 d2.evaluation.evaluator]: \u001b[0mInference done 15/1780. Dataloading: 0.0019 s/iter. Inference: 0.0348 s/iter. Eval: 0.0436 s/iter. Total: 0.0804 s/iter. ETA=0:02:21\n",
      "\u001b[32m[07/06 03:33:01 d2.evaluation.evaluator]: \u001b[0mInference done 81/1780. Dataloading: 0.0021 s/iter. Inference: 0.0351 s/iter. Eval: 0.0396 s/iter. Total: 0.0768 s/iter. ETA=0:02:10\n",
      "\u001b[32m[07/06 03:33:06 d2.evaluation.evaluator]: \u001b[0mInference done 147/1780. Dataloading: 0.0021 s/iter. Inference: 0.0351 s/iter. Eval: 0.0391 s/iter. Total: 0.0764 s/iter. ETA=0:02:04\n",
      "\u001b[32m[07/06 03:33:12 d2.evaluation.evaluator]: \u001b[0mInference done 213/1780. Dataloading: 0.0021 s/iter. Inference: 0.0351 s/iter. Eval: 0.0390 s/iter. Total: 0.0764 s/iter. ETA=0:01:59\n",
      "\u001b[32m[07/06 03:33:17 d2.evaluation.evaluator]: \u001b[0mInference done 277/1780. Dataloading: 0.0021 s/iter. Inference: 0.0351 s/iter. Eval: 0.0395 s/iter. Total: 0.0768 s/iter. ETA=0:01:55\n",
      "\u001b[32m[07/06 03:33:22 d2.evaluation.evaluator]: \u001b[0mInference done 341/1780. Dataloading: 0.0022 s/iter. Inference: 0.0351 s/iter. Eval: 0.0399 s/iter. Total: 0.0773 s/iter. ETA=0:01:51\n",
      "\u001b[32m[07/06 03:33:27 d2.evaluation.evaluator]: \u001b[0mInference done 405/1780. Dataloading: 0.0022 s/iter. Inference: 0.0352 s/iter. Eval: 0.0401 s/iter. Total: 0.0775 s/iter. ETA=0:01:46\n",
      "\u001b[32m[07/06 03:33:32 d2.evaluation.evaluator]: \u001b[0mInference done 469/1780. Dataloading: 0.0022 s/iter. Inference: 0.0352 s/iter. Eval: 0.0402 s/iter. Total: 0.0777 s/iter. ETA=0:01:41\n",
      "\u001b[32m[07/06 03:33:37 d2.evaluation.evaluator]: \u001b[0mInference done 534/1780. Dataloading: 0.0022 s/iter. Inference: 0.0352 s/iter. Eval: 0.0402 s/iter. Total: 0.0777 s/iter. ETA=0:01:36\n",
      "\u001b[32m[07/06 03:33:42 d2.evaluation.evaluator]: \u001b[0mInference done 599/1780. Dataloading: 0.0022 s/iter. Inference: 0.0352 s/iter. Eval: 0.0402 s/iter. Total: 0.0777 s/iter. ETA=0:01:31\n",
      "\u001b[32m[07/06 03:33:47 d2.evaluation.evaluator]: \u001b[0mInference done 663/1780. Dataloading: 0.0022 s/iter. Inference: 0.0352 s/iter. Eval: 0.0402 s/iter. Total: 0.0777 s/iter. ETA=0:01:26\n",
      "\u001b[32m[07/06 03:33:52 d2.evaluation.evaluator]: \u001b[0mInference done 728/1780. Dataloading: 0.0022 s/iter. Inference: 0.0352 s/iter. Eval: 0.0403 s/iter. Total: 0.0777 s/iter. ETA=0:01:21\n",
      "\u001b[32m[07/06 03:33:57 d2.evaluation.evaluator]: \u001b[0mInference done 793/1780. Dataloading: 0.0022 s/iter. Inference: 0.0352 s/iter. Eval: 0.0402 s/iter. Total: 0.0777 s/iter. ETA=0:01:16\n",
      "\u001b[32m[07/06 03:34:02 d2.evaluation.evaluator]: \u001b[0mInference done 857/1780. Dataloading: 0.0022 s/iter. Inference: 0.0352 s/iter. Eval: 0.0402 s/iter. Total: 0.0778 s/iter. ETA=0:01:11\n",
      "\u001b[32m[07/06 03:34:07 d2.evaluation.evaluator]: \u001b[0mInference done 921/1780. Dataloading: 0.0022 s/iter. Inference: 0.0352 s/iter. Eval: 0.0403 s/iter. Total: 0.0778 s/iter. ETA=0:01:06\n",
      "\u001b[32m[07/06 03:34:12 d2.evaluation.evaluator]: \u001b[0mInference done 984/1780. Dataloading: 0.0022 s/iter. Inference: 0.0354 s/iter. Eval: 0.0403 s/iter. Total: 0.0779 s/iter. ETA=0:01:02\n",
      "\u001b[32m[07/06 03:34:17 d2.evaluation.evaluator]: \u001b[0mInference done 1049/1780. Dataloading: 0.0022 s/iter. Inference: 0.0354 s/iter. Eval: 0.0402 s/iter. Total: 0.0779 s/iter. ETA=0:00:56\n",
      "\u001b[32m[07/06 03:34:22 d2.evaluation.evaluator]: \u001b[0mInference done 1094/1780. Dataloading: 0.0022 s/iter. Inference: 0.0355 s/iter. Eval: 0.0416 s/iter. Total: 0.0794 s/iter. ETA=0:00:54\n",
      "\u001b[32m[07/06 03:34:27 d2.evaluation.evaluator]: \u001b[0mInference done 1120/1780. Dataloading: 0.0022 s/iter. Inference: 0.0357 s/iter. Eval: 0.0441 s/iter. Total: 0.0821 s/iter. ETA=0:00:54\n",
      "\u001b[32m[07/06 03:34:32 d2.evaluation.evaluator]: \u001b[0mInference done 1146/1780. Dataloading: 0.0022 s/iter. Inference: 0.0360 s/iter. Eval: 0.0465 s/iter. Total: 0.0847 s/iter. ETA=0:00:53\n",
      "\u001b[32m[07/06 03:34:37 d2.evaluation.evaluator]: \u001b[0mInference done 1172/1780. Dataloading: 0.0022 s/iter. Inference: 0.0362 s/iter. Eval: 0.0487 s/iter. Total: 0.0872 s/iter. ETA=0:00:53\n",
      "\u001b[32m[07/06 03:34:43 d2.evaluation.evaluator]: \u001b[0mInference done 1199/1780. Dataloading: 0.0022 s/iter. Inference: 0.0365 s/iter. Eval: 0.0508 s/iter. Total: 0.0895 s/iter. ETA=0:00:52\n",
      "\u001b[32m[07/06 03:34:48 d2.evaluation.evaluator]: \u001b[0mInference done 1226/1780. Dataloading: 0.0022 s/iter. Inference: 0.0367 s/iter. Eval: 0.0527 s/iter. Total: 0.0917 s/iter. ETA=0:00:50\n",
      "\u001b[32m[07/06 03:34:53 d2.evaluation.evaluator]: \u001b[0mInference done 1253/1780. Dataloading: 0.0022 s/iter. Inference: 0.0369 s/iter. Eval: 0.0547 s/iter. Total: 0.0939 s/iter. ETA=0:00:49\n",
      "\u001b[32m[07/06 03:34:58 d2.evaluation.evaluator]: \u001b[0mInference done 1277/1780. Dataloading: 0.0022 s/iter. Inference: 0.0371 s/iter. Eval: 0.0567 s/iter. Total: 0.0961 s/iter. ETA=0:00:48\n",
      "\u001b[32m[07/06 03:35:03 d2.evaluation.evaluator]: \u001b[0mInference done 1302/1780. Dataloading: 0.0022 s/iter. Inference: 0.0373 s/iter. Eval: 0.0587 s/iter. Total: 0.0982 s/iter. ETA=0:00:46\n",
      "\u001b[32m[07/06 03:35:08 d2.evaluation.evaluator]: \u001b[0mInference done 1328/1780. Dataloading: 0.0022 s/iter. Inference: 0.0375 s/iter. Eval: 0.0605 s/iter. Total: 0.1002 s/iter. ETA=0:00:45\n",
      "\u001b[32m[07/06 03:35:13 d2.evaluation.evaluator]: \u001b[0mInference done 1353/1780. Dataloading: 0.0022 s/iter. Inference: 0.0376 s/iter. Eval: 0.0622 s/iter. Total: 0.1021 s/iter. ETA=0:00:43\n",
      "\u001b[32m[07/06 03:35:18 d2.evaluation.evaluator]: \u001b[0mInference done 1378/1780. Dataloading: 0.0022 s/iter. Inference: 0.0378 s/iter. Eval: 0.0638 s/iter. Total: 0.1039 s/iter. ETA=0:00:41\n",
      "\u001b[32m[07/06 03:35:23 d2.evaluation.evaluator]: \u001b[0mInference done 1403/1780. Dataloading: 0.0022 s/iter. Inference: 0.0380 s/iter. Eval: 0.0655 s/iter. Total: 0.1057 s/iter. ETA=0:00:39\n",
      "\u001b[32m[07/06 03:35:29 d2.evaluation.evaluator]: \u001b[0mInference done 1428/1780. Dataloading: 0.0022 s/iter. Inference: 0.0381 s/iter. Eval: 0.0671 s/iter. Total: 0.1075 s/iter. ETA=0:00:37\n",
      "\u001b[32m[07/06 03:35:34 d2.evaluation.evaluator]: \u001b[0mInference done 1454/1780. Dataloading: 0.0022 s/iter. Inference: 0.0383 s/iter. Eval: 0.0685 s/iter. Total: 0.1091 s/iter. ETA=0:00:35\n",
      "\u001b[32m[07/06 03:35:39 d2.evaluation.evaluator]: \u001b[0mInference done 1479/1780. Dataloading: 0.0022 s/iter. Inference: 0.0384 s/iter. Eval: 0.0700 s/iter. Total: 0.1107 s/iter. ETA=0:00:33\n",
      "\u001b[32m[07/06 03:35:44 d2.evaluation.evaluator]: \u001b[0mInference done 1505/1780. Dataloading: 0.0022 s/iter. Inference: 0.0386 s/iter. Eval: 0.0714 s/iter. Total: 0.1122 s/iter. ETA=0:00:30\n",
      "\u001b[32m[07/06 03:35:49 d2.evaluation.evaluator]: \u001b[0mInference done 1531/1780. Dataloading: 0.0022 s/iter. Inference: 0.0387 s/iter. Eval: 0.0727 s/iter. Total: 0.1137 s/iter. ETA=0:00:28\n",
      "\u001b[32m[07/06 03:35:54 d2.evaluation.evaluator]: \u001b[0mInference done 1557/1780. Dataloading: 0.0022 s/iter. Inference: 0.0389 s/iter. Eval: 0.0740 s/iter. Total: 0.1151 s/iter. ETA=0:00:25\n",
      "\u001b[32m[07/06 03:35:59 d2.evaluation.evaluator]: \u001b[0mInference done 1582/1780. Dataloading: 0.0022 s/iter. Inference: 0.0390 s/iter. Eval: 0.0753 s/iter. Total: 0.1165 s/iter. ETA=0:00:23\n",
      "\u001b[32m[07/06 03:36:04 d2.evaluation.evaluator]: \u001b[0mInference done 1607/1780. Dataloading: 0.0022 s/iter. Inference: 0.0391 s/iter. Eval: 0.0765 s/iter. Total: 0.1179 s/iter. ETA=0:00:20\n",
      "\u001b[32m[07/06 03:36:10 d2.evaluation.evaluator]: \u001b[0mInference done 1632/1780. Dataloading: 0.0022 s/iter. Inference: 0.0392 s/iter. Eval: 0.0777 s/iter. Total: 0.1192 s/iter. ETA=0:00:17\n",
      "\u001b[32m[07/06 03:36:15 d2.evaluation.evaluator]: \u001b[0mInference done 1657/1780. Dataloading: 0.0022 s/iter. Inference: 0.0393 s/iter. Eval: 0.0788 s/iter. Total: 0.1205 s/iter. ETA=0:00:14\n",
      "\u001b[32m[07/06 03:36:20 d2.evaluation.evaluator]: \u001b[0mInference done 1682/1780. Dataloading: 0.0022 s/iter. Inference: 0.0394 s/iter. Eval: 0.0800 s/iter. Total: 0.1218 s/iter. ETA=0:00:11\n",
      "\u001b[32m[07/06 03:36:25 d2.evaluation.evaluator]: \u001b[0mInference done 1707/1780. Dataloading: 0.0022 s/iter. Inference: 0.0396 s/iter. Eval: 0.0812 s/iter. Total: 0.1230 s/iter. ETA=0:00:08\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/06 03:36:30 d2.evaluation.evaluator]: \u001b[0mInference done 1733/1780. Dataloading: 0.0022 s/iter. Inference: 0.0397 s/iter. Eval: 0.0822 s/iter. Total: 0.1242 s/iter. ETA=0:00:05\n",
      "\u001b[32m[07/06 03:36:35 d2.evaluation.evaluator]: \u001b[0mInference done 1758/1780. Dataloading: 0.0022 s/iter. Inference: 0.0398 s/iter. Eval: 0.0832 s/iter. Total: 0.1253 s/iter. ETA=0:00:02\n",
      "\u001b[32m[07/06 03:36:40 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:03:44.272093 (0.126350 s / iter per device, on 1 devices)\n",
      "\u001b[32m[07/06 03:36:40 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:01:10 (0.039852 s / iter per device, on 1 devices)\n",
      "\u001b[32m[07/06 03:36:40 d2.evaluation.sem_seg_evaluation]: \u001b[0mOrderedDict([('sem_seg', {'mIoU': 63.502572210261796, 'fwIoU': 85.13722649872068, 'IoU-Unlabeled': nan, 'IoU-Building': 81.61962867325423, 'IoU-Fence': 36.699013485367026, 'IoU-Pedestrian': 69.24265979471905, 'IoU-Pole': 45.165703100424864, 'IoU-Road': 95.8009276481106, 'IoU-SideWalk': 73.03533542494377, 'IoU-Vegetation': 78.76527504634268, 'IoU-Vehicles': 85.8430594304369, 'IoU-Wall': 48.83640161856003, 'IoU-TrafficSign': 56.637425559958, 'IoU-Sky': 86.58213623829513, 'IoU-TrafficLight': 56.57270469913951, 'IoU-Terrain': 53.58353258641891, 'IoU-ConstructionVehicle': 82.4296637657435, 'IoU-workzone_object': 65.22768829247455, 'IoU-Detour': 0.0, 'mACC': 71.95826840673026, 'pACC': 91.57676985707694, 'ACC-Unlabeled': nan, 'ACC-Building': 96.70139061412996, 'ACC-Fence': 45.30573366481263, 'ACC-Pedestrian': 85.90006021590443, 'ACC-Pole': 52.9416978281917, 'ACC-Road': 97.22617505236728, 'ACC-SideWalk': 84.73103812478769, 'ACC-Vegetation': 83.73017994233393, 'ACC-Vehicles': 90.95464987618442, 'ACC-Wall': 69.09188904354981, 'ACC-TrafficSign': 63.693736558876616, 'ACC-Sky': 88.34198947285063, 'ACC-TrafficLight': 64.76792483769475, 'ACC-Terrain': 66.4906443336448, 'ACC-ConstructionVehicle': 86.8761766796154, 'ACC-workzone_object': 74.57900826273995, 'ACC-Detour': 0.0})])\n",
      "\u001b[32m[07/06 03:36:40 d2.engine.defaults]: \u001b[0mEvaluation results for combined_rain_val in csv format:\n",
      "\u001b[32m[07/06 03:36:40 d2.evaluation.testing]: \u001b[0mcopypaste: Task: sem_seg\n",
      "\u001b[32m[07/06 03:36:40 d2.evaluation.testing]: \u001b[0mcopypaste: mIoU,fwIoU,mACC,pACC\n",
      "\u001b[32m[07/06 03:36:40 d2.evaluation.testing]: \u001b[0mcopypaste: 63.5026,85.1372,71.9583,91.5768\n"
     ]
    }
   ],
   "source": [
    "trainer_day = Detectron2Trainer('combined_clear_train', 'combined_rain_val', output_folder='./output_day_clear_40k')\n",
    "trainer_day.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd193271",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer_day = Detectron2Trainer('combined_clear_train', 'combined_all_val', output_folder='./output_day_clear_40k')\n",
    "trainer_day.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1891d066",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/05 17:36:37 d2.engine.defaults]: \u001b[0mModel:\n",
      "SemanticSegmentor(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (sem_seg_head): SemSegFPNHead(\n",
      "    (p2): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "    )\n",
      "    (p3): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (1): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "    )\n",
      "    (p4): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (1): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      (2): Conv2d(\n",
      "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (3): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "    )\n",
      "    (p5): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (1): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      (2): Conv2d(\n",
      "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (3): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      (4): Conv2d(\n",
      "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (5): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "    )\n",
      "    (predictor): Conv2d(128, 17, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/05 17:36:37 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(720, 720), max_size=2048, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[07/05 17:36:37 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[07/05 17:36:37 d2.data.common]: \u001b[0mSerializing 22288 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[07/05 17:36:37 d2.data.common]: \u001b[0mSerialized dataset takes 6.80 MiB\n",
      "Last checkpoint: model_final.pth\n",
      "\u001b[32m[07/05 17:36:38 d2.checkpoint.c2_model_loading]: \u001b[0mFollowing weights matched with model:\n",
      "| Names in Model                       | Names in Checkpoint                                                                                  | Shapes                                          |\n",
      "|:-------------------------------------|:-----------------------------------------------------------------------------------------------------|:------------------------------------------------|\n",
      "| backbone.bottom_up.res2.0.conv1.*    | backbone.bottom_up.res2.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,1,1)             |\n",
      "| backbone.bottom_up.res2.0.conv2.*    | backbone.bottom_up.res2.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |\n",
      "| backbone.bottom_up.res2.0.conv3.*    | backbone.bottom_up.res2.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res2.0.shortcut.* | backbone.bottom_up.res2.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res2.1.conv1.*    | backbone.bottom_up.res2.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |\n",
      "| backbone.bottom_up.res2.1.conv2.*    | backbone.bottom_up.res2.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |\n",
      "| backbone.bottom_up.res2.1.conv3.*    | backbone.bottom_up.res2.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res2.2.conv1.*    | backbone.bottom_up.res2.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |\n",
      "| backbone.bottom_up.res2.2.conv2.*    | backbone.bottom_up.res2.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |\n",
      "| backbone.bottom_up.res2.2.conv3.*    | backbone.bottom_up.res2.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res3.0.conv1.*    | backbone.bottom_up.res3.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,256,1,1)       |\n",
      "| backbone.bottom_up.res3.0.conv2.*    | backbone.bottom_up.res3.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.0.conv3.*    | backbone.bottom_up.res3.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res3.0.shortcut.* | backbone.bottom_up.res3.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (512,) (512,) (512,) (512,) (512,256,1,1)       |\n",
      "| backbone.bottom_up.res3.1.conv1.*    | backbone.bottom_up.res3.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |\n",
      "| backbone.bottom_up.res3.1.conv2.*    | backbone.bottom_up.res3.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.1.conv3.*    | backbone.bottom_up.res3.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res3.2.conv1.*    | backbone.bottom_up.res3.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |\n",
      "| backbone.bottom_up.res3.2.conv2.*    | backbone.bottom_up.res3.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.2.conv3.*    | backbone.bottom_up.res3.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res3.3.conv1.*    | backbone.bottom_up.res3.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |\n",
      "| backbone.bottom_up.res3.3.conv2.*    | backbone.bottom_up.res3.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.3.conv3.*    | backbone.bottom_up.res3.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res4.0.conv1.*    | backbone.bottom_up.res4.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,512,1,1)       |\n",
      "| backbone.bottom_up.res4.0.conv2.*    | backbone.bottom_up.res4.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.0.conv3.*    | backbone.bottom_up.res4.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.0.shortcut.* | backbone.bottom_up.res4.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (1024,) (1024,) (1024,) (1024,) (1024,512,1,1)  |\n",
      "| backbone.bottom_up.res4.1.conv1.*    | backbone.bottom_up.res4.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.1.conv2.*    | backbone.bottom_up.res4.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.1.conv3.*    | backbone.bottom_up.res4.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.2.conv1.*    | backbone.bottom_up.res4.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.2.conv2.*    | backbone.bottom_up.res4.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.2.conv3.*    | backbone.bottom_up.res4.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.3.conv1.*    | backbone.bottom_up.res4.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.3.conv2.*    | backbone.bottom_up.res4.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.3.conv3.*    | backbone.bottom_up.res4.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.4.conv1.*    | backbone.bottom_up.res4.4.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.4.conv2.*    | backbone.bottom_up.res4.4.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.4.conv3.*    | backbone.bottom_up.res4.4.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.5.conv1.*    | backbone.bottom_up.res4.5.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.5.conv2.*    | backbone.bottom_up.res4.5.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.5.conv3.*    | backbone.bottom_up.res4.5.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res5.0.conv1.*    | backbone.bottom_up.res5.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,1024,1,1)      |\n",
      "| backbone.bottom_up.res5.0.conv2.*    | backbone.bottom_up.res5.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |\n",
      "| backbone.bottom_up.res5.0.conv3.*    | backbone.bottom_up.res5.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
      "| backbone.bottom_up.res5.0.shortcut.* | backbone.bottom_up.res5.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (2048,) (2048,) (2048,) (2048,) (2048,1024,1,1) |\n",
      "| backbone.bottom_up.res5.1.conv1.*    | backbone.bottom_up.res5.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |\n",
      "| backbone.bottom_up.res5.1.conv2.*    | backbone.bottom_up.res5.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |\n",
      "| backbone.bottom_up.res5.1.conv3.*    | backbone.bottom_up.res5.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
      "| backbone.bottom_up.res5.2.conv1.*    | backbone.bottom_up.res5.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |\n",
      "| backbone.bottom_up.res5.2.conv2.*    | backbone.bottom_up.res5.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |\n",
      "| backbone.bottom_up.res5.2.conv3.*    | backbone.bottom_up.res5.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
      "| backbone.bottom_up.stem.conv1.*      | backbone.bottom_up.stem.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}      | (64,) (64,) (64,) (64,) (64,3,7,7)              |\n",
      "| backbone.fpn_lateral2.*              | backbone.fpn_lateral2.{bias,weight}                                                                  | (256,) (256,256,1,1)                            |\n",
      "| backbone.fpn_lateral3.*              | backbone.fpn_lateral3.{bias,weight}                                                                  | (256,) (256,512,1,1)                            |\n",
      "| backbone.fpn_lateral4.*              | backbone.fpn_lateral4.{bias,weight}                                                                  | (256,) (256,1024,1,1)                           |\n",
      "| backbone.fpn_lateral5.*              | backbone.fpn_lateral5.{bias,weight}                                                                  | (256,) (256,2048,1,1)                           |\n",
      "| backbone.fpn_output2.*               | backbone.fpn_output2.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| backbone.fpn_output3.*               | backbone.fpn_output3.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| backbone.fpn_output4.*               | backbone.fpn_output4.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| backbone.fpn_output5.*               | backbone.fpn_output5.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| sem_seg_head.p2.0.*                  | sem_seg_head.p2.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p3.0.*                  | sem_seg_head.p3.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p4.0.*                  | sem_seg_head.p4.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p4.2.*                  | sem_seg_head.p4.2.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,128,3,3)                     |\n",
      "| sem_seg_head.p5.0.*                  | sem_seg_head.p5.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p5.2.*                  | sem_seg_head.p5.2.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,128,3,3)                     |\n",
      "| sem_seg_head.p5.4.*                  | sem_seg_head.p5.4.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,128,3,3)                     |\n",
      "| sem_seg_head.predictor.*             | sem_seg_head.predictor.{bias,weight}                                                                 | (17,) (17,128,1,1)                              |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/05 17:36:38 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(720, 720), max_size=2048, sample_style='choice')]\n",
      "\u001b[32m[07/05 17:36:38 d2.data.common]: \u001b[0mSerializing 3258 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[07/05 17:36:38 d2.data.common]: \u001b[0mSerialized dataset takes 0.99 MiB\n",
      "\u001b[32m[07/05 17:36:38 d2.evaluation.evaluator]: \u001b[0mStart inference on 3258 batches\n",
      "\u001b[32m[07/05 17:36:39 d2.evaluation.evaluator]: \u001b[0mInference done 11/3258. Dataloading: 0.0016 s/iter. Inference: 0.0355 s/iter. Eval: 0.0443 s/iter. Total: 0.0814 s/iter. ETA=0:04:24\n",
      "\u001b[32m[07/05 17:36:44 d2.evaluation.evaluator]: \u001b[0mInference done 76/3258. Dataloading: 0.0020 s/iter. Inference: 0.0351 s/iter. Eval: 0.0405 s/iter. Total: 0.0777 s/iter. ETA=0:04:07\n",
      "\u001b[32m[07/05 17:36:49 d2.evaluation.evaluator]: \u001b[0mInference done 143/3258. Dataloading: 0.0021 s/iter. Inference: 0.0351 s/iter. Eval: 0.0392 s/iter. Total: 0.0765 s/iter. ETA=0:03:58\n",
      "\u001b[32m[07/05 17:36:54 d2.evaluation.evaluator]: \u001b[0mInference done 211/3258. Dataloading: 0.0021 s/iter. Inference: 0.0352 s/iter. Eval: 0.0384 s/iter. Total: 0.0758 s/iter. ETA=0:03:50\n",
      "\u001b[32m[07/05 17:36:59 d2.evaluation.evaluator]: \u001b[0mInference done 278/3258. Dataloading: 0.0021 s/iter. Inference: 0.0352 s/iter. Eval: 0.0383 s/iter. Total: 0.0757 s/iter. ETA=0:03:45\n",
      "\u001b[32m[07/05 17:37:04 d2.evaluation.evaluator]: \u001b[0mInference done 345/3258. Dataloading: 0.0021 s/iter. Inference: 0.0352 s/iter. Eval: 0.0381 s/iter. Total: 0.0755 s/iter. ETA=0:03:39\n",
      "\u001b[32m[07/05 17:37:09 d2.evaluation.evaluator]: \u001b[0mInference done 412/3258. Dataloading: 0.0021 s/iter. Inference: 0.0352 s/iter. Eval: 0.0380 s/iter. Total: 0.0754 s/iter. ETA=0:03:34\n",
      "\u001b[32m[07/05 17:37:14 d2.evaluation.evaluator]: \u001b[0mInference done 478/3258. Dataloading: 0.0021 s/iter. Inference: 0.0353 s/iter. Eval: 0.0381 s/iter. Total: 0.0756 s/iter. ETA=0:03:30\n",
      "\u001b[32m[07/05 17:37:19 d2.evaluation.evaluator]: \u001b[0mInference done 545/3258. Dataloading: 0.0021 s/iter. Inference: 0.0353 s/iter. Eval: 0.0381 s/iter. Total: 0.0755 s/iter. ETA=0:03:24\n",
      "\u001b[32m[07/05 17:37:24 d2.evaluation.evaluator]: \u001b[0mInference done 611/3258. Dataloading: 0.0021 s/iter. Inference: 0.0353 s/iter. Eval: 0.0381 s/iter. Total: 0.0756 s/iter. ETA=0:03:20\n",
      "\u001b[32m[07/05 17:37:29 d2.evaluation.evaluator]: \u001b[0mInference done 676/3258. Dataloading: 0.0021 s/iter. Inference: 0.0353 s/iter. Eval: 0.0382 s/iter. Total: 0.0757 s/iter. ETA=0:03:15\n",
      "\u001b[32m[07/05 17:37:34 d2.evaluation.evaluator]: \u001b[0mInference done 740/3258. Dataloading: 0.0021 s/iter. Inference: 0.0353 s/iter. Eval: 0.0385 s/iter. Total: 0.0760 s/iter. ETA=0:03:11\n",
      "\u001b[32m[07/05 17:37:39 d2.evaluation.evaluator]: \u001b[0mInference done 805/3258. Dataloading: 0.0021 s/iter. Inference: 0.0353 s/iter. Eval: 0.0386 s/iter. Total: 0.0761 s/iter. ETA=0:03:06\n",
      "\u001b[32m[07/05 17:37:44 d2.evaluation.evaluator]: \u001b[0mInference done 870/3258. Dataloading: 0.0021 s/iter. Inference: 0.0353 s/iter. Eval: 0.0387 s/iter. Total: 0.0762 s/iter. ETA=0:03:01\n",
      "\u001b[32m[07/05 17:37:49 d2.evaluation.evaluator]: \u001b[0mInference done 935/3258. Dataloading: 0.0021 s/iter. Inference: 0.0353 s/iter. Eval: 0.0388 s/iter. Total: 0.0763 s/iter. ETA=0:02:57\n",
      "\u001b[32m[07/05 17:37:54 d2.evaluation.evaluator]: \u001b[0mInference done 1001/3258. Dataloading: 0.0021 s/iter. Inference: 0.0353 s/iter. Eval: 0.0388 s/iter. Total: 0.0763 s/iter. ETA=0:02:52\n",
      "\u001b[32m[07/05 17:37:59 d2.evaluation.evaluator]: \u001b[0mInference done 1067/3258. Dataloading: 0.0021 s/iter. Inference: 0.0353 s/iter. Eval: 0.0387 s/iter. Total: 0.0763 s/iter. ETA=0:02:47\n",
      "\u001b[32m[07/05 17:38:04 d2.evaluation.evaluator]: \u001b[0mInference done 1133/3258. Dataloading: 0.0021 s/iter. Inference: 0.0353 s/iter. Eval: 0.0388 s/iter. Total: 0.0763 s/iter. ETA=0:02:42\n",
      "\u001b[32m[07/05 17:38:09 d2.evaluation.evaluator]: \u001b[0mInference done 1198/3258. Dataloading: 0.0021 s/iter. Inference: 0.0353 s/iter. Eval: 0.0389 s/iter. Total: 0.0764 s/iter. ETA=0:02:37\n",
      "\u001b[32m[07/05 17:38:14 d2.evaluation.evaluator]: \u001b[0mInference done 1261/3258. Dataloading: 0.0021 s/iter. Inference: 0.0353 s/iter. Eval: 0.0390 s/iter. Total: 0.0765 s/iter. ETA=0:02:32\n",
      "\u001b[32m[07/05 17:38:19 d2.evaluation.evaluator]: \u001b[0mInference done 1324/3258. Dataloading: 0.0022 s/iter. Inference: 0.0353 s/iter. Eval: 0.0391 s/iter. Total: 0.0767 s/iter. ETA=0:02:28\n",
      "\u001b[32m[07/05 17:38:25 d2.evaluation.evaluator]: \u001b[0mInference done 1390/3258. Dataloading: 0.0022 s/iter. Inference: 0.0354 s/iter. Eval: 0.0391 s/iter. Total: 0.0767 s/iter. ETA=0:02:23\n",
      "\u001b[32m[07/05 17:38:30 d2.evaluation.evaluator]: \u001b[0mInference done 1455/3258. Dataloading: 0.0022 s/iter. Inference: 0.0354 s/iter. Eval: 0.0391 s/iter. Total: 0.0768 s/iter. ETA=0:02:18\n",
      "\u001b[32m[07/05 17:38:35 d2.evaluation.evaluator]: \u001b[0mInference done 1520/3258. Dataloading: 0.0022 s/iter. Inference: 0.0354 s/iter. Eval: 0.0391 s/iter. Total: 0.0768 s/iter. ETA=0:02:13\n",
      "\u001b[32m[07/05 17:38:40 d2.evaluation.evaluator]: \u001b[0mInference done 1585/3258. Dataloading: 0.0022 s/iter. Inference: 0.0354 s/iter. Eval: 0.0392 s/iter. Total: 0.0768 s/iter. ETA=0:02:08\n",
      "\u001b[32m[07/05 17:38:45 d2.evaluation.evaluator]: \u001b[0mInference done 1649/3258. Dataloading: 0.0022 s/iter. Inference: 0.0354 s/iter. Eval: 0.0392 s/iter. Total: 0.0769 s/iter. ETA=0:02:03\n",
      "\u001b[32m[07/05 17:38:50 d2.evaluation.evaluator]: \u001b[0mInference done 1712/3258. Dataloading: 0.0022 s/iter. Inference: 0.0354 s/iter. Eval: 0.0394 s/iter. Total: 0.0770 s/iter. ETA=0:01:59\n",
      "\u001b[32m[07/05 17:38:55 d2.evaluation.evaluator]: \u001b[0mInference done 1777/3258. Dataloading: 0.0022 s/iter. Inference: 0.0354 s/iter. Eval: 0.0394 s/iter. Total: 0.0770 s/iter. ETA=0:01:54\n",
      "\u001b[32m[07/05 17:39:00 d2.evaluation.evaluator]: \u001b[0mInference done 1840/3258. Dataloading: 0.0022 s/iter. Inference: 0.0354 s/iter. Eval: 0.0395 s/iter. Total: 0.0771 s/iter. ETA=0:01:49\n",
      "\u001b[32m[07/05 17:39:05 d2.evaluation.evaluator]: \u001b[0mInference done 1902/3258. Dataloading: 0.0022 s/iter. Inference: 0.0354 s/iter. Eval: 0.0396 s/iter. Total: 0.0772 s/iter. ETA=0:01:44\n",
      "\u001b[32m[07/05 17:39:10 d2.evaluation.evaluator]: \u001b[0mInference done 1966/3258. Dataloading: 0.0022 s/iter. Inference: 0.0354 s/iter. Eval: 0.0397 s/iter. Total: 0.0773 s/iter. ETA=0:01:39\n",
      "\u001b[32m[07/05 17:39:15 d2.evaluation.evaluator]: \u001b[0mInference done 2031/3258. Dataloading: 0.0022 s/iter. Inference: 0.0354 s/iter. Eval: 0.0396 s/iter. Total: 0.0773 s/iter. ETA=0:01:34\n",
      "\u001b[32m[07/05 17:39:20 d2.evaluation.evaluator]: \u001b[0mInference done 2096/3258. Dataloading: 0.0022 s/iter. Inference: 0.0354 s/iter. Eval: 0.0396 s/iter. Total: 0.0773 s/iter. ETA=0:01:29\n",
      "\u001b[32m[07/05 17:39:25 d2.evaluation.evaluator]: \u001b[0mInference done 2161/3258. Dataloading: 0.0022 s/iter. Inference: 0.0354 s/iter. Eval: 0.0396 s/iter. Total: 0.0773 s/iter. ETA=0:01:24\n",
      "\u001b[32m[07/05 17:39:30 d2.evaluation.evaluator]: \u001b[0mInference done 2226/3258. Dataloading: 0.0022 s/iter. Inference: 0.0354 s/iter. Eval: 0.0396 s/iter. Total: 0.0773 s/iter. ETA=0:01:19\n",
      "\u001b[32m[07/05 17:39:35 d2.evaluation.evaluator]: \u001b[0mInference done 2291/3258. Dataloading: 0.0022 s/iter. Inference: 0.0354 s/iter. Eval: 0.0396 s/iter. Total: 0.0773 s/iter. ETA=0:01:14\n",
      "\u001b[32m[07/05 17:39:40 d2.evaluation.evaluator]: \u001b[0mInference done 2356/3258. Dataloading: 0.0022 s/iter. Inference: 0.0354 s/iter. Eval: 0.0396 s/iter. Total: 0.0773 s/iter. ETA=0:01:09\n",
      "\u001b[32m[07/05 17:39:45 d2.evaluation.evaluator]: \u001b[0mInference done 2421/3258. Dataloading: 0.0022 s/iter. Inference: 0.0354 s/iter. Eval: 0.0396 s/iter. Total: 0.0773 s/iter. ETA=0:01:04\n",
      "\u001b[32m[07/05 17:39:50 d2.evaluation.evaluator]: \u001b[0mInference done 2486/3258. Dataloading: 0.0022 s/iter. Inference: 0.0354 s/iter. Eval: 0.0396 s/iter. Total: 0.0773 s/iter. ETA=0:00:59\n",
      "\u001b[32m[07/05 17:39:55 d2.evaluation.evaluator]: \u001b[0mInference done 2552/3258. Dataloading: 0.0022 s/iter. Inference: 0.0354 s/iter. Eval: 0.0396 s/iter. Total: 0.0773 s/iter. ETA=0:00:54\n",
      "\u001b[32m[07/05 17:40:00 d2.evaluation.evaluator]: \u001b[0mInference done 2618/3258. Dataloading: 0.0022 s/iter. Inference: 0.0354 s/iter. Eval: 0.0396 s/iter. Total: 0.0773 s/iter. ETA=0:00:49\n",
      "\u001b[32m[07/05 17:40:05 d2.evaluation.evaluator]: \u001b[0mInference done 2683/3258. Dataloading: 0.0022 s/iter. Inference: 0.0354 s/iter. Eval: 0.0396 s/iter. Total: 0.0773 s/iter. ETA=0:00:44\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/05 17:40:10 d2.evaluation.evaluator]: \u001b[0mInference done 2748/3258. Dataloading: 0.0022 s/iter. Inference: 0.0354 s/iter. Eval: 0.0396 s/iter. Total: 0.0773 s/iter. ETA=0:00:39\n",
      "\u001b[32m[07/05 17:40:15 d2.evaluation.evaluator]: \u001b[0mInference done 2814/3258. Dataloading: 0.0022 s/iter. Inference: 0.0354 s/iter. Eval: 0.0396 s/iter. Total: 0.0773 s/iter. ETA=0:00:34\n",
      "\u001b[32m[07/05 17:40:20 d2.evaluation.evaluator]: \u001b[0mInference done 2880/3258. Dataloading: 0.0022 s/iter. Inference: 0.0354 s/iter. Eval: 0.0395 s/iter. Total: 0.0772 s/iter. ETA=0:00:29\n",
      "\u001b[32m[07/05 17:40:25 d2.evaluation.evaluator]: \u001b[0mInference done 2946/3258. Dataloading: 0.0022 s/iter. Inference: 0.0354 s/iter. Eval: 0.0395 s/iter. Total: 0.0772 s/iter. ETA=0:00:24\n",
      "\u001b[32m[07/05 17:40:30 d2.evaluation.evaluator]: \u001b[0mInference done 3012/3258. Dataloading: 0.0022 s/iter. Inference: 0.0355 s/iter. Eval: 0.0395 s/iter. Total: 0.0772 s/iter. ETA=0:00:18\n",
      "\u001b[32m[07/05 17:40:35 d2.evaluation.evaluator]: \u001b[0mInference done 3077/3258. Dataloading: 0.0022 s/iter. Inference: 0.0355 s/iter. Eval: 0.0395 s/iter. Total: 0.0772 s/iter. ETA=0:00:13\n",
      "\u001b[32m[07/05 17:40:40 d2.evaluation.evaluator]: \u001b[0mInference done 3142/3258. Dataloading: 0.0022 s/iter. Inference: 0.0355 s/iter. Eval: 0.0395 s/iter. Total: 0.0772 s/iter. ETA=0:00:08\n",
      "\u001b[32m[07/05 17:40:45 d2.evaluation.evaluator]: \u001b[0mInference done 3207/3258. Dataloading: 0.0022 s/iter. Inference: 0.0355 s/iter. Eval: 0.0395 s/iter. Total: 0.0772 s/iter. ETA=0:00:03\n",
      "\u001b[32m[07/05 17:40:49 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:04:11.147082 (0.077205 s / iter per device, on 1 devices)\n",
      "\u001b[32m[07/05 17:40:49 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:01:55 (0.035462 s / iter per device, on 1 devices)\n",
      "\u001b[32m[07/05 17:40:50 d2.evaluation.sem_seg_evaluation]: \u001b[0mOrderedDict([('sem_seg', {'mIoU': 71.03922925818868, 'fwIoU': 93.73325204626296, 'IoU-Unlabeled': nan, 'IoU-Building': 92.49940279986562, 'IoU-Fence': 41.453715876827616, 'IoU-Pedestrian': 48.49854547543188, 'IoU-Pole': 61.3014188464904, 'IoU-Road': 99.01843298117558, 'IoU-SideWalk': 90.32541622930678, 'IoU-Vegetation': 83.21515521914513, 'IoU-Vehicles': 86.47836988613771, 'IoU-Wall': 84.90583915115401, 'IoU-TrafficSign': 52.30723615861417, 'IoU-Sky': 97.06189263766933, 'IoU-TrafficLight': 71.66785652514712, 'IoU-Terrain': 71.70257849053576, 'IoU-ConstructionVehicle': 65.61078712689216, 'IoU-workzone_object': 77.01264465824973, 'IoU-Detour': 13.568376068376068, 'mACC': 79.30941252939843, 'pACC': 96.60267471845296, 'ACC-Unlabeled': nan, 'ACC-Building': 96.82890919102732, 'ACC-Fence': 55.405025103908834, 'ACC-Pedestrian': 62.93895111248303, 'ACC-Pole': 70.73300770467569, 'ACC-Road': 99.45612764350264, 'ACC-SideWalk': 95.551640967667, 'ACC-Vegetation': 93.00764863151032, 'ACC-Vehicles': 88.80650680602523, 'ACC-Wall': 93.81941012057943, 'ACC-TrafficSign': 61.37672206683633, 'ACC-Sky': 98.35855339297365, 'ACC-TrafficLight': 81.32084874750845, 'ACC-Terrain': 76.47421368625287, 'ACC-ConstructionVehicle': 94.43896465772335, 'ACC-workzone_object': 86.1893049348093, 'ACC-Detour': 14.244765702891327})])\n",
      "\u001b[32m[07/05 17:40:50 d2.engine.defaults]: \u001b[0mEvaluation results for carla_clear_val in csv format:\n",
      "\u001b[32m[07/05 17:40:50 d2.evaluation.testing]: \u001b[0mcopypaste: Task: sem_seg\n",
      "\u001b[32m[07/05 17:40:50 d2.evaluation.testing]: \u001b[0mcopypaste: mIoU,fwIoU,mACC,pACC\n",
      "\u001b[32m[07/05 17:40:50 d2.evaluation.testing]: \u001b[0mcopypaste: 71.0392,93.7333,79.3094,96.6027\n"
     ]
    }
   ],
   "source": [
    "trainer_day = Detectron2Trainer('combined_all_train', 'carla_clear_val', output_folder='./output_day_40k')\n",
    "trainer_day.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f0d4da55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/05 17:40:50 d2.engine.defaults]: \u001b[0mModel:\n",
      "SemanticSegmentor(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (sem_seg_head): SemSegFPNHead(\n",
      "    (p2): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "    )\n",
      "    (p3): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (1): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "    )\n",
      "    (p4): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (1): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      (2): Conv2d(\n",
      "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (3): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "    )\n",
      "    (p5): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (1): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      (2): Conv2d(\n",
      "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (3): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      (4): Conv2d(\n",
      "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (5): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "    )\n",
      "    (predictor): Conv2d(128, 17, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/05 17:40:50 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(720, 720), max_size=2048, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[07/05 17:40:50 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[07/05 17:40:50 d2.data.common]: \u001b[0mSerializing 22288 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[07/05 17:40:50 d2.data.common]: \u001b[0mSerialized dataset takes 6.80 MiB\n",
      "Last checkpoint: model_final.pth\n",
      "\u001b[32m[07/05 17:40:51 d2.checkpoint.c2_model_loading]: \u001b[0mFollowing weights matched with model:\n",
      "| Names in Model                       | Names in Checkpoint                                                                                  | Shapes                                          |\n",
      "|:-------------------------------------|:-----------------------------------------------------------------------------------------------------|:------------------------------------------------|\n",
      "| backbone.bottom_up.res2.0.conv1.*    | backbone.bottom_up.res2.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,1,1)             |\n",
      "| backbone.bottom_up.res2.0.conv2.*    | backbone.bottom_up.res2.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |\n",
      "| backbone.bottom_up.res2.0.conv3.*    | backbone.bottom_up.res2.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res2.0.shortcut.* | backbone.bottom_up.res2.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res2.1.conv1.*    | backbone.bottom_up.res2.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |\n",
      "| backbone.bottom_up.res2.1.conv2.*    | backbone.bottom_up.res2.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |\n",
      "| backbone.bottom_up.res2.1.conv3.*    | backbone.bottom_up.res2.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res2.2.conv1.*    | backbone.bottom_up.res2.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |\n",
      "| backbone.bottom_up.res2.2.conv2.*    | backbone.bottom_up.res2.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |\n",
      "| backbone.bottom_up.res2.2.conv3.*    | backbone.bottom_up.res2.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res3.0.conv1.*    | backbone.bottom_up.res3.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,256,1,1)       |\n",
      "| backbone.bottom_up.res3.0.conv2.*    | backbone.bottom_up.res3.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.0.conv3.*    | backbone.bottom_up.res3.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res3.0.shortcut.* | backbone.bottom_up.res3.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (512,) (512,) (512,) (512,) (512,256,1,1)       |\n",
      "| backbone.bottom_up.res3.1.conv1.*    | backbone.bottom_up.res3.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |\n",
      "| backbone.bottom_up.res3.1.conv2.*    | backbone.bottom_up.res3.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.1.conv3.*    | backbone.bottom_up.res3.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res3.2.conv1.*    | backbone.bottom_up.res3.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |\n",
      "| backbone.bottom_up.res3.2.conv2.*    | backbone.bottom_up.res3.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.2.conv3.*    | backbone.bottom_up.res3.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res3.3.conv1.*    | backbone.bottom_up.res3.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |\n",
      "| backbone.bottom_up.res3.3.conv2.*    | backbone.bottom_up.res3.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.3.conv3.*    | backbone.bottom_up.res3.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res4.0.conv1.*    | backbone.bottom_up.res4.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,512,1,1)       |\n",
      "| backbone.bottom_up.res4.0.conv2.*    | backbone.bottom_up.res4.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.0.conv3.*    | backbone.bottom_up.res4.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.0.shortcut.* | backbone.bottom_up.res4.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (1024,) (1024,) (1024,) (1024,) (1024,512,1,1)  |\n",
      "| backbone.bottom_up.res4.1.conv1.*    | backbone.bottom_up.res4.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.1.conv2.*    | backbone.bottom_up.res4.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.1.conv3.*    | backbone.bottom_up.res4.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.2.conv1.*    | backbone.bottom_up.res4.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.2.conv2.*    | backbone.bottom_up.res4.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.2.conv3.*    | backbone.bottom_up.res4.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.3.conv1.*    | backbone.bottom_up.res4.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.3.conv2.*    | backbone.bottom_up.res4.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.3.conv3.*    | backbone.bottom_up.res4.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.4.conv1.*    | backbone.bottom_up.res4.4.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.4.conv2.*    | backbone.bottom_up.res4.4.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.4.conv3.*    | backbone.bottom_up.res4.4.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.5.conv1.*    | backbone.bottom_up.res4.5.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.5.conv2.*    | backbone.bottom_up.res4.5.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.5.conv3.*    | backbone.bottom_up.res4.5.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res5.0.conv1.*    | backbone.bottom_up.res5.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,1024,1,1)      |\n",
      "| backbone.bottom_up.res5.0.conv2.*    | backbone.bottom_up.res5.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |\n",
      "| backbone.bottom_up.res5.0.conv3.*    | backbone.bottom_up.res5.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
      "| backbone.bottom_up.res5.0.shortcut.* | backbone.bottom_up.res5.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (2048,) (2048,) (2048,) (2048,) (2048,1024,1,1) |\n",
      "| backbone.bottom_up.res5.1.conv1.*    | backbone.bottom_up.res5.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |\n",
      "| backbone.bottom_up.res5.1.conv2.*    | backbone.bottom_up.res5.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |\n",
      "| backbone.bottom_up.res5.1.conv3.*    | backbone.bottom_up.res5.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
      "| backbone.bottom_up.res5.2.conv1.*    | backbone.bottom_up.res5.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |\n",
      "| backbone.bottom_up.res5.2.conv2.*    | backbone.bottom_up.res5.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |\n",
      "| backbone.bottom_up.res5.2.conv3.*    | backbone.bottom_up.res5.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
      "| backbone.bottom_up.stem.conv1.*      | backbone.bottom_up.stem.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}      | (64,) (64,) (64,) (64,) (64,3,7,7)              |\n",
      "| backbone.fpn_lateral2.*              | backbone.fpn_lateral2.{bias,weight}                                                                  | (256,) (256,256,1,1)                            |\n",
      "| backbone.fpn_lateral3.*              | backbone.fpn_lateral3.{bias,weight}                                                                  | (256,) (256,512,1,1)                            |\n",
      "| backbone.fpn_lateral4.*              | backbone.fpn_lateral4.{bias,weight}                                                                  | (256,) (256,1024,1,1)                           |\n",
      "| backbone.fpn_lateral5.*              | backbone.fpn_lateral5.{bias,weight}                                                                  | (256,) (256,2048,1,1)                           |\n",
      "| backbone.fpn_output2.*               | backbone.fpn_output2.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| backbone.fpn_output3.*               | backbone.fpn_output3.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| backbone.fpn_output4.*               | backbone.fpn_output4.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| backbone.fpn_output5.*               | backbone.fpn_output5.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| sem_seg_head.p2.0.*                  | sem_seg_head.p2.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p3.0.*                  | sem_seg_head.p3.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p4.0.*                  | sem_seg_head.p4.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p4.2.*                  | sem_seg_head.p4.2.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,128,3,3)                     |\n",
      "| sem_seg_head.p5.0.*                  | sem_seg_head.p5.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p5.2.*                  | sem_seg_head.p5.2.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,128,3,3)                     |\n",
      "| sem_seg_head.p5.4.*                  | sem_seg_head.p5.4.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,128,3,3)                     |\n",
      "| sem_seg_head.predictor.*             | sem_seg_head.predictor.{bias,weight}                                                                 | (17,) (17,128,1,1)                              |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/05 17:40:51 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(720, 720), max_size=2048, sample_style='choice')]\n",
      "\u001b[32m[07/05 17:40:51 d2.data.common]: \u001b[0mSerializing 699 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[07/05 17:40:51 d2.data.common]: \u001b[0mSerialized dataset takes 0.22 MiB\n",
      "\u001b[32m[07/05 17:40:51 d2.evaluation.evaluator]: \u001b[0mStart inference on 699 batches\n",
      "\u001b[32m[07/05 17:40:53 d2.evaluation.evaluator]: \u001b[0mInference done 11/699. Dataloading: 0.0017 s/iter. Inference: 0.0468 s/iter. Eval: 0.1467 s/iter. Total: 0.1953 s/iter. ETA=0:02:14\n",
      "\u001b[32m[07/05 17:40:59 d2.evaluation.evaluator]: \u001b[0mInference done 37/699. Dataloading: 0.0020 s/iter. Inference: 0.0469 s/iter. Eval: 0.1477 s/iter. Total: 0.1967 s/iter. ETA=0:02:10\n",
      "\u001b[32m[07/05 17:41:04 d2.evaluation.evaluator]: \u001b[0mInference done 63/699. Dataloading: 0.0021 s/iter. Inference: 0.0468 s/iter. Eval: 0.1472 s/iter. Total: 0.1962 s/iter. ETA=0:02:04\n",
      "\u001b[32m[07/05 17:41:09 d2.evaluation.evaluator]: \u001b[0mInference done 88/699. Dataloading: 0.0020 s/iter. Inference: 0.0468 s/iter. Eval: 0.1485 s/iter. Total: 0.1975 s/iter. ETA=0:02:00\n",
      "\u001b[32m[07/05 17:41:14 d2.evaluation.evaluator]: \u001b[0mInference done 114/699. Dataloading: 0.0021 s/iter. Inference: 0.0468 s/iter. Eval: 0.1483 s/iter. Total: 0.1973 s/iter. ETA=0:01:55\n",
      "\u001b[32m[07/05 17:41:19 d2.evaluation.evaluator]: \u001b[0mInference done 141/699. Dataloading: 0.0021 s/iter. Inference: 0.0468 s/iter. Eval: 0.1471 s/iter. Total: 0.1960 s/iter. ETA=0:01:49\n",
      "\u001b[32m[07/05 17:41:24 d2.evaluation.evaluator]: \u001b[0mInference done 168/699. Dataloading: 0.0020 s/iter. Inference: 0.0468 s/iter. Eval: 0.1458 s/iter. Total: 0.1947 s/iter. ETA=0:01:43\n",
      "\u001b[32m[07/05 17:41:29 d2.evaluation.evaluator]: \u001b[0mInference done 193/699. Dataloading: 0.0020 s/iter. Inference: 0.0468 s/iter. Eval: 0.1470 s/iter. Total: 0.1960 s/iter. ETA=0:01:39\n",
      "\u001b[32m[07/05 17:41:34 d2.evaluation.evaluator]: \u001b[0mInference done 219/699. Dataloading: 0.0020 s/iter. Inference: 0.0468 s/iter. Eval: 0.1474 s/iter. Total: 0.1964 s/iter. ETA=0:01:34\n",
      "\u001b[32m[07/05 17:41:39 d2.evaluation.evaluator]: \u001b[0mInference done 245/699. Dataloading: 0.0020 s/iter. Inference: 0.0468 s/iter. Eval: 0.1476 s/iter. Total: 0.1966 s/iter. ETA=0:01:29\n",
      "\u001b[32m[07/05 17:41:45 d2.evaluation.evaluator]: \u001b[0mInference done 271/699. Dataloading: 0.0020 s/iter. Inference: 0.0468 s/iter. Eval: 0.1477 s/iter. Total: 0.1967 s/iter. ETA=0:01:24\n",
      "\u001b[32m[07/05 17:41:50 d2.evaluation.evaluator]: \u001b[0mInference done 297/699. Dataloading: 0.0020 s/iter. Inference: 0.0468 s/iter. Eval: 0.1475 s/iter. Total: 0.1965 s/iter. ETA=0:01:18\n",
      "\u001b[32m[07/05 17:41:55 d2.evaluation.evaluator]: \u001b[0mInference done 323/699. Dataloading: 0.0020 s/iter. Inference: 0.0468 s/iter. Eval: 0.1478 s/iter. Total: 0.1967 s/iter. ETA=0:01:13\n",
      "\u001b[32m[07/05 17:42:00 d2.evaluation.evaluator]: \u001b[0mInference done 349/699. Dataloading: 0.0020 s/iter. Inference: 0.0468 s/iter. Eval: 0.1479 s/iter. Total: 0.1968 s/iter. ETA=0:01:08\n",
      "\u001b[32m[07/05 17:42:05 d2.evaluation.evaluator]: \u001b[0mInference done 375/699. Dataloading: 0.0023 s/iter. Inference: 0.0468 s/iter. Eval: 0.1477 s/iter. Total: 0.1969 s/iter. ETA=0:01:03\n",
      "\u001b[32m[07/05 17:42:10 d2.evaluation.evaluator]: \u001b[0mInference done 401/699. Dataloading: 0.0023 s/iter. Inference: 0.0468 s/iter. Eval: 0.1476 s/iter. Total: 0.1968 s/iter. ETA=0:00:58\n",
      "\u001b[32m[07/05 17:42:15 d2.evaluation.evaluator]: \u001b[0mInference done 427/699. Dataloading: 0.0023 s/iter. Inference: 0.0468 s/iter. Eval: 0.1474 s/iter. Total: 0.1966 s/iter. ETA=0:00:53\n",
      "\u001b[32m[07/05 17:42:20 d2.evaluation.evaluator]: \u001b[0mInference done 454/699. Dataloading: 0.0023 s/iter. Inference: 0.0468 s/iter. Eval: 0.1469 s/iter. Total: 0.1961 s/iter. ETA=0:00:48\n",
      "\u001b[32m[07/05 17:42:25 d2.evaluation.evaluator]: \u001b[0mInference done 482/699. Dataloading: 0.0023 s/iter. Inference: 0.0468 s/iter. Eval: 0.1462 s/iter. Total: 0.1954 s/iter. ETA=0:00:42\n",
      "\u001b[32m[07/05 17:42:31 d2.evaluation.evaluator]: \u001b[0mInference done 509/699. Dataloading: 0.0023 s/iter. Inference: 0.0468 s/iter. Eval: 0.1459 s/iter. Total: 0.1951 s/iter. ETA=0:00:37\n",
      "\u001b[32m[07/05 17:42:36 d2.evaluation.evaluator]: \u001b[0mInference done 536/699. Dataloading: 0.0023 s/iter. Inference: 0.0468 s/iter. Eval: 0.1455 s/iter. Total: 0.1947 s/iter. ETA=0:00:31\n",
      "\u001b[32m[07/05 17:42:41 d2.evaluation.evaluator]: \u001b[0mInference done 563/699. Dataloading: 0.0023 s/iter. Inference: 0.0468 s/iter. Eval: 0.1452 s/iter. Total: 0.1943 s/iter. ETA=0:00:26\n",
      "\u001b[32m[07/05 17:42:46 d2.evaluation.evaluator]: \u001b[0mInference done 589/699. Dataloading: 0.0023 s/iter. Inference: 0.0468 s/iter. Eval: 0.1452 s/iter. Total: 0.1944 s/iter. ETA=0:00:21\n",
      "\u001b[32m[07/05 17:42:51 d2.evaluation.evaluator]: \u001b[0mInference done 616/699. Dataloading: 0.0023 s/iter. Inference: 0.0468 s/iter. Eval: 0.1451 s/iter. Total: 0.1943 s/iter. ETA=0:00:16\n",
      "\u001b[32m[07/05 17:42:56 d2.evaluation.evaluator]: \u001b[0mInference done 643/699. Dataloading: 0.0023 s/iter. Inference: 0.0468 s/iter. Eval: 0.1449 s/iter. Total: 0.1941 s/iter. ETA=0:00:10\n",
      "\u001b[32m[07/05 17:43:01 d2.evaluation.evaluator]: \u001b[0mInference done 670/699. Dataloading: 0.0023 s/iter. Inference: 0.0468 s/iter. Eval: 0.1447 s/iter. Total: 0.1938 s/iter. ETA=0:00:05\n",
      "\u001b[32m[07/05 17:43:06 d2.evaluation.evaluator]: \u001b[0mInference done 696/699. Dataloading: 0.0023 s/iter. Inference: 0.0468 s/iter. Eval: 0.1447 s/iter. Total: 0.1939 s/iter. ETA=0:00:00\n",
      "\u001b[32m[07/05 17:43:07 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:02:14.642123 (0.194009 s / iter per device, on 1 devices)\n",
      "\u001b[32m[07/05 17:43:07 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:32 (0.046795 s / iter per device, on 1 devices)\n",
      "\u001b[32m[07/05 17:43:07 d2.evaluation.sem_seg_evaluation]: \u001b[0mOrderedDict([('sem_seg', {'mIoU': 68.529418274466, 'fwIoU': 90.69049868692126, 'IoU-Unlabeled': nan, 'IoU-Building': 91.10228702258534, 'IoU-Fence': 54.35573416104956, 'IoU-Pedestrian': 78.77313467582354, 'IoU-Pole': 52.80074988476415, 'IoU-Road': 96.63979331968613, 'IoU-SideWalk': 78.77954228246024, 'IoU-Vegetation': 90.88674006180736, 'IoU-Vehicles': 90.80460054900887, 'IoU-Wall': 48.07296959547238, 'IoU-TrafficSign': 65.48880818212903, 'IoU-Sky': 94.54166706892254, 'IoU-TrafficLight': 55.61231363473173, 'IoU-Terrain': 61.55351540408319, 'IoU-ConstructionVehicle': nan, 'IoU-workzone_object': nan, 'IoU-Detour': nan, 'mACC': 81.86095252232727, 'pACC': 94.92112748797265, 'ACC-Unlabeled': nan, 'ACC-Building': 95.65641097366947, 'ACC-Fence': 70.48260238721106, 'ACC-Pedestrian': 87.97061896270598, 'ACC-Pole': 66.96038170400689, 'ACC-Road': 98.69609330946899, 'ACC-SideWalk': 85.8275246401359, 'ACC-Vegetation': 96.12540741217532, 'ACC-Vehicles': 95.11285655589876, 'ACC-Wall': 57.86831103626794, 'ACC-TrafficSign': 75.25261566553556, 'ACC-Sky': 97.2208490769573, 'ACC-TrafficLight': 64.56661457014451, 'ACC-Terrain': 72.45209649607666, 'ACC-ConstructionVehicle': nan, 'ACC-workzone_object': nan, 'ACC-Detour': nan})])\n",
      "\u001b[32m[07/05 17:43:07 d2.engine.defaults]: \u001b[0mEvaluation results for cityscapes_clear_val in csv format:\n",
      "\u001b[32m[07/05 17:43:07 d2.evaluation.testing]: \u001b[0mcopypaste: Task: sem_seg\n",
      "\u001b[32m[07/05 17:43:07 d2.evaluation.testing]: \u001b[0mcopypaste: mIoU,fwIoU,mACC,pACC\n",
      "\u001b[32m[07/05 17:43:07 d2.evaluation.testing]: \u001b[0mcopypaste: 68.5294,90.6905,81.8610,94.9211\n"
     ]
    }
   ],
   "source": [
    "trainer_day = Detectron2Trainer('combined_all_train', 'cityscapes_clear_val', output_folder='./output_day_40k')\n",
    "trainer_day.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e958a9af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/05 17:43:07 d2.engine.defaults]: \u001b[0mModel:\n",
      "SemanticSegmentor(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (sem_seg_head): SemSegFPNHead(\n",
      "    (p2): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "    )\n",
      "    (p3): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (1): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "    )\n",
      "    (p4): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (1): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      (2): Conv2d(\n",
      "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (3): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "    )\n",
      "    (p5): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (1): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      (2): Conv2d(\n",
      "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (3): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      (4): Conv2d(\n",
      "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (5): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "    )\n",
      "    (predictor): Conv2d(128, 17, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/05 17:43:07 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(720, 720), max_size=2048, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[07/05 17:43:07 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[07/05 17:43:07 d2.data.common]: \u001b[0mSerializing 22288 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[07/05 17:43:07 d2.data.common]: \u001b[0mSerialized dataset takes 6.80 MiB\n",
      "Last checkpoint: model_final.pth\n",
      "\u001b[32m[07/05 17:43:08 d2.checkpoint.c2_model_loading]: \u001b[0mFollowing weights matched with model:\n",
      "| Names in Model                       | Names in Checkpoint                                                                                  | Shapes                                          |\n",
      "|:-------------------------------------|:-----------------------------------------------------------------------------------------------------|:------------------------------------------------|\n",
      "| backbone.bottom_up.res2.0.conv1.*    | backbone.bottom_up.res2.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,1,1)             |\n",
      "| backbone.bottom_up.res2.0.conv2.*    | backbone.bottom_up.res2.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |\n",
      "| backbone.bottom_up.res2.0.conv3.*    | backbone.bottom_up.res2.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res2.0.shortcut.* | backbone.bottom_up.res2.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res2.1.conv1.*    | backbone.bottom_up.res2.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |\n",
      "| backbone.bottom_up.res2.1.conv2.*    | backbone.bottom_up.res2.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |\n",
      "| backbone.bottom_up.res2.1.conv3.*    | backbone.bottom_up.res2.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res2.2.conv1.*    | backbone.bottom_up.res2.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |\n",
      "| backbone.bottom_up.res2.2.conv2.*    | backbone.bottom_up.res2.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |\n",
      "| backbone.bottom_up.res2.2.conv3.*    | backbone.bottom_up.res2.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res3.0.conv1.*    | backbone.bottom_up.res3.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,256,1,1)       |\n",
      "| backbone.bottom_up.res3.0.conv2.*    | backbone.bottom_up.res3.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.0.conv3.*    | backbone.bottom_up.res3.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res3.0.shortcut.* | backbone.bottom_up.res3.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (512,) (512,) (512,) (512,) (512,256,1,1)       |\n",
      "| backbone.bottom_up.res3.1.conv1.*    | backbone.bottom_up.res3.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |\n",
      "| backbone.bottom_up.res3.1.conv2.*    | backbone.bottom_up.res3.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.1.conv3.*    | backbone.bottom_up.res3.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res3.2.conv1.*    | backbone.bottom_up.res3.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |\n",
      "| backbone.bottom_up.res3.2.conv2.*    | backbone.bottom_up.res3.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.2.conv3.*    | backbone.bottom_up.res3.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res3.3.conv1.*    | backbone.bottom_up.res3.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |\n",
      "| backbone.bottom_up.res3.3.conv2.*    | backbone.bottom_up.res3.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.3.conv3.*    | backbone.bottom_up.res3.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res4.0.conv1.*    | backbone.bottom_up.res4.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,512,1,1)       |\n",
      "| backbone.bottom_up.res4.0.conv2.*    | backbone.bottom_up.res4.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.0.conv3.*    | backbone.bottom_up.res4.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.0.shortcut.* | backbone.bottom_up.res4.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (1024,) (1024,) (1024,) (1024,) (1024,512,1,1)  |\n",
      "| backbone.bottom_up.res4.1.conv1.*    | backbone.bottom_up.res4.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.1.conv2.*    | backbone.bottom_up.res4.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.1.conv3.*    | backbone.bottom_up.res4.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.2.conv1.*    | backbone.bottom_up.res4.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.2.conv2.*    | backbone.bottom_up.res4.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.2.conv3.*    | backbone.bottom_up.res4.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.3.conv1.*    | backbone.bottom_up.res4.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.3.conv2.*    | backbone.bottom_up.res4.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.3.conv3.*    | backbone.bottom_up.res4.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.4.conv1.*    | backbone.bottom_up.res4.4.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.4.conv2.*    | backbone.bottom_up.res4.4.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.4.conv3.*    | backbone.bottom_up.res4.4.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.5.conv1.*    | backbone.bottom_up.res4.5.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.5.conv2.*    | backbone.bottom_up.res4.5.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.5.conv3.*    | backbone.bottom_up.res4.5.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res5.0.conv1.*    | backbone.bottom_up.res5.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,1024,1,1)      |\n",
      "| backbone.bottom_up.res5.0.conv2.*    | backbone.bottom_up.res5.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |\n",
      "| backbone.bottom_up.res5.0.conv3.*    | backbone.bottom_up.res5.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
      "| backbone.bottom_up.res5.0.shortcut.* | backbone.bottom_up.res5.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (2048,) (2048,) (2048,) (2048,) (2048,1024,1,1) |\n",
      "| backbone.bottom_up.res5.1.conv1.*    | backbone.bottom_up.res5.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |\n",
      "| backbone.bottom_up.res5.1.conv2.*    | backbone.bottom_up.res5.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |\n",
      "| backbone.bottom_up.res5.1.conv3.*    | backbone.bottom_up.res5.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
      "| backbone.bottom_up.res5.2.conv1.*    | backbone.bottom_up.res5.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |\n",
      "| backbone.bottom_up.res5.2.conv2.*    | backbone.bottom_up.res5.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |\n",
      "| backbone.bottom_up.res5.2.conv3.*    | backbone.bottom_up.res5.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
      "| backbone.bottom_up.stem.conv1.*      | backbone.bottom_up.stem.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}      | (64,) (64,) (64,) (64,) (64,3,7,7)              |\n",
      "| backbone.fpn_lateral2.*              | backbone.fpn_lateral2.{bias,weight}                                                                  | (256,) (256,256,1,1)                            |\n",
      "| backbone.fpn_lateral3.*              | backbone.fpn_lateral3.{bias,weight}                                                                  | (256,) (256,512,1,1)                            |\n",
      "| backbone.fpn_lateral4.*              | backbone.fpn_lateral4.{bias,weight}                                                                  | (256,) (256,1024,1,1)                           |\n",
      "| backbone.fpn_lateral5.*              | backbone.fpn_lateral5.{bias,weight}                                                                  | (256,) (256,2048,1,1)                           |\n",
      "| backbone.fpn_output2.*               | backbone.fpn_output2.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| backbone.fpn_output3.*               | backbone.fpn_output3.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| backbone.fpn_output4.*               | backbone.fpn_output4.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| backbone.fpn_output5.*               | backbone.fpn_output5.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| sem_seg_head.p2.0.*                  | sem_seg_head.p2.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p3.0.*                  | sem_seg_head.p3.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p4.0.*                  | sem_seg_head.p4.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p4.2.*                  | sem_seg_head.p4.2.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,128,3,3)                     |\n",
      "| sem_seg_head.p5.0.*                  | sem_seg_head.p5.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p5.2.*                  | sem_seg_head.p5.2.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,128,3,3)                     |\n",
      "| sem_seg_head.p5.4.*                  | sem_seg_head.p5.4.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,128,3,3)                     |\n",
      "| sem_seg_head.predictor.*             | sem_seg_head.predictor.{bias,weight}                                                                 | (17,) (17,128,1,1)                              |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/05 17:43:08 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(720, 720), max_size=2048, sample_style='choice')]\n",
      "\u001b[32m[07/05 17:43:08 d2.data.common]: \u001b[0mSerializing 3957 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[07/05 17:43:08 d2.data.common]: \u001b[0mSerialized dataset takes 1.21 MiB\n",
      "\u001b[32m[07/05 17:43:08 d2.evaluation.evaluator]: \u001b[0mStart inference on 3957 batches\n",
      "\u001b[32m[07/05 17:43:11 d2.evaluation.evaluator]: \u001b[0mInference done 38/3957. Dataloading: 0.0020 s/iter. Inference: 0.0353 s/iter. Eval: 0.0427 s/iter. Total: 0.0801 s/iter. ETA=0:05:13\n",
      "\u001b[32m[07/05 17:43:16 d2.evaluation.evaluator]: \u001b[0mInference done 104/3957. Dataloading: 0.0021 s/iter. Inference: 0.0352 s/iter. Eval: 0.0402 s/iter. Total: 0.0775 s/iter. ETA=0:04:58\n",
      "\u001b[32m[07/05 17:43:21 d2.evaluation.evaluator]: \u001b[0mInference done 170/3957. Dataloading: 0.0021 s/iter. Inference: 0.0352 s/iter. Eval: 0.0395 s/iter. Total: 0.0769 s/iter. ETA=0:04:51\n",
      "\u001b[32m[07/05 17:43:26 d2.evaluation.evaluator]: \u001b[0mInference done 237/3957. Dataloading: 0.0022 s/iter. Inference: 0.0352 s/iter. Eval: 0.0390 s/iter. Total: 0.0764 s/iter. ETA=0:04:44\n",
      "\u001b[32m[07/05 17:43:31 d2.evaluation.evaluator]: \u001b[0mInference done 303/3957. Dataloading: 0.0022 s/iter. Inference: 0.0352 s/iter. Eval: 0.0388 s/iter. Total: 0.0763 s/iter. ETA=0:04:38\n",
      "\u001b[32m[07/05 17:43:36 d2.evaluation.evaluator]: \u001b[0mInference done 370/3957. Dataloading: 0.0022 s/iter. Inference: 0.0352 s/iter. Eval: 0.0386 s/iter. Total: 0.0761 s/iter. ETA=0:04:32\n",
      "\u001b[32m[07/05 17:43:41 d2.evaluation.evaluator]: \u001b[0mInference done 437/3957. Dataloading: 0.0022 s/iter. Inference: 0.0352 s/iter. Eval: 0.0385 s/iter. Total: 0.0760 s/iter. ETA=0:04:27\n",
      "\u001b[32m[07/05 17:43:46 d2.evaluation.evaluator]: \u001b[0mInference done 504/3957. Dataloading: 0.0022 s/iter. Inference: 0.0352 s/iter. Eval: 0.0383 s/iter. Total: 0.0759 s/iter. ETA=0:04:21\n",
      "\u001b[32m[07/05 17:43:51 d2.evaluation.evaluator]: \u001b[0mInference done 572/3957. Dataloading: 0.0022 s/iter. Inference: 0.0353 s/iter. Eval: 0.0381 s/iter. Total: 0.0756 s/iter. ETA=0:04:15\n",
      "\u001b[32m[07/05 17:43:57 d2.evaluation.evaluator]: \u001b[0mInference done 638/3957. Dataloading: 0.0022 s/iter. Inference: 0.0353 s/iter. Eval: 0.0381 s/iter. Total: 0.0757 s/iter. ETA=0:04:11\n",
      "\u001b[32m[07/05 17:44:02 d2.evaluation.evaluator]: \u001b[0mInference done 704/3957. Dataloading: 0.0022 s/iter. Inference: 0.0353 s/iter. Eval: 0.0382 s/iter. Total: 0.0757 s/iter. ETA=0:04:06\n",
      "\u001b[32m[07/05 17:44:07 d2.evaluation.evaluator]: \u001b[0mInference done 769/3957. Dataloading: 0.0022 s/iter. Inference: 0.0353 s/iter. Eval: 0.0383 s/iter. Total: 0.0759 s/iter. ETA=0:04:02\n",
      "\u001b[32m[07/05 17:44:12 d2.evaluation.evaluator]: \u001b[0mInference done 835/3957. Dataloading: 0.0022 s/iter. Inference: 0.0353 s/iter. Eval: 0.0384 s/iter. Total: 0.0760 s/iter. ETA=0:03:57\n",
      "\u001b[32m[07/05 17:44:17 d2.evaluation.evaluator]: \u001b[0mInference done 900/3957. Dataloading: 0.0022 s/iter. Inference: 0.0353 s/iter. Eval: 0.0385 s/iter. Total: 0.0761 s/iter. ETA=0:03:52\n",
      "\u001b[32m[07/05 17:44:22 d2.evaluation.evaluator]: \u001b[0mInference done 965/3957. Dataloading: 0.0022 s/iter. Inference: 0.0353 s/iter. Eval: 0.0386 s/iter. Total: 0.0762 s/iter. ETA=0:03:48\n",
      "\u001b[32m[07/05 17:44:27 d2.evaluation.evaluator]: \u001b[0mInference done 1030/3957. Dataloading: 0.0022 s/iter. Inference: 0.0353 s/iter. Eval: 0.0387 s/iter. Total: 0.0763 s/iter. ETA=0:03:43\n",
      "\u001b[32m[07/05 17:44:32 d2.evaluation.evaluator]: \u001b[0mInference done 1096/3957. Dataloading: 0.0022 s/iter. Inference: 0.0353 s/iter. Eval: 0.0387 s/iter. Total: 0.0764 s/iter. ETA=0:03:38\n",
      "\u001b[32m[07/05 17:44:37 d2.evaluation.evaluator]: \u001b[0mInference done 1161/3957. Dataloading: 0.0022 s/iter. Inference: 0.0353 s/iter. Eval: 0.0388 s/iter. Total: 0.0764 s/iter. ETA=0:03:33\n",
      "\u001b[32m[07/05 17:44:42 d2.evaluation.evaluator]: \u001b[0mInference done 1226/3957. Dataloading: 0.0022 s/iter. Inference: 0.0353 s/iter. Eval: 0.0389 s/iter. Total: 0.0765 s/iter. ETA=0:03:28\n",
      "\u001b[32m[07/05 17:44:47 d2.evaluation.evaluator]: \u001b[0mInference done 1291/3957. Dataloading: 0.0022 s/iter. Inference: 0.0354 s/iter. Eval: 0.0389 s/iter. Total: 0.0766 s/iter. ETA=0:03:24\n",
      "\u001b[32m[07/05 17:44:52 d2.evaluation.evaluator]: \u001b[0mInference done 1356/3957. Dataloading: 0.0022 s/iter. Inference: 0.0354 s/iter. Eval: 0.0390 s/iter. Total: 0.0767 s/iter. ETA=0:03:19\n",
      "\u001b[32m[07/05 17:44:57 d2.evaluation.evaluator]: \u001b[0mInference done 1422/3957. Dataloading: 0.0022 s/iter. Inference: 0.0354 s/iter. Eval: 0.0390 s/iter. Total: 0.0766 s/iter. ETA=0:03:14\n",
      "\u001b[32m[07/05 17:45:02 d2.evaluation.evaluator]: \u001b[0mInference done 1487/3957. Dataloading: 0.0022 s/iter. Inference: 0.0354 s/iter. Eval: 0.0390 s/iter. Total: 0.0767 s/iter. ETA=0:03:09\n",
      "\u001b[32m[07/05 17:45:07 d2.evaluation.evaluator]: \u001b[0mInference done 1551/3957. Dataloading: 0.0022 s/iter. Inference: 0.0354 s/iter. Eval: 0.0391 s/iter. Total: 0.0767 s/iter. ETA=0:03:04\n",
      "\u001b[32m[07/05 17:45:12 d2.evaluation.evaluator]: \u001b[0mInference done 1616/3957. Dataloading: 0.0022 s/iter. Inference: 0.0354 s/iter. Eval: 0.0391 s/iter. Total: 0.0768 s/iter. ETA=0:02:59\n",
      "\u001b[32m[07/05 17:45:17 d2.evaluation.evaluator]: \u001b[0mInference done 1680/3957. Dataloading: 0.0022 s/iter. Inference: 0.0354 s/iter. Eval: 0.0392 s/iter. Total: 0.0768 s/iter. ETA=0:02:54\n",
      "\u001b[32m[07/05 17:45:22 d2.evaluation.evaluator]: \u001b[0mInference done 1745/3957. Dataloading: 0.0022 s/iter. Inference: 0.0354 s/iter. Eval: 0.0392 s/iter. Total: 0.0768 s/iter. ETA=0:02:49\n",
      "\u001b[32m[07/05 17:45:27 d2.evaluation.evaluator]: \u001b[0mInference done 1809/3957. Dataloading: 0.0022 s/iter. Inference: 0.0354 s/iter. Eval: 0.0392 s/iter. Total: 0.0769 s/iter. ETA=0:02:45\n",
      "\u001b[32m[07/05 17:45:32 d2.evaluation.evaluator]: \u001b[0mInference done 1872/3957. Dataloading: 0.0022 s/iter. Inference: 0.0354 s/iter. Eval: 0.0393 s/iter. Total: 0.0770 s/iter. ETA=0:02:40\n",
      "\u001b[32m[07/05 17:45:37 d2.evaluation.evaluator]: \u001b[0mInference done 1937/3957. Dataloading: 0.0022 s/iter. Inference: 0.0354 s/iter. Eval: 0.0393 s/iter. Total: 0.0770 s/iter. ETA=0:02:35\n",
      "\u001b[32m[07/05 17:45:42 d2.evaluation.evaluator]: \u001b[0mInference done 2002/3957. Dataloading: 0.0022 s/iter. Inference: 0.0354 s/iter. Eval: 0.0393 s/iter. Total: 0.0770 s/iter. ETA=0:02:30\n",
      "\u001b[32m[07/05 17:45:48 d2.evaluation.evaluator]: \u001b[0mInference done 2068/3957. Dataloading: 0.0022 s/iter. Inference: 0.0354 s/iter. Eval: 0.0393 s/iter. Total: 0.0770 s/iter. ETA=0:02:25\n",
      "\u001b[32m[07/05 17:45:53 d2.evaluation.evaluator]: \u001b[0mInference done 2134/3957. Dataloading: 0.0022 s/iter. Inference: 0.0354 s/iter. Eval: 0.0393 s/iter. Total: 0.0770 s/iter. ETA=0:02:20\n",
      "\u001b[32m[07/05 17:45:58 d2.evaluation.evaluator]: \u001b[0mInference done 2200/3957. Dataloading: 0.0022 s/iter. Inference: 0.0354 s/iter. Eval: 0.0393 s/iter. Total: 0.0770 s/iter. ETA=0:02:15\n",
      "\u001b[32m[07/05 17:46:03 d2.evaluation.evaluator]: \u001b[0mInference done 2266/3957. Dataloading: 0.0022 s/iter. Inference: 0.0354 s/iter. Eval: 0.0392 s/iter. Total: 0.0770 s/iter. ETA=0:02:10\n",
      "\u001b[32m[07/05 17:46:08 d2.evaluation.evaluator]: \u001b[0mInference done 2332/3957. Dataloading: 0.0022 s/iter. Inference: 0.0354 s/iter. Eval: 0.0392 s/iter. Total: 0.0769 s/iter. ETA=0:02:05\n",
      "\u001b[32m[07/05 17:46:13 d2.evaluation.evaluator]: \u001b[0mInference done 2398/3957. Dataloading: 0.0022 s/iter. Inference: 0.0354 s/iter. Eval: 0.0392 s/iter. Total: 0.0769 s/iter. ETA=0:01:59\n",
      "\u001b[32m[07/05 17:46:18 d2.evaluation.evaluator]: \u001b[0mInference done 2464/3957. Dataloading: 0.0022 s/iter. Inference: 0.0354 s/iter. Eval: 0.0392 s/iter. Total: 0.0769 s/iter. ETA=0:01:54\n",
      "\u001b[32m[07/05 17:46:23 d2.evaluation.evaluator]: \u001b[0mInference done 2530/3957. Dataloading: 0.0022 s/iter. Inference: 0.0354 s/iter. Eval: 0.0391 s/iter. Total: 0.0769 s/iter. ETA=0:01:49\n",
      "\u001b[32m[07/05 17:46:28 d2.evaluation.evaluator]: \u001b[0mInference done 2597/3957. Dataloading: 0.0022 s/iter. Inference: 0.0354 s/iter. Eval: 0.0391 s/iter. Total: 0.0768 s/iter. ETA=0:01:44\n",
      "\u001b[32m[07/05 17:46:33 d2.evaluation.evaluator]: \u001b[0mInference done 2663/3957. Dataloading: 0.0022 s/iter. Inference: 0.0354 s/iter. Eval: 0.0391 s/iter. Total: 0.0768 s/iter. ETA=0:01:39\n",
      "\u001b[32m[07/05 17:46:38 d2.evaluation.evaluator]: \u001b[0mInference done 2729/3957. Dataloading: 0.0022 s/iter. Inference: 0.0355 s/iter. Eval: 0.0391 s/iter. Total: 0.0768 s/iter. ETA=0:01:34\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/05 17:46:43 d2.evaluation.evaluator]: \u001b[0mInference done 2795/3957. Dataloading: 0.0022 s/iter. Inference: 0.0355 s/iter. Eval: 0.0390 s/iter. Total: 0.0768 s/iter. ETA=0:01:29\n",
      "\u001b[32m[07/05 17:46:48 d2.evaluation.evaluator]: \u001b[0mInference done 2861/3957. Dataloading: 0.0022 s/iter. Inference: 0.0355 s/iter. Eval: 0.0390 s/iter. Total: 0.0768 s/iter. ETA=0:01:24\n",
      "\u001b[32m[07/05 17:46:53 d2.evaluation.evaluator]: \u001b[0mInference done 2927/3957. Dataloading: 0.0022 s/iter. Inference: 0.0355 s/iter. Eval: 0.0390 s/iter. Total: 0.0768 s/iter. ETA=0:01:19\n",
      "\u001b[32m[07/05 17:46:58 d2.evaluation.evaluator]: \u001b[0mInference done 2993/3957. Dataloading: 0.0022 s/iter. Inference: 0.0355 s/iter. Eval: 0.0390 s/iter. Total: 0.0768 s/iter. ETA=0:01:13\n",
      "\u001b[32m[07/05 17:47:03 d2.evaluation.evaluator]: \u001b[0mInference done 3059/3957. Dataloading: 0.0022 s/iter. Inference: 0.0355 s/iter. Eval: 0.0390 s/iter. Total: 0.0768 s/iter. ETA=0:01:08\n",
      "\u001b[32m[07/05 17:47:08 d2.evaluation.evaluator]: \u001b[0mInference done 3125/3957. Dataloading: 0.0022 s/iter. Inference: 0.0355 s/iter. Eval: 0.0390 s/iter. Total: 0.0767 s/iter. ETA=0:01:03\n",
      "\u001b[32m[07/05 17:47:13 d2.evaluation.evaluator]: \u001b[0mInference done 3191/3957. Dataloading: 0.0022 s/iter. Inference: 0.0355 s/iter. Eval: 0.0390 s/iter. Total: 0.0767 s/iter. ETA=0:00:58\n",
      "\u001b[32m[07/05 17:47:18 d2.evaluation.evaluator]: \u001b[0mInference done 3257/3957. Dataloading: 0.0022 s/iter. Inference: 0.0355 s/iter. Eval: 0.0389 s/iter. Total: 0.0767 s/iter. ETA=0:00:53\n",
      "\u001b[32m[07/05 17:47:23 d2.evaluation.evaluator]: \u001b[0mInference done 3285/3957. Dataloading: 0.0022 s/iter. Inference: 0.0356 s/iter. Eval: 0.0398 s/iter. Total: 0.0776 s/iter. ETA=0:00:52\n",
      "\u001b[32m[07/05 17:47:28 d2.evaluation.evaluator]: \u001b[0mInference done 3311/3957. Dataloading: 0.0022 s/iter. Inference: 0.0356 s/iter. Eval: 0.0406 s/iter. Total: 0.0785 s/iter. ETA=0:00:50\n",
      "\u001b[32m[07/05 17:47:33 d2.evaluation.evaluator]: \u001b[0mInference done 3337/3957. Dataloading: 0.0022 s/iter. Inference: 0.0357 s/iter. Eval: 0.0414 s/iter. Total: 0.0795 s/iter. ETA=0:00:49\n",
      "\u001b[32m[07/05 17:47:38 d2.evaluation.evaluator]: \u001b[0mInference done 3364/3957. Dataloading: 0.0022 s/iter. Inference: 0.0358 s/iter. Eval: 0.0422 s/iter. Total: 0.0803 s/iter. ETA=0:00:47\n",
      "\u001b[32m[07/05 17:47:43 d2.evaluation.evaluator]: \u001b[0mInference done 3391/3957. Dataloading: 0.0022 s/iter. Inference: 0.0359 s/iter. Eval: 0.0430 s/iter. Total: 0.0812 s/iter. ETA=0:00:45\n",
      "\u001b[32m[07/05 17:47:49 d2.evaluation.evaluator]: \u001b[0mInference done 3419/3957. Dataloading: 0.0022 s/iter. Inference: 0.0360 s/iter. Eval: 0.0437 s/iter. Total: 0.0820 s/iter. ETA=0:00:44\n",
      "\u001b[32m[07/05 17:47:54 d2.evaluation.evaluator]: \u001b[0mInference done 3444/3957. Dataloading: 0.0022 s/iter. Inference: 0.0361 s/iter. Eval: 0.0445 s/iter. Total: 0.0829 s/iter. ETA=0:00:42\n",
      "\u001b[32m[07/05 17:47:59 d2.evaluation.evaluator]: \u001b[0mInference done 3470/3957. Dataloading: 0.0022 s/iter. Inference: 0.0361 s/iter. Eval: 0.0453 s/iter. Total: 0.0837 s/iter. ETA=0:00:40\n",
      "\u001b[32m[07/05 17:48:04 d2.evaluation.evaluator]: \u001b[0mInference done 3495/3957. Dataloading: 0.0022 s/iter. Inference: 0.0362 s/iter. Eval: 0.0461 s/iter. Total: 0.0846 s/iter. ETA=0:00:39\n",
      "\u001b[32m[07/05 17:48:09 d2.evaluation.evaluator]: \u001b[0mInference done 3521/3957. Dataloading: 0.0022 s/iter. Inference: 0.0363 s/iter. Eval: 0.0468 s/iter. Total: 0.0854 s/iter. ETA=0:00:37\n",
      "\u001b[32m[07/05 17:48:14 d2.evaluation.evaluator]: \u001b[0mInference done 3548/3957. Dataloading: 0.0022 s/iter. Inference: 0.0364 s/iter. Eval: 0.0475 s/iter. Total: 0.0862 s/iter. ETA=0:00:35\n",
      "\u001b[32m[07/05 17:48:19 d2.evaluation.evaluator]: \u001b[0mInference done 3574/3957. Dataloading: 0.0022 s/iter. Inference: 0.0365 s/iter. Eval: 0.0482 s/iter. Total: 0.0870 s/iter. ETA=0:00:33\n",
      "\u001b[32m[07/05 17:48:24 d2.evaluation.evaluator]: \u001b[0mInference done 3600/3957. Dataloading: 0.0022 s/iter. Inference: 0.0365 s/iter. Eval: 0.0490 s/iter. Total: 0.0878 s/iter. ETA=0:00:31\n",
      "\u001b[32m[07/05 17:48:29 d2.evaluation.evaluator]: \u001b[0mInference done 3626/3957. Dataloading: 0.0022 s/iter. Inference: 0.0366 s/iter. Eval: 0.0497 s/iter. Total: 0.0886 s/iter. ETA=0:00:29\n",
      "\u001b[32m[07/05 17:48:34 d2.evaluation.evaluator]: \u001b[0mInference done 3652/3957. Dataloading: 0.0022 s/iter. Inference: 0.0367 s/iter. Eval: 0.0504 s/iter. Total: 0.0893 s/iter. ETA=0:00:27\n",
      "\u001b[32m[07/05 17:48:40 d2.evaluation.evaluator]: \u001b[0mInference done 3678/3957. Dataloading: 0.0022 s/iter. Inference: 0.0367 s/iter. Eval: 0.0510 s/iter. Total: 0.0901 s/iter. ETA=0:00:25\n",
      "\u001b[32m[07/05 17:48:45 d2.evaluation.evaluator]: \u001b[0mInference done 3704/3957. Dataloading: 0.0022 s/iter. Inference: 0.0368 s/iter. Eval: 0.0517 s/iter. Total: 0.0908 s/iter. ETA=0:00:22\n",
      "\u001b[32m[07/05 17:48:50 d2.evaluation.evaluator]: \u001b[0mInference done 3731/3957. Dataloading: 0.0022 s/iter. Inference: 0.0369 s/iter. Eval: 0.0523 s/iter. Total: 0.0915 s/iter. ETA=0:00:20\n",
      "\u001b[32m[07/05 17:48:55 d2.evaluation.evaluator]: \u001b[0mInference done 3757/3957. Dataloading: 0.0022 s/iter. Inference: 0.0370 s/iter. Eval: 0.0530 s/iter. Total: 0.0923 s/iter. ETA=0:00:18\n",
      "\u001b[32m[07/05 17:49:00 d2.evaluation.evaluator]: \u001b[0mInference done 3783/3957. Dataloading: 0.0022 s/iter. Inference: 0.0370 s/iter. Eval: 0.0536 s/iter. Total: 0.0930 s/iter. ETA=0:00:16\n",
      "\u001b[32m[07/05 17:49:05 d2.evaluation.evaluator]: \u001b[0mInference done 3809/3957. Dataloading: 0.0022 s/iter. Inference: 0.0371 s/iter. Eval: 0.0543 s/iter. Total: 0.0937 s/iter. ETA=0:00:13\n",
      "\u001b[32m[07/05 17:49:10 d2.evaluation.evaluator]: \u001b[0mInference done 3835/3957. Dataloading: 0.0022 s/iter. Inference: 0.0372 s/iter. Eval: 0.0549 s/iter. Total: 0.0944 s/iter. ETA=0:00:11\n",
      "\u001b[32m[07/05 17:49:15 d2.evaluation.evaluator]: \u001b[0mInference done 3861/3957. Dataloading: 0.0022 s/iter. Inference: 0.0372 s/iter. Eval: 0.0555 s/iter. Total: 0.0951 s/iter. ETA=0:00:09\n",
      "\u001b[32m[07/05 17:49:20 d2.evaluation.evaluator]: \u001b[0mInference done 3886/3957. Dataloading: 0.0022 s/iter. Inference: 0.0373 s/iter. Eval: 0.0561 s/iter. Total: 0.0957 s/iter. ETA=0:00:06\n",
      "\u001b[32m[07/05 17:49:25 d2.evaluation.evaluator]: \u001b[0mInference done 3912/3957. Dataloading: 0.0022 s/iter. Inference: 0.0373 s/iter. Eval: 0.0567 s/iter. Total: 0.0964 s/iter. ETA=0:00:04\n",
      "\u001b[32m[07/05 17:49:30 d2.evaluation.evaluator]: \u001b[0mInference done 3938/3957. Dataloading: 0.0022 s/iter. Inference: 0.0374 s/iter. Eval: 0.0573 s/iter. Total: 0.0970 s/iter. ETA=0:00:01\n",
      "\u001b[32m[07/05 17:49:34 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:06:25.545131 (0.097557 s / iter per device, on 1 devices)\n",
      "\u001b[32m[07/05 17:49:34 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:02:28 (0.037456 s / iter per device, on 1 devices)\n",
      "\u001b[32m[07/05 17:49:35 d2.evaluation.sem_seg_evaluation]: \u001b[0mOrderedDict([('sem_seg', {'mIoU': 72.57972531915358, 'fwIoU': 92.7333838200948, 'IoU-Unlabeled': nan, 'IoU-Building': 92.06390424741141, 'IoU-Fence': 47.42055436650479, 'IoU-Pedestrian': 76.68900555173201, 'IoU-Pole': 59.23608503519737, 'IoU-Road': 98.30211219507557, 'IoU-SideWalk': 85.70507861514373, 'IoU-Vegetation': 87.29143533600158, 'IoU-Vehicles': 88.81822039656282, 'IoU-Wall': 77.7281068699923, 'IoU-TrafficSign': 60.67508574301003, 'IoU-Sky': 96.81569389334732, 'IoU-TrafficLight': 66.27814052115258, 'IoU-Terrain': 68.22078651842654, 'IoU-ConstructionVehicle': 65.45037509027344, 'IoU-workzone_object': 77.01264465824973, 'IoU-Detour': 13.568376068376068, 'mACC': 80.92400545606152, 'pACC': 96.06777524309665, 'ACC-Unlabeled': nan, 'ACC-Building': 96.46419014655937, 'ACC-Fence': 62.491604855826175, 'ACC-Pedestrian': 86.47336789452001, 'ACC-Pole': 69.88035566920665, 'ACC-Road': 99.22989887121449, 'ACC-SideWalk': 91.72882675343462, 'ACC-Vegetation': 94.7070439547505, 'ACC-Vehicles': 92.1862944344426, 'ACC-Wall': 87.28389191462287, 'ACC-TrafficSign': 70.25245468654462, 'ACC-Sky': 98.24887489468561, 'ACC-TrafficLight': 75.78194464593034, 'ACC-Terrain': 75.18230327982245, 'ACC-ConstructionVehicle': 94.43896465772335, 'ACC-workzone_object': 86.1893049348093, 'ACC-Detour': 14.244765702891327})])\n",
      "\u001b[32m[07/05 17:49:35 d2.engine.defaults]: \u001b[0mEvaluation results for combined_clear_val in csv format:\n",
      "\u001b[32m[07/05 17:49:35 d2.evaluation.testing]: \u001b[0mcopypaste: Task: sem_seg\n",
      "\u001b[32m[07/05 17:49:35 d2.evaluation.testing]: \u001b[0mcopypaste: mIoU,fwIoU,mACC,pACC\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/05 17:49:35 d2.evaluation.testing]: \u001b[0mcopypaste: 72.5797,92.7334,80.9240,96.0678\n"
     ]
    }
   ],
   "source": [
    "trainer_day = Detectron2Trainer('combined_all_train', 'combined_clear_val', output_folder='./output_day_40k')\n",
    "trainer_day.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b25459e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/06 01:42:29 d2.engine.defaults]: \u001b[0mModel:\n",
      "SemanticSegmentor(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (sem_seg_head): SemSegFPNHead(\n",
      "    (p2): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "    )\n",
      "    (p3): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (1): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "    )\n",
      "    (p4): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (1): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      (2): Conv2d(\n",
      "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (3): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "    )\n",
      "    (p5): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (1): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      (2): Conv2d(\n",
      "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (3): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      (4): Conv2d(\n",
      "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (5): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "    )\n",
      "    (predictor): Conv2d(128, 17, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/06 01:42:29 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(720, 720), max_size=2048, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[07/06 01:42:29 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[07/06 01:42:29 d2.data.common]: \u001b[0mSerializing 10470 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[07/06 01:42:30 d2.data.common]: \u001b[0mSerialized dataset takes 3.22 MiB\n",
      "Last checkpoint: model_final.pth\n",
      "\u001b[32m[07/06 01:42:30 d2.checkpoint.c2_model_loading]: \u001b[0mFollowing weights matched with model:\n",
      "| Names in Model                       | Names in Checkpoint                                                                                  | Shapes                                          |\n",
      "|:-------------------------------------|:-----------------------------------------------------------------------------------------------------|:------------------------------------------------|\n",
      "| backbone.bottom_up.res2.0.conv1.*    | backbone.bottom_up.res2.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,1,1)             |\n",
      "| backbone.bottom_up.res2.0.conv2.*    | backbone.bottom_up.res2.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |\n",
      "| backbone.bottom_up.res2.0.conv3.*    | backbone.bottom_up.res2.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res2.0.shortcut.* | backbone.bottom_up.res2.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res2.1.conv1.*    | backbone.bottom_up.res2.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |\n",
      "| backbone.bottom_up.res2.1.conv2.*    | backbone.bottom_up.res2.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |\n",
      "| backbone.bottom_up.res2.1.conv3.*    | backbone.bottom_up.res2.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res2.2.conv1.*    | backbone.bottom_up.res2.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |\n",
      "| backbone.bottom_up.res2.2.conv2.*    | backbone.bottom_up.res2.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |\n",
      "| backbone.bottom_up.res2.2.conv3.*    | backbone.bottom_up.res2.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res3.0.conv1.*    | backbone.bottom_up.res3.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,256,1,1)       |\n",
      "| backbone.bottom_up.res3.0.conv2.*    | backbone.bottom_up.res3.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.0.conv3.*    | backbone.bottom_up.res3.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res3.0.shortcut.* | backbone.bottom_up.res3.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (512,) (512,) (512,) (512,) (512,256,1,1)       |\n",
      "| backbone.bottom_up.res3.1.conv1.*    | backbone.bottom_up.res3.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |\n",
      "| backbone.bottom_up.res3.1.conv2.*    | backbone.bottom_up.res3.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.1.conv3.*    | backbone.bottom_up.res3.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res3.2.conv1.*    | backbone.bottom_up.res3.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |\n",
      "| backbone.bottom_up.res3.2.conv2.*    | backbone.bottom_up.res3.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.2.conv3.*    | backbone.bottom_up.res3.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res3.3.conv1.*    | backbone.bottom_up.res3.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |\n",
      "| backbone.bottom_up.res3.3.conv2.*    | backbone.bottom_up.res3.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.3.conv3.*    | backbone.bottom_up.res3.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res4.0.conv1.*    | backbone.bottom_up.res4.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,512,1,1)       |\n",
      "| backbone.bottom_up.res4.0.conv2.*    | backbone.bottom_up.res4.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.0.conv3.*    | backbone.bottom_up.res4.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.0.shortcut.* | backbone.bottom_up.res4.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (1024,) (1024,) (1024,) (1024,) (1024,512,1,1)  |\n",
      "| backbone.bottom_up.res4.1.conv1.*    | backbone.bottom_up.res4.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.1.conv2.*    | backbone.bottom_up.res4.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.1.conv3.*    | backbone.bottom_up.res4.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.2.conv1.*    | backbone.bottom_up.res4.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.2.conv2.*    | backbone.bottom_up.res4.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.2.conv3.*    | backbone.bottom_up.res4.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.3.conv1.*    | backbone.bottom_up.res4.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.3.conv2.*    | backbone.bottom_up.res4.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.3.conv3.*    | backbone.bottom_up.res4.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.4.conv1.*    | backbone.bottom_up.res4.4.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.4.conv2.*    | backbone.bottom_up.res4.4.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.4.conv3.*    | backbone.bottom_up.res4.4.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.5.conv1.*    | backbone.bottom_up.res4.5.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.5.conv2.*    | backbone.bottom_up.res4.5.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.5.conv3.*    | backbone.bottom_up.res4.5.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res5.0.conv1.*    | backbone.bottom_up.res5.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,1024,1,1)      |\n",
      "| backbone.bottom_up.res5.0.conv2.*    | backbone.bottom_up.res5.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |\n",
      "| backbone.bottom_up.res5.0.conv3.*    | backbone.bottom_up.res5.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
      "| backbone.bottom_up.res5.0.shortcut.* | backbone.bottom_up.res5.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (2048,) (2048,) (2048,) (2048,) (2048,1024,1,1) |\n",
      "| backbone.bottom_up.res5.1.conv1.*    | backbone.bottom_up.res5.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |\n",
      "| backbone.bottom_up.res5.1.conv2.*    | backbone.bottom_up.res5.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |\n",
      "| backbone.bottom_up.res5.1.conv3.*    | backbone.bottom_up.res5.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
      "| backbone.bottom_up.res5.2.conv1.*    | backbone.bottom_up.res5.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |\n",
      "| backbone.bottom_up.res5.2.conv2.*    | backbone.bottom_up.res5.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |\n",
      "| backbone.bottom_up.res5.2.conv3.*    | backbone.bottom_up.res5.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
      "| backbone.bottom_up.stem.conv1.*      | backbone.bottom_up.stem.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}      | (64,) (64,) (64,) (64,) (64,3,7,7)              |\n",
      "| backbone.fpn_lateral2.*              | backbone.fpn_lateral2.{bias,weight}                                                                  | (256,) (256,256,1,1)                            |\n",
      "| backbone.fpn_lateral3.*              | backbone.fpn_lateral3.{bias,weight}                                                                  | (256,) (256,512,1,1)                            |\n",
      "| backbone.fpn_lateral4.*              | backbone.fpn_lateral4.{bias,weight}                                                                  | (256,) (256,1024,1,1)                           |\n",
      "| backbone.fpn_lateral5.*              | backbone.fpn_lateral5.{bias,weight}                                                                  | (256,) (256,2048,1,1)                           |\n",
      "| backbone.fpn_output2.*               | backbone.fpn_output2.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| backbone.fpn_output3.*               | backbone.fpn_output3.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| backbone.fpn_output4.*               | backbone.fpn_output4.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| backbone.fpn_output5.*               | backbone.fpn_output5.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| sem_seg_head.p2.0.*                  | sem_seg_head.p2.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p3.0.*                  | sem_seg_head.p3.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p4.0.*                  | sem_seg_head.p4.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p4.2.*                  | sem_seg_head.p4.2.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,128,3,3)                     |\n",
      "| sem_seg_head.p5.0.*                  | sem_seg_head.p5.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p5.2.*                  | sem_seg_head.p5.2.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,128,3,3)                     |\n",
      "| sem_seg_head.p5.4.*                  | sem_seg_head.p5.4.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,128,3,3)                     |\n",
      "| sem_seg_head.predictor.*             | sem_seg_head.predictor.{bias,weight}                                                                 | (17,) (17,128,1,1)                              |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/06 01:42:30 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(720, 720), max_size=2048, sample_style='choice')]\n",
      "\u001b[32m[07/06 01:42:30 d2.data.common]: \u001b[0mSerializing 1089 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[07/06 01:42:30 d2.data.common]: \u001b[0mSerialized dataset takes 0.33 MiB\n",
      "\u001b[32m[07/06 01:42:30 d2.evaluation.evaluator]: \u001b[0mStart inference on 1089 batches\n",
      "\u001b[32m[07/06 01:42:31 d2.evaluation.evaluator]: \u001b[0mInference done 11/1089. Dataloading: 0.0017 s/iter. Inference: 0.0351 s/iter. Eval: 0.0435 s/iter. Total: 0.0802 s/iter. ETA=0:01:26\n",
      "\u001b[32m[07/06 01:42:36 d2.evaluation.evaluator]: \u001b[0mInference done 75/1089. Dataloading: 0.0020 s/iter. Inference: 0.0361 s/iter. Eval: 0.0405 s/iter. Total: 0.0787 s/iter. ETA=0:01:19\n",
      "\u001b[32m[07/06 01:42:41 d2.evaluation.evaluator]: \u001b[0mInference done 139/1089. Dataloading: 0.0021 s/iter. Inference: 0.0363 s/iter. Eval: 0.0402 s/iter. Total: 0.0787 s/iter. ETA=0:01:14\n",
      "\u001b[32m[07/06 01:42:46 d2.evaluation.evaluator]: \u001b[0mInference done 203/1089. Dataloading: 0.0021 s/iter. Inference: 0.0365 s/iter. Eval: 0.0402 s/iter. Total: 0.0788 s/iter. ETA=0:01:09\n",
      "\u001b[32m[07/06 01:42:51 d2.evaluation.evaluator]: \u001b[0mInference done 266/1089. Dataloading: 0.0021 s/iter. Inference: 0.0364 s/iter. Eval: 0.0404 s/iter. Total: 0.0790 s/iter. ETA=0:01:04\n",
      "\u001b[32m[07/06 01:42:56 d2.evaluation.evaluator]: \u001b[0mInference done 330/1089. Dataloading: 0.0021 s/iter. Inference: 0.0363 s/iter. Eval: 0.0405 s/iter. Total: 0.0790 s/iter. ETA=0:00:59\n",
      "\u001b[32m[07/06 01:43:01 d2.evaluation.evaluator]: \u001b[0mInference done 393/1089. Dataloading: 0.0021 s/iter. Inference: 0.0364 s/iter. Eval: 0.0406 s/iter. Total: 0.0792 s/iter. ETA=0:00:55\n",
      "\u001b[32m[07/06 01:43:06 d2.evaluation.evaluator]: \u001b[0mInference done 456/1089. Dataloading: 0.0021 s/iter. Inference: 0.0364 s/iter. Eval: 0.0407 s/iter. Total: 0.0793 s/iter. ETA=0:00:50\n",
      "\u001b[32m[07/06 01:43:12 d2.evaluation.evaluator]: \u001b[0mInference done 520/1089. Dataloading: 0.0021 s/iter. Inference: 0.0364 s/iter. Eval: 0.0407 s/iter. Total: 0.0792 s/iter. ETA=0:00:45\n",
      "\u001b[32m[07/06 01:43:17 d2.evaluation.evaluator]: \u001b[0mInference done 583/1089. Dataloading: 0.0021 s/iter. Inference: 0.0364 s/iter. Eval: 0.0407 s/iter. Total: 0.0792 s/iter. ETA=0:00:40\n",
      "\u001b[32m[07/06 01:43:22 d2.evaluation.evaluator]: \u001b[0mInference done 645/1089. Dataloading: 0.0021 s/iter. Inference: 0.0364 s/iter. Eval: 0.0409 s/iter. Total: 0.0795 s/iter. ETA=0:00:35\n",
      "\u001b[32m[07/06 01:43:27 d2.evaluation.evaluator]: \u001b[0mInference done 709/1089. Dataloading: 0.0021 s/iter. Inference: 0.0364 s/iter. Eval: 0.0409 s/iter. Total: 0.0795 s/iter. ETA=0:00:30\n",
      "\u001b[32m[07/06 01:43:32 d2.evaluation.evaluator]: \u001b[0mInference done 773/1089. Dataloading: 0.0020 s/iter. Inference: 0.0364 s/iter. Eval: 0.0408 s/iter. Total: 0.0794 s/iter. ETA=0:00:25\n",
      "\u001b[32m[07/06 01:43:37 d2.evaluation.evaluator]: \u001b[0mInference done 837/1089. Dataloading: 0.0020 s/iter. Inference: 0.0365 s/iter. Eval: 0.0408 s/iter. Total: 0.0794 s/iter. ETA=0:00:19\n",
      "\u001b[32m[07/06 01:43:42 d2.evaluation.evaluator]: \u001b[0mInference done 902/1089. Dataloading: 0.0020 s/iter. Inference: 0.0365 s/iter. Eval: 0.0406 s/iter. Total: 0.0793 s/iter. ETA=0:00:14\n",
      "\u001b[32m[07/06 01:43:47 d2.evaluation.evaluator]: \u001b[0mInference done 966/1089. Dataloading: 0.0021 s/iter. Inference: 0.0365 s/iter. Eval: 0.0406 s/iter. Total: 0.0793 s/iter. ETA=0:00:09\n",
      "\u001b[32m[07/06 01:43:52 d2.evaluation.evaluator]: \u001b[0mInference done 1030/1089. Dataloading: 0.0021 s/iter. Inference: 0.0366 s/iter. Eval: 0.0406 s/iter. Total: 0.0792 s/iter. ETA=0:00:04\n",
      "\u001b[32m[07/06 01:43:57 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:01:26.035069 (0.079368 s / iter per device, on 1 devices)\n",
      "\u001b[32m[07/06 01:43:57 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:39 (0.036675 s / iter per device, on 1 devices)\n",
      "\u001b[32m[07/06 01:43:57 d2.evaluation.sem_seg_evaluation]: \u001b[0mOrderedDict([('sem_seg', {'mIoU': 70.65658340267612, 'fwIoU': 93.54253892076585, 'IoU-Unlabeled': nan, 'IoU-Building': 92.4357085713673, 'IoU-Fence': 39.99942544110861, 'IoU-Pedestrian': 49.89213396217993, 'IoU-Pole': 61.516318832051034, 'IoU-Road': 98.88607168328124, 'IoU-SideWalk': 89.29194464860377, 'IoU-Vegetation': 83.21684144309901, 'IoU-Vehicles': 86.16347341846715, 'IoU-Wall': 84.09272622073654, 'IoU-TrafficSign': 53.843796424944316, 'IoU-Sky': 96.94860158286586, 'IoU-TrafficLight': 72.18548471337229, 'IoU-Terrain': 70.67398365952097, 'IoU-ConstructionVehicle': 64.96856470717715, 'IoU-workzone_object': 73.30708101202389, 'IoU-Detour': 13.083178122018808, 'mACC': 79.26460120384327, 'pACC': 96.49941194264972, 'ACC-Unlabeled': nan, 'ACC-Building': 96.83793347377258, 'ACC-Fence': 53.834599112069995, 'ACC-Pedestrian': 66.33317581898305, 'ACC-Pole': 70.6898275679801, 'ACC-Road': 99.44627792703365, 'ACC-SideWalk': 94.43222149028806, 'ACC-Vegetation': 92.87118443061, 'ACC-Vehicles': 88.72898950370795, 'ACC-Wall': 93.70766240230967, 'ACC-TrafficSign': 63.35189604879342, 'ACC-Sky': 98.31288212814388, 'ACC-TrafficLight': 81.69657773715385, 'ACC-Terrain': 75.32256494142827, 'ACC-ConstructionVehicle': 94.22109815565713, 'ACC-workzone_object': 84.93004386593653, 'ACC-Detour': 13.516684657624257})])\n",
      "\u001b[32m[07/06 01:43:57 d2.engine.defaults]: \u001b[0mEvaluation results for carla_rain_val in csv format:\n",
      "\u001b[32m[07/06 01:43:57 d2.evaluation.testing]: \u001b[0mcopypaste: Task: sem_seg\n",
      "\u001b[32m[07/06 01:43:57 d2.evaluation.testing]: \u001b[0mcopypaste: mIoU,fwIoU,mACC,pACC\n",
      "\u001b[32m[07/06 01:43:57 d2.evaluation.testing]: \u001b[0mcopypaste: 70.6566,93.5425,79.2646,96.4994\n"
     ]
    }
   ],
   "source": [
    "trainer_day = Detectron2Trainer('combined_all_train', 'carla_rain_val', output_folder='./output_day_40k')\n",
    "trainer_day.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "03b24476",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/06 01:43:57 d2.engine.defaults]: \u001b[0mModel:\n",
      "SemanticSegmentor(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (sem_seg_head): SemSegFPNHead(\n",
      "    (p2): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "    )\n",
      "    (p3): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (1): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "    )\n",
      "    (p4): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (1): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      (2): Conv2d(\n",
      "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (3): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "    )\n",
      "    (p5): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (1): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      (2): Conv2d(\n",
      "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (3): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      (4): Conv2d(\n",
      "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (5): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "    )\n",
      "    (predictor): Conv2d(128, 17, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/06 01:43:57 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(720, 720), max_size=2048, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[07/06 01:43:57 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[07/06 01:43:57 d2.data.common]: \u001b[0mSerializing 10470 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[07/06 01:43:57 d2.data.common]: \u001b[0mSerialized dataset takes 3.22 MiB\n",
      "Last checkpoint: model_final.pth\n",
      "\u001b[32m[07/06 01:43:58 d2.checkpoint.c2_model_loading]: \u001b[0mFollowing weights matched with model:\n",
      "| Names in Model                       | Names in Checkpoint                                                                                  | Shapes                                          |\n",
      "|:-------------------------------------|:-----------------------------------------------------------------------------------------------------|:------------------------------------------------|\n",
      "| backbone.bottom_up.res2.0.conv1.*    | backbone.bottom_up.res2.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,1,1)             |\n",
      "| backbone.bottom_up.res2.0.conv2.*    | backbone.bottom_up.res2.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |\n",
      "| backbone.bottom_up.res2.0.conv3.*    | backbone.bottom_up.res2.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res2.0.shortcut.* | backbone.bottom_up.res2.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res2.1.conv1.*    | backbone.bottom_up.res2.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |\n",
      "| backbone.bottom_up.res2.1.conv2.*    | backbone.bottom_up.res2.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |\n",
      "| backbone.bottom_up.res2.1.conv3.*    | backbone.bottom_up.res2.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res2.2.conv1.*    | backbone.bottom_up.res2.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |\n",
      "| backbone.bottom_up.res2.2.conv2.*    | backbone.bottom_up.res2.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |\n",
      "| backbone.bottom_up.res2.2.conv3.*    | backbone.bottom_up.res2.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res3.0.conv1.*    | backbone.bottom_up.res3.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,256,1,1)       |\n",
      "| backbone.bottom_up.res3.0.conv2.*    | backbone.bottom_up.res3.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.0.conv3.*    | backbone.bottom_up.res3.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res3.0.shortcut.* | backbone.bottom_up.res3.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (512,) (512,) (512,) (512,) (512,256,1,1)       |\n",
      "| backbone.bottom_up.res3.1.conv1.*    | backbone.bottom_up.res3.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |\n",
      "| backbone.bottom_up.res3.1.conv2.*    | backbone.bottom_up.res3.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.1.conv3.*    | backbone.bottom_up.res3.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res3.2.conv1.*    | backbone.bottom_up.res3.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |\n",
      "| backbone.bottom_up.res3.2.conv2.*    | backbone.bottom_up.res3.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.2.conv3.*    | backbone.bottom_up.res3.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res3.3.conv1.*    | backbone.bottom_up.res3.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |\n",
      "| backbone.bottom_up.res3.3.conv2.*    | backbone.bottom_up.res3.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.3.conv3.*    | backbone.bottom_up.res3.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res4.0.conv1.*    | backbone.bottom_up.res4.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,512,1,1)       |\n",
      "| backbone.bottom_up.res4.0.conv2.*    | backbone.bottom_up.res4.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.0.conv3.*    | backbone.bottom_up.res4.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.0.shortcut.* | backbone.bottom_up.res4.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (1024,) (1024,) (1024,) (1024,) (1024,512,1,1)  |\n",
      "| backbone.bottom_up.res4.1.conv1.*    | backbone.bottom_up.res4.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.1.conv2.*    | backbone.bottom_up.res4.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.1.conv3.*    | backbone.bottom_up.res4.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.2.conv1.*    | backbone.bottom_up.res4.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.2.conv2.*    | backbone.bottom_up.res4.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.2.conv3.*    | backbone.bottom_up.res4.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.3.conv1.*    | backbone.bottom_up.res4.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.3.conv2.*    | backbone.bottom_up.res4.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.3.conv3.*    | backbone.bottom_up.res4.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.4.conv1.*    | backbone.bottom_up.res4.4.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.4.conv2.*    | backbone.bottom_up.res4.4.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.4.conv3.*    | backbone.bottom_up.res4.4.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.5.conv1.*    | backbone.bottom_up.res4.5.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.5.conv2.*    | backbone.bottom_up.res4.5.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.5.conv3.*    | backbone.bottom_up.res4.5.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res5.0.conv1.*    | backbone.bottom_up.res5.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,1024,1,1)      |\n",
      "| backbone.bottom_up.res5.0.conv2.*    | backbone.bottom_up.res5.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |\n",
      "| backbone.bottom_up.res5.0.conv3.*    | backbone.bottom_up.res5.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
      "| backbone.bottom_up.res5.0.shortcut.* | backbone.bottom_up.res5.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (2048,) (2048,) (2048,) (2048,) (2048,1024,1,1) |\n",
      "| backbone.bottom_up.res5.1.conv1.*    | backbone.bottom_up.res5.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |\n",
      "| backbone.bottom_up.res5.1.conv2.*    | backbone.bottom_up.res5.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |\n",
      "| backbone.bottom_up.res5.1.conv3.*    | backbone.bottom_up.res5.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
      "| backbone.bottom_up.res5.2.conv1.*    | backbone.bottom_up.res5.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |\n",
      "| backbone.bottom_up.res5.2.conv2.*    | backbone.bottom_up.res5.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |\n",
      "| backbone.bottom_up.res5.2.conv3.*    | backbone.bottom_up.res5.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
      "| backbone.bottom_up.stem.conv1.*      | backbone.bottom_up.stem.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}      | (64,) (64,) (64,) (64,) (64,3,7,7)              |\n",
      "| backbone.fpn_lateral2.*              | backbone.fpn_lateral2.{bias,weight}                                                                  | (256,) (256,256,1,1)                            |\n",
      "| backbone.fpn_lateral3.*              | backbone.fpn_lateral3.{bias,weight}                                                                  | (256,) (256,512,1,1)                            |\n",
      "| backbone.fpn_lateral4.*              | backbone.fpn_lateral4.{bias,weight}                                                                  | (256,) (256,1024,1,1)                           |\n",
      "| backbone.fpn_lateral5.*              | backbone.fpn_lateral5.{bias,weight}                                                                  | (256,) (256,2048,1,1)                           |\n",
      "| backbone.fpn_output2.*               | backbone.fpn_output2.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| backbone.fpn_output3.*               | backbone.fpn_output3.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| backbone.fpn_output4.*               | backbone.fpn_output4.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| backbone.fpn_output5.*               | backbone.fpn_output5.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| sem_seg_head.p2.0.*                  | sem_seg_head.p2.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p3.0.*                  | sem_seg_head.p3.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p4.0.*                  | sem_seg_head.p4.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p4.2.*                  | sem_seg_head.p4.2.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,128,3,3)                     |\n",
      "| sem_seg_head.p5.0.*                  | sem_seg_head.p5.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p5.2.*                  | sem_seg_head.p5.2.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,128,3,3)                     |\n",
      "| sem_seg_head.p5.4.*                  | sem_seg_head.p5.4.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,128,3,3)                     |\n",
      "| sem_seg_head.predictor.*             | sem_seg_head.predictor.{bias,weight}                                                                 | (17,) (17,128,1,1)                              |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/06 01:43:58 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(720, 720), max_size=2048, sample_style='choice')]\n",
      "\u001b[32m[07/06 01:43:58 d2.data.common]: \u001b[0mSerializing 699 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[07/06 01:43:58 d2.data.common]: \u001b[0mSerialized dataset takes 0.21 MiB\n",
      "\u001b[32m[07/06 01:43:58 d2.evaluation.evaluator]: \u001b[0mStart inference on 699 batches\n",
      "\u001b[32m[07/06 01:44:00 d2.evaluation.evaluator]: \u001b[0mInference done 11/699. Dataloading: 0.0018 s/iter. Inference: 0.0408 s/iter. Eval: 0.1416 s/iter. Total: 0.1841 s/iter. ETA=0:02:06\n",
      "\u001b[32m[07/06 01:44:05 d2.evaluation.evaluator]: \u001b[0mInference done 38/699. Dataloading: 0.0021 s/iter. Inference: 0.0410 s/iter. Eval: 0.1432 s/iter. Total: 0.1865 s/iter. ETA=0:02:03\n",
      "\u001b[32m[07/06 01:44:10 d2.evaluation.evaluator]: \u001b[0mInference done 66/699. Dataloading: 0.0021 s/iter. Inference: 0.0416 s/iter. Eval: 0.1412 s/iter. Total: 0.1850 s/iter. ETA=0:01:57\n",
      "\u001b[32m[07/06 01:44:16 d2.evaluation.evaluator]: \u001b[0mInference done 93/699. Dataloading: 0.0021 s/iter. Inference: 0.0428 s/iter. Eval: 0.1418 s/iter. Total: 0.1868 s/iter. ETA=0:01:53\n",
      "\u001b[32m[07/06 01:44:21 d2.evaluation.evaluator]: \u001b[0mInference done 122/699. Dataloading: 0.0022 s/iter. Inference: 0.0426 s/iter. Eval: 0.1397 s/iter. Total: 0.1845 s/iter. ETA=0:01:46\n",
      "\u001b[32m[07/06 01:44:26 d2.evaluation.evaluator]: \u001b[0mInference done 151/699. Dataloading: 0.0022 s/iter. Inference: 0.0431 s/iter. Eval: 0.1371 s/iter. Total: 0.1825 s/iter. ETA=0:01:40\n",
      "\u001b[32m[07/06 01:44:31 d2.evaluation.evaluator]: \u001b[0mInference done 178/699. Dataloading: 0.0022 s/iter. Inference: 0.0434 s/iter. Eval: 0.1383 s/iter. Total: 0.1840 s/iter. ETA=0:01:35\n",
      "\u001b[32m[07/06 01:44:36 d2.evaluation.evaluator]: \u001b[0mInference done 204/699. Dataloading: 0.0022 s/iter. Inference: 0.0435 s/iter. Eval: 0.1395 s/iter. Total: 0.1853 s/iter. ETA=0:01:31\n",
      "\u001b[32m[07/06 01:44:41 d2.evaluation.evaluator]: \u001b[0mInference done 230/699. Dataloading: 0.0022 s/iter. Inference: 0.0435 s/iter. Eval: 0.1407 s/iter. Total: 0.1865 s/iter. ETA=0:01:27\n",
      "\u001b[32m[07/06 01:44:46 d2.evaluation.evaluator]: \u001b[0mInference done 257/699. Dataloading: 0.0021 s/iter. Inference: 0.0432 s/iter. Eval: 0.1409 s/iter. Total: 0.1864 s/iter. ETA=0:01:22\n",
      "\u001b[32m[07/06 01:44:51 d2.evaluation.evaluator]: \u001b[0mInference done 285/699. Dataloading: 0.0021 s/iter. Inference: 0.0431 s/iter. Eval: 0.1407 s/iter. Total: 0.1860 s/iter. ETA=0:01:17\n",
      "\u001b[32m[07/06 01:44:56 d2.evaluation.evaluator]: \u001b[0mInference done 312/699. Dataloading: 0.0021 s/iter. Inference: 0.0433 s/iter. Eval: 0.1410 s/iter. Total: 0.1865 s/iter. ETA=0:01:12\n",
      "\u001b[32m[07/06 01:45:01 d2.evaluation.evaluator]: \u001b[0mInference done 339/699. Dataloading: 0.0021 s/iter. Inference: 0.0431 s/iter. Eval: 0.1412 s/iter. Total: 0.1865 s/iter. ETA=0:01:07\n",
      "\u001b[32m[07/06 01:45:07 d2.evaluation.evaluator]: \u001b[0mInference done 366/699. Dataloading: 0.0021 s/iter. Inference: 0.0433 s/iter. Eval: 0.1415 s/iter. Total: 0.1870 s/iter. ETA=0:01:02\n",
      "\u001b[32m[07/06 01:45:12 d2.evaluation.evaluator]: \u001b[0mInference done 393/699. Dataloading: 0.0021 s/iter. Inference: 0.0433 s/iter. Eval: 0.1418 s/iter. Total: 0.1874 s/iter. ETA=0:00:57\n",
      "\u001b[32m[07/06 01:45:17 d2.evaluation.evaluator]: \u001b[0mInference done 420/699. Dataloading: 0.0021 s/iter. Inference: 0.0433 s/iter. Eval: 0.1419 s/iter. Total: 0.1875 s/iter. ETA=0:00:52\n",
      "\u001b[32m[07/06 01:45:22 d2.evaluation.evaluator]: \u001b[0mInference done 447/699. Dataloading: 0.0021 s/iter. Inference: 0.0434 s/iter. Eval: 0.1419 s/iter. Total: 0.1875 s/iter. ETA=0:00:47\n",
      "\u001b[32m[07/06 01:45:27 d2.evaluation.evaluator]: \u001b[0mInference done 475/699. Dataloading: 0.0021 s/iter. Inference: 0.0434 s/iter. Eval: 0.1417 s/iter. Total: 0.1873 s/iter. ETA=0:00:41\n",
      "\u001b[32m[07/06 01:45:32 d2.evaluation.evaluator]: \u001b[0mInference done 502/699. Dataloading: 0.0021 s/iter. Inference: 0.0433 s/iter. Eval: 0.1420 s/iter. Total: 0.1876 s/iter. ETA=0:00:36\n",
      "\u001b[32m[07/06 01:45:38 d2.evaluation.evaluator]: \u001b[0mInference done 529/699. Dataloading: 0.0021 s/iter. Inference: 0.0434 s/iter. Eval: 0.1421 s/iter. Total: 0.1877 s/iter. ETA=0:00:31\n",
      "\u001b[32m[07/06 01:45:43 d2.evaluation.evaluator]: \u001b[0mInference done 556/699. Dataloading: 0.0021 s/iter. Inference: 0.0434 s/iter. Eval: 0.1422 s/iter. Total: 0.1878 s/iter. ETA=0:00:26\n",
      "\u001b[32m[07/06 01:45:48 d2.evaluation.evaluator]: \u001b[0mInference done 583/699. Dataloading: 0.0021 s/iter. Inference: 0.0434 s/iter. Eval: 0.1422 s/iter. Total: 0.1878 s/iter. ETA=0:00:21\n",
      "\u001b[32m[07/06 01:45:53 d2.evaluation.evaluator]: \u001b[0mInference done 610/699. Dataloading: 0.0021 s/iter. Inference: 0.0433 s/iter. Eval: 0.1422 s/iter. Total: 0.1878 s/iter. ETA=0:00:16\n",
      "\u001b[32m[07/06 01:45:58 d2.evaluation.evaluator]: \u001b[0mInference done 637/699. Dataloading: 0.0021 s/iter. Inference: 0.0433 s/iter. Eval: 0.1423 s/iter. Total: 0.1878 s/iter. ETA=0:00:11\n",
      "\u001b[32m[07/06 01:46:03 d2.evaluation.evaluator]: \u001b[0mInference done 665/699. Dataloading: 0.0021 s/iter. Inference: 0.0433 s/iter. Eval: 0.1421 s/iter. Total: 0.1876 s/iter. ETA=0:00:06\n",
      "\u001b[32m[07/06 01:46:08 d2.evaluation.evaluator]: \u001b[0mInference done 692/699. Dataloading: 0.0021 s/iter. Inference: 0.0434 s/iter. Eval: 0.1420 s/iter. Total: 0.1876 s/iter. ETA=0:00:01\n",
      "\u001b[32m[07/06 01:46:09 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:02:10.314104 (0.187772 s / iter per device, on 1 devices)\n",
      "\u001b[32m[07/06 01:46:09 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:30 (0.043382 s / iter per device, on 1 devices)\n",
      "\u001b[32m[07/06 01:46:10 d2.evaluation.sem_seg_evaluation]: \u001b[0mOrderedDict([('sem_seg', {'mIoU': 68.27497496156779, 'fwIoU': 90.54222469653251, 'IoU-Unlabeled': nan, 'IoU-Building': 90.95151887105693, 'IoU-Fence': 53.88990981542023, 'IoU-Pedestrian': 78.59215957143144, 'IoU-Pole': 52.34811183560251, 'IoU-Road': 96.59802986516829, 'IoU-SideWalk': 78.45267701614065, 'IoU-Vegetation': 90.63849078184234, 'IoU-Vehicles': 90.63397594364459, 'IoU-Wall': 47.886202117233964, 'IoU-TrafficSign': 65.16298754425989, 'IoU-Sky': 94.42793136159932, 'IoU-TrafficLight': 54.94849511378834, 'IoU-Terrain': 61.31915962476071, 'IoU-ConstructionVehicle': nan, 'IoU-workzone_object': nan, 'IoU-Detour': nan, 'mACC': 81.66100922476338, 'pACC': 94.83526786813839, 'ACC-Unlabeled': nan, 'ACC-Building': 95.52912243347846, 'ACC-Fence': 69.97655961658118, 'ACC-Pedestrian': 87.89507311171357, 'ACC-Pole': 66.67424607134652, 'ACC-Road': 98.66681995539273, 'ACC-SideWalk': 85.5500166377243, 'ACC-Vegetation': 95.99024507250238, 'ACC-Vehicles': 95.08266646671878, 'ACC-Wall': 57.816199795229764, 'ACC-TrafficSign': 74.81764880542683, 'ACC-Sky': 97.46374173792567, 'ACC-TrafficLight': 63.813659885663846, 'ACC-Terrain': 72.31712033221986, 'ACC-ConstructionVehicle': nan, 'ACC-workzone_object': nan, 'ACC-Detour': nan})])\n",
      "\u001b[32m[07/06 01:46:10 d2.engine.defaults]: \u001b[0mEvaluation results for cityscapes_rain_val in csv format:\n",
      "\u001b[32m[07/06 01:46:10 d2.evaluation.testing]: \u001b[0mcopypaste: Task: sem_seg\n",
      "\u001b[32m[07/06 01:46:10 d2.evaluation.testing]: \u001b[0mcopypaste: mIoU,fwIoU,mACC,pACC\n",
      "\u001b[32m[07/06 01:46:10 d2.evaluation.testing]: \u001b[0mcopypaste: 68.2750,90.5422,81.6610,94.8353\n"
     ]
    }
   ],
   "source": [
    "trainer_day = Detectron2Trainer('combined_all_train', 'cityscapes_rain_val', output_folder='./output_day_40k')\n",
    "trainer_day.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "932f176e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/06 01:46:10 d2.engine.defaults]: \u001b[0mModel:\n",
      "SemanticSegmentor(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (sem_seg_head): SemSegFPNHead(\n",
      "    (p2): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "    )\n",
      "    (p3): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (1): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "    )\n",
      "    (p4): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (1): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      (2): Conv2d(\n",
      "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (3): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "    )\n",
      "    (p5): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (1): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      (2): Conv2d(\n",
      "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (3): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      (4): Conv2d(\n",
      "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (5): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "    )\n",
      "    (predictor): Conv2d(128, 17, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/06 01:46:10 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(720, 720), max_size=2048, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[07/06 01:46:10 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[07/06 01:46:10 d2.data.common]: \u001b[0mSerializing 10470 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[07/06 01:46:10 d2.data.common]: \u001b[0mSerialized dataset takes 3.22 MiB\n",
      "Last checkpoint: model_final.pth\n",
      "\u001b[32m[07/06 01:46:10 d2.checkpoint.c2_model_loading]: \u001b[0mFollowing weights matched with model:\n",
      "| Names in Model                       | Names in Checkpoint                                                                                  | Shapes                                          |\n",
      "|:-------------------------------------|:-----------------------------------------------------------------------------------------------------|:------------------------------------------------|\n",
      "| backbone.bottom_up.res2.0.conv1.*    | backbone.bottom_up.res2.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,1,1)             |\n",
      "| backbone.bottom_up.res2.0.conv2.*    | backbone.bottom_up.res2.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |\n",
      "| backbone.bottom_up.res2.0.conv3.*    | backbone.bottom_up.res2.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res2.0.shortcut.* | backbone.bottom_up.res2.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res2.1.conv1.*    | backbone.bottom_up.res2.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |\n",
      "| backbone.bottom_up.res2.1.conv2.*    | backbone.bottom_up.res2.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |\n",
      "| backbone.bottom_up.res2.1.conv3.*    | backbone.bottom_up.res2.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res2.2.conv1.*    | backbone.bottom_up.res2.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |\n",
      "| backbone.bottom_up.res2.2.conv2.*    | backbone.bottom_up.res2.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |\n",
      "| backbone.bottom_up.res2.2.conv3.*    | backbone.bottom_up.res2.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res3.0.conv1.*    | backbone.bottom_up.res3.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,256,1,1)       |\n",
      "| backbone.bottom_up.res3.0.conv2.*    | backbone.bottom_up.res3.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.0.conv3.*    | backbone.bottom_up.res3.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res3.0.shortcut.* | backbone.bottom_up.res3.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (512,) (512,) (512,) (512,) (512,256,1,1)       |\n",
      "| backbone.bottom_up.res3.1.conv1.*    | backbone.bottom_up.res3.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |\n",
      "| backbone.bottom_up.res3.1.conv2.*    | backbone.bottom_up.res3.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.1.conv3.*    | backbone.bottom_up.res3.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res3.2.conv1.*    | backbone.bottom_up.res3.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |\n",
      "| backbone.bottom_up.res3.2.conv2.*    | backbone.bottom_up.res3.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.2.conv3.*    | backbone.bottom_up.res3.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res3.3.conv1.*    | backbone.bottom_up.res3.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |\n",
      "| backbone.bottom_up.res3.3.conv2.*    | backbone.bottom_up.res3.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.3.conv3.*    | backbone.bottom_up.res3.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res4.0.conv1.*    | backbone.bottom_up.res4.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,512,1,1)       |\n",
      "| backbone.bottom_up.res4.0.conv2.*    | backbone.bottom_up.res4.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.0.conv3.*    | backbone.bottom_up.res4.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.0.shortcut.* | backbone.bottom_up.res4.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (1024,) (1024,) (1024,) (1024,) (1024,512,1,1)  |\n",
      "| backbone.bottom_up.res4.1.conv1.*    | backbone.bottom_up.res4.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.1.conv2.*    | backbone.bottom_up.res4.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.1.conv3.*    | backbone.bottom_up.res4.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.2.conv1.*    | backbone.bottom_up.res4.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.2.conv2.*    | backbone.bottom_up.res4.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.2.conv3.*    | backbone.bottom_up.res4.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.3.conv1.*    | backbone.bottom_up.res4.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.3.conv2.*    | backbone.bottom_up.res4.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.3.conv3.*    | backbone.bottom_up.res4.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.4.conv1.*    | backbone.bottom_up.res4.4.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.4.conv2.*    | backbone.bottom_up.res4.4.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.4.conv3.*    | backbone.bottom_up.res4.4.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.5.conv1.*    | backbone.bottom_up.res4.5.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.5.conv2.*    | backbone.bottom_up.res4.5.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.5.conv3.*    | backbone.bottom_up.res4.5.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res5.0.conv1.*    | backbone.bottom_up.res5.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,1024,1,1)      |\n",
      "| backbone.bottom_up.res5.0.conv2.*    | backbone.bottom_up.res5.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |\n",
      "| backbone.bottom_up.res5.0.conv3.*    | backbone.bottom_up.res5.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
      "| backbone.bottom_up.res5.0.shortcut.* | backbone.bottom_up.res5.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (2048,) (2048,) (2048,) (2048,) (2048,1024,1,1) |\n",
      "| backbone.bottom_up.res5.1.conv1.*    | backbone.bottom_up.res5.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |\n",
      "| backbone.bottom_up.res5.1.conv2.*    | backbone.bottom_up.res5.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |\n",
      "| backbone.bottom_up.res5.1.conv3.*    | backbone.bottom_up.res5.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
      "| backbone.bottom_up.res5.2.conv1.*    | backbone.bottom_up.res5.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |\n",
      "| backbone.bottom_up.res5.2.conv2.*    | backbone.bottom_up.res5.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |\n",
      "| backbone.bottom_up.res5.2.conv3.*    | backbone.bottom_up.res5.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
      "| backbone.bottom_up.stem.conv1.*      | backbone.bottom_up.stem.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}      | (64,) (64,) (64,) (64,) (64,3,7,7)              |\n",
      "| backbone.fpn_lateral2.*              | backbone.fpn_lateral2.{bias,weight}                                                                  | (256,) (256,256,1,1)                            |\n",
      "| backbone.fpn_lateral3.*              | backbone.fpn_lateral3.{bias,weight}                                                                  | (256,) (256,512,1,1)                            |\n",
      "| backbone.fpn_lateral4.*              | backbone.fpn_lateral4.{bias,weight}                                                                  | (256,) (256,1024,1,1)                           |\n",
      "| backbone.fpn_lateral5.*              | backbone.fpn_lateral5.{bias,weight}                                                                  | (256,) (256,2048,1,1)                           |\n",
      "| backbone.fpn_output2.*               | backbone.fpn_output2.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| backbone.fpn_output3.*               | backbone.fpn_output3.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| backbone.fpn_output4.*               | backbone.fpn_output4.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| backbone.fpn_output5.*               | backbone.fpn_output5.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| sem_seg_head.p2.0.*                  | sem_seg_head.p2.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p3.0.*                  | sem_seg_head.p3.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p4.0.*                  | sem_seg_head.p4.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p4.2.*                  | sem_seg_head.p4.2.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,128,3,3)                     |\n",
      "| sem_seg_head.p5.0.*                  | sem_seg_head.p5.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p5.2.*                  | sem_seg_head.p5.2.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,128,3,3)                     |\n",
      "| sem_seg_head.p5.4.*                  | sem_seg_head.p5.4.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,128,3,3)                     |\n",
      "| sem_seg_head.predictor.*             | sem_seg_head.predictor.{bias,weight}                                                                 | (17,) (17,128,1,1)                              |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/06 01:46:11 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(720, 720), max_size=2048, sample_style='choice')]\n",
      "\u001b[32m[07/06 01:46:11 d2.data.common]: \u001b[0mSerializing 1788 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[07/06 01:46:11 d2.data.common]: \u001b[0mSerialized dataset takes 0.54 MiB\n",
      "\u001b[32m[07/06 01:46:11 d2.evaluation.evaluator]: \u001b[0mStart inference on 1788 batches\n",
      "\u001b[32m[07/06 01:46:13 d2.evaluation.evaluator]: \u001b[0mInference done 28/1788. Dataloading: 0.0019 s/iter. Inference: 0.0367 s/iter. Eval: 0.0429 s/iter. Total: 0.0816 s/iter. ETA=0:02:23\n",
      "\u001b[32m[07/06 01:46:18 d2.evaluation.evaluator]: \u001b[0mInference done 92/1788. Dataloading: 0.0020 s/iter. Inference: 0.0368 s/iter. Eval: 0.0404 s/iter. Total: 0.0793 s/iter. ETA=0:02:14\n",
      "\u001b[32m[07/06 01:46:23 d2.evaluation.evaluator]: \u001b[0mInference done 156/1788. Dataloading: 0.0020 s/iter. Inference: 0.0368 s/iter. Eval: 0.0401 s/iter. Total: 0.0790 s/iter. ETA=0:02:08\n",
      "\u001b[32m[07/06 01:46:28 d2.evaluation.evaluator]: \u001b[0mInference done 219/1788. Dataloading: 0.0020 s/iter. Inference: 0.0367 s/iter. Eval: 0.0403 s/iter. Total: 0.0792 s/iter. ETA=0:02:04\n",
      "\u001b[32m[07/06 01:46:33 d2.evaluation.evaluator]: \u001b[0mInference done 281/1788. Dataloading: 0.0021 s/iter. Inference: 0.0368 s/iter. Eval: 0.0406 s/iter. Total: 0.0796 s/iter. ETA=0:01:59\n",
      "\u001b[32m[07/06 01:46:38 d2.evaluation.evaluator]: \u001b[0mInference done 343/1788. Dataloading: 0.0021 s/iter. Inference: 0.0368 s/iter. Eval: 0.0409 s/iter. Total: 0.0799 s/iter. ETA=0:01:55\n",
      "\u001b[32m[07/06 01:46:43 d2.evaluation.evaluator]: \u001b[0mInference done 405/1788. Dataloading: 0.0021 s/iter. Inference: 0.0369 s/iter. Eval: 0.0411 s/iter. Total: 0.0801 s/iter. ETA=0:01:50\n",
      "\u001b[32m[07/06 01:46:48 d2.evaluation.evaluator]: \u001b[0mInference done 467/1788. Dataloading: 0.0021 s/iter. Inference: 0.0368 s/iter. Eval: 0.0412 s/iter. Total: 0.0802 s/iter. ETA=0:01:45\n",
      "\u001b[32m[07/06 01:46:53 d2.evaluation.evaluator]: \u001b[0mInference done 529/1788. Dataloading: 0.0021 s/iter. Inference: 0.0369 s/iter. Eval: 0.0413 s/iter. Total: 0.0803 s/iter. ETA=0:01:41\n",
      "\u001b[32m[07/06 01:46:58 d2.evaluation.evaluator]: \u001b[0mInference done 592/1788. Dataloading: 0.0021 s/iter. Inference: 0.0368 s/iter. Eval: 0.0413 s/iter. Total: 0.0803 s/iter. ETA=0:01:36\n",
      "\u001b[32m[07/06 01:47:03 d2.evaluation.evaluator]: \u001b[0mInference done 653/1788. Dataloading: 0.0021 s/iter. Inference: 0.0369 s/iter. Eval: 0.0415 s/iter. Total: 0.0805 s/iter. ETA=0:01:31\n",
      "\u001b[32m[07/06 01:47:09 d2.evaluation.evaluator]: \u001b[0mInference done 717/1788. Dataloading: 0.0021 s/iter. Inference: 0.0368 s/iter. Eval: 0.0414 s/iter. Total: 0.0804 s/iter. ETA=0:01:26\n",
      "\u001b[32m[07/06 01:47:14 d2.evaluation.evaluator]: \u001b[0mInference done 781/1788. Dataloading: 0.0021 s/iter. Inference: 0.0368 s/iter. Eval: 0.0413 s/iter. Total: 0.0803 s/iter. ETA=0:01:20\n",
      "\u001b[32m[07/06 01:47:19 d2.evaluation.evaluator]: \u001b[0mInference done 846/1788. Dataloading: 0.0021 s/iter. Inference: 0.0368 s/iter. Eval: 0.0411 s/iter. Total: 0.0801 s/iter. ETA=0:01:15\n",
      "\u001b[32m[07/06 01:47:24 d2.evaluation.evaluator]: \u001b[0mInference done 911/1788. Dataloading: 0.0021 s/iter. Inference: 0.0368 s/iter. Eval: 0.0409 s/iter. Total: 0.0799 s/iter. ETA=0:01:10\n",
      "\u001b[32m[07/06 01:47:29 d2.evaluation.evaluator]: \u001b[0mInference done 976/1788. Dataloading: 0.0020 s/iter. Inference: 0.0368 s/iter. Eval: 0.0407 s/iter. Total: 0.0797 s/iter. ETA=0:01:04\n",
      "\u001b[32m[07/06 01:47:34 d2.evaluation.evaluator]: \u001b[0mInference done 1042/1788. Dataloading: 0.0021 s/iter. Inference: 0.0368 s/iter. Eval: 0.0406 s/iter. Total: 0.0795 s/iter. ETA=0:00:59\n",
      "\u001b[32m[07/06 01:47:39 d2.evaluation.evaluator]: \u001b[0mInference done 1096/1788. Dataloading: 0.0020 s/iter. Inference: 0.0369 s/iter. Eval: 0.0412 s/iter. Total: 0.0802 s/iter. ETA=0:00:55\n",
      "\u001b[32m[07/06 01:47:44 d2.evaluation.evaluator]: \u001b[0mInference done 1122/1788. Dataloading: 0.0021 s/iter. Inference: 0.0371 s/iter. Eval: 0.0436 s/iter. Total: 0.0828 s/iter. ETA=0:00:55\n",
      "\u001b[32m[07/06 01:47:49 d2.evaluation.evaluator]: \u001b[0mInference done 1148/1788. Dataloading: 0.0021 s/iter. Inference: 0.0373 s/iter. Eval: 0.0459 s/iter. Total: 0.0854 s/iter. ETA=0:00:54\n",
      "\u001b[32m[07/06 01:47:54 d2.evaluation.evaluator]: \u001b[0mInference done 1175/1788. Dataloading: 0.0021 s/iter. Inference: 0.0375 s/iter. Eval: 0.0482 s/iter. Total: 0.0878 s/iter. ETA=0:00:53\n",
      "\u001b[32m[07/06 01:47:59 d2.evaluation.evaluator]: \u001b[0mInference done 1203/1788. Dataloading: 0.0021 s/iter. Inference: 0.0376 s/iter. Eval: 0.0503 s/iter. Total: 0.0900 s/iter. ETA=0:00:52\n",
      "\u001b[32m[07/06 01:48:04 d2.evaluation.evaluator]: \u001b[0mInference done 1232/1788. Dataloading: 0.0021 s/iter. Inference: 0.0377 s/iter. Eval: 0.0522 s/iter. Total: 0.0921 s/iter. ETA=0:00:51\n",
      "\u001b[32m[07/06 01:48:09 d2.evaluation.evaluator]: \u001b[0mInference done 1260/1788. Dataloading: 0.0021 s/iter. Inference: 0.0378 s/iter. Eval: 0.0541 s/iter. Total: 0.0941 s/iter. ETA=0:00:49\n",
      "\u001b[32m[07/06 01:48:14 d2.evaluation.evaluator]: \u001b[0mInference done 1287/1788. Dataloading: 0.0021 s/iter. Inference: 0.0380 s/iter. Eval: 0.0560 s/iter. Total: 0.0961 s/iter. ETA=0:00:48\n",
      "\u001b[32m[07/06 01:48:20 d2.evaluation.evaluator]: \u001b[0mInference done 1312/1788. Dataloading: 0.0022 s/iter. Inference: 0.0381 s/iter. Eval: 0.0577 s/iter. Total: 0.0981 s/iter. ETA=0:00:46\n",
      "\u001b[32m[07/06 01:48:25 d2.evaluation.evaluator]: \u001b[0mInference done 1338/1788. Dataloading: 0.0022 s/iter. Inference: 0.0382 s/iter. Eval: 0.0595 s/iter. Total: 0.1000 s/iter. ETA=0:00:44\n",
      "\u001b[32m[07/06 01:48:30 d2.evaluation.evaluator]: \u001b[0mInference done 1364/1788. Dataloading: 0.0022 s/iter. Inference: 0.0383 s/iter. Eval: 0.0612 s/iter. Total: 0.1018 s/iter. ETA=0:00:43\n",
      "\u001b[32m[07/06 01:48:35 d2.evaluation.evaluator]: \u001b[0mInference done 1391/1788. Dataloading: 0.0022 s/iter. Inference: 0.0384 s/iter. Eval: 0.0628 s/iter. Total: 0.1035 s/iter. ETA=0:00:41\n",
      "\u001b[32m[07/06 01:48:40 d2.evaluation.evaluator]: \u001b[0mInference done 1417/1788. Dataloading: 0.0022 s/iter. Inference: 0.0385 s/iter. Eval: 0.0644 s/iter. Total: 0.1052 s/iter. ETA=0:00:39\n",
      "\u001b[32m[07/06 01:48:45 d2.evaluation.evaluator]: \u001b[0mInference done 1443/1788. Dataloading: 0.0022 s/iter. Inference: 0.0386 s/iter. Eval: 0.0659 s/iter. Total: 0.1068 s/iter. ETA=0:00:36\n",
      "\u001b[32m[07/06 01:48:50 d2.evaluation.evaluator]: \u001b[0mInference done 1469/1788. Dataloading: 0.0022 s/iter. Inference: 0.0387 s/iter. Eval: 0.0674 s/iter. Total: 0.1084 s/iter. ETA=0:00:34\n",
      "\u001b[32m[07/06 01:48:55 d2.evaluation.evaluator]: \u001b[0mInference done 1495/1788. Dataloading: 0.0022 s/iter. Inference: 0.0388 s/iter. Eval: 0.0688 s/iter. Total: 0.1099 s/iter. ETA=0:00:32\n",
      "\u001b[32m[07/06 01:49:00 d2.evaluation.evaluator]: \u001b[0mInference done 1522/1788. Dataloading: 0.0022 s/iter. Inference: 0.0389 s/iter. Eval: 0.0702 s/iter. Total: 0.1114 s/iter. ETA=0:00:29\n",
      "\u001b[32m[07/06 01:49:05 d2.evaluation.evaluator]: \u001b[0mInference done 1549/1788. Dataloading: 0.0022 s/iter. Inference: 0.0390 s/iter. Eval: 0.0714 s/iter. Total: 0.1127 s/iter. ETA=0:00:26\n",
      "\u001b[32m[07/06 01:49:10 d2.evaluation.evaluator]: \u001b[0mInference done 1576/1788. Dataloading: 0.0022 s/iter. Inference: 0.0391 s/iter. Eval: 0.0727 s/iter. Total: 0.1141 s/iter. ETA=0:00:24\n",
      "\u001b[32m[07/06 01:49:16 d2.evaluation.evaluator]: \u001b[0mInference done 1603/1788. Dataloading: 0.0022 s/iter. Inference: 0.0392 s/iter. Eval: 0.0739 s/iter. Total: 0.1154 s/iter. ETA=0:00:21\n",
      "\u001b[32m[07/06 01:49:21 d2.evaluation.evaluator]: \u001b[0mInference done 1630/1788. Dataloading: 0.0022 s/iter. Inference: 0.0393 s/iter. Eval: 0.0750 s/iter. Total: 0.1166 s/iter. ETA=0:00:18\n",
      "\u001b[32m[07/06 01:49:26 d2.evaluation.evaluator]: \u001b[0mInference done 1656/1788. Dataloading: 0.0022 s/iter. Inference: 0.0394 s/iter. Eval: 0.0762 s/iter. Total: 0.1178 s/iter. ETA=0:00:15\n",
      "\u001b[32m[07/06 01:49:31 d2.evaluation.evaluator]: \u001b[0mInference done 1682/1788. Dataloading: 0.0022 s/iter. Inference: 0.0394 s/iter. Eval: 0.0773 s/iter. Total: 0.1190 s/iter. ETA=0:00:12\n",
      "\u001b[32m[07/06 01:49:36 d2.evaluation.evaluator]: \u001b[0mInference done 1708/1788. Dataloading: 0.0022 s/iter. Inference: 0.0395 s/iter. Eval: 0.0784 s/iter. Total: 0.1201 s/iter. ETA=0:00:09\n",
      "\u001b[32m[07/06 01:49:41 d2.evaluation.evaluator]: \u001b[0mInference done 1735/1788. Dataloading: 0.0022 s/iter. Inference: 0.0395 s/iter. Eval: 0.0794 s/iter. Total: 0.1212 s/iter. ETA=0:00:06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/06 01:49:46 d2.evaluation.evaluator]: \u001b[0mInference done 1762/1788. Dataloading: 0.0022 s/iter. Inference: 0.0396 s/iter. Eval: 0.0804 s/iter. Total: 0.1222 s/iter. ETA=0:00:03\n",
      "\u001b[32m[07/06 01:49:51 d2.evaluation.evaluator]: \u001b[0mInference done 1788/1788. Dataloading: 0.0022 s/iter. Inference: 0.0397 s/iter. Eval: 0.0814 s/iter. Total: 0.1233 s/iter. ETA=0:00:00\n",
      "\u001b[32m[07/06 01:49:51 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:03:39.953208 (0.123361 s / iter per device, on 1 devices)\n",
      "\u001b[32m[07/06 01:49:51 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:01:10 (0.039664 s / iter per device, on 1 devices)\n",
      "\u001b[32m[07/06 01:49:52 d2.evaluation.sem_seg_evaluation]: \u001b[0mOrderedDict([('sem_seg', {'mIoU': 71.31689084175994, 'fwIoU': 91.76156662378858, 'IoU-Unlabeled': nan, 'IoU-Building': 91.57833519727593, 'IoU-Fence': 49.99255167142559, 'IoU-Pedestrian': 77.75145973685973, 'IoU-Pole': 57.0295706008061, 'IoU-Road': 97.59723285476997, 'IoU-SideWalk': 82.1070664544052, 'IoU-Vegetation': 88.92481603512218, 'IoU-Vehicles': 89.67159035902603, 'IoU-Wall': 68.99875864592364, 'IoU-TrafficSign': 63.31109616916778, 'IoU-Sky': 96.3353623946222, 'IoU-TrafficLight': 61.81497353936507, 'IoU-Terrain': 65.06749561168473, 'IoU-ConstructionVehicle': 64.49968506366213, 'IoU-workzone_object': 73.30708101202389, 'IoU-Detour': 13.083178122018808, 'mACC': 80.14276231271798, 'pACC': 95.53010194175157, 'ACC-Unlabeled': nan, 'ACC-Building': 96.0826949613917, 'ACC-Fence': 65.56332379329052, 'ACC-Pedestrian': 87.36129904246643, 'ACC-Pole': 68.82773185995748, 'ACC-Road': 99.01019717729143, 'ACC-SideWalk': 88.60570381247574, 'ACC-Vegetation': 95.29865962680674, 'ACC-Vehicles': 93.69483624135428, 'ACC-Wall': 79.43961786686, 'ACC-TrafficSign': 72.97983384590184, 'ACC-Sky': 98.10904931628095, 'ACC-TrafficLight': 71.0483019578446, 'ACC-Terrain': 73.59512082234788, 'ACC-ConstructionVehicle': 94.22109815565713, 'ACC-workzone_object': 84.93004386593653, 'ACC-Detour': 13.516684657624257})])\n",
      "\u001b[32m[07/06 01:49:52 d2.engine.defaults]: \u001b[0mEvaluation results for combined_rain_val in csv format:\n",
      "\u001b[32m[07/06 01:49:52 d2.evaluation.testing]: \u001b[0mcopypaste: Task: sem_seg\n",
      "\u001b[32m[07/06 01:49:52 d2.evaluation.testing]: \u001b[0mcopypaste: mIoU,fwIoU,mACC,pACC\n",
      "\u001b[32m[07/06 01:49:52 d2.evaluation.testing]: \u001b[0mcopypaste: 71.3169,91.7616,80.1428,95.5301\n"
     ]
    }
   ],
   "source": [
    "trainer_day = Detectron2Trainer('combined_all_train', 'combined_rain_val', output_folder='./output_day_40k')\n",
    "trainer_day.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0ad75e09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/05 18:02:26 d2.engine.defaults]: \u001b[0mModel:\n",
      "SemanticSegmentor(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (sem_seg_head): SemSegFPNHead(\n",
      "    (p2): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "    )\n",
      "    (p3): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (1): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "    )\n",
      "    (p4): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (1): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      (2): Conv2d(\n",
      "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (3): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "    )\n",
      "    (p5): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (1): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      (2): Conv2d(\n",
      "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (3): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      (4): Conv2d(\n",
      "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (5): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "    )\n",
      "    (predictor): Conv2d(128, 17, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/05 18:02:26 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(720, 720), max_size=2048, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[07/05 18:02:26 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[07/05 18:02:26 d2.data.common]: \u001b[0mSerializing 22288 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[07/05 18:02:26 d2.data.common]: \u001b[0mSerialized dataset takes 6.80 MiB\n",
      "Last checkpoint: model_final.pth\n",
      "\u001b[32m[07/05 18:02:27 d2.checkpoint.c2_model_loading]: \u001b[0mFollowing weights matched with model:\n",
      "| Names in Model                       | Names in Checkpoint                                                                                  | Shapes                                          |\n",
      "|:-------------------------------------|:-----------------------------------------------------------------------------------------------------|:------------------------------------------------|\n",
      "| backbone.bottom_up.res2.0.conv1.*    | backbone.bottom_up.res2.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,1,1)             |\n",
      "| backbone.bottom_up.res2.0.conv2.*    | backbone.bottom_up.res2.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |\n",
      "| backbone.bottom_up.res2.0.conv3.*    | backbone.bottom_up.res2.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res2.0.shortcut.* | backbone.bottom_up.res2.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res2.1.conv1.*    | backbone.bottom_up.res2.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |\n",
      "| backbone.bottom_up.res2.1.conv2.*    | backbone.bottom_up.res2.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |\n",
      "| backbone.bottom_up.res2.1.conv3.*    | backbone.bottom_up.res2.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res2.2.conv1.*    | backbone.bottom_up.res2.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |\n",
      "| backbone.bottom_up.res2.2.conv2.*    | backbone.bottom_up.res2.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |\n",
      "| backbone.bottom_up.res2.2.conv3.*    | backbone.bottom_up.res2.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res3.0.conv1.*    | backbone.bottom_up.res3.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,256,1,1)       |\n",
      "| backbone.bottom_up.res3.0.conv2.*    | backbone.bottom_up.res3.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.0.conv3.*    | backbone.bottom_up.res3.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res3.0.shortcut.* | backbone.bottom_up.res3.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (512,) (512,) (512,) (512,) (512,256,1,1)       |\n",
      "| backbone.bottom_up.res3.1.conv1.*    | backbone.bottom_up.res3.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |\n",
      "| backbone.bottom_up.res3.1.conv2.*    | backbone.bottom_up.res3.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.1.conv3.*    | backbone.bottom_up.res3.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res3.2.conv1.*    | backbone.bottom_up.res3.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |\n",
      "| backbone.bottom_up.res3.2.conv2.*    | backbone.bottom_up.res3.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.2.conv3.*    | backbone.bottom_up.res3.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res3.3.conv1.*    | backbone.bottom_up.res3.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |\n",
      "| backbone.bottom_up.res3.3.conv2.*    | backbone.bottom_up.res3.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.3.conv3.*    | backbone.bottom_up.res3.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res4.0.conv1.*    | backbone.bottom_up.res4.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,512,1,1)       |\n",
      "| backbone.bottom_up.res4.0.conv2.*    | backbone.bottom_up.res4.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.0.conv3.*    | backbone.bottom_up.res4.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.0.shortcut.* | backbone.bottom_up.res4.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (1024,) (1024,) (1024,) (1024,) (1024,512,1,1)  |\n",
      "| backbone.bottom_up.res4.1.conv1.*    | backbone.bottom_up.res4.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.1.conv2.*    | backbone.bottom_up.res4.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.1.conv3.*    | backbone.bottom_up.res4.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.2.conv1.*    | backbone.bottom_up.res4.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.2.conv2.*    | backbone.bottom_up.res4.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.2.conv3.*    | backbone.bottom_up.res4.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.3.conv1.*    | backbone.bottom_up.res4.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.3.conv2.*    | backbone.bottom_up.res4.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.3.conv3.*    | backbone.bottom_up.res4.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.4.conv1.*    | backbone.bottom_up.res4.4.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.4.conv2.*    | backbone.bottom_up.res4.4.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.4.conv3.*    | backbone.bottom_up.res4.4.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.5.conv1.*    | backbone.bottom_up.res4.5.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.5.conv2.*    | backbone.bottom_up.res4.5.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.5.conv3.*    | backbone.bottom_up.res4.5.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res5.0.conv1.*    | backbone.bottom_up.res5.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,1024,1,1)      |\n",
      "| backbone.bottom_up.res5.0.conv2.*    | backbone.bottom_up.res5.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |\n",
      "| backbone.bottom_up.res5.0.conv3.*    | backbone.bottom_up.res5.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
      "| backbone.bottom_up.res5.0.shortcut.* | backbone.bottom_up.res5.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (2048,) (2048,) (2048,) (2048,) (2048,1024,1,1) |\n",
      "| backbone.bottom_up.res5.1.conv1.*    | backbone.bottom_up.res5.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |\n",
      "| backbone.bottom_up.res5.1.conv2.*    | backbone.bottom_up.res5.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |\n",
      "| backbone.bottom_up.res5.1.conv3.*    | backbone.bottom_up.res5.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
      "| backbone.bottom_up.res5.2.conv1.*    | backbone.bottom_up.res5.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |\n",
      "| backbone.bottom_up.res5.2.conv2.*    | backbone.bottom_up.res5.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |\n",
      "| backbone.bottom_up.res5.2.conv3.*    | backbone.bottom_up.res5.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
      "| backbone.bottom_up.stem.conv1.*      | backbone.bottom_up.stem.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}      | (64,) (64,) (64,) (64,) (64,3,7,7)              |\n",
      "| backbone.fpn_lateral2.*              | backbone.fpn_lateral2.{bias,weight}                                                                  | (256,) (256,256,1,1)                            |\n",
      "| backbone.fpn_lateral3.*              | backbone.fpn_lateral3.{bias,weight}                                                                  | (256,) (256,512,1,1)                            |\n",
      "| backbone.fpn_lateral4.*              | backbone.fpn_lateral4.{bias,weight}                                                                  | (256,) (256,1024,1,1)                           |\n",
      "| backbone.fpn_lateral5.*              | backbone.fpn_lateral5.{bias,weight}                                                                  | (256,) (256,2048,1,1)                           |\n",
      "| backbone.fpn_output2.*               | backbone.fpn_output2.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| backbone.fpn_output3.*               | backbone.fpn_output3.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| backbone.fpn_output4.*               | backbone.fpn_output4.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| backbone.fpn_output5.*               | backbone.fpn_output5.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| sem_seg_head.p2.0.*                  | sem_seg_head.p2.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p3.0.*                  | sem_seg_head.p3.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p4.0.*                  | sem_seg_head.p4.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p4.2.*                  | sem_seg_head.p4.2.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,128,3,3)                     |\n",
      "| sem_seg_head.p5.0.*                  | sem_seg_head.p5.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p5.2.*                  | sem_seg_head.p5.2.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,128,3,3)                     |\n",
      "| sem_seg_head.p5.4.*                  | sem_seg_head.p5.4.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,128,3,3)                     |\n",
      "| sem_seg_head.predictor.*             | sem_seg_head.predictor.{bias,weight}                                                                 | (17,) (17,128,1,1)                              |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/05 18:02:27 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(720, 720), max_size=2048, sample_style='choice')]\n",
      "\u001b[32m[07/05 18:02:27 d2.data.common]: \u001b[0mSerializing 7914 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[07/05 18:02:27 d2.data.common]: \u001b[0mSerialized dataset takes 2.41 MiB\n",
      "\u001b[32m[07/05 18:02:27 d2.evaluation.evaluator]: \u001b[0mStart inference on 7914 batches\n",
      "\u001b[32m[07/05 18:02:28 d2.evaluation.evaluator]: \u001b[0mInference done 11/7914. Dataloading: 0.0018 s/iter. Inference: 0.0348 s/iter. Eval: 0.0445 s/iter. Total: 0.0811 s/iter. ETA=0:10:40\n",
      "\u001b[32m[07/05 18:02:33 d2.evaluation.evaluator]: \u001b[0mInference done 74/7914. Dataloading: 0.0022 s/iter. Inference: 0.0351 s/iter. Eval: 0.0430 s/iter. Total: 0.0803 s/iter. ETA=0:10:29\n",
      "\u001b[32m[07/05 18:02:38 d2.evaluation.evaluator]: \u001b[0mInference done 139/7914. Dataloading: 0.0022 s/iter. Inference: 0.0351 s/iter. Eval: 0.0415 s/iter. Total: 0.0789 s/iter. ETA=0:10:13\n",
      "\u001b[32m[07/05 18:02:43 d2.evaluation.evaluator]: \u001b[0mInference done 206/7914. Dataloading: 0.0022 s/iter. Inference: 0.0352 s/iter. Eval: 0.0403 s/iter. Total: 0.0778 s/iter. ETA=0:09:59\n",
      "\u001b[32m[07/05 18:02:48 d2.evaluation.evaluator]: \u001b[0mInference done 273/7914. Dataloading: 0.0022 s/iter. Inference: 0.0352 s/iter. Eval: 0.0397 s/iter. Total: 0.0773 s/iter. ETA=0:09:50\n",
      "\u001b[32m[07/05 18:02:53 d2.evaluation.evaluator]: \u001b[0mInference done 339/7914. Dataloading: 0.0022 s/iter. Inference: 0.0352 s/iter. Eval: 0.0394 s/iter. Total: 0.0770 s/iter. ETA=0:09:43\n",
      "\u001b[32m[07/05 18:02:58 d2.evaluation.evaluator]: \u001b[0mInference done 406/7914. Dataloading: 0.0022 s/iter. Inference: 0.0353 s/iter. Eval: 0.0391 s/iter. Total: 0.0767 s/iter. ETA=0:09:35\n",
      "\u001b[32m[07/05 18:03:03 d2.evaluation.evaluator]: \u001b[0mInference done 472/7914. Dataloading: 0.0022 s/iter. Inference: 0.0353 s/iter. Eval: 0.0390 s/iter. Total: 0.0766 s/iter. ETA=0:09:29\n",
      "\u001b[32m[07/05 18:03:08 d2.evaluation.evaluator]: \u001b[0mInference done 539/7914. Dataloading: 0.0022 s/iter. Inference: 0.0353 s/iter. Eval: 0.0388 s/iter. Total: 0.0764 s/iter. ETA=0:09:23\n",
      "\u001b[32m[07/05 18:03:13 d2.evaluation.evaluator]: \u001b[0mInference done 605/7914. Dataloading: 0.0022 s/iter. Inference: 0.0353 s/iter. Eval: 0.0388 s/iter. Total: 0.0764 s/iter. ETA=0:09:18\n",
      "\u001b[32m[07/05 18:03:18 d2.evaluation.evaluator]: \u001b[0mInference done 673/7914. Dataloading: 0.0022 s/iter. Inference: 0.0353 s/iter. Eval: 0.0386 s/iter. Total: 0.0762 s/iter. ETA=0:09:11\n",
      "\u001b[32m[07/05 18:03:23 d2.evaluation.evaluator]: \u001b[0mInference done 740/7914. Dataloading: 0.0022 s/iter. Inference: 0.0353 s/iter. Eval: 0.0385 s/iter. Total: 0.0762 s/iter. ETA=0:09:06\n",
      "\u001b[32m[07/05 18:03:28 d2.evaluation.evaluator]: \u001b[0mInference done 806/7914. Dataloading: 0.0022 s/iter. Inference: 0.0354 s/iter. Eval: 0.0385 s/iter. Total: 0.0761 s/iter. ETA=0:09:01\n",
      "\u001b[32m[07/05 18:03:33 d2.evaluation.evaluator]: \u001b[0mInference done 872/7914. Dataloading: 0.0022 s/iter. Inference: 0.0354 s/iter. Eval: 0.0384 s/iter. Total: 0.0761 s/iter. ETA=0:08:56\n",
      "\u001b[32m[07/05 18:03:38 d2.evaluation.evaluator]: \u001b[0mInference done 938/7914. Dataloading: 0.0022 s/iter. Inference: 0.0354 s/iter. Eval: 0.0384 s/iter. Total: 0.0761 s/iter. ETA=0:08:51\n",
      "\u001b[32m[07/05 18:03:43 d2.evaluation.evaluator]: \u001b[0mInference done 1004/7914. Dataloading: 0.0022 s/iter. Inference: 0.0354 s/iter. Eval: 0.0384 s/iter. Total: 0.0761 s/iter. ETA=0:08:46\n",
      "\u001b[32m[07/05 18:03:49 d2.evaluation.evaluator]: \u001b[0mInference done 1071/7914. Dataloading: 0.0022 s/iter. Inference: 0.0354 s/iter. Eval: 0.0384 s/iter. Total: 0.0761 s/iter. ETA=0:08:40\n",
      "\u001b[32m[07/05 18:03:54 d2.evaluation.evaluator]: \u001b[0mInference done 1138/7914. Dataloading: 0.0023 s/iter. Inference: 0.0354 s/iter. Eval: 0.0383 s/iter. Total: 0.0761 s/iter. ETA=0:08:35\n",
      "\u001b[32m[07/05 18:03:59 d2.evaluation.evaluator]: \u001b[0mInference done 1204/7914. Dataloading: 0.0023 s/iter. Inference: 0.0354 s/iter. Eval: 0.0384 s/iter. Total: 0.0761 s/iter. ETA=0:08:30\n",
      "\u001b[32m[07/05 18:04:04 d2.evaluation.evaluator]: \u001b[0mInference done 1268/7914. Dataloading: 0.0023 s/iter. Inference: 0.0354 s/iter. Eval: 0.0385 s/iter. Total: 0.0762 s/iter. ETA=0:08:26\n",
      "\u001b[32m[07/05 18:04:09 d2.evaluation.evaluator]: \u001b[0mInference done 1334/7914. Dataloading: 0.0023 s/iter. Inference: 0.0354 s/iter. Eval: 0.0385 s/iter. Total: 0.0763 s/iter. ETA=0:08:21\n",
      "\u001b[32m[07/05 18:04:14 d2.evaluation.evaluator]: \u001b[0mInference done 1399/7914. Dataloading: 0.0023 s/iter. Inference: 0.0354 s/iter. Eval: 0.0386 s/iter. Total: 0.0763 s/iter. ETA=0:08:17\n",
      "\u001b[32m[07/05 18:04:19 d2.evaluation.evaluator]: \u001b[0mInference done 1463/7914. Dataloading: 0.0023 s/iter. Inference: 0.0354 s/iter. Eval: 0.0387 s/iter. Total: 0.0764 s/iter. ETA=0:08:13\n",
      "\u001b[32m[07/05 18:04:24 d2.evaluation.evaluator]: \u001b[0mInference done 1528/7914. Dataloading: 0.0023 s/iter. Inference: 0.0354 s/iter. Eval: 0.0387 s/iter. Total: 0.0765 s/iter. ETA=0:08:08\n",
      "\u001b[32m[07/05 18:04:29 d2.evaluation.evaluator]: \u001b[0mInference done 1593/7914. Dataloading: 0.0023 s/iter. Inference: 0.0354 s/iter. Eval: 0.0388 s/iter. Total: 0.0766 s/iter. ETA=0:08:03\n",
      "\u001b[32m[07/05 18:04:34 d2.evaluation.evaluator]: \u001b[0mInference done 1658/7914. Dataloading: 0.0023 s/iter. Inference: 0.0354 s/iter. Eval: 0.0388 s/iter. Total: 0.0766 s/iter. ETA=0:07:59\n",
      "\u001b[32m[07/05 18:04:39 d2.evaluation.evaluator]: \u001b[0mInference done 1723/7914. Dataloading: 0.0023 s/iter. Inference: 0.0354 s/iter. Eval: 0.0389 s/iter. Total: 0.0767 s/iter. ETA=0:07:54\n",
      "\u001b[32m[07/05 18:04:44 d2.evaluation.evaluator]: \u001b[0mInference done 1788/7914. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0389 s/iter. Total: 0.0767 s/iter. ETA=0:07:49\n",
      "\u001b[32m[07/05 18:04:49 d2.evaluation.evaluator]: \u001b[0mInference done 1851/7914. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0390 s/iter. Total: 0.0768 s/iter. ETA=0:07:45\n",
      "\u001b[32m[07/05 18:04:54 d2.evaluation.evaluator]: \u001b[0mInference done 1915/7914. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0391 s/iter. Total: 0.0769 s/iter. ETA=0:07:41\n",
      "\u001b[32m[07/05 18:04:59 d2.evaluation.evaluator]: \u001b[0mInference done 1979/7914. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0391 s/iter. Total: 0.0769 s/iter. ETA=0:07:36\n",
      "\u001b[32m[07/05 18:05:04 d2.evaluation.evaluator]: \u001b[0mInference done 2044/7914. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0392 s/iter. Total: 0.0770 s/iter. ETA=0:07:31\n",
      "\u001b[32m[07/05 18:05:09 d2.evaluation.evaluator]: \u001b[0mInference done 2108/7914. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0392 s/iter. Total: 0.0770 s/iter. ETA=0:07:27\n",
      "\u001b[32m[07/05 18:05:14 d2.evaluation.evaluator]: \u001b[0mInference done 2173/7914. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0392 s/iter. Total: 0.0770 s/iter. ETA=0:07:22\n",
      "\u001b[32m[07/05 18:05:19 d2.evaluation.evaluator]: \u001b[0mInference done 2237/7914. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0393 s/iter. Total: 0.0771 s/iter. ETA=0:07:17\n",
      "\u001b[32m[07/05 18:05:24 d2.evaluation.evaluator]: \u001b[0mInference done 2301/7914. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0393 s/iter. Total: 0.0771 s/iter. ETA=0:07:12\n",
      "\u001b[32m[07/05 18:05:30 d2.evaluation.evaluator]: \u001b[0mInference done 2366/7914. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0393 s/iter. Total: 0.0771 s/iter. ETA=0:07:07\n",
      "\u001b[32m[07/05 18:05:35 d2.evaluation.evaluator]: \u001b[0mInference done 2429/7914. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0394 s/iter. Total: 0.0772 s/iter. ETA=0:07:03\n",
      "\u001b[32m[07/05 18:05:40 d2.evaluation.evaluator]: \u001b[0mInference done 2493/7914. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0394 s/iter. Total: 0.0772 s/iter. ETA=0:06:58\n",
      "\u001b[32m[07/05 18:05:45 d2.evaluation.evaluator]: \u001b[0mInference done 2556/7914. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0395 s/iter. Total: 0.0773 s/iter. ETA=0:06:54\n",
      "\u001b[32m[07/05 18:05:50 d2.evaluation.evaluator]: \u001b[0mInference done 2619/7914. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0396 s/iter. Total: 0.0774 s/iter. ETA=0:06:49\n",
      "\u001b[32m[07/05 18:05:55 d2.evaluation.evaluator]: \u001b[0mInference done 2683/7914. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0396 s/iter. Total: 0.0774 s/iter. ETA=0:06:44\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/05 18:06:00 d2.evaluation.evaluator]: \u001b[0mInference done 2748/7914. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0396 s/iter. Total: 0.0774 s/iter. ETA=0:06:39\n",
      "\u001b[32m[07/05 18:06:05 d2.evaluation.evaluator]: \u001b[0mInference done 2815/7914. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0395 s/iter. Total: 0.0774 s/iter. ETA=0:06:34\n",
      "\u001b[32m[07/05 18:06:10 d2.evaluation.evaluator]: \u001b[0mInference done 2879/7914. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0396 s/iter. Total: 0.0774 s/iter. ETA=0:06:29\n",
      "\u001b[32m[07/05 18:06:15 d2.evaluation.evaluator]: \u001b[0mInference done 2944/7914. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0396 s/iter. Total: 0.0774 s/iter. ETA=0:06:24\n",
      "\u001b[32m[07/05 18:06:20 d2.evaluation.evaluator]: \u001b[0mInference done 3008/7914. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0396 s/iter. Total: 0.0774 s/iter. ETA=0:06:19\n",
      "\u001b[32m[07/05 18:06:25 d2.evaluation.evaluator]: \u001b[0mInference done 3072/7914. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0397 s/iter. Total: 0.0775 s/iter. ETA=0:06:15\n",
      "\u001b[32m[07/05 18:06:30 d2.evaluation.evaluator]: \u001b[0mInference done 3135/7914. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0397 s/iter. Total: 0.0775 s/iter. ETA=0:06:10\n",
      "\u001b[32m[07/05 18:06:35 d2.evaluation.evaluator]: \u001b[0mInference done 3203/7914. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0396 s/iter. Total: 0.0775 s/iter. ETA=0:06:04\n",
      "\u001b[32m[07/05 18:06:40 d2.evaluation.evaluator]: \u001b[0mInference done 3268/7914. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0396 s/iter. Total: 0.0775 s/iter. ETA=0:05:59\n",
      "\u001b[32m[07/05 18:06:45 d2.evaluation.evaluator]: \u001b[0mInference done 3331/7914. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0397 s/iter. Total: 0.0775 s/iter. ETA=0:05:55\n",
      "\u001b[32m[07/05 18:06:50 d2.evaluation.evaluator]: \u001b[0mInference done 3395/7914. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0397 s/iter. Total: 0.0775 s/iter. ETA=0:05:50\n",
      "\u001b[32m[07/05 18:06:55 d2.evaluation.evaluator]: \u001b[0mInference done 3460/7914. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0397 s/iter. Total: 0.0775 s/iter. ETA=0:05:45\n",
      "\u001b[32m[07/05 18:07:00 d2.evaluation.evaluator]: \u001b[0mInference done 3526/7914. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0397 s/iter. Total: 0.0775 s/iter. ETA=0:05:40\n",
      "\u001b[32m[07/05 18:07:05 d2.evaluation.evaluator]: \u001b[0mInference done 3590/7914. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0397 s/iter. Total: 0.0775 s/iter. ETA=0:05:35\n",
      "\u001b[32m[07/05 18:07:10 d2.evaluation.evaluator]: \u001b[0mInference done 3655/7914. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0397 s/iter. Total: 0.0775 s/iter. ETA=0:05:30\n",
      "\u001b[32m[07/05 18:07:15 d2.evaluation.evaluator]: \u001b[0mInference done 3716/7914. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0398 s/iter. Total: 0.0776 s/iter. ETA=0:05:25\n",
      "\u001b[32m[07/05 18:07:21 d2.evaluation.evaluator]: \u001b[0mInference done 3780/7914. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0398 s/iter. Total: 0.0776 s/iter. ETA=0:05:20\n",
      "\u001b[32m[07/05 18:07:26 d2.evaluation.evaluator]: \u001b[0mInference done 3844/7914. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0398 s/iter. Total: 0.0777 s/iter. ETA=0:05:16\n",
      "\u001b[32m[07/05 18:07:31 d2.evaluation.evaluator]: \u001b[0mInference done 3908/7914. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0398 s/iter. Total: 0.0777 s/iter. ETA=0:05:11\n",
      "\u001b[32m[07/05 18:07:36 d2.evaluation.evaluator]: \u001b[0mInference done 3973/7914. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0399 s/iter. Total: 0.0777 s/iter. ETA=0:05:06\n",
      "\u001b[32m[07/05 18:07:41 d2.evaluation.evaluator]: \u001b[0mInference done 4039/7914. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0398 s/iter. Total: 0.0777 s/iter. ETA=0:05:00\n",
      "\u001b[32m[07/05 18:07:46 d2.evaluation.evaluator]: \u001b[0mInference done 4105/7914. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0398 s/iter. Total: 0.0776 s/iter. ETA=0:04:55\n",
      "\u001b[32m[07/05 18:07:51 d2.evaluation.evaluator]: \u001b[0mInference done 4171/7914. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0398 s/iter. Total: 0.0776 s/iter. ETA=0:04:50\n",
      "\u001b[32m[07/05 18:07:56 d2.evaluation.evaluator]: \u001b[0mInference done 4236/7914. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0398 s/iter. Total: 0.0776 s/iter. ETA=0:04:45\n",
      "\u001b[32m[07/05 18:08:01 d2.evaluation.evaluator]: \u001b[0mInference done 4302/7914. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0398 s/iter. Total: 0.0776 s/iter. ETA=0:04:40\n",
      "\u001b[32m[07/05 18:08:06 d2.evaluation.evaluator]: \u001b[0mInference done 4369/7914. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0397 s/iter. Total: 0.0776 s/iter. ETA=0:04:34\n",
      "\u001b[32m[07/05 18:08:11 d2.evaluation.evaluator]: \u001b[0mInference done 4435/7914. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0397 s/iter. Total: 0.0775 s/iter. ETA=0:04:29\n",
      "\u001b[32m[07/05 18:08:16 d2.evaluation.evaluator]: \u001b[0mInference done 4502/7914. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0397 s/iter. Total: 0.0775 s/iter. ETA=0:04:24\n",
      "\u001b[32m[07/05 18:08:21 d2.evaluation.evaluator]: \u001b[0mInference done 4568/7914. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0397 s/iter. Total: 0.0775 s/iter. ETA=0:04:19\n",
      "\u001b[32m[07/05 18:08:26 d2.evaluation.evaluator]: \u001b[0mInference done 4635/7914. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0396 s/iter. Total: 0.0775 s/iter. ETA=0:04:14\n",
      "\u001b[32m[07/05 18:08:31 d2.evaluation.evaluator]: \u001b[0mInference done 4701/7914. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0396 s/iter. Total: 0.0775 s/iter. ETA=0:04:08\n",
      "\u001b[32m[07/05 18:08:36 d2.evaluation.evaluator]: \u001b[0mInference done 4767/7914. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0396 s/iter. Total: 0.0774 s/iter. ETA=0:04:03\n",
      "\u001b[32m[07/05 18:08:41 d2.evaluation.evaluator]: \u001b[0mInference done 4834/7914. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0396 s/iter. Total: 0.0774 s/iter. ETA=0:03:58\n",
      "\u001b[32m[07/05 18:08:46 d2.evaluation.evaluator]: \u001b[0mInference done 4901/7914. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0396 s/iter. Total: 0.0774 s/iter. ETA=0:03:53\n",
      "\u001b[32m[07/05 18:08:51 d2.evaluation.evaluator]: \u001b[0mInference done 4967/7914. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0395 s/iter. Total: 0.0774 s/iter. ETA=0:03:48\n",
      "\u001b[32m[07/05 18:08:56 d2.evaluation.evaluator]: \u001b[0mInference done 5034/7914. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0395 s/iter. Total: 0.0773 s/iter. ETA=0:03:42\n",
      "\u001b[32m[07/05 18:09:01 d2.evaluation.evaluator]: \u001b[0mInference done 5101/7914. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0395 s/iter. Total: 0.0773 s/iter. ETA=0:03:37\n",
      "\u001b[32m[07/05 18:09:06 d2.evaluation.evaluator]: \u001b[0mInference done 5167/7914. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0395 s/iter. Total: 0.0773 s/iter. ETA=0:03:32\n",
      "\u001b[32m[07/05 18:09:12 d2.evaluation.evaluator]: \u001b[0mInference done 5233/7914. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0395 s/iter. Total: 0.0773 s/iter. ETA=0:03:27\n",
      "\u001b[32m[07/05 18:09:17 d2.evaluation.evaluator]: \u001b[0mInference done 5299/7914. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0394 s/iter. Total: 0.0773 s/iter. ETA=0:03:22\n",
      "\u001b[32m[07/05 18:09:22 d2.evaluation.evaluator]: \u001b[0mInference done 5366/7914. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0394 s/iter. Total: 0.0773 s/iter. ETA=0:03:16\n",
      "\u001b[32m[07/05 18:09:27 d2.evaluation.evaluator]: \u001b[0mInference done 5432/7914. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0394 s/iter. Total: 0.0772 s/iter. ETA=0:03:11\n",
      "\u001b[32m[07/05 18:09:32 d2.evaluation.evaluator]: \u001b[0mInference done 5497/7914. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0394 s/iter. Total: 0.0772 s/iter. ETA=0:03:06\n",
      "\u001b[32m[07/05 18:09:37 d2.evaluation.evaluator]: \u001b[0mInference done 5562/7914. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0394 s/iter. Total: 0.0772 s/iter. ETA=0:03:01\n",
      "\u001b[32m[07/05 18:09:42 d2.evaluation.evaluator]: \u001b[0mInference done 5628/7914. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0394 s/iter. Total: 0.0772 s/iter. ETA=0:02:56\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/05 18:09:47 d2.evaluation.evaluator]: \u001b[0mInference done 5694/7914. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0394 s/iter. Total: 0.0772 s/iter. ETA=0:02:51\n",
      "\u001b[32m[07/05 18:09:52 d2.evaluation.evaluator]: \u001b[0mInference done 5760/7914. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0394 s/iter. Total: 0.0772 s/iter. ETA=0:02:46\n",
      "\u001b[32m[07/05 18:09:57 d2.evaluation.evaluator]: \u001b[0mInference done 5827/7914. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0394 s/iter. Total: 0.0772 s/iter. ETA=0:02:41\n",
      "\u001b[32m[07/05 18:10:02 d2.evaluation.evaluator]: \u001b[0mInference done 5893/7914. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0393 s/iter. Total: 0.0772 s/iter. ETA=0:02:35\n",
      "\u001b[32m[07/05 18:10:07 d2.evaluation.evaluator]: \u001b[0mInference done 5959/7914. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0393 s/iter. Total: 0.0772 s/iter. ETA=0:02:30\n",
      "\u001b[32m[07/05 18:10:12 d2.evaluation.evaluator]: \u001b[0mInference done 6026/7914. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0393 s/iter. Total: 0.0771 s/iter. ETA=0:02:25\n",
      "\u001b[32m[07/05 18:10:17 d2.evaluation.evaluator]: \u001b[0mInference done 6093/7914. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0393 s/iter. Total: 0.0771 s/iter. ETA=0:02:20\n",
      "\u001b[32m[07/05 18:10:22 d2.evaluation.evaluator]: \u001b[0mInference done 6158/7914. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0393 s/iter. Total: 0.0771 s/iter. ETA=0:02:15\n",
      "\u001b[32m[07/05 18:10:27 d2.evaluation.evaluator]: \u001b[0mInference done 6224/7914. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0393 s/iter. Total: 0.0771 s/iter. ETA=0:02:10\n",
      "\u001b[32m[07/05 18:10:32 d2.evaluation.evaluator]: \u001b[0mInference done 6291/7914. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0392 s/iter. Total: 0.0771 s/iter. ETA=0:02:05\n",
      "\u001b[32m[07/05 18:10:37 d2.evaluation.evaluator]: \u001b[0mInference done 6358/7914. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0392 s/iter. Total: 0.0771 s/iter. ETA=0:01:59\n",
      "\u001b[32m[07/05 18:10:42 d2.evaluation.evaluator]: \u001b[0mInference done 6425/7914. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0392 s/iter. Total: 0.0771 s/iter. ETA=0:01:54\n",
      "\u001b[32m[07/05 18:10:47 d2.evaluation.evaluator]: \u001b[0mInference done 6491/7914. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0392 s/iter. Total: 0.0771 s/iter. ETA=0:01:49\n",
      "\u001b[32m[07/05 18:10:52 d2.evaluation.evaluator]: \u001b[0mInference done 6533/7914. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0395 s/iter. Total: 0.0773 s/iter. ETA=0:01:46\n",
      "\u001b[32m[07/05 18:10:57 d2.evaluation.evaluator]: \u001b[0mInference done 6560/7914. Dataloading: 0.0023 s/iter. Inference: 0.0356 s/iter. Eval: 0.0399 s/iter. Total: 0.0778 s/iter. ETA=0:01:45\n",
      "\u001b[32m[07/05 18:11:03 d2.evaluation.evaluator]: \u001b[0mInference done 6587/7914. Dataloading: 0.0023 s/iter. Inference: 0.0356 s/iter. Eval: 0.0403 s/iter. Total: 0.0783 s/iter. ETA=0:01:43\n",
      "\u001b[32m[07/05 18:11:08 d2.evaluation.evaluator]: \u001b[0mInference done 6614/7914. Dataloading: 0.0023 s/iter. Inference: 0.0357 s/iter. Eval: 0.0407 s/iter. Total: 0.0787 s/iter. ETA=0:01:42\n",
      "\u001b[32m[07/05 18:11:13 d2.evaluation.evaluator]: \u001b[0mInference done 6641/7914. Dataloading: 0.0023 s/iter. Inference: 0.0357 s/iter. Eval: 0.0411 s/iter. Total: 0.0791 s/iter. ETA=0:01:40\n",
      "\u001b[32m[07/05 18:11:18 d2.evaluation.evaluator]: \u001b[0mInference done 6667/7914. Dataloading: 0.0023 s/iter. Inference: 0.0358 s/iter. Eval: 0.0415 s/iter. Total: 0.0796 s/iter. ETA=0:01:39\n",
      "\u001b[32m[07/05 18:11:23 d2.evaluation.evaluator]: \u001b[0mInference done 6694/7914. Dataloading: 0.0023 s/iter. Inference: 0.0358 s/iter. Eval: 0.0419 s/iter. Total: 0.0800 s/iter. ETA=0:01:37\n",
      "\u001b[32m[07/05 18:11:28 d2.evaluation.evaluator]: \u001b[0mInference done 6721/7914. Dataloading: 0.0023 s/iter. Inference: 0.0358 s/iter. Eval: 0.0423 s/iter. Total: 0.0805 s/iter. ETA=0:01:35\n",
      "\u001b[32m[07/05 18:11:33 d2.evaluation.evaluator]: \u001b[0mInference done 6748/7914. Dataloading: 0.0023 s/iter. Inference: 0.0359 s/iter. Eval: 0.0427 s/iter. Total: 0.0809 s/iter. ETA=0:01:34\n",
      "\u001b[32m[07/05 18:11:38 d2.evaluation.evaluator]: \u001b[0mInference done 6776/7914. Dataloading: 0.0023 s/iter. Inference: 0.0359 s/iter. Eval: 0.0430 s/iter. Total: 0.0813 s/iter. ETA=0:01:32\n",
      "\u001b[32m[07/05 18:11:43 d2.evaluation.evaluator]: \u001b[0mInference done 6803/7914. Dataloading: 0.0023 s/iter. Inference: 0.0360 s/iter. Eval: 0.0434 s/iter. Total: 0.0817 s/iter. ETA=0:01:30\n",
      "\u001b[32m[07/05 18:11:48 d2.evaluation.evaluator]: \u001b[0mInference done 6831/7914. Dataloading: 0.0023 s/iter. Inference: 0.0360 s/iter. Eval: 0.0438 s/iter. Total: 0.0821 s/iter. ETA=0:01:28\n",
      "\u001b[32m[07/05 18:11:53 d2.evaluation.evaluator]: \u001b[0mInference done 6857/7914. Dataloading: 0.0023 s/iter. Inference: 0.0361 s/iter. Eval: 0.0441 s/iter. Total: 0.0825 s/iter. ETA=0:01:27\n",
      "\u001b[32m[07/05 18:11:58 d2.evaluation.evaluator]: \u001b[0mInference done 6883/7914. Dataloading: 0.0023 s/iter. Inference: 0.0361 s/iter. Eval: 0.0445 s/iter. Total: 0.0830 s/iter. ETA=0:01:25\n",
      "\u001b[32m[07/05 18:12:03 d2.evaluation.evaluator]: \u001b[0mInference done 6909/7914. Dataloading: 0.0023 s/iter. Inference: 0.0361 s/iter. Eval: 0.0449 s/iter. Total: 0.0834 s/iter. ETA=0:01:23\n",
      "\u001b[32m[07/05 18:12:08 d2.evaluation.evaluator]: \u001b[0mInference done 6935/7914. Dataloading: 0.0023 s/iter. Inference: 0.0362 s/iter. Eval: 0.0453 s/iter. Total: 0.0838 s/iter. ETA=0:01:22\n",
      "\u001b[32m[07/05 18:12:13 d2.evaluation.evaluator]: \u001b[0mInference done 6960/7914. Dataloading: 0.0023 s/iter. Inference: 0.0362 s/iter. Eval: 0.0457 s/iter. Total: 0.0843 s/iter. ETA=0:01:20\n",
      "\u001b[32m[07/05 18:12:19 d2.evaluation.evaluator]: \u001b[0mInference done 6986/7914. Dataloading: 0.0023 s/iter. Inference: 0.0363 s/iter. Eval: 0.0461 s/iter. Total: 0.0847 s/iter. ETA=0:01:18\n",
      "\u001b[32m[07/05 18:12:24 d2.evaluation.evaluator]: \u001b[0mInference done 7013/7914. Dataloading: 0.0023 s/iter. Inference: 0.0363 s/iter. Eval: 0.0464 s/iter. Total: 0.0851 s/iter. ETA=0:01:16\n",
      "\u001b[32m[07/05 18:12:29 d2.evaluation.evaluator]: \u001b[0mInference done 7039/7914. Dataloading: 0.0023 s/iter. Inference: 0.0363 s/iter. Eval: 0.0468 s/iter. Total: 0.0855 s/iter. ETA=0:01:14\n",
      "\u001b[32m[07/05 18:12:34 d2.evaluation.evaluator]: \u001b[0mInference done 7066/7914. Dataloading: 0.0023 s/iter. Inference: 0.0364 s/iter. Eval: 0.0472 s/iter. Total: 0.0859 s/iter. ETA=0:01:12\n",
      "\u001b[32m[07/05 18:12:39 d2.evaluation.evaluator]: \u001b[0mInference done 7093/7914. Dataloading: 0.0023 s/iter. Inference: 0.0364 s/iter. Eval: 0.0475 s/iter. Total: 0.0863 s/iter. ETA=0:01:10\n",
      "\u001b[32m[07/05 18:12:44 d2.evaluation.evaluator]: \u001b[0mInference done 7119/7914. Dataloading: 0.0023 s/iter. Inference: 0.0365 s/iter. Eval: 0.0479 s/iter. Total: 0.0867 s/iter. ETA=0:01:08\n",
      "\u001b[32m[07/05 18:12:49 d2.evaluation.evaluator]: \u001b[0mInference done 7145/7914. Dataloading: 0.0023 s/iter. Inference: 0.0365 s/iter. Eval: 0.0483 s/iter. Total: 0.0871 s/iter. ETA=0:01:06\n",
      "\u001b[32m[07/05 18:12:54 d2.evaluation.evaluator]: \u001b[0mInference done 7171/7914. Dataloading: 0.0023 s/iter. Inference: 0.0365 s/iter. Eval: 0.0486 s/iter. Total: 0.0875 s/iter. ETA=0:01:04\n",
      "\u001b[32m[07/05 18:12:59 d2.evaluation.evaluator]: \u001b[0mInference done 7197/7914. Dataloading: 0.0023 s/iter. Inference: 0.0366 s/iter. Eval: 0.0490 s/iter. Total: 0.0879 s/iter. ETA=0:01:02\n",
      "\u001b[32m[07/05 18:13:04 d2.evaluation.evaluator]: \u001b[0mInference done 7224/7914. Dataloading: 0.0023 s/iter. Inference: 0.0366 s/iter. Eval: 0.0493 s/iter. Total: 0.0882 s/iter. ETA=0:01:00\n",
      "\u001b[32m[07/05 18:13:09 d2.evaluation.evaluator]: \u001b[0mInference done 7249/7914. Dataloading: 0.0023 s/iter. Inference: 0.0366 s/iter. Eval: 0.0496 s/iter. Total: 0.0886 s/iter. ETA=0:00:58\n",
      "\u001b[32m[07/05 18:13:15 d2.evaluation.evaluator]: \u001b[0mInference done 7275/7914. Dataloading: 0.0023 s/iter. Inference: 0.0367 s/iter. Eval: 0.0500 s/iter. Total: 0.0890 s/iter. ETA=0:00:56\n",
      "\u001b[32m[07/05 18:13:20 d2.evaluation.evaluator]: \u001b[0mInference done 7301/7914. Dataloading: 0.0023 s/iter. Inference: 0.0367 s/iter. Eval: 0.0503 s/iter. Total: 0.0894 s/iter. ETA=0:00:54\n",
      "\u001b[32m[07/05 18:13:25 d2.evaluation.evaluator]: \u001b[0mInference done 7327/7914. Dataloading: 0.0023 s/iter. Inference: 0.0367 s/iter. Eval: 0.0507 s/iter. Total: 0.0898 s/iter. ETA=0:00:52\n",
      "\u001b[32m[07/05 18:13:30 d2.evaluation.evaluator]: \u001b[0mInference done 7354/7914. Dataloading: 0.0023 s/iter. Inference: 0.0368 s/iter. Eval: 0.0510 s/iter. Total: 0.0901 s/iter. ETA=0:00:50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/05 18:13:35 d2.evaluation.evaluator]: \u001b[0mInference done 7381/7914. Dataloading: 0.0023 s/iter. Inference: 0.0368 s/iter. Eval: 0.0513 s/iter. Total: 0.0905 s/iter. ETA=0:00:48\n",
      "\u001b[32m[07/05 18:13:40 d2.evaluation.evaluator]: \u001b[0mInference done 7407/7914. Dataloading: 0.0023 s/iter. Inference: 0.0369 s/iter. Eval: 0.0517 s/iter. Total: 0.0909 s/iter. ETA=0:00:46\n",
      "\u001b[32m[07/05 18:13:45 d2.evaluation.evaluator]: \u001b[0mInference done 7434/7914. Dataloading: 0.0023 s/iter. Inference: 0.0369 s/iter. Eval: 0.0520 s/iter. Total: 0.0912 s/iter. ETA=0:00:43\n",
      "\u001b[32m[07/05 18:13:50 d2.evaluation.evaluator]: \u001b[0mInference done 7462/7914. Dataloading: 0.0023 s/iter. Inference: 0.0369 s/iter. Eval: 0.0523 s/iter. Total: 0.0916 s/iter. ETA=0:00:41\n",
      "\u001b[32m[07/05 18:13:55 d2.evaluation.evaluator]: \u001b[0mInference done 7488/7914. Dataloading: 0.0023 s/iter. Inference: 0.0370 s/iter. Eval: 0.0526 s/iter. Total: 0.0919 s/iter. ETA=0:00:39\n",
      "\u001b[32m[07/05 18:14:00 d2.evaluation.evaluator]: \u001b[0mInference done 7514/7914. Dataloading: 0.0023 s/iter. Inference: 0.0370 s/iter. Eval: 0.0529 s/iter. Total: 0.0923 s/iter. ETA=0:00:36\n",
      "\u001b[32m[07/05 18:14:06 d2.evaluation.evaluator]: \u001b[0mInference done 7540/7914. Dataloading: 0.0023 s/iter. Inference: 0.0370 s/iter. Eval: 0.0533 s/iter. Total: 0.0926 s/iter. ETA=0:00:34\n",
      "\u001b[32m[07/05 18:14:11 d2.evaluation.evaluator]: \u001b[0mInference done 7567/7914. Dataloading: 0.0023 s/iter. Inference: 0.0371 s/iter. Eval: 0.0536 s/iter. Total: 0.0930 s/iter. ETA=0:00:32\n",
      "\u001b[32m[07/05 18:14:16 d2.evaluation.evaluator]: \u001b[0mInference done 7594/7914. Dataloading: 0.0023 s/iter. Inference: 0.0371 s/iter. Eval: 0.0539 s/iter. Total: 0.0933 s/iter. ETA=0:00:29\n",
      "\u001b[32m[07/05 18:14:21 d2.evaluation.evaluator]: \u001b[0mInference done 7619/7914. Dataloading: 0.0023 s/iter. Inference: 0.0371 s/iter. Eval: 0.0542 s/iter. Total: 0.0937 s/iter. ETA=0:00:27\n",
      "\u001b[32m[07/05 18:14:26 d2.evaluation.evaluator]: \u001b[0mInference done 7645/7914. Dataloading: 0.0023 s/iter. Inference: 0.0372 s/iter. Eval: 0.0545 s/iter. Total: 0.0940 s/iter. ETA=0:00:25\n",
      "\u001b[32m[07/05 18:14:31 d2.evaluation.evaluator]: \u001b[0mInference done 7671/7914. Dataloading: 0.0023 s/iter. Inference: 0.0372 s/iter. Eval: 0.0548 s/iter. Total: 0.0944 s/iter. ETA=0:00:22\n",
      "\u001b[32m[07/05 18:14:36 d2.evaluation.evaluator]: \u001b[0mInference done 7697/7914. Dataloading: 0.0023 s/iter. Inference: 0.0372 s/iter. Eval: 0.0552 s/iter. Total: 0.0947 s/iter. ETA=0:00:20\n",
      "\u001b[32m[07/05 18:14:41 d2.evaluation.evaluator]: \u001b[0mInference done 7723/7914. Dataloading: 0.0023 s/iter. Inference: 0.0373 s/iter. Eval: 0.0555 s/iter. Total: 0.0951 s/iter. ETA=0:00:18\n",
      "\u001b[32m[07/05 18:14:46 d2.evaluation.evaluator]: \u001b[0mInference done 7749/7914. Dataloading: 0.0023 s/iter. Inference: 0.0373 s/iter. Eval: 0.0558 s/iter. Total: 0.0954 s/iter. ETA=0:00:15\n",
      "\u001b[32m[07/05 18:14:52 d2.evaluation.evaluator]: \u001b[0mInference done 7776/7914. Dataloading: 0.0023 s/iter. Inference: 0.0373 s/iter. Eval: 0.0561 s/iter. Total: 0.0958 s/iter. ETA=0:00:13\n",
      "\u001b[32m[07/05 18:14:57 d2.evaluation.evaluator]: \u001b[0mInference done 7803/7914. Dataloading: 0.0023 s/iter. Inference: 0.0374 s/iter. Eval: 0.0564 s/iter. Total: 0.0961 s/iter. ETA=0:00:10\n",
      "\u001b[32m[07/05 18:15:02 d2.evaluation.evaluator]: \u001b[0mInference done 7830/7914. Dataloading: 0.0023 s/iter. Inference: 0.0374 s/iter. Eval: 0.0567 s/iter. Total: 0.0964 s/iter. ETA=0:00:08\n",
      "\u001b[32m[07/05 18:15:07 d2.evaluation.evaluator]: \u001b[0mInference done 7857/7914. Dataloading: 0.0023 s/iter. Inference: 0.0374 s/iter. Eval: 0.0569 s/iter. Total: 0.0967 s/iter. ETA=0:00:05\n",
      "\u001b[32m[07/05 18:15:12 d2.evaluation.evaluator]: \u001b[0mInference done 7883/7914. Dataloading: 0.0023 s/iter. Inference: 0.0375 s/iter. Eval: 0.0572 s/iter. Total: 0.0970 s/iter. ETA=0:00:03\n",
      "\u001b[32m[07/05 18:15:17 d2.evaluation.evaluator]: \u001b[0mInference done 7908/7914. Dataloading: 0.0023 s/iter. Inference: 0.0375 s/iter. Eval: 0.0575 s/iter. Total: 0.0974 s/iter. ETA=0:00:00\n",
      "\u001b[32m[07/05 18:15:18 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:12:50.836179 (0.097463 s / iter per device, on 1 devices)\n",
      "\u001b[32m[07/05 18:15:18 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:04:56 (0.037496 s / iter per device, on 1 devices)\n",
      "\u001b[32m[07/05 18:15:20 d2.evaluation.sem_seg_evaluation]: \u001b[0mOrderedDict([('sem_seg', {'mIoU': 72.43304415052386, 'fwIoU': 92.52849231265388, 'IoU-Unlabeled': nan, 'IoU-Building': 91.90459570680758, 'IoU-Fence': 46.79569494838163, 'IoU-Pedestrian': 76.24525963940823, 'IoU-Pole': 58.70663750941727, 'IoU-Road': 98.22941083286521, 'IoU-SideWalk': 85.19446207890357, 'IoU-Vegetation': 86.86909488332823, 'IoU-Vehicles': 88.61590095596779, 'IoU-Wall': 77.83580968952141, 'IoU-TrafficSign': 60.723513804175255, 'IoU-Sky': 96.42183407619287, 'IoU-TrafficLight': 66.65270924900886, 'IoU-Terrain': 68.09993350403279, 'IoU-ConstructionVehicle': 66.10137975487578, 'IoU-workzone_object': 76.64384827134481, 'IoU-Detour': 13.888621504150223, 'mACC': 80.8067411540824, 'pACC': 95.95531918362096, 'ACC-Unlabeled': nan, 'ACC-Building': 96.40956850934708, 'ACC-Fence': 61.7709547820173, 'ACC-Pedestrian': 86.27786100964586, 'ACC-Pole': 69.32571881859263, 'ACC-Road': 99.22567198863564, 'ACC-SideWalk': 91.12339033779179, 'ACC-Vegetation': 94.49647359510611, 'ACC-Vehicles': 92.11292180313777, 'ACC-Wall': 87.19848751941598, 'ACC-TrafficSign': 70.28239482403826, 'ACC-Sky': 98.00665854637131, 'ACC-TrafficLight': 76.24043803826433, 'ACC-Terrain': 75.21980658454828, 'ACC-ConstructionVehicle': 94.61841629832345, 'ACC-workzone_object': 85.98901978814854, 'ACC-Detour': 14.610076021934198})])\n",
      "\u001b[32m[07/05 18:15:20 d2.engine.defaults]: \u001b[0mEvaluation results for combined_all_val in csv format:\n",
      "\u001b[32m[07/05 18:15:20 d2.evaluation.testing]: \u001b[0mcopypaste: Task: sem_seg\n",
      "\u001b[32m[07/05 18:15:20 d2.evaluation.testing]: \u001b[0mcopypaste: mIoU,fwIoU,mACC,pACC\n",
      "\u001b[32m[07/05 18:15:20 d2.evaluation.testing]: \u001b[0mcopypaste: 72.4330,92.5285,80.8067,95.9553\n"
     ]
    }
   ],
   "source": [
    "trainer_day = Detectron2Trainer('combined_all_train', 'combined_all_val', output_folder='./output_day_40k')\n",
    "trainer_day.test()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b97272",
   "metadata": {},
   "source": [
    "### 2. Night"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4e45353d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainer_night = Detectron2Trainer('carla_night_all_train', 'carla_night_clear_val', output_folder='./output_night_clear_40k')\n",
    "#trainer_night.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "12253421",
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainer_night = Detectron2Trainer('carla_night_all_train', 'carla_night_all_val', output_folder='./output_night_40k')\n",
    "#trainer_night.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1951860a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/05 18:15:20 d2.engine.defaults]: \u001b[0mModel:\n",
      "SemanticSegmentor(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (sem_seg_head): SemSegFPNHead(\n",
      "    (p2): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "    )\n",
      "    (p3): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (1): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "    )\n",
      "    (p4): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (1): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      (2): Conv2d(\n",
      "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (3): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "    )\n",
      "    (p5): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (1): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      (2): Conv2d(\n",
      "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (3): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      (4): Conv2d(\n",
      "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (5): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "    )\n",
      "    (predictor): Conv2d(128, 17, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/05 18:15:20 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(720, 720), max_size=2048, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[07/05 18:15:20 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[07/05 18:15:20 d2.data.common]: \u001b[0mSerializing 7723 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[07/05 18:15:20 d2.data.common]: \u001b[0mSerialized dataset takes 2.52 MiB\n",
      "Last checkpoint: model_final.pth\n",
      "\u001b[32m[07/05 18:15:21 d2.checkpoint.c2_model_loading]: \u001b[0mFollowing weights matched with model:\n",
      "| Names in Model                       | Names in Checkpoint                                                                                  | Shapes                                          |\n",
      "|:-------------------------------------|:-----------------------------------------------------------------------------------------------------|:------------------------------------------------|\n",
      "| backbone.bottom_up.res2.0.conv1.*    | backbone.bottom_up.res2.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,1,1)             |\n",
      "| backbone.bottom_up.res2.0.conv2.*    | backbone.bottom_up.res2.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |\n",
      "| backbone.bottom_up.res2.0.conv3.*    | backbone.bottom_up.res2.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res2.0.shortcut.* | backbone.bottom_up.res2.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res2.1.conv1.*    | backbone.bottom_up.res2.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |\n",
      "| backbone.bottom_up.res2.1.conv2.*    | backbone.bottom_up.res2.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |\n",
      "| backbone.bottom_up.res2.1.conv3.*    | backbone.bottom_up.res2.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res2.2.conv1.*    | backbone.bottom_up.res2.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |\n",
      "| backbone.bottom_up.res2.2.conv2.*    | backbone.bottom_up.res2.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |\n",
      "| backbone.bottom_up.res2.2.conv3.*    | backbone.bottom_up.res2.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res3.0.conv1.*    | backbone.bottom_up.res3.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,256,1,1)       |\n",
      "| backbone.bottom_up.res3.0.conv2.*    | backbone.bottom_up.res3.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.0.conv3.*    | backbone.bottom_up.res3.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res3.0.shortcut.* | backbone.bottom_up.res3.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (512,) (512,) (512,) (512,) (512,256,1,1)       |\n",
      "| backbone.bottom_up.res3.1.conv1.*    | backbone.bottom_up.res3.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |\n",
      "| backbone.bottom_up.res3.1.conv2.*    | backbone.bottom_up.res3.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.1.conv3.*    | backbone.bottom_up.res3.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res3.2.conv1.*    | backbone.bottom_up.res3.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |\n",
      "| backbone.bottom_up.res3.2.conv2.*    | backbone.bottom_up.res3.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.2.conv3.*    | backbone.bottom_up.res3.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res3.3.conv1.*    | backbone.bottom_up.res3.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |\n",
      "| backbone.bottom_up.res3.3.conv2.*    | backbone.bottom_up.res3.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.3.conv3.*    | backbone.bottom_up.res3.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res4.0.conv1.*    | backbone.bottom_up.res4.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,512,1,1)       |\n",
      "| backbone.bottom_up.res4.0.conv2.*    | backbone.bottom_up.res4.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.0.conv3.*    | backbone.bottom_up.res4.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.0.shortcut.* | backbone.bottom_up.res4.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (1024,) (1024,) (1024,) (1024,) (1024,512,1,1)  |\n",
      "| backbone.bottom_up.res4.1.conv1.*    | backbone.bottom_up.res4.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.1.conv2.*    | backbone.bottom_up.res4.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.1.conv3.*    | backbone.bottom_up.res4.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.2.conv1.*    | backbone.bottom_up.res4.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.2.conv2.*    | backbone.bottom_up.res4.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.2.conv3.*    | backbone.bottom_up.res4.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.3.conv1.*    | backbone.bottom_up.res4.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.3.conv2.*    | backbone.bottom_up.res4.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.3.conv3.*    | backbone.bottom_up.res4.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.4.conv1.*    | backbone.bottom_up.res4.4.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.4.conv2.*    | backbone.bottom_up.res4.4.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.4.conv3.*    | backbone.bottom_up.res4.4.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.5.conv1.*    | backbone.bottom_up.res4.5.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.5.conv2.*    | backbone.bottom_up.res4.5.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.5.conv3.*    | backbone.bottom_up.res4.5.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res5.0.conv1.*    | backbone.bottom_up.res5.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,1024,1,1)      |\n",
      "| backbone.bottom_up.res5.0.conv2.*    | backbone.bottom_up.res5.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |\n",
      "| backbone.bottom_up.res5.0.conv3.*    | backbone.bottom_up.res5.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
      "| backbone.bottom_up.res5.0.shortcut.* | backbone.bottom_up.res5.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (2048,) (2048,) (2048,) (2048,) (2048,1024,1,1) |\n",
      "| backbone.bottom_up.res5.1.conv1.*    | backbone.bottom_up.res5.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |\n",
      "| backbone.bottom_up.res5.1.conv2.*    | backbone.bottom_up.res5.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |\n",
      "| backbone.bottom_up.res5.1.conv3.*    | backbone.bottom_up.res5.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
      "| backbone.bottom_up.res5.2.conv1.*    | backbone.bottom_up.res5.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |\n",
      "| backbone.bottom_up.res5.2.conv2.*    | backbone.bottom_up.res5.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |\n",
      "| backbone.bottom_up.res5.2.conv3.*    | backbone.bottom_up.res5.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
      "| backbone.bottom_up.stem.conv1.*      | backbone.bottom_up.stem.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}      | (64,) (64,) (64,) (64,) (64,3,7,7)              |\n",
      "| backbone.fpn_lateral2.*              | backbone.fpn_lateral2.{bias,weight}                                                                  | (256,) (256,256,1,1)                            |\n",
      "| backbone.fpn_lateral3.*              | backbone.fpn_lateral3.{bias,weight}                                                                  | (256,) (256,512,1,1)                            |\n",
      "| backbone.fpn_lateral4.*              | backbone.fpn_lateral4.{bias,weight}                                                                  | (256,) (256,1024,1,1)                           |\n",
      "| backbone.fpn_lateral5.*              | backbone.fpn_lateral5.{bias,weight}                                                                  | (256,) (256,2048,1,1)                           |\n",
      "| backbone.fpn_output2.*               | backbone.fpn_output2.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| backbone.fpn_output3.*               | backbone.fpn_output3.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| backbone.fpn_output4.*               | backbone.fpn_output4.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| backbone.fpn_output5.*               | backbone.fpn_output5.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| sem_seg_head.p2.0.*                  | sem_seg_head.p2.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p3.0.*                  | sem_seg_head.p3.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p4.0.*                  | sem_seg_head.p4.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p4.2.*                  | sem_seg_head.p4.2.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,128,3,3)                     |\n",
      "| sem_seg_head.p5.0.*                  | sem_seg_head.p5.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p5.2.*                  | sem_seg_head.p5.2.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,128,3,3)                     |\n",
      "| sem_seg_head.p5.4.*                  | sem_seg_head.p5.4.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,128,3,3)                     |\n",
      "| sem_seg_head.predictor.*             | sem_seg_head.predictor.{bias,weight}                                                                 | (17,) (17,128,1,1)                              |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/05 18:15:21 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(720, 720), max_size=2048, sample_style='choice')]\n",
      "\u001b[32m[07/05 18:15:21 d2.data.common]: \u001b[0mSerializing 3273 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[07/05 18:15:21 d2.data.common]: \u001b[0mSerialized dataset takes 1.04 MiB\n",
      "\u001b[32m[07/05 18:15:21 d2.evaluation.evaluator]: \u001b[0mStart inference on 3273 batches\n",
      "\u001b[32m[07/05 18:15:22 d2.evaluation.evaluator]: \u001b[0mInference done 14/3273. Dataloading: 0.0021 s/iter. Inference: 0.0350 s/iter. Eval: 0.0455 s/iter. Total: 0.0827 s/iter. ETA=0:04:29\n",
      "\u001b[32m[07/05 18:15:27 d2.evaluation.evaluator]: \u001b[0mInference done 76/3273. Dataloading: 0.0023 s/iter. Inference: 0.0352 s/iter. Eval: 0.0435 s/iter. Total: 0.0810 s/iter. ETA=0:04:19\n",
      "\u001b[32m[07/05 18:15:32 d2.evaluation.evaluator]: \u001b[0mInference done 137/3273. Dataloading: 0.0023 s/iter. Inference: 0.0352 s/iter. Eval: 0.0444 s/iter. Total: 0.0819 s/iter. ETA=0:04:16\n",
      "\u001b[32m[07/05 18:15:37 d2.evaluation.evaluator]: \u001b[0mInference done 198/3273. Dataloading: 0.0023 s/iter. Inference: 0.0352 s/iter. Eval: 0.0445 s/iter. Total: 0.0821 s/iter. ETA=0:04:12\n",
      "\u001b[32m[07/05 18:15:42 d2.evaluation.evaluator]: \u001b[0mInference done 259/3273. Dataloading: 0.0023 s/iter. Inference: 0.0352 s/iter. Eval: 0.0445 s/iter. Total: 0.0821 s/iter. ETA=0:04:07\n",
      "\u001b[32m[07/05 18:15:47 d2.evaluation.evaluator]: \u001b[0mInference done 320/3273. Dataloading: 0.0023 s/iter. Inference: 0.0352 s/iter. Eval: 0.0445 s/iter. Total: 0.0821 s/iter. ETA=0:04:02\n",
      "\u001b[32m[07/05 18:15:52 d2.evaluation.evaluator]: \u001b[0mInference done 380/3273. Dataloading: 0.0023 s/iter. Inference: 0.0352 s/iter. Eval: 0.0448 s/iter. Total: 0.0824 s/iter. ETA=0:03:58\n",
      "\u001b[32m[07/05 18:15:57 d2.evaluation.evaluator]: \u001b[0mInference done 440/3273. Dataloading: 0.0023 s/iter. Inference: 0.0353 s/iter. Eval: 0.0450 s/iter. Total: 0.0826 s/iter. ETA=0:03:54\n",
      "\u001b[32m[07/05 18:16:02 d2.evaluation.evaluator]: \u001b[0mInference done 498/3273. Dataloading: 0.0023 s/iter. Inference: 0.0353 s/iter. Eval: 0.0454 s/iter. Total: 0.0831 s/iter. ETA=0:03:50\n",
      "\u001b[32m[07/05 18:16:07 d2.evaluation.evaluator]: \u001b[0mInference done 559/3273. Dataloading: 0.0023 s/iter. Inference: 0.0353 s/iter. Eval: 0.0454 s/iter. Total: 0.0830 s/iter. ETA=0:03:45\n",
      "\u001b[32m[07/05 18:16:12 d2.evaluation.evaluator]: \u001b[0mInference done 620/3273. Dataloading: 0.0023 s/iter. Inference: 0.0353 s/iter. Eval: 0.0453 s/iter. Total: 0.0830 s/iter. ETA=0:03:40\n",
      "\u001b[32m[07/05 18:16:17 d2.evaluation.evaluator]: \u001b[0mInference done 680/3273. Dataloading: 0.0023 s/iter. Inference: 0.0353 s/iter. Eval: 0.0454 s/iter. Total: 0.0831 s/iter. ETA=0:03:35\n",
      "\u001b[32m[07/05 18:16:22 d2.evaluation.evaluator]: \u001b[0mInference done 739/3273. Dataloading: 0.0023 s/iter. Inference: 0.0353 s/iter. Eval: 0.0457 s/iter. Total: 0.0833 s/iter. ETA=0:03:31\n",
      "\u001b[32m[07/05 18:16:27 d2.evaluation.evaluator]: \u001b[0mInference done 800/3273. Dataloading: 0.0023 s/iter. Inference: 0.0353 s/iter. Eval: 0.0456 s/iter. Total: 0.0833 s/iter. ETA=0:03:25\n",
      "\u001b[32m[07/05 18:16:33 d2.evaluation.evaluator]: \u001b[0mInference done 864/3273. Dataloading: 0.0023 s/iter. Inference: 0.0353 s/iter. Eval: 0.0452 s/iter. Total: 0.0829 s/iter. ETA=0:03:19\n",
      "\u001b[32m[07/05 18:16:38 d2.evaluation.evaluator]: \u001b[0mInference done 928/3273. Dataloading: 0.0023 s/iter. Inference: 0.0353 s/iter. Eval: 0.0449 s/iter. Total: 0.0826 s/iter. ETA=0:03:13\n",
      "\u001b[32m[07/05 18:16:43 d2.evaluation.evaluator]: \u001b[0mInference done 992/3273. Dataloading: 0.0023 s/iter. Inference: 0.0353 s/iter. Eval: 0.0446 s/iter. Total: 0.0823 s/iter. ETA=0:03:07\n",
      "\u001b[32m[07/05 18:16:48 d2.evaluation.evaluator]: \u001b[0mInference done 1056/3273. Dataloading: 0.0023 s/iter. Inference: 0.0353 s/iter. Eval: 0.0444 s/iter. Total: 0.0821 s/iter. ETA=0:03:02\n",
      "\u001b[32m[07/05 18:16:53 d2.evaluation.evaluator]: \u001b[0mInference done 1119/3273. Dataloading: 0.0023 s/iter. Inference: 0.0354 s/iter. Eval: 0.0443 s/iter. Total: 0.0820 s/iter. ETA=0:02:56\n",
      "\u001b[32m[07/05 18:16:58 d2.evaluation.evaluator]: \u001b[0mInference done 1184/3273. Dataloading: 0.0023 s/iter. Inference: 0.0354 s/iter. Eval: 0.0441 s/iter. Total: 0.0818 s/iter. ETA=0:02:50\n",
      "\u001b[32m[07/05 18:17:03 d2.evaluation.evaluator]: \u001b[0mInference done 1248/3273. Dataloading: 0.0023 s/iter. Inference: 0.0354 s/iter. Eval: 0.0439 s/iter. Total: 0.0816 s/iter. ETA=0:02:45\n",
      "\u001b[32m[07/05 18:17:08 d2.evaluation.evaluator]: \u001b[0mInference done 1312/3273. Dataloading: 0.0023 s/iter. Inference: 0.0354 s/iter. Eval: 0.0438 s/iter. Total: 0.0815 s/iter. ETA=0:02:39\n",
      "\u001b[32m[07/05 18:17:13 d2.evaluation.evaluator]: \u001b[0mInference done 1375/3273. Dataloading: 0.0023 s/iter. Inference: 0.0354 s/iter. Eval: 0.0437 s/iter. Total: 0.0815 s/iter. ETA=0:02:34\n",
      "\u001b[32m[07/05 18:17:18 d2.evaluation.evaluator]: \u001b[0mInference done 1439/3273. Dataloading: 0.0023 s/iter. Inference: 0.0354 s/iter. Eval: 0.0436 s/iter. Total: 0.0814 s/iter. ETA=0:02:29\n",
      "\u001b[32m[07/05 18:17:23 d2.evaluation.evaluator]: \u001b[0mInference done 1502/3273. Dataloading: 0.0023 s/iter. Inference: 0.0354 s/iter. Eval: 0.0435 s/iter. Total: 0.0813 s/iter. ETA=0:02:23\n",
      "\u001b[32m[07/05 18:17:28 d2.evaluation.evaluator]: \u001b[0mInference done 1564/3273. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0435 s/iter. Total: 0.0813 s/iter. ETA=0:02:18\n",
      "\u001b[32m[07/05 18:17:33 d2.evaluation.evaluator]: \u001b[0mInference done 1627/3273. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0434 s/iter. Total: 0.0813 s/iter. ETA=0:02:13\n",
      "\u001b[32m[07/05 18:17:38 d2.evaluation.evaluator]: \u001b[0mInference done 1691/3273. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0434 s/iter. Total: 0.0812 s/iter. ETA=0:02:08\n",
      "\u001b[32m[07/05 18:17:43 d2.evaluation.evaluator]: \u001b[0mInference done 1755/3273. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0433 s/iter. Total: 0.0811 s/iter. ETA=0:02:03\n",
      "\u001b[32m[07/05 18:17:48 d2.evaluation.evaluator]: \u001b[0mInference done 1819/3273. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0432 s/iter. Total: 0.0810 s/iter. ETA=0:01:57\n",
      "\u001b[32m[07/05 18:17:53 d2.evaluation.evaluator]: \u001b[0mInference done 1884/3273. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0431 s/iter. Total: 0.0809 s/iter. ETA=0:01:52\n",
      "\u001b[32m[07/05 18:17:58 d2.evaluation.evaluator]: \u001b[0mInference done 1949/3273. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0429 s/iter. Total: 0.0808 s/iter. ETA=0:01:46\n",
      "\u001b[32m[07/05 18:18:03 d2.evaluation.evaluator]: \u001b[0mInference done 2014/3273. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0429 s/iter. Total: 0.0807 s/iter. ETA=0:01:41\n",
      "\u001b[32m[07/05 18:18:09 d2.evaluation.evaluator]: \u001b[0mInference done 2079/3273. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0428 s/iter. Total: 0.0806 s/iter. ETA=0:01:36\n",
      "\u001b[32m[07/05 18:18:14 d2.evaluation.evaluator]: \u001b[0mInference done 2144/3273. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0427 s/iter. Total: 0.0805 s/iter. ETA=0:01:30\n",
      "\u001b[32m[07/05 18:18:19 d2.evaluation.evaluator]: \u001b[0mInference done 2209/3273. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0426 s/iter. Total: 0.0805 s/iter. ETA=0:01:25\n",
      "\u001b[32m[07/05 18:18:24 d2.evaluation.evaluator]: \u001b[0mInference done 2273/3273. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0425 s/iter. Total: 0.0804 s/iter. ETA=0:01:20\n",
      "\u001b[32m[07/05 18:18:29 d2.evaluation.evaluator]: \u001b[0mInference done 2337/3273. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0425 s/iter. Total: 0.0804 s/iter. ETA=0:01:15\n",
      "\u001b[32m[07/05 18:18:34 d2.evaluation.evaluator]: \u001b[0mInference done 2400/3273. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0425 s/iter. Total: 0.0804 s/iter. ETA=0:01:10\n",
      "\u001b[32m[07/05 18:18:39 d2.evaluation.evaluator]: \u001b[0mInference done 2461/3273. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0425 s/iter. Total: 0.0804 s/iter. ETA=0:01:05\n",
      "\u001b[32m[07/05 18:18:44 d2.evaluation.evaluator]: \u001b[0mInference done 2523/3273. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0425 s/iter. Total: 0.0804 s/iter. ETA=0:01:00\n",
      "\u001b[32m[07/05 18:18:49 d2.evaluation.evaluator]: \u001b[0mInference done 2586/3273. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0425 s/iter. Total: 0.0804 s/iter. ETA=0:00:55\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/05 18:18:54 d2.evaluation.evaluator]: \u001b[0mInference done 2648/3273. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0426 s/iter. Total: 0.0804 s/iter. ETA=0:00:50\n",
      "\u001b[32m[07/05 18:18:59 d2.evaluation.evaluator]: \u001b[0mInference done 2710/3273. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0426 s/iter. Total: 0.0805 s/iter. ETA=0:00:45\n",
      "\u001b[32m[07/05 18:19:04 d2.evaluation.evaluator]: \u001b[0mInference done 2772/3273. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0426 s/iter. Total: 0.0805 s/iter. ETA=0:00:40\n",
      "\u001b[32m[07/05 18:19:09 d2.evaluation.evaluator]: \u001b[0mInference done 2834/3273. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0426 s/iter. Total: 0.0805 s/iter. ETA=0:00:35\n",
      "\u001b[32m[07/05 18:19:14 d2.evaluation.evaluator]: \u001b[0mInference done 2895/3273. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0427 s/iter. Total: 0.0805 s/iter. ETA=0:00:30\n",
      "\u001b[32m[07/05 18:19:19 d2.evaluation.evaluator]: \u001b[0mInference done 2956/3273. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0427 s/iter. Total: 0.0806 s/iter. ETA=0:00:25\n",
      "\u001b[32m[07/05 18:19:24 d2.evaluation.evaluator]: \u001b[0mInference done 3017/3273. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0427 s/iter. Total: 0.0806 s/iter. ETA=0:00:20\n",
      "\u001b[32m[07/05 18:19:29 d2.evaluation.evaluator]: \u001b[0mInference done 3079/3273. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0427 s/iter. Total: 0.0806 s/iter. ETA=0:00:15\n",
      "\u001b[32m[07/05 18:19:34 d2.evaluation.evaluator]: \u001b[0mInference done 3140/3273. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0428 s/iter. Total: 0.0807 s/iter. ETA=0:00:10\n",
      "\u001b[32m[07/05 18:19:39 d2.evaluation.evaluator]: \u001b[0mInference done 3203/3273. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0428 s/iter. Total: 0.0807 s/iter. ETA=0:00:05\n",
      "\u001b[32m[07/05 18:19:44 d2.evaluation.evaluator]: \u001b[0mInference done 3266/3273. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0428 s/iter. Total: 0.0806 s/iter. ETA=0:00:00\n",
      "\u001b[32m[07/05 18:19:45 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:04:23.618531 (0.080667 s / iter per device, on 1 devices)\n",
      "\u001b[32m[07/05 18:19:45 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:01:56 (0.035541 s / iter per device, on 1 devices)\n",
      "\u001b[32m[07/05 18:19:46 d2.evaluation.sem_seg_evaluation]: \u001b[0mOrderedDict([('sem_seg', {'mIoU': 30.33838480332871, 'fwIoU': 64.27690314161804, 'IoU-Unlabeled': nan, 'IoU-Building': 41.529102286714995, 'IoU-Fence': 9.597897149210844, 'IoU-Pedestrian': 12.124291890726614, 'IoU-Pole': 34.84247405796961, 'IoU-Road': 88.92367581588125, 'IoU-SideWalk': 40.88859697483544, 'IoU-Vegetation': 36.76587457114645, 'IoU-Vehicles': 39.71596215651606, 'IoU-Wall': 6.578766100847694, 'IoU-TrafficSign': 28.557978878792973, 'IoU-Sky': 75.04021359235155, 'IoU-TrafficLight': 18.619451804657544, 'IoU-Terrain': 0.15599804891794627, 'IoU-ConstructionVehicle': 59.07309914559728, 'IoU-workzone_object': 10.020722169447017, 'IoU-Detour': 13.31843701297482, 'mACC': 53.35032371448555, 'pACC': 75.67358055314442, 'ACC-Unlabeled': nan, 'ACC-Building': 91.65319913406496, 'ACC-Fence': 15.524745551127204, 'ACC-Pedestrian': 65.5039968527292, 'ACC-Pole': 41.605264779125406, 'ACC-Road': 94.22307761962607, 'ACC-SideWalk': 55.790892820188795, 'ACC-Vegetation': 44.03692050905064, 'ACC-Vehicles': 80.83342044336858, 'ACC-Wall': 6.804041823856115, 'ACC-TrafficSign': 39.99537875648272, 'ACC-Sky': 80.40319611634804, 'ACC-TrafficLight': 20.87312560301422, 'ACC-Terrain': 0.1567082824592334, 'ACC-ConstructionVehicle': 93.46265996656982, 'ACC-workzone_object': 76.51803768490072, 'ACC-Detour': 46.22051348885703})])\n",
      "\u001b[32m[07/05 18:19:46 d2.engine.defaults]: \u001b[0mEvaluation results for carla_night_clear_val in csv format:\n",
      "\u001b[32m[07/05 18:19:46 d2.evaluation.testing]: \u001b[0mcopypaste: Task: sem_seg\n",
      "\u001b[32m[07/05 18:19:46 d2.evaluation.testing]: \u001b[0mcopypaste: mIoU,fwIoU,mACC,pACC\n",
      "\u001b[32m[07/05 18:19:46 d2.evaluation.testing]: \u001b[0mcopypaste: 30.3384,64.2769,53.3503,75.6736\n"
     ]
    }
   ],
   "source": [
    "trainer_day = Detectron2Trainer('carla_night_clear_train', 'carla_night_clear_val', output_folder='./output_night_clear_40k')\n",
    "trainer_day.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e51733d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainer_day = Detectron2Trainer('carla_night_clear_train', 'cityscapes_clear_val', output_folder='./output_night_clear_40k')\n",
    "#trainer_day.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "30827fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainer_day = Detectron2Trainer('carla_night_clear_train', 'combined_clear_val', output_folder='./output_night_clear_40k')\n",
    "#trainer_day.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4c1cd1de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/06 03:37:43 d2.engine.defaults]: \u001b[0mModel:\n",
      "SemanticSegmentor(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (sem_seg_head): SemSegFPNHead(\n",
      "    (p2): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "    )\n",
      "    (p3): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (1): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "    )\n",
      "    (p4): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (1): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      (2): Conv2d(\n",
      "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (3): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "    )\n",
      "    (p5): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (1): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      (2): Conv2d(\n",
      "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (3): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      (4): Conv2d(\n",
      "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (5): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "    )\n",
      "    (predictor): Conv2d(128, 17, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/06 03:37:43 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(720, 720), max_size=2048, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[07/06 03:37:43 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[07/06 03:37:43 d2.data.common]: \u001b[0mSerializing 1104 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[07/06 03:37:43 d2.data.common]: \u001b[0mSerialized dataset takes 0.41 MiB\n",
      "Last checkpoint: model_final.pth\n",
      "\u001b[32m[07/06 03:37:44 d2.checkpoint.c2_model_loading]: \u001b[0mFollowing weights matched with model:\n",
      "| Names in Model                       | Names in Checkpoint                                                                                  | Shapes                                          |\n",
      "|:-------------------------------------|:-----------------------------------------------------------------------------------------------------|:------------------------------------------------|\n",
      "| backbone.bottom_up.res2.0.conv1.*    | backbone.bottom_up.res2.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,1,1)             |\n",
      "| backbone.bottom_up.res2.0.conv2.*    | backbone.bottom_up.res2.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |\n",
      "| backbone.bottom_up.res2.0.conv3.*    | backbone.bottom_up.res2.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res2.0.shortcut.* | backbone.bottom_up.res2.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res2.1.conv1.*    | backbone.bottom_up.res2.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |\n",
      "| backbone.bottom_up.res2.1.conv2.*    | backbone.bottom_up.res2.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |\n",
      "| backbone.bottom_up.res2.1.conv3.*    | backbone.bottom_up.res2.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res2.2.conv1.*    | backbone.bottom_up.res2.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |\n",
      "| backbone.bottom_up.res2.2.conv2.*    | backbone.bottom_up.res2.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |\n",
      "| backbone.bottom_up.res2.2.conv3.*    | backbone.bottom_up.res2.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res3.0.conv1.*    | backbone.bottom_up.res3.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,256,1,1)       |\n",
      "| backbone.bottom_up.res3.0.conv2.*    | backbone.bottom_up.res3.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.0.conv3.*    | backbone.bottom_up.res3.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res3.0.shortcut.* | backbone.bottom_up.res3.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (512,) (512,) (512,) (512,) (512,256,1,1)       |\n",
      "| backbone.bottom_up.res3.1.conv1.*    | backbone.bottom_up.res3.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |\n",
      "| backbone.bottom_up.res3.1.conv2.*    | backbone.bottom_up.res3.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.1.conv3.*    | backbone.bottom_up.res3.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res3.2.conv1.*    | backbone.bottom_up.res3.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |\n",
      "| backbone.bottom_up.res3.2.conv2.*    | backbone.bottom_up.res3.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.2.conv3.*    | backbone.bottom_up.res3.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res3.3.conv1.*    | backbone.bottom_up.res3.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |\n",
      "| backbone.bottom_up.res3.3.conv2.*    | backbone.bottom_up.res3.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.3.conv3.*    | backbone.bottom_up.res3.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res4.0.conv1.*    | backbone.bottom_up.res4.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,512,1,1)       |\n",
      "| backbone.bottom_up.res4.0.conv2.*    | backbone.bottom_up.res4.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.0.conv3.*    | backbone.bottom_up.res4.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.0.shortcut.* | backbone.bottom_up.res4.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (1024,) (1024,) (1024,) (1024,) (1024,512,1,1)  |\n",
      "| backbone.bottom_up.res4.1.conv1.*    | backbone.bottom_up.res4.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.1.conv2.*    | backbone.bottom_up.res4.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.1.conv3.*    | backbone.bottom_up.res4.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.2.conv1.*    | backbone.bottom_up.res4.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.2.conv2.*    | backbone.bottom_up.res4.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.2.conv3.*    | backbone.bottom_up.res4.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.3.conv1.*    | backbone.bottom_up.res4.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.3.conv2.*    | backbone.bottom_up.res4.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.3.conv3.*    | backbone.bottom_up.res4.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.4.conv1.*    | backbone.bottom_up.res4.4.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.4.conv2.*    | backbone.bottom_up.res4.4.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.4.conv3.*    | backbone.bottom_up.res4.4.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.5.conv1.*    | backbone.bottom_up.res4.5.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.5.conv2.*    | backbone.bottom_up.res4.5.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.5.conv3.*    | backbone.bottom_up.res4.5.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res5.0.conv1.*    | backbone.bottom_up.res5.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,1024,1,1)      |\n",
      "| backbone.bottom_up.res5.0.conv2.*    | backbone.bottom_up.res5.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |\n",
      "| backbone.bottom_up.res5.0.conv3.*    | backbone.bottom_up.res5.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
      "| backbone.bottom_up.res5.0.shortcut.* | backbone.bottom_up.res5.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (2048,) (2048,) (2048,) (2048,) (2048,1024,1,1) |\n",
      "| backbone.bottom_up.res5.1.conv1.*    | backbone.bottom_up.res5.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |\n",
      "| backbone.bottom_up.res5.1.conv2.*    | backbone.bottom_up.res5.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |\n",
      "| backbone.bottom_up.res5.1.conv3.*    | backbone.bottom_up.res5.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
      "| backbone.bottom_up.res5.2.conv1.*    | backbone.bottom_up.res5.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |\n",
      "| backbone.bottom_up.res5.2.conv2.*    | backbone.bottom_up.res5.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |\n",
      "| backbone.bottom_up.res5.2.conv3.*    | backbone.bottom_up.res5.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
      "| backbone.bottom_up.stem.conv1.*      | backbone.bottom_up.stem.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}      | (64,) (64,) (64,) (64,) (64,3,7,7)              |\n",
      "| backbone.fpn_lateral2.*              | backbone.fpn_lateral2.{bias,weight}                                                                  | (256,) (256,256,1,1)                            |\n",
      "| backbone.fpn_lateral3.*              | backbone.fpn_lateral3.{bias,weight}                                                                  | (256,) (256,512,1,1)                            |\n",
      "| backbone.fpn_lateral4.*              | backbone.fpn_lateral4.{bias,weight}                                                                  | (256,) (256,1024,1,1)                           |\n",
      "| backbone.fpn_lateral5.*              | backbone.fpn_lateral5.{bias,weight}                                                                  | (256,) (256,2048,1,1)                           |\n",
      "| backbone.fpn_output2.*               | backbone.fpn_output2.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| backbone.fpn_output3.*               | backbone.fpn_output3.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| backbone.fpn_output4.*               | backbone.fpn_output4.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| backbone.fpn_output5.*               | backbone.fpn_output5.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| sem_seg_head.p2.0.*                  | sem_seg_head.p2.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p3.0.*                  | sem_seg_head.p3.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p4.0.*                  | sem_seg_head.p4.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p4.2.*                  | sem_seg_head.p4.2.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,128,3,3)                     |\n",
      "| sem_seg_head.p5.0.*                  | sem_seg_head.p5.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p5.2.*                  | sem_seg_head.p5.2.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,128,3,3)                     |\n",
      "| sem_seg_head.p5.4.*                  | sem_seg_head.p5.4.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,128,3,3)                     |\n",
      "| sem_seg_head.predictor.*             | sem_seg_head.predictor.{bias,weight}                                                                 | (17,) (17,128,1,1)                              |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/06 03:37:44 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(720, 720), max_size=2048, sample_style='choice')]\n",
      "\u001b[32m[07/06 03:37:44 d2.data.common]: \u001b[0mSerializing 1104 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[07/06 03:37:44 d2.data.common]: \u001b[0mSerialized dataset takes 0.41 MiB\n",
      "\u001b[32m[07/06 03:37:44 d2.evaluation.evaluator]: \u001b[0mStart inference on 1104 batches\n",
      "\u001b[32m[07/06 03:37:45 d2.evaluation.evaluator]: \u001b[0mInference done 11/1104. Dataloading: 0.0018 s/iter. Inference: 0.0373 s/iter. Eval: 0.0416 s/iter. Total: 0.0806 s/iter. ETA=0:01:28\n",
      "\u001b[32m[07/06 03:37:50 d2.evaluation.evaluator]: \u001b[0mInference done 76/1104. Dataloading: 0.0021 s/iter. Inference: 0.0351 s/iter. Eval: 0.0410 s/iter. Total: 0.0783 s/iter. ETA=0:01:20\n",
      "\u001b[32m[07/06 03:37:55 d2.evaluation.evaluator]: \u001b[0mInference done 140/1104. Dataloading: 0.0021 s/iter. Inference: 0.0350 s/iter. Eval: 0.0415 s/iter. Total: 0.0788 s/iter. ETA=0:01:15\n",
      "\u001b[32m[07/06 03:38:00 d2.evaluation.evaluator]: \u001b[0mInference done 203/1104. Dataloading: 0.0022 s/iter. Inference: 0.0350 s/iter. Eval: 0.0418 s/iter. Total: 0.0790 s/iter. ETA=0:01:11\n",
      "\u001b[32m[07/06 03:38:05 d2.evaluation.evaluator]: \u001b[0mInference done 267/1104. Dataloading: 0.0022 s/iter. Inference: 0.0351 s/iter. Eval: 0.0417 s/iter. Total: 0.0790 s/iter. ETA=0:01:06\n",
      "\u001b[32m[07/06 03:38:10 d2.evaluation.evaluator]: \u001b[0mInference done 333/1104. Dataloading: 0.0022 s/iter. Inference: 0.0351 s/iter. Eval: 0.0411 s/iter. Total: 0.0785 s/iter. ETA=0:01:00\n",
      "\u001b[32m[07/06 03:38:15 d2.evaluation.evaluator]: \u001b[0mInference done 399/1104. Dataloading: 0.0022 s/iter. Inference: 0.0351 s/iter. Eval: 0.0407 s/iter. Total: 0.0780 s/iter. ETA=0:00:55\n",
      "\u001b[32m[07/06 03:38:20 d2.evaluation.evaluator]: \u001b[0mInference done 465/1104. Dataloading: 0.0022 s/iter. Inference: 0.0351 s/iter. Eval: 0.0403 s/iter. Total: 0.0778 s/iter. ETA=0:00:49\n",
      "\u001b[32m[07/06 03:38:25 d2.evaluation.evaluator]: \u001b[0mInference done 532/1104. Dataloading: 0.0022 s/iter. Inference: 0.0352 s/iter. Eval: 0.0400 s/iter. Total: 0.0774 s/iter. ETA=0:00:44\n",
      "\u001b[32m[07/06 03:38:31 d2.evaluation.evaluator]: \u001b[0mInference done 599/1104. Dataloading: 0.0022 s/iter. Inference: 0.0352 s/iter. Eval: 0.0397 s/iter. Total: 0.0772 s/iter. ETA=0:00:38\n",
      "\u001b[32m[07/06 03:38:36 d2.evaluation.evaluator]: \u001b[0mInference done 666/1104. Dataloading: 0.0022 s/iter. Inference: 0.0352 s/iter. Eval: 0.0395 s/iter. Total: 0.0770 s/iter. ETA=0:00:33\n",
      "\u001b[32m[07/06 03:38:41 d2.evaluation.evaluator]: \u001b[0mInference done 733/1104. Dataloading: 0.0022 s/iter. Inference: 0.0352 s/iter. Eval: 0.0393 s/iter. Total: 0.0768 s/iter. ETA=0:00:28\n",
      "\u001b[32m[07/06 03:38:46 d2.evaluation.evaluator]: \u001b[0mInference done 799/1104. Dataloading: 0.0022 s/iter. Inference: 0.0353 s/iter. Eval: 0.0392 s/iter. Total: 0.0768 s/iter. ETA=0:00:23\n",
      "\u001b[32m[07/06 03:38:51 d2.evaluation.evaluator]: \u001b[0mInference done 866/1104. Dataloading: 0.0022 s/iter. Inference: 0.0353 s/iter. Eval: 0.0391 s/iter. Total: 0.0767 s/iter. ETA=0:00:18\n",
      "\u001b[32m[07/06 03:38:56 d2.evaluation.evaluator]: \u001b[0mInference done 933/1104. Dataloading: 0.0022 s/iter. Inference: 0.0353 s/iter. Eval: 0.0390 s/iter. Total: 0.0766 s/iter. ETA=0:00:13\n",
      "\u001b[32m[07/06 03:39:01 d2.evaluation.evaluator]: \u001b[0mInference done 999/1104. Dataloading: 0.0022 s/iter. Inference: 0.0353 s/iter. Eval: 0.0390 s/iter. Total: 0.0766 s/iter. ETA=0:00:08\n",
      "\u001b[32m[07/06 03:39:06 d2.evaluation.evaluator]: \u001b[0mInference done 1066/1104. Dataloading: 0.0022 s/iter. Inference: 0.0353 s/iter. Eval: 0.0389 s/iter. Total: 0.0765 s/iter. ETA=0:00:02\n",
      "\u001b[32m[07/06 03:39:09 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:01:24.127358 (0.076549 s / iter per device, on 1 devices)\n",
      "\u001b[32m[07/06 03:39:09 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:38 (0.035302 s / iter per device, on 1 devices)\n",
      "\u001b[32m[07/06 03:39:09 d2.evaluation.sem_seg_evaluation]: \u001b[0mOrderedDict([('sem_seg', {'mIoU': 21.142184358752502, 'fwIoU': 41.80770850987569, 'IoU-Unlabeled': nan, 'IoU-Building': 25.63257156735422, 'IoU-Fence': 0.331085645043709, 'IoU-Pedestrian': 2.951910999118633, 'IoU-Pole': 31.686238929485892, 'IoU-Road': 73.78798404415107, 'IoU-SideWalk': 29.93534157406294, 'IoU-Vegetation': 14.697270869605436, 'IoU-Vehicles': 13.691103269848421, 'IoU-Wall': 0.7057174362978537, 'IoU-TrafficSign': 24.31285666667502, 'IoU-Sky': 32.65366185468795, 'IoU-TrafficLight': 19.55532695743354, 'IoU-Terrain': 0.15716748007033585, 'IoU-ConstructionVehicle': 78.78284138825819, 'IoU-workzone_object': 10.475328906817479, 'IoU-Detour': 0.060726509881859334, 'mACC': 41.20367595665139, 'pACC': 53.94023460291428, 'ACC-Unlabeled': nan, 'ACC-Building': 93.10660154693483, 'ACC-Fence': 0.33912112441432946, 'ACC-Pedestrian': 57.90440863111169, 'ACC-Pole': 40.02808331383103, 'ACC-Road': 79.2411225102479, 'ACC-SideWalk': 50.126558147866675, 'ACC-Vegetation': 16.01850470454486, 'ACC-Vehicles': 76.6588459051529, 'ACC-Wall': 0.7230249204515634, 'ACC-TrafficSign': 34.135853730629016, 'ACC-Sky': 33.335551444892886, 'ACC-TrafficLight': 20.562200519404513, 'ACC-Terrain': 0.15828700773552987, 'ACC-ConstructionVehicle': 88.03026309286503, 'ACC-workzone_object': 68.7203732503888, 'ACC-Detour': 0.17001545595054096})])\n",
      "\u001b[32m[07/06 03:39:09 d2.engine.defaults]: \u001b[0mEvaluation results for carla_night_rain_val in csv format:\n",
      "\u001b[32m[07/06 03:39:09 d2.evaluation.testing]: \u001b[0mcopypaste: Task: sem_seg\n",
      "\u001b[32m[07/06 03:39:09 d2.evaluation.testing]: \u001b[0mcopypaste: mIoU,fwIoU,mACC,pACC\n",
      "\u001b[32m[07/06 03:39:09 d2.evaluation.testing]: \u001b[0mcopypaste: 21.1422,41.8077,41.2037,53.9402\n"
     ]
    }
   ],
   "source": [
    "trainer_day = Detectron2Trainer('carla_night_clear_train', 'carla_night_rain_val', output_folder='./output_night_clear_40k')\n",
    "trainer_day.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "807650e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainer_day = Detectron2Trainer('carla_night_clear_train', 'cityscapes_rain_val', output_folder='./output_night_clear_40k')\n",
    "#trainer_day.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3c3ca578",
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainer_day = Detectron2Trainer('carla_night_clear_train', 'combined_rain_val', output_folder='./output_night_clear_40k')\n",
    "#trainer_day.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "be68e0b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainer_day = Detectron2Trainer('carla_night_clear_train', 'combined_all_val', output_folder='./output_night_clear_40k')\n",
    "#trainer_day.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "97d8445f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/06 00:31:31 d2.engine.defaults]: \u001b[0mModel:\n",
      "SemanticSegmentor(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (sem_seg_head): SemSegFPNHead(\n",
      "    (p2): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "    )\n",
      "    (p3): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (1): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "    )\n",
      "    (p4): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (1): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      (2): Conv2d(\n",
      "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (3): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "    )\n",
      "    (p5): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (1): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      (2): Conv2d(\n",
      "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (3): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      (4): Conv2d(\n",
      "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (5): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "    )\n",
      "    (predictor): Conv2d(128, 17, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/06 00:31:31 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(720, 720), max_size=2048, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[07/06 00:31:31 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[07/06 00:31:31 d2.data.common]: \u001b[0mSerializing 5154 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[07/06 00:31:31 d2.data.common]: \u001b[0mSerialized dataset takes 1.68 MiB\n",
      "Last checkpoint: model_final.pth\n",
      "\u001b[32m[07/06 00:31:31 d2.checkpoint.c2_model_loading]: \u001b[0mFollowing weights matched with model:\n",
      "| Names in Model                       | Names in Checkpoint                                                                                  | Shapes                                          |\n",
      "|:-------------------------------------|:-----------------------------------------------------------------------------------------------------|:------------------------------------------------|\n",
      "| backbone.bottom_up.res2.0.conv1.*    | backbone.bottom_up.res2.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,1,1)             |\n",
      "| backbone.bottom_up.res2.0.conv2.*    | backbone.bottom_up.res2.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |\n",
      "| backbone.bottom_up.res2.0.conv3.*    | backbone.bottom_up.res2.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res2.0.shortcut.* | backbone.bottom_up.res2.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res2.1.conv1.*    | backbone.bottom_up.res2.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |\n",
      "| backbone.bottom_up.res2.1.conv2.*    | backbone.bottom_up.res2.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |\n",
      "| backbone.bottom_up.res2.1.conv3.*    | backbone.bottom_up.res2.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res2.2.conv1.*    | backbone.bottom_up.res2.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |\n",
      "| backbone.bottom_up.res2.2.conv2.*    | backbone.bottom_up.res2.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |\n",
      "| backbone.bottom_up.res2.2.conv3.*    | backbone.bottom_up.res2.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res3.0.conv1.*    | backbone.bottom_up.res3.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,256,1,1)       |\n",
      "| backbone.bottom_up.res3.0.conv2.*    | backbone.bottom_up.res3.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.0.conv3.*    | backbone.bottom_up.res3.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res3.0.shortcut.* | backbone.bottom_up.res3.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (512,) (512,) (512,) (512,) (512,256,1,1)       |\n",
      "| backbone.bottom_up.res3.1.conv1.*    | backbone.bottom_up.res3.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |\n",
      "| backbone.bottom_up.res3.1.conv2.*    | backbone.bottom_up.res3.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.1.conv3.*    | backbone.bottom_up.res3.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res3.2.conv1.*    | backbone.bottom_up.res3.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |\n",
      "| backbone.bottom_up.res3.2.conv2.*    | backbone.bottom_up.res3.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.2.conv3.*    | backbone.bottom_up.res3.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res3.3.conv1.*    | backbone.bottom_up.res3.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |\n",
      "| backbone.bottom_up.res3.3.conv2.*    | backbone.bottom_up.res3.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.3.conv3.*    | backbone.bottom_up.res3.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res4.0.conv1.*    | backbone.bottom_up.res4.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,512,1,1)       |\n",
      "| backbone.bottom_up.res4.0.conv2.*    | backbone.bottom_up.res4.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.0.conv3.*    | backbone.bottom_up.res4.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.0.shortcut.* | backbone.bottom_up.res4.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (1024,) (1024,) (1024,) (1024,) (1024,512,1,1)  |\n",
      "| backbone.bottom_up.res4.1.conv1.*    | backbone.bottom_up.res4.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.1.conv2.*    | backbone.bottom_up.res4.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.1.conv3.*    | backbone.bottom_up.res4.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.2.conv1.*    | backbone.bottom_up.res4.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.2.conv2.*    | backbone.bottom_up.res4.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.2.conv3.*    | backbone.bottom_up.res4.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.3.conv1.*    | backbone.bottom_up.res4.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.3.conv2.*    | backbone.bottom_up.res4.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.3.conv3.*    | backbone.bottom_up.res4.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.4.conv1.*    | backbone.bottom_up.res4.4.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.4.conv2.*    | backbone.bottom_up.res4.4.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.4.conv3.*    | backbone.bottom_up.res4.4.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.5.conv1.*    | backbone.bottom_up.res4.5.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.5.conv2.*    | backbone.bottom_up.res4.5.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.5.conv3.*    | backbone.bottom_up.res4.5.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res5.0.conv1.*    | backbone.bottom_up.res5.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,1024,1,1)      |\n",
      "| backbone.bottom_up.res5.0.conv2.*    | backbone.bottom_up.res5.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |\n",
      "| backbone.bottom_up.res5.0.conv3.*    | backbone.bottom_up.res5.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
      "| backbone.bottom_up.res5.0.shortcut.* | backbone.bottom_up.res5.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (2048,) (2048,) (2048,) (2048,) (2048,1024,1,1) |\n",
      "| backbone.bottom_up.res5.1.conv1.*    | backbone.bottom_up.res5.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |\n",
      "| backbone.bottom_up.res5.1.conv2.*    | backbone.bottom_up.res5.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |\n",
      "| backbone.bottom_up.res5.1.conv3.*    | backbone.bottom_up.res5.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
      "| backbone.bottom_up.res5.2.conv1.*    | backbone.bottom_up.res5.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |\n",
      "| backbone.bottom_up.res5.2.conv2.*    | backbone.bottom_up.res5.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |\n",
      "| backbone.bottom_up.res5.2.conv3.*    | backbone.bottom_up.res5.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
      "| backbone.bottom_up.stem.conv1.*      | backbone.bottom_up.stem.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}      | (64,) (64,) (64,) (64,) (64,3,7,7)              |\n",
      "| backbone.fpn_lateral2.*              | backbone.fpn_lateral2.{bias,weight}                                                                  | (256,) (256,256,1,1)                            |\n",
      "| backbone.fpn_lateral3.*              | backbone.fpn_lateral3.{bias,weight}                                                                  | (256,) (256,512,1,1)                            |\n",
      "| backbone.fpn_lateral4.*              | backbone.fpn_lateral4.{bias,weight}                                                                  | (256,) (256,1024,1,1)                           |\n",
      "| backbone.fpn_lateral5.*              | backbone.fpn_lateral5.{bias,weight}                                                                  | (256,) (256,2048,1,1)                           |\n",
      "| backbone.fpn_output2.*               | backbone.fpn_output2.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| backbone.fpn_output3.*               | backbone.fpn_output3.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| backbone.fpn_output4.*               | backbone.fpn_output4.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| backbone.fpn_output5.*               | backbone.fpn_output5.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| sem_seg_head.p2.0.*                  | sem_seg_head.p2.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p3.0.*                  | sem_seg_head.p3.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p4.0.*                  | sem_seg_head.p4.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p4.2.*                  | sem_seg_head.p4.2.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,128,3,3)                     |\n",
      "| sem_seg_head.p5.0.*                  | sem_seg_head.p5.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p5.2.*                  | sem_seg_head.p5.2.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,128,3,3)                     |\n",
      "| sem_seg_head.p5.4.*                  | sem_seg_head.p5.4.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,128,3,3)                     |\n",
      "| sem_seg_head.predictor.*             | sem_seg_head.predictor.{bias,weight}                                                                 | (17,) (17,128,1,1)                              |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/06 00:31:31 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(720, 720), max_size=2048, sample_style='choice')]\n",
      "\u001b[32m[07/06 00:31:31 d2.data.common]: \u001b[0mSerializing 1067 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[07/06 00:31:31 d2.data.common]: \u001b[0mSerialized dataset takes 0.34 MiB\n",
      "\u001b[32m[07/06 00:31:31 d2.evaluation.evaluator]: \u001b[0mStart inference on 1067 batches\n",
      "\u001b[32m[07/06 00:31:33 d2.evaluation.evaluator]: \u001b[0mInference done 11/1067. Dataloading: 0.0018 s/iter. Inference: 0.0356 s/iter. Eval: 0.0439 s/iter. Total: 0.0813 s/iter. ETA=0:01:25\n",
      "\u001b[32m[07/06 00:31:38 d2.evaluation.evaluator]: \u001b[0mInference done 74/1067. Dataloading: 0.0021 s/iter. Inference: 0.0353 s/iter. Eval: 0.0425 s/iter. Total: 0.0799 s/iter. ETA=0:01:19\n",
      "\u001b[32m[07/06 00:31:43 d2.evaluation.evaluator]: \u001b[0mInference done 138/1067. Dataloading: 0.0021 s/iter. Inference: 0.0353 s/iter. Eval: 0.0419 s/iter. Total: 0.0794 s/iter. ETA=0:01:13\n",
      "\u001b[32m[07/06 00:31:48 d2.evaluation.evaluator]: \u001b[0mInference done 201/1067. Dataloading: 0.0021 s/iter. Inference: 0.0353 s/iter. Eval: 0.0422 s/iter. Total: 0.0797 s/iter. ETA=0:01:08\n",
      "\u001b[32m[07/06 00:31:53 d2.evaluation.evaluator]: \u001b[0mInference done 265/1067. Dataloading: 0.0021 s/iter. Inference: 0.0353 s/iter. Eval: 0.0419 s/iter. Total: 0.0794 s/iter. ETA=0:01:03\n",
      "\u001b[32m[07/06 00:31:58 d2.evaluation.evaluator]: \u001b[0mInference done 331/1067. Dataloading: 0.0021 s/iter. Inference: 0.0353 s/iter. Eval: 0.0412 s/iter. Total: 0.0788 s/iter. ETA=0:00:57\n",
      "\u001b[32m[07/06 00:32:03 d2.evaluation.evaluator]: \u001b[0mInference done 396/1067. Dataloading: 0.0021 s/iter. Inference: 0.0354 s/iter. Eval: 0.0409 s/iter. Total: 0.0785 s/iter. ETA=0:00:52\n",
      "\u001b[32m[07/06 00:32:08 d2.evaluation.evaluator]: \u001b[0mInference done 461/1067. Dataloading: 0.0021 s/iter. Inference: 0.0354 s/iter. Eval: 0.0407 s/iter. Total: 0.0783 s/iter. ETA=0:00:47\n",
      "\u001b[32m[07/06 00:32:13 d2.evaluation.evaluator]: \u001b[0mInference done 529/1067. Dataloading: 0.0021 s/iter. Inference: 0.0354 s/iter. Eval: 0.0402 s/iter. Total: 0.0778 s/iter. ETA=0:00:41\n",
      "\u001b[32m[07/06 00:32:18 d2.evaluation.evaluator]: \u001b[0mInference done 597/1067. Dataloading: 0.0021 s/iter. Inference: 0.0354 s/iter. Eval: 0.0397 s/iter. Total: 0.0774 s/iter. ETA=0:00:36\n",
      "\u001b[32m[07/06 00:32:23 d2.evaluation.evaluator]: \u001b[0mInference done 665/1067. Dataloading: 0.0021 s/iter. Inference: 0.0354 s/iter. Eval: 0.0394 s/iter. Total: 0.0770 s/iter. ETA=0:00:30\n",
      "\u001b[32m[07/06 00:32:28 d2.evaluation.evaluator]: \u001b[0mInference done 731/1067. Dataloading: 0.0021 s/iter. Inference: 0.0354 s/iter. Eval: 0.0393 s/iter. Total: 0.0769 s/iter. ETA=0:00:25\n",
      "\u001b[32m[07/06 00:32:33 d2.evaluation.evaluator]: \u001b[0mInference done 797/1067. Dataloading: 0.0021 s/iter. Inference: 0.0354 s/iter. Eval: 0.0393 s/iter. Total: 0.0769 s/iter. ETA=0:00:20\n",
      "\u001b[32m[07/06 00:32:38 d2.evaluation.evaluator]: \u001b[0mInference done 862/1067. Dataloading: 0.0021 s/iter. Inference: 0.0354 s/iter. Eval: 0.0394 s/iter. Total: 0.0770 s/iter. ETA=0:00:15\n",
      "\u001b[32m[07/06 00:32:43 d2.evaluation.evaluator]: \u001b[0mInference done 927/1067. Dataloading: 0.0021 s/iter. Inference: 0.0354 s/iter. Eval: 0.0394 s/iter. Total: 0.0770 s/iter. ETA=0:00:10\n",
      "\u001b[32m[07/06 00:32:48 d2.evaluation.evaluator]: \u001b[0mInference done 991/1067. Dataloading: 0.0022 s/iter. Inference: 0.0354 s/iter. Eval: 0.0395 s/iter. Total: 0.0772 s/iter. ETA=0:00:05\n",
      "\u001b[32m[07/06 00:32:53 d2.evaluation.evaluator]: \u001b[0mInference done 1056/1067. Dataloading: 0.0022 s/iter. Inference: 0.0354 s/iter. Eval: 0.0395 s/iter. Total: 0.0772 s/iter. ETA=0:00:00\n",
      "\u001b[32m[07/06 00:32:54 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:01:22.043291 (0.077254 s / iter per device, on 1 devices)\n",
      "\u001b[32m[07/06 00:32:54 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:37 (0.035430 s / iter per device, on 1 devices)\n",
      "\u001b[32m[07/06 00:32:54 d2.evaluation.sem_seg_evaluation]: \u001b[0mOrderedDict([('sem_seg', {'mIoU': 33.83625186055617, 'fwIoU': 64.15301407988503, 'IoU-Unlabeled': nan, 'IoU-Building': 40.14208418400545, 'IoU-Fence': 9.508176755321918, 'IoU-Pedestrian': 16.393508467446154, 'IoU-Pole': 35.35830017384798, 'IoU-Road': 88.93203026805864, 'IoU-SideWalk': 44.401142392326875, 'IoU-Vegetation': 43.42712078316284, 'IoU-Vehicles': 48.65623441493063, 'IoU-Wall': 4.40028242757498, 'IoU-TrafficSign': 26.425675000356954, 'IoU-Sky': 72.7017278158777, 'IoU-TrafficLight': 21.05178833721594, 'IoU-Terrain': 0.028354102667625936, 'IoU-ConstructionVehicle': 66.29833052706137, 'IoU-workzone_object': 8.441029764671885, 'IoU-Detour': 15.214244354371742, 'mACC': 52.864176554944265, 'pACC': 75.4941458508591, 'ACC-Unlabeled': nan, 'ACC-Building': 93.15354488266205, 'ACC-Fence': 13.598828723954956, 'ACC-Pedestrian': 65.32064807678539, 'ACC-Pole': 42.59291957124282, 'ACC-Road': 94.24469086784852, 'ACC-SideWalk': 66.69859973921139, 'ACC-Vegetation': 52.68884683555919, 'ACC-Vehicles': 77.24283311512959, 'ACC-Wall': 4.507556631046479, 'ACC-TrafficSign': 44.86672888813469, 'ACC-Sky': 75.856641607979, 'ACC-TrafficLight': 23.281135623514317, 'ACC-Terrain': 0.028375906422268057, 'ACC-ConstructionVehicle': 90.65279630274661, 'ACC-workzone_object': 75.91299435028247, 'ACC-Detour': 25.179683756588407})])\n",
      "\u001b[32m[07/06 00:32:54 d2.engine.defaults]: \u001b[0mEvaluation results for carla_night_clear_val in csv format:\n",
      "\u001b[32m[07/06 00:32:54 d2.evaluation.testing]: \u001b[0mcopypaste: Task: sem_seg\n",
      "\u001b[32m[07/06 00:32:54 d2.evaluation.testing]: \u001b[0mcopypaste: mIoU,fwIoU,mACC,pACC\n",
      "\u001b[32m[07/06 00:32:54 d2.evaluation.testing]: \u001b[0mcopypaste: 33.8363,64.1530,52.8642,75.4941\n"
     ]
    }
   ],
   "source": [
    "trainer_day = Detectron2Trainer('carla_night_all_train', 'carla_night_clear_val', output_folder='./output_night_40k')\n",
    "trainer_day.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c8690500",
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainer_day = Detectron2Trainer('carla_night_all_train', 'cityscapes_clear_val', output_folder='./output_night_40k')\n",
    "#trainer_day.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e8d81e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainer_day = Detectron2Trainer('carla_night_all_train', 'combined_clear_val', output_folder='./output_night_40k')\n",
    "#trainer_day.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f02a5f5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/06 01:57:45 d2.engine.defaults]: \u001b[0mModel:\n",
      "SemanticSegmentor(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (sem_seg_head): SemSegFPNHead(\n",
      "    (p2): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "    )\n",
      "    (p3): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (1): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "    )\n",
      "    (p4): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (1): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      (2): Conv2d(\n",
      "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (3): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "    )\n",
      "    (p5): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (1): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      (2): Conv2d(\n",
      "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (3): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      (4): Conv2d(\n",
      "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (5): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "    )\n",
      "    (predictor): Conv2d(128, 17, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/06 01:57:45 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(720, 720), max_size=2048, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[07/06 01:57:45 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[07/06 01:57:45 d2.data.common]: \u001b[0mSerializing 5236 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[07/06 01:57:45 d2.data.common]: \u001b[0mSerialized dataset takes 1.71 MiB\n",
      "Last checkpoint: model_final.pth\n",
      "\u001b[32m[07/06 01:57:46 d2.checkpoint.c2_model_loading]: \u001b[0mFollowing weights matched with model:\n",
      "| Names in Model                       | Names in Checkpoint                                                                                  | Shapes                                          |\n",
      "|:-------------------------------------|:-----------------------------------------------------------------------------------------------------|:------------------------------------------------|\n",
      "| backbone.bottom_up.res2.0.conv1.*    | backbone.bottom_up.res2.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,1,1)             |\n",
      "| backbone.bottom_up.res2.0.conv2.*    | backbone.bottom_up.res2.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |\n",
      "| backbone.bottom_up.res2.0.conv3.*    | backbone.bottom_up.res2.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res2.0.shortcut.* | backbone.bottom_up.res2.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res2.1.conv1.*    | backbone.bottom_up.res2.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |\n",
      "| backbone.bottom_up.res2.1.conv2.*    | backbone.bottom_up.res2.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |\n",
      "| backbone.bottom_up.res2.1.conv3.*    | backbone.bottom_up.res2.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res2.2.conv1.*    | backbone.bottom_up.res2.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |\n",
      "| backbone.bottom_up.res2.2.conv2.*    | backbone.bottom_up.res2.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |\n",
      "| backbone.bottom_up.res2.2.conv3.*    | backbone.bottom_up.res2.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res3.0.conv1.*    | backbone.bottom_up.res3.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,256,1,1)       |\n",
      "| backbone.bottom_up.res3.0.conv2.*    | backbone.bottom_up.res3.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.0.conv3.*    | backbone.bottom_up.res3.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res3.0.shortcut.* | backbone.bottom_up.res3.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (512,) (512,) (512,) (512,) (512,256,1,1)       |\n",
      "| backbone.bottom_up.res3.1.conv1.*    | backbone.bottom_up.res3.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |\n",
      "| backbone.bottom_up.res3.1.conv2.*    | backbone.bottom_up.res3.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.1.conv3.*    | backbone.bottom_up.res3.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res3.2.conv1.*    | backbone.bottom_up.res3.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |\n",
      "| backbone.bottom_up.res3.2.conv2.*    | backbone.bottom_up.res3.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.2.conv3.*    | backbone.bottom_up.res3.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res3.3.conv1.*    | backbone.bottom_up.res3.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |\n",
      "| backbone.bottom_up.res3.3.conv2.*    | backbone.bottom_up.res3.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.3.conv3.*    | backbone.bottom_up.res3.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res4.0.conv1.*    | backbone.bottom_up.res4.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,512,1,1)       |\n",
      "| backbone.bottom_up.res4.0.conv2.*    | backbone.bottom_up.res4.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.0.conv3.*    | backbone.bottom_up.res4.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.0.shortcut.* | backbone.bottom_up.res4.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (1024,) (1024,) (1024,) (1024,) (1024,512,1,1)  |\n",
      "| backbone.bottom_up.res4.1.conv1.*    | backbone.bottom_up.res4.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.1.conv2.*    | backbone.bottom_up.res4.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.1.conv3.*    | backbone.bottom_up.res4.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.2.conv1.*    | backbone.bottom_up.res4.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.2.conv2.*    | backbone.bottom_up.res4.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.2.conv3.*    | backbone.bottom_up.res4.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.3.conv1.*    | backbone.bottom_up.res4.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.3.conv2.*    | backbone.bottom_up.res4.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.3.conv3.*    | backbone.bottom_up.res4.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.4.conv1.*    | backbone.bottom_up.res4.4.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.4.conv2.*    | backbone.bottom_up.res4.4.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.4.conv3.*    | backbone.bottom_up.res4.4.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.5.conv1.*    | backbone.bottom_up.res4.5.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.5.conv2.*    | backbone.bottom_up.res4.5.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.5.conv3.*    | backbone.bottom_up.res4.5.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res5.0.conv1.*    | backbone.bottom_up.res5.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,1024,1,1)      |\n",
      "| backbone.bottom_up.res5.0.conv2.*    | backbone.bottom_up.res5.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |\n",
      "| backbone.bottom_up.res5.0.conv3.*    | backbone.bottom_up.res5.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
      "| backbone.bottom_up.res5.0.shortcut.* | backbone.bottom_up.res5.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (2048,) (2048,) (2048,) (2048,) (2048,1024,1,1) |\n",
      "| backbone.bottom_up.res5.1.conv1.*    | backbone.bottom_up.res5.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |\n",
      "| backbone.bottom_up.res5.1.conv2.*    | backbone.bottom_up.res5.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |\n",
      "| backbone.bottom_up.res5.1.conv3.*    | backbone.bottom_up.res5.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
      "| backbone.bottom_up.res5.2.conv1.*    | backbone.bottom_up.res5.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |\n",
      "| backbone.bottom_up.res5.2.conv2.*    | backbone.bottom_up.res5.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |\n",
      "| backbone.bottom_up.res5.2.conv3.*    | backbone.bottom_up.res5.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
      "| backbone.bottom_up.stem.conv1.*      | backbone.bottom_up.stem.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}      | (64,) (64,) (64,) (64,) (64,3,7,7)              |\n",
      "| backbone.fpn_lateral2.*              | backbone.fpn_lateral2.{bias,weight}                                                                  | (256,) (256,256,1,1)                            |\n",
      "| backbone.fpn_lateral3.*              | backbone.fpn_lateral3.{bias,weight}                                                                  | (256,) (256,512,1,1)                            |\n",
      "| backbone.fpn_lateral4.*              | backbone.fpn_lateral4.{bias,weight}                                                                  | (256,) (256,1024,1,1)                           |\n",
      "| backbone.fpn_lateral5.*              | backbone.fpn_lateral5.{bias,weight}                                                                  | (256,) (256,2048,1,1)                           |\n",
      "| backbone.fpn_output2.*               | backbone.fpn_output2.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| backbone.fpn_output3.*               | backbone.fpn_output3.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| backbone.fpn_output4.*               | backbone.fpn_output4.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| backbone.fpn_output5.*               | backbone.fpn_output5.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| sem_seg_head.p2.0.*                  | sem_seg_head.p2.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p3.0.*                  | sem_seg_head.p3.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p4.0.*                  | sem_seg_head.p4.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p4.2.*                  | sem_seg_head.p4.2.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,128,3,3)                     |\n",
      "| sem_seg_head.p5.0.*                  | sem_seg_head.p5.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p5.2.*                  | sem_seg_head.p5.2.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,128,3,3)                     |\n",
      "| sem_seg_head.p5.4.*                  | sem_seg_head.p5.4.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,128,3,3)                     |\n",
      "| sem_seg_head.predictor.*             | sem_seg_head.predictor.{bias,weight}                                                                 | (17,) (17,128,1,1)                              |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/06 01:57:46 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(720, 720), max_size=2048, sample_style='choice')]\n",
      "\u001b[32m[07/06 01:57:46 d2.data.common]: \u001b[0mSerializing 1102 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[07/06 01:57:46 d2.data.common]: \u001b[0mSerialized dataset takes 0.35 MiB\n",
      "\u001b[32m[07/06 01:57:46 d2.evaluation.evaluator]: \u001b[0mStart inference on 1102 batches\n",
      "\u001b[32m[07/06 01:57:47 d2.evaluation.evaluator]: \u001b[0mInference done 11/1102. Dataloading: 0.0018 s/iter. Inference: 0.0358 s/iter. Eval: 0.0440 s/iter. Total: 0.0816 s/iter. ETA=0:01:29\n",
      "\u001b[32m[07/06 01:57:52 d2.evaluation.evaluator]: \u001b[0mInference done 74/1102. Dataloading: 0.0021 s/iter. Inference: 0.0349 s/iter. Eval: 0.0426 s/iter. Total: 0.0797 s/iter. ETA=0:01:21\n",
      "\u001b[32m[07/06 01:57:57 d2.evaluation.evaluator]: \u001b[0mInference done 139/1102. Dataloading: 0.0021 s/iter. Inference: 0.0349 s/iter. Eval: 0.0417 s/iter. Total: 0.0789 s/iter. ETA=0:01:15\n",
      "\u001b[32m[07/06 01:58:02 d2.evaluation.evaluator]: \u001b[0mInference done 202/1102. Dataloading: 0.0021 s/iter. Inference: 0.0350 s/iter. Eval: 0.0419 s/iter. Total: 0.0791 s/iter. ETA=0:01:11\n",
      "\u001b[32m[07/06 01:58:07 d2.evaluation.evaluator]: \u001b[0mInference done 266/1102. Dataloading: 0.0021 s/iter. Inference: 0.0350 s/iter. Eval: 0.0418 s/iter. Total: 0.0790 s/iter. ETA=0:01:06\n",
      "\u001b[32m[07/06 01:58:12 d2.evaluation.evaluator]: \u001b[0mInference done 333/1102. Dataloading: 0.0021 s/iter. Inference: 0.0350 s/iter. Eval: 0.0410 s/iter. Total: 0.0781 s/iter. ETA=0:01:00\n",
      "\u001b[32m[07/06 01:58:17 d2.evaluation.evaluator]: \u001b[0mInference done 400/1102. Dataloading: 0.0021 s/iter. Inference: 0.0350 s/iter. Eval: 0.0404 s/iter. Total: 0.0776 s/iter. ETA=0:00:54\n",
      "\u001b[32m[07/06 01:58:22 d2.evaluation.evaluator]: \u001b[0mInference done 466/1102. Dataloading: 0.0021 s/iter. Inference: 0.0350 s/iter. Eval: 0.0403 s/iter. Total: 0.0775 s/iter. ETA=0:00:49\n",
      "\u001b[32m[07/06 01:58:27 d2.evaluation.evaluator]: \u001b[0mInference done 534/1102. Dataloading: 0.0021 s/iter. Inference: 0.0351 s/iter. Eval: 0.0398 s/iter. Total: 0.0770 s/iter. ETA=0:00:43\n",
      "\u001b[32m[07/06 01:58:32 d2.evaluation.evaluator]: \u001b[0mInference done 603/1102. Dataloading: 0.0021 s/iter. Inference: 0.0351 s/iter. Eval: 0.0393 s/iter. Total: 0.0766 s/iter. ETA=0:00:38\n",
      "\u001b[32m[07/06 01:58:37 d2.evaluation.evaluator]: \u001b[0mInference done 671/1102. Dataloading: 0.0021 s/iter. Inference: 0.0351 s/iter. Eval: 0.0390 s/iter. Total: 0.0764 s/iter. ETA=0:00:32\n",
      "\u001b[32m[07/06 01:58:42 d2.evaluation.evaluator]: \u001b[0mInference done 739/1102. Dataloading: 0.0021 s/iter. Inference: 0.0351 s/iter. Eval: 0.0388 s/iter. Total: 0.0761 s/iter. ETA=0:00:27\n",
      "\u001b[32m[07/06 01:58:47 d2.evaluation.evaluator]: \u001b[0mInference done 805/1102. Dataloading: 0.0021 s/iter. Inference: 0.0352 s/iter. Eval: 0.0388 s/iter. Total: 0.0761 s/iter. ETA=0:00:22\n",
      "\u001b[32m[07/06 01:58:52 d2.evaluation.evaluator]: \u001b[0mInference done 870/1102. Dataloading: 0.0021 s/iter. Inference: 0.0352 s/iter. Eval: 0.0388 s/iter. Total: 0.0762 s/iter. ETA=0:00:17\n",
      "\u001b[32m[07/06 01:58:57 d2.evaluation.evaluator]: \u001b[0mInference done 936/1102. Dataloading: 0.0021 s/iter. Inference: 0.0352 s/iter. Eval: 0.0388 s/iter. Total: 0.0762 s/iter. ETA=0:00:12\n",
      "\u001b[32m[07/06 01:59:02 d2.evaluation.evaluator]: \u001b[0mInference done 998/1102. Dataloading: 0.0021 s/iter. Inference: 0.0352 s/iter. Eval: 0.0391 s/iter. Total: 0.0765 s/iter. ETA=0:00:07\n",
      "\u001b[32m[07/06 01:59:07 d2.evaluation.evaluator]: \u001b[0mInference done 1063/1102. Dataloading: 0.0021 s/iter. Inference: 0.0352 s/iter. Eval: 0.0391 s/iter. Total: 0.0765 s/iter. ETA=0:00:02\n",
      "\u001b[32m[07/06 01:59:11 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:01:24.018993 (0.076590 s / iter per device, on 1 devices)\n",
      "\u001b[32m[07/06 01:59:11 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:38 (0.035217 s / iter per device, on 1 devices)\n",
      "\u001b[32m[07/06 01:59:11 d2.evaluation.sem_seg_evaluation]: \u001b[0mOrderedDict([('sem_seg', {'mIoU': 38.26999150452076, 'fwIoU': 70.62719577034969, 'IoU-Unlabeled': nan, 'IoU-Building': 55.45720955237513, 'IoU-Fence': 14.932597644907919, 'IoU-Pedestrian': 26.27671058458813, 'IoU-Pole': 38.45020439092614, 'IoU-Road': 90.14528705157372, 'IoU-SideWalk': 46.27210008555213, 'IoU-Vegetation': 46.31310408371105, 'IoU-Vehicles': 55.67072300346049, 'IoU-Wall': 5.381199303580307, 'IoU-TrafficSign': 26.484654909963506, 'IoU-Sky': 84.9682101564679, 'IoU-TrafficLight': 25.316055625790142, 'IoU-Terrain': 0.01502288341611276, 'IoU-ConstructionVehicle': 40.47566976489885, 'IoU-workzone_object': 23.39333692548485, 'IoU-Detour': 32.767778105635884, 'mACC': 57.15851218822999, 'pACC': 81.78200118149142, 'ACC-Unlabeled': nan, 'ACC-Building': 91.45179061517061, 'ACC-Fence': 20.194912559242237, 'ACC-Pedestrian': 62.770217496415, 'ACC-Pole': 45.345345774657844, 'ACC-Road': 95.70988044856344, 'ACC-SideWalk': 64.69482326260783, 'ACC-Vegetation': 56.26468782061137, 'ACC-Vehicles': 80.81951405280535, 'ACC-Wall': 5.524228515945994, 'ACC-TrafficSign': 48.40089043571218, 'ACC-Sky': 93.95435642063163, 'ACC-TrafficLight': 27.91870032772427, 'ACC-Terrain': 0.015031614059001844, 'ACC-ConstructionVehicle': 89.75806007164509, 'ACC-workzone_object': 84.47853654016704, 'ACC-Detour': 47.23521905572097})])\n",
      "\u001b[32m[07/06 01:59:11 d2.engine.defaults]: \u001b[0mEvaluation results for carla_night_rain_val in csv format:\n",
      "\u001b[32m[07/06 01:59:11 d2.evaluation.testing]: \u001b[0mcopypaste: Task: sem_seg\n",
      "\u001b[32m[07/06 01:59:11 d2.evaluation.testing]: \u001b[0mcopypaste: mIoU,fwIoU,mACC,pACC\n",
      "\u001b[32m[07/06 01:59:11 d2.evaluation.testing]: \u001b[0mcopypaste: 38.2700,70.6272,57.1585,81.7820\n"
     ]
    }
   ],
   "source": [
    "trainer_day = Detectron2Trainer('carla_night_all_train', 'carla_night_rain_val', output_folder='./output_night_40k')\n",
    "trainer_day.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "30ac207b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainer_day = Detectron2Trainer('carla_night_all_train', 'cityscapes_rain_val', output_folder='./output_night_40k')\n",
    "#trainer_day.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1bd90d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainer_day = Detectron2Trainer('carla_night_all_train', 'combined_rain_val', output_folder='./output_night_40k')\n",
    "#trainer_day.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "0a71e85c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainer_day = Detectron2Trainer('carla_night_all_train', 'combined_all_val', output_folder='./output_night_40k')\n",
    "#trainer_day.test()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "145a97b0",
   "metadata": {},
   "source": [
    "### 3. Day and Night"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "bbf53191",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/05 18:32:39 d2.engine.defaults]: \u001b[0mModel:\n",
      "SemanticSegmentor(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (sem_seg_head): SemSegFPNHead(\n",
      "    (p2): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "    )\n",
      "    (p3): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (1): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "    )\n",
      "    (p4): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (1): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      (2): Conv2d(\n",
      "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (3): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "    )\n",
      "    (p5): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (1): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      (2): Conv2d(\n",
      "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (3): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      (4): Conv2d(\n",
      "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (5): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "    )\n",
      "    (predictor): Conv2d(128, 17, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/05 18:32:39 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(720, 720), max_size=2048, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[07/05 18:32:39 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[07/05 18:32:39 d2.data.common]: \u001b[0mSerializing 18867 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[07/05 18:32:39 d2.data.common]: \u001b[0mSerialized dataset takes 5.94 MiB\n",
      "Last checkpoint: model_final.pth\n",
      "\u001b[32m[07/05 18:32:39 d2.checkpoint.c2_model_loading]: \u001b[0mFollowing weights matched with model:\n",
      "| Names in Model                       | Names in Checkpoint                                                                                  | Shapes                                          |\n",
      "|:-------------------------------------|:-----------------------------------------------------------------------------------------------------|:------------------------------------------------|\n",
      "| backbone.bottom_up.res2.0.conv1.*    | backbone.bottom_up.res2.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,1,1)             |\n",
      "| backbone.bottom_up.res2.0.conv2.*    | backbone.bottom_up.res2.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |\n",
      "| backbone.bottom_up.res2.0.conv3.*    | backbone.bottom_up.res2.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res2.0.shortcut.* | backbone.bottom_up.res2.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res2.1.conv1.*    | backbone.bottom_up.res2.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |\n",
      "| backbone.bottom_up.res2.1.conv2.*    | backbone.bottom_up.res2.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |\n",
      "| backbone.bottom_up.res2.1.conv3.*    | backbone.bottom_up.res2.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res2.2.conv1.*    | backbone.bottom_up.res2.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |\n",
      "| backbone.bottom_up.res2.2.conv2.*    | backbone.bottom_up.res2.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |\n",
      "| backbone.bottom_up.res2.2.conv3.*    | backbone.bottom_up.res2.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res3.0.conv1.*    | backbone.bottom_up.res3.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,256,1,1)       |\n",
      "| backbone.bottom_up.res3.0.conv2.*    | backbone.bottom_up.res3.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.0.conv3.*    | backbone.bottom_up.res3.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res3.0.shortcut.* | backbone.bottom_up.res3.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (512,) (512,) (512,) (512,) (512,256,1,1)       |\n",
      "| backbone.bottom_up.res3.1.conv1.*    | backbone.bottom_up.res3.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |\n",
      "| backbone.bottom_up.res3.1.conv2.*    | backbone.bottom_up.res3.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.1.conv3.*    | backbone.bottom_up.res3.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res3.2.conv1.*    | backbone.bottom_up.res3.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |\n",
      "| backbone.bottom_up.res3.2.conv2.*    | backbone.bottom_up.res3.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.2.conv3.*    | backbone.bottom_up.res3.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res3.3.conv1.*    | backbone.bottom_up.res3.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |\n",
      "| backbone.bottom_up.res3.3.conv2.*    | backbone.bottom_up.res3.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.3.conv3.*    | backbone.bottom_up.res3.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res4.0.conv1.*    | backbone.bottom_up.res4.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,512,1,1)       |\n",
      "| backbone.bottom_up.res4.0.conv2.*    | backbone.bottom_up.res4.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.0.conv3.*    | backbone.bottom_up.res4.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.0.shortcut.* | backbone.bottom_up.res4.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (1024,) (1024,) (1024,) (1024,) (1024,512,1,1)  |\n",
      "| backbone.bottom_up.res4.1.conv1.*    | backbone.bottom_up.res4.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.1.conv2.*    | backbone.bottom_up.res4.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.1.conv3.*    | backbone.bottom_up.res4.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.2.conv1.*    | backbone.bottom_up.res4.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.2.conv2.*    | backbone.bottom_up.res4.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.2.conv3.*    | backbone.bottom_up.res4.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.3.conv1.*    | backbone.bottom_up.res4.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.3.conv2.*    | backbone.bottom_up.res4.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.3.conv3.*    | backbone.bottom_up.res4.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.4.conv1.*    | backbone.bottom_up.res4.4.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.4.conv2.*    | backbone.bottom_up.res4.4.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.4.conv3.*    | backbone.bottom_up.res4.4.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.5.conv1.*    | backbone.bottom_up.res4.5.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.5.conv2.*    | backbone.bottom_up.res4.5.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.5.conv3.*    | backbone.bottom_up.res4.5.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res5.0.conv1.*    | backbone.bottom_up.res5.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,1024,1,1)      |\n",
      "| backbone.bottom_up.res5.0.conv2.*    | backbone.bottom_up.res5.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |\n",
      "| backbone.bottom_up.res5.0.conv3.*    | backbone.bottom_up.res5.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
      "| backbone.bottom_up.res5.0.shortcut.* | backbone.bottom_up.res5.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (2048,) (2048,) (2048,) (2048,) (2048,1024,1,1) |\n",
      "| backbone.bottom_up.res5.1.conv1.*    | backbone.bottom_up.res5.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |\n",
      "| backbone.bottom_up.res5.1.conv2.*    | backbone.bottom_up.res5.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |\n",
      "| backbone.bottom_up.res5.1.conv3.*    | backbone.bottom_up.res5.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
      "| backbone.bottom_up.res5.2.conv1.*    | backbone.bottom_up.res5.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |\n",
      "| backbone.bottom_up.res5.2.conv2.*    | backbone.bottom_up.res5.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |\n",
      "| backbone.bottom_up.res5.2.conv3.*    | backbone.bottom_up.res5.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
      "| backbone.bottom_up.stem.conv1.*      | backbone.bottom_up.stem.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}      | (64,) (64,) (64,) (64,) (64,3,7,7)              |\n",
      "| backbone.fpn_lateral2.*              | backbone.fpn_lateral2.{bias,weight}                                                                  | (256,) (256,256,1,1)                            |\n",
      "| backbone.fpn_lateral3.*              | backbone.fpn_lateral3.{bias,weight}                                                                  | (256,) (256,512,1,1)                            |\n",
      "| backbone.fpn_lateral4.*              | backbone.fpn_lateral4.{bias,weight}                                                                  | (256,) (256,1024,1,1)                           |\n",
      "| backbone.fpn_lateral5.*              | backbone.fpn_lateral5.{bias,weight}                                                                  | (256,) (256,2048,1,1)                           |\n",
      "| backbone.fpn_output2.*               | backbone.fpn_output2.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| backbone.fpn_output3.*               | backbone.fpn_output3.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| backbone.fpn_output4.*               | backbone.fpn_output4.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| backbone.fpn_output5.*               | backbone.fpn_output5.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| sem_seg_head.p2.0.*                  | sem_seg_head.p2.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p3.0.*                  | sem_seg_head.p3.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p4.0.*                  | sem_seg_head.p4.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p4.2.*                  | sem_seg_head.p4.2.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,128,3,3)                     |\n",
      "| sem_seg_head.p5.0.*                  | sem_seg_head.p5.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p5.2.*                  | sem_seg_head.p5.2.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,128,3,3)                     |\n",
      "| sem_seg_head.p5.4.*                  | sem_seg_head.p5.4.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,128,3,3)                     |\n",
      "| sem_seg_head.predictor.*             | sem_seg_head.predictor.{bias,weight}                                                                 | (17,) (17,128,1,1)                              |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/05 18:32:39 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(720, 720), max_size=2048, sample_style='choice')]\n",
      "\u001b[32m[07/05 18:32:39 d2.data.common]: \u001b[0mSerializing 6531 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[07/05 18:32:39 d2.data.common]: \u001b[0mSerialized dataset takes 2.03 MiB\n",
      "\u001b[32m[07/05 18:32:39 d2.evaluation.evaluator]: \u001b[0mStart inference on 6531 batches\n",
      "\u001b[32m[07/05 18:32:42 d2.evaluation.evaluator]: \u001b[0mInference done 34/6531. Dataloading: 0.0018 s/iter. Inference: 0.0353 s/iter. Eval: 0.0432 s/iter. Total: 0.0804 s/iter. ETA=0:08:42\n",
      "\u001b[32m[07/05 18:32:47 d2.evaluation.evaluator]: \u001b[0mInference done 99/6531. Dataloading: 0.0020 s/iter. Inference: 0.0355 s/iter. Eval: 0.0406 s/iter. Total: 0.0782 s/iter. ETA=0:08:22\n",
      "\u001b[32m[07/05 18:32:52 d2.evaluation.evaluator]: \u001b[0mInference done 166/6531. Dataloading: 0.0021 s/iter. Inference: 0.0355 s/iter. Eval: 0.0392 s/iter. Total: 0.0770 s/iter. ETA=0:08:09\n",
      "\u001b[32m[07/05 18:32:57 d2.evaluation.evaluator]: \u001b[0mInference done 232/6531. Dataloading: 0.0022 s/iter. Inference: 0.0355 s/iter. Eval: 0.0390 s/iter. Total: 0.0768 s/iter. ETA=0:08:03\n",
      "\u001b[32m[07/05 18:33:02 d2.evaluation.evaluator]: \u001b[0mInference done 298/6531. Dataloading: 0.0022 s/iter. Inference: 0.0356 s/iter. Eval: 0.0388 s/iter. Total: 0.0766 s/iter. ETA=0:07:57\n",
      "\u001b[32m[07/05 18:33:08 d2.evaluation.evaluator]: \u001b[0mInference done 365/6531. Dataloading: 0.0022 s/iter. Inference: 0.0356 s/iter. Eval: 0.0386 s/iter. Total: 0.0765 s/iter. ETA=0:07:51\n",
      "\u001b[32m[07/05 18:33:13 d2.evaluation.evaluator]: \u001b[0mInference done 430/6531. Dataloading: 0.0026 s/iter. Inference: 0.0356 s/iter. Eval: 0.0385 s/iter. Total: 0.0767 s/iter. ETA=0:07:47\n",
      "\u001b[32m[07/05 18:33:18 d2.evaluation.evaluator]: \u001b[0mInference done 496/6531. Dataloading: 0.0025 s/iter. Inference: 0.0356 s/iter. Eval: 0.0384 s/iter. Total: 0.0766 s/iter. ETA=0:07:42\n",
      "\u001b[32m[07/05 18:33:23 d2.evaluation.evaluator]: \u001b[0mInference done 562/6531. Dataloading: 0.0025 s/iter. Inference: 0.0356 s/iter. Eval: 0.0384 s/iter. Total: 0.0765 s/iter. ETA=0:07:36\n",
      "\u001b[32m[07/05 18:33:28 d2.evaluation.evaluator]: \u001b[0mInference done 628/6531. Dataloading: 0.0025 s/iter. Inference: 0.0356 s/iter. Eval: 0.0384 s/iter. Total: 0.0765 s/iter. ETA=0:07:31\n",
      "\u001b[32m[07/05 18:33:33 d2.evaluation.evaluator]: \u001b[0mInference done 694/6531. Dataloading: 0.0025 s/iter. Inference: 0.0356 s/iter. Eval: 0.0384 s/iter. Total: 0.0765 s/iter. ETA=0:07:26\n",
      "\u001b[32m[07/05 18:33:38 d2.evaluation.evaluator]: \u001b[0mInference done 757/6531. Dataloading: 0.0025 s/iter. Inference: 0.0356 s/iter. Eval: 0.0387 s/iter. Total: 0.0768 s/iter. ETA=0:07:23\n",
      "\u001b[32m[07/05 18:33:43 d2.evaluation.evaluator]: \u001b[0mInference done 822/6531. Dataloading: 0.0025 s/iter. Inference: 0.0356 s/iter. Eval: 0.0388 s/iter. Total: 0.0769 s/iter. ETA=0:07:18\n",
      "\u001b[32m[07/05 18:33:48 d2.evaluation.evaluator]: \u001b[0mInference done 886/6531. Dataloading: 0.0024 s/iter. Inference: 0.0356 s/iter. Eval: 0.0389 s/iter. Total: 0.0770 s/iter. ETA=0:07:14\n",
      "\u001b[32m[07/05 18:33:53 d2.evaluation.evaluator]: \u001b[0mInference done 951/6531. Dataloading: 0.0024 s/iter. Inference: 0.0356 s/iter. Eval: 0.0390 s/iter. Total: 0.0771 s/iter. ETA=0:07:10\n",
      "\u001b[32m[07/05 18:33:58 d2.evaluation.evaluator]: \u001b[0mInference done 1016/6531. Dataloading: 0.0024 s/iter. Inference: 0.0356 s/iter. Eval: 0.0391 s/iter. Total: 0.0771 s/iter. ETA=0:07:05\n",
      "\u001b[32m[07/05 18:34:03 d2.evaluation.evaluator]: \u001b[0mInference done 1081/6531. Dataloading: 0.0024 s/iter. Inference: 0.0356 s/iter. Eval: 0.0391 s/iter. Total: 0.0772 s/iter. ETA=0:07:00\n",
      "\u001b[32m[07/05 18:34:08 d2.evaluation.evaluator]: \u001b[0mInference done 1146/6531. Dataloading: 0.0024 s/iter. Inference: 0.0356 s/iter. Eval: 0.0391 s/iter. Total: 0.0772 s/iter. ETA=0:06:55\n",
      "\u001b[32m[07/05 18:34:13 d2.evaluation.evaluator]: \u001b[0mInference done 1211/6531. Dataloading: 0.0024 s/iter. Inference: 0.0356 s/iter. Eval: 0.0392 s/iter. Total: 0.0772 s/iter. ETA=0:06:50\n",
      "\u001b[32m[07/05 18:34:18 d2.evaluation.evaluator]: \u001b[0mInference done 1275/6531. Dataloading: 0.0024 s/iter. Inference: 0.0356 s/iter. Eval: 0.0392 s/iter. Total: 0.0773 s/iter. ETA=0:06:46\n",
      "\u001b[32m[07/05 18:34:23 d2.evaluation.evaluator]: \u001b[0mInference done 1339/6531. Dataloading: 0.0024 s/iter. Inference: 0.0356 s/iter. Eval: 0.0393 s/iter. Total: 0.0774 s/iter. ETA=0:06:41\n",
      "\u001b[32m[07/05 18:34:28 d2.evaluation.evaluator]: \u001b[0mInference done 1405/6531. Dataloading: 0.0024 s/iter. Inference: 0.0356 s/iter. Eval: 0.0393 s/iter. Total: 0.0773 s/iter. ETA=0:06:36\n",
      "\u001b[32m[07/05 18:34:33 d2.evaluation.evaluator]: \u001b[0mInference done 1470/6531. Dataloading: 0.0024 s/iter. Inference: 0.0356 s/iter. Eval: 0.0393 s/iter. Total: 0.0773 s/iter. ETA=0:06:31\n",
      "\u001b[32m[07/05 18:34:38 d2.evaluation.evaluator]: \u001b[0mInference done 1534/6531. Dataloading: 0.0024 s/iter. Inference: 0.0356 s/iter. Eval: 0.0393 s/iter. Total: 0.0774 s/iter. ETA=0:06:26\n",
      "\u001b[32m[07/05 18:34:43 d2.evaluation.evaluator]: \u001b[0mInference done 1599/6531. Dataloading: 0.0024 s/iter. Inference: 0.0356 s/iter. Eval: 0.0393 s/iter. Total: 0.0774 s/iter. ETA=0:06:21\n",
      "\u001b[32m[07/05 18:34:48 d2.evaluation.evaluator]: \u001b[0mInference done 1663/6531. Dataloading: 0.0024 s/iter. Inference: 0.0356 s/iter. Eval: 0.0394 s/iter. Total: 0.0774 s/iter. ETA=0:06:16\n",
      "\u001b[32m[07/05 18:34:53 d2.evaluation.evaluator]: \u001b[0mInference done 1727/6531. Dataloading: 0.0024 s/iter. Inference: 0.0356 s/iter. Eval: 0.0394 s/iter. Total: 0.0775 s/iter. ETA=0:06:12\n",
      "\u001b[32m[07/05 18:34:58 d2.evaluation.evaluator]: \u001b[0mInference done 1792/6531. Dataloading: 0.0024 s/iter. Inference: 0.0356 s/iter. Eval: 0.0394 s/iter. Total: 0.0775 s/iter. ETA=0:06:07\n",
      "\u001b[32m[07/05 18:35:03 d2.evaluation.evaluator]: \u001b[0mInference done 1855/6531. Dataloading: 0.0024 s/iter. Inference: 0.0356 s/iter. Eval: 0.0395 s/iter. Total: 0.0776 s/iter. ETA=0:06:02\n",
      "\u001b[32m[07/05 18:35:08 d2.evaluation.evaluator]: \u001b[0mInference done 1918/6531. Dataloading: 0.0024 s/iter. Inference: 0.0356 s/iter. Eval: 0.0396 s/iter. Total: 0.0776 s/iter. ETA=0:05:58\n",
      "\u001b[32m[07/05 18:35:14 d2.evaluation.evaluator]: \u001b[0mInference done 1982/6531. Dataloading: 0.0024 s/iter. Inference: 0.0356 s/iter. Eval: 0.0396 s/iter. Total: 0.0777 s/iter. ETA=0:05:53\n",
      "\u001b[32m[07/05 18:35:19 d2.evaluation.evaluator]: \u001b[0mInference done 2048/6531. Dataloading: 0.0024 s/iter. Inference: 0.0356 s/iter. Eval: 0.0396 s/iter. Total: 0.0776 s/iter. ETA=0:05:48\n",
      "\u001b[32m[07/05 18:35:24 d2.evaluation.evaluator]: \u001b[0mInference done 2113/6531. Dataloading: 0.0024 s/iter. Inference: 0.0356 s/iter. Eval: 0.0396 s/iter. Total: 0.0776 s/iter. ETA=0:05:43\n",
      "\u001b[32m[07/05 18:35:29 d2.evaluation.evaluator]: \u001b[0mInference done 2178/6531. Dataloading: 0.0024 s/iter. Inference: 0.0356 s/iter. Eval: 0.0396 s/iter. Total: 0.0776 s/iter. ETA=0:05:37\n",
      "\u001b[32m[07/05 18:35:34 d2.evaluation.evaluator]: \u001b[0mInference done 2243/6531. Dataloading: 0.0024 s/iter. Inference: 0.0356 s/iter. Eval: 0.0396 s/iter. Total: 0.0776 s/iter. ETA=0:05:32\n",
      "\u001b[32m[07/05 18:35:39 d2.evaluation.evaluator]: \u001b[0mInference done 2308/6531. Dataloading: 0.0024 s/iter. Inference: 0.0356 s/iter. Eval: 0.0396 s/iter. Total: 0.0776 s/iter. ETA=0:05:27\n",
      "\u001b[32m[07/05 18:35:44 d2.evaluation.evaluator]: \u001b[0mInference done 2373/6531. Dataloading: 0.0024 s/iter. Inference: 0.0356 s/iter. Eval: 0.0396 s/iter. Total: 0.0776 s/iter. ETA=0:05:22\n",
      "\u001b[32m[07/05 18:35:49 d2.evaluation.evaluator]: \u001b[0mInference done 2438/6531. Dataloading: 0.0024 s/iter. Inference: 0.0356 s/iter. Eval: 0.0396 s/iter. Total: 0.0776 s/iter. ETA=0:05:17\n",
      "\u001b[32m[07/05 18:35:54 d2.evaluation.evaluator]: \u001b[0mInference done 2503/6531. Dataloading: 0.0024 s/iter. Inference: 0.0356 s/iter. Eval: 0.0395 s/iter. Total: 0.0776 s/iter. ETA=0:05:12\n",
      "\u001b[32m[07/05 18:35:59 d2.evaluation.evaluator]: \u001b[0mInference done 2568/6531. Dataloading: 0.0024 s/iter. Inference: 0.0356 s/iter. Eval: 0.0395 s/iter. Total: 0.0776 s/iter. ETA=0:05:07\n",
      "\u001b[32m[07/05 18:36:04 d2.evaluation.evaluator]: \u001b[0mInference done 2633/6531. Dataloading: 0.0024 s/iter. Inference: 0.0356 s/iter. Eval: 0.0395 s/iter. Total: 0.0776 s/iter. ETA=0:05:02\n",
      "\u001b[32m[07/05 18:36:09 d2.evaluation.evaluator]: \u001b[0mInference done 2699/6531. Dataloading: 0.0024 s/iter. Inference: 0.0356 s/iter. Eval: 0.0395 s/iter. Total: 0.0775 s/iter. ETA=0:04:57\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/05 18:36:14 d2.evaluation.evaluator]: \u001b[0mInference done 2765/6531. Dataloading: 0.0024 s/iter. Inference: 0.0356 s/iter. Eval: 0.0395 s/iter. Total: 0.0775 s/iter. ETA=0:04:51\n",
      "\u001b[32m[07/05 18:36:19 d2.evaluation.evaluator]: \u001b[0mInference done 2832/6531. Dataloading: 0.0024 s/iter. Inference: 0.0356 s/iter. Eval: 0.0394 s/iter. Total: 0.0774 s/iter. ETA=0:04:46\n",
      "\u001b[32m[07/05 18:36:24 d2.evaluation.evaluator]: \u001b[0mInference done 2898/6531. Dataloading: 0.0024 s/iter. Inference: 0.0356 s/iter. Eval: 0.0394 s/iter. Total: 0.0774 s/iter. ETA=0:04:41\n",
      "\u001b[32m[07/05 18:36:29 d2.evaluation.evaluator]: \u001b[0mInference done 2963/6531. Dataloading: 0.0024 s/iter. Inference: 0.0356 s/iter. Eval: 0.0394 s/iter. Total: 0.0774 s/iter. ETA=0:04:36\n",
      "\u001b[32m[07/05 18:36:34 d2.evaluation.evaluator]: \u001b[0mInference done 3028/6531. Dataloading: 0.0024 s/iter. Inference: 0.0356 s/iter. Eval: 0.0394 s/iter. Total: 0.0774 s/iter. ETA=0:04:31\n",
      "\u001b[32m[07/05 18:36:39 d2.evaluation.evaluator]: \u001b[0mInference done 3093/6531. Dataloading: 0.0024 s/iter. Inference: 0.0356 s/iter. Eval: 0.0394 s/iter. Total: 0.0774 s/iter. ETA=0:04:26\n",
      "\u001b[32m[07/05 18:36:44 d2.evaluation.evaluator]: \u001b[0mInference done 3159/6531. Dataloading: 0.0024 s/iter. Inference: 0.0356 s/iter. Eval: 0.0393 s/iter. Total: 0.0774 s/iter. ETA=0:04:20\n",
      "\u001b[32m[07/05 18:36:49 d2.evaluation.evaluator]: \u001b[0mInference done 3224/6531. Dataloading: 0.0024 s/iter. Inference: 0.0356 s/iter. Eval: 0.0393 s/iter. Total: 0.0774 s/iter. ETA=0:04:15\n",
      "\u001b[32m[07/05 18:36:54 d2.evaluation.evaluator]: \u001b[0mInference done 3289/6531. Dataloading: 0.0024 s/iter. Inference: 0.0356 s/iter. Eval: 0.0393 s/iter. Total: 0.0774 s/iter. ETA=0:04:10\n",
      "\u001b[32m[07/05 18:36:59 d2.evaluation.evaluator]: \u001b[0mInference done 3352/6531. Dataloading: 0.0024 s/iter. Inference: 0.0356 s/iter. Eval: 0.0394 s/iter. Total: 0.0774 s/iter. ETA=0:04:06\n",
      "\u001b[32m[07/05 18:37:04 d2.evaluation.evaluator]: \u001b[0mInference done 3416/6531. Dataloading: 0.0024 s/iter. Inference: 0.0356 s/iter. Eval: 0.0394 s/iter. Total: 0.0775 s/iter. ETA=0:04:01\n",
      "\u001b[32m[07/05 18:37:09 d2.evaluation.evaluator]: \u001b[0mInference done 3480/6531. Dataloading: 0.0024 s/iter. Inference: 0.0356 s/iter. Eval: 0.0395 s/iter. Total: 0.0775 s/iter. ETA=0:03:56\n",
      "\u001b[32m[07/05 18:37:14 d2.evaluation.evaluator]: \u001b[0mInference done 3542/6531. Dataloading: 0.0024 s/iter. Inference: 0.0356 s/iter. Eval: 0.0395 s/iter. Total: 0.0775 s/iter. ETA=0:03:51\n",
      "\u001b[32m[07/05 18:37:19 d2.evaluation.evaluator]: \u001b[0mInference done 3604/6531. Dataloading: 0.0024 s/iter. Inference: 0.0356 s/iter. Eval: 0.0395 s/iter. Total: 0.0776 s/iter. ETA=0:03:47\n",
      "\u001b[32m[07/05 18:37:24 d2.evaluation.evaluator]: \u001b[0mInference done 3667/6531. Dataloading: 0.0024 s/iter. Inference: 0.0356 s/iter. Eval: 0.0396 s/iter. Total: 0.0777 s/iter. ETA=0:03:42\n",
      "\u001b[32m[07/05 18:37:29 d2.evaluation.evaluator]: \u001b[0mInference done 3728/6531. Dataloading: 0.0024 s/iter. Inference: 0.0356 s/iter. Eval: 0.0397 s/iter. Total: 0.0777 s/iter. ETA=0:03:37\n",
      "\u001b[32m[07/05 18:37:34 d2.evaluation.evaluator]: \u001b[0mInference done 3789/6531. Dataloading: 0.0024 s/iter. Inference: 0.0356 s/iter. Eval: 0.0397 s/iter. Total: 0.0778 s/iter. ETA=0:03:33\n",
      "\u001b[32m[07/05 18:37:39 d2.evaluation.evaluator]: \u001b[0mInference done 3850/6531. Dataloading: 0.0024 s/iter. Inference: 0.0356 s/iter. Eval: 0.0398 s/iter. Total: 0.0779 s/iter. ETA=0:03:28\n",
      "\u001b[32m[07/05 18:37:44 d2.evaluation.evaluator]: \u001b[0mInference done 3912/6531. Dataloading: 0.0024 s/iter. Inference: 0.0356 s/iter. Eval: 0.0399 s/iter. Total: 0.0779 s/iter. ETA=0:03:24\n",
      "\u001b[32m[07/05 18:37:49 d2.evaluation.evaluator]: \u001b[0mInference done 3974/6531. Dataloading: 0.0024 s/iter. Inference: 0.0356 s/iter. Eval: 0.0399 s/iter. Total: 0.0780 s/iter. ETA=0:03:19\n",
      "\u001b[32m[07/05 18:37:55 d2.evaluation.evaluator]: \u001b[0mInference done 4037/6531. Dataloading: 0.0024 s/iter. Inference: 0.0356 s/iter. Eval: 0.0400 s/iter. Total: 0.0780 s/iter. ETA=0:03:14\n",
      "\u001b[32m[07/05 18:38:00 d2.evaluation.evaluator]: \u001b[0mInference done 4101/6531. Dataloading: 0.0024 s/iter. Inference: 0.0356 s/iter. Eval: 0.0400 s/iter. Total: 0.0780 s/iter. ETA=0:03:09\n",
      "\u001b[32m[07/05 18:38:05 d2.evaluation.evaluator]: \u001b[0mInference done 4166/6531. Dataloading: 0.0024 s/iter. Inference: 0.0356 s/iter. Eval: 0.0400 s/iter. Total: 0.0780 s/iter. ETA=0:03:04\n",
      "\u001b[32m[07/05 18:38:10 d2.evaluation.evaluator]: \u001b[0mInference done 4231/6531. Dataloading: 0.0024 s/iter. Inference: 0.0356 s/iter. Eval: 0.0399 s/iter. Total: 0.0780 s/iter. ETA=0:02:59\n",
      "\u001b[32m[07/05 18:38:15 d2.evaluation.evaluator]: \u001b[0mInference done 4296/6531. Dataloading: 0.0024 s/iter. Inference: 0.0356 s/iter. Eval: 0.0399 s/iter. Total: 0.0780 s/iter. ETA=0:02:54\n",
      "\u001b[32m[07/05 18:38:20 d2.evaluation.evaluator]: \u001b[0mInference done 4361/6531. Dataloading: 0.0024 s/iter. Inference: 0.0356 s/iter. Eval: 0.0399 s/iter. Total: 0.0780 s/iter. ETA=0:02:49\n",
      "\u001b[32m[07/05 18:38:25 d2.evaluation.evaluator]: \u001b[0mInference done 4427/6531. Dataloading: 0.0024 s/iter. Inference: 0.0356 s/iter. Eval: 0.0399 s/iter. Total: 0.0780 s/iter. ETA=0:02:44\n",
      "\u001b[32m[07/05 18:38:30 d2.evaluation.evaluator]: \u001b[0mInference done 4493/6531. Dataloading: 0.0024 s/iter. Inference: 0.0356 s/iter. Eval: 0.0399 s/iter. Total: 0.0780 s/iter. ETA=0:02:38\n",
      "\u001b[32m[07/05 18:38:35 d2.evaluation.evaluator]: \u001b[0mInference done 4558/6531. Dataloading: 0.0024 s/iter. Inference: 0.0356 s/iter. Eval: 0.0399 s/iter. Total: 0.0779 s/iter. ETA=0:02:33\n",
      "\u001b[32m[07/05 18:38:40 d2.evaluation.evaluator]: \u001b[0mInference done 4621/6531. Dataloading: 0.0024 s/iter. Inference: 0.0356 s/iter. Eval: 0.0399 s/iter. Total: 0.0780 s/iter. ETA=0:02:28\n",
      "\u001b[32m[07/05 18:38:45 d2.evaluation.evaluator]: \u001b[0mInference done 4686/6531. Dataloading: 0.0024 s/iter. Inference: 0.0356 s/iter. Eval: 0.0399 s/iter. Total: 0.0780 s/iter. ETA=0:02:23\n",
      "\u001b[32m[07/05 18:38:50 d2.evaluation.evaluator]: \u001b[0mInference done 4752/6531. Dataloading: 0.0024 s/iter. Inference: 0.0356 s/iter. Eval: 0.0399 s/iter. Total: 0.0779 s/iter. ETA=0:02:18\n",
      "\u001b[32m[07/05 18:38:55 d2.evaluation.evaluator]: \u001b[0mInference done 4818/6531. Dataloading: 0.0024 s/iter. Inference: 0.0356 s/iter. Eval: 0.0399 s/iter. Total: 0.0779 s/iter. ETA=0:02:13\n",
      "\u001b[32m[07/05 18:39:00 d2.evaluation.evaluator]: \u001b[0mInference done 4883/6531. Dataloading: 0.0024 s/iter. Inference: 0.0356 s/iter. Eval: 0.0399 s/iter. Total: 0.0779 s/iter. ETA=0:02:08\n",
      "\u001b[32m[07/05 18:39:05 d2.evaluation.evaluator]: \u001b[0mInference done 4949/6531. Dataloading: 0.0024 s/iter. Inference: 0.0356 s/iter. Eval: 0.0398 s/iter. Total: 0.0779 s/iter. ETA=0:02:03\n",
      "\u001b[32m[07/05 18:39:10 d2.evaluation.evaluator]: \u001b[0mInference done 5015/6531. Dataloading: 0.0024 s/iter. Inference: 0.0356 s/iter. Eval: 0.0398 s/iter. Total: 0.0779 s/iter. ETA=0:01:58\n",
      "\u001b[32m[07/05 18:39:15 d2.evaluation.evaluator]: \u001b[0mInference done 5081/6531. Dataloading: 0.0024 s/iter. Inference: 0.0356 s/iter. Eval: 0.0398 s/iter. Total: 0.0778 s/iter. ETA=0:01:52\n",
      "\u001b[32m[07/05 18:39:20 d2.evaluation.evaluator]: \u001b[0mInference done 5147/6531. Dataloading: 0.0024 s/iter. Inference: 0.0356 s/iter. Eval: 0.0398 s/iter. Total: 0.0778 s/iter. ETA=0:01:47\n",
      "\u001b[32m[07/05 18:39:25 d2.evaluation.evaluator]: \u001b[0mInference done 5212/6531. Dataloading: 0.0024 s/iter. Inference: 0.0356 s/iter. Eval: 0.0398 s/iter. Total: 0.0778 s/iter. ETA=0:01:42\n",
      "\u001b[32m[07/05 18:39:30 d2.evaluation.evaluator]: \u001b[0mInference done 5279/6531. Dataloading: 0.0024 s/iter. Inference: 0.0356 s/iter. Eval: 0.0398 s/iter. Total: 0.0778 s/iter. ETA=0:01:37\n",
      "\u001b[32m[07/05 18:39:35 d2.evaluation.evaluator]: \u001b[0mInference done 5344/6531. Dataloading: 0.0024 s/iter. Inference: 0.0356 s/iter. Eval: 0.0398 s/iter. Total: 0.0778 s/iter. ETA=0:01:32\n",
      "\u001b[32m[07/05 18:39:40 d2.evaluation.evaluator]: \u001b[0mInference done 5409/6531. Dataloading: 0.0024 s/iter. Inference: 0.0356 s/iter. Eval: 0.0398 s/iter. Total: 0.0778 s/iter. ETA=0:01:27\n",
      "\u001b[32m[07/05 18:39:45 d2.evaluation.evaluator]: \u001b[0mInference done 5477/6531. Dataloading: 0.0024 s/iter. Inference: 0.0356 s/iter. Eval: 0.0397 s/iter. Total: 0.0777 s/iter. ETA=0:01:21\n",
      "\u001b[32m[07/05 18:39:50 d2.evaluation.evaluator]: \u001b[0mInference done 5544/6531. Dataloading: 0.0024 s/iter. Inference: 0.0356 s/iter. Eval: 0.0397 s/iter. Total: 0.0777 s/iter. ETA=0:01:16\n",
      "\u001b[32m[07/05 18:39:55 d2.evaluation.evaluator]: \u001b[0mInference done 5611/6531. Dataloading: 0.0024 s/iter. Inference: 0.0356 s/iter. Eval: 0.0397 s/iter. Total: 0.0777 s/iter. ETA=0:01:11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/05 18:40:01 d2.evaluation.evaluator]: \u001b[0mInference done 5676/6531. Dataloading: 0.0024 s/iter. Inference: 0.0356 s/iter. Eval: 0.0397 s/iter. Total: 0.0777 s/iter. ETA=0:01:06\n",
      "\u001b[32m[07/05 18:40:06 d2.evaluation.evaluator]: \u001b[0mInference done 5741/6531. Dataloading: 0.0024 s/iter. Inference: 0.0356 s/iter. Eval: 0.0397 s/iter. Total: 0.0777 s/iter. ETA=0:01:01\n",
      "\u001b[32m[07/05 18:40:11 d2.evaluation.evaluator]: \u001b[0mInference done 5807/6531. Dataloading: 0.0024 s/iter. Inference: 0.0356 s/iter. Eval: 0.0397 s/iter. Total: 0.0777 s/iter. ETA=0:00:56\n",
      "\u001b[32m[07/05 18:40:16 d2.evaluation.evaluator]: \u001b[0mInference done 5874/6531. Dataloading: 0.0024 s/iter. Inference: 0.0356 s/iter. Eval: 0.0396 s/iter. Total: 0.0777 s/iter. ETA=0:00:51\n",
      "\u001b[32m[07/05 18:40:21 d2.evaluation.evaluator]: \u001b[0mInference done 5940/6531. Dataloading: 0.0024 s/iter. Inference: 0.0356 s/iter. Eval: 0.0396 s/iter. Total: 0.0776 s/iter. ETA=0:00:45\n",
      "\u001b[32m[07/05 18:40:26 d2.evaluation.evaluator]: \u001b[0mInference done 6007/6531. Dataloading: 0.0024 s/iter. Inference: 0.0356 s/iter. Eval: 0.0396 s/iter. Total: 0.0776 s/iter. ETA=0:00:40\n",
      "\u001b[32m[07/05 18:40:31 d2.evaluation.evaluator]: \u001b[0mInference done 6072/6531. Dataloading: 0.0024 s/iter. Inference: 0.0356 s/iter. Eval: 0.0396 s/iter. Total: 0.0776 s/iter. ETA=0:00:35\n",
      "\u001b[32m[07/05 18:40:36 d2.evaluation.evaluator]: \u001b[0mInference done 6136/6531. Dataloading: 0.0024 s/iter. Inference: 0.0356 s/iter. Eval: 0.0396 s/iter. Total: 0.0776 s/iter. ETA=0:00:30\n",
      "\u001b[32m[07/05 18:40:41 d2.evaluation.evaluator]: \u001b[0mInference done 6198/6531. Dataloading: 0.0024 s/iter. Inference: 0.0356 s/iter. Eval: 0.0396 s/iter. Total: 0.0776 s/iter. ETA=0:00:25\n",
      "\u001b[32m[07/05 18:40:46 d2.evaluation.evaluator]: \u001b[0mInference done 6261/6531. Dataloading: 0.0024 s/iter. Inference: 0.0356 s/iter. Eval: 0.0397 s/iter. Total: 0.0777 s/iter. ETA=0:00:20\n",
      "\u001b[32m[07/05 18:40:51 d2.evaluation.evaluator]: \u001b[0mInference done 6326/6531. Dataloading: 0.0024 s/iter. Inference: 0.0356 s/iter. Eval: 0.0397 s/iter. Total: 0.0777 s/iter. ETA=0:00:15\n",
      "\u001b[32m[07/05 18:40:56 d2.evaluation.evaluator]: \u001b[0mInference done 6391/6531. Dataloading: 0.0024 s/iter. Inference: 0.0356 s/iter. Eval: 0.0397 s/iter. Total: 0.0777 s/iter. ETA=0:00:10\n",
      "\u001b[32m[07/05 18:41:01 d2.evaluation.evaluator]: \u001b[0mInference done 6457/6531. Dataloading: 0.0024 s/iter. Inference: 0.0356 s/iter. Eval: 0.0397 s/iter. Total: 0.0777 s/iter. ETA=0:00:05\n",
      "\u001b[32m[07/05 18:41:06 d2.evaluation.evaluator]: \u001b[0mInference done 6523/6531. Dataloading: 0.0024 s/iter. Inference: 0.0356 s/iter. Eval: 0.0396 s/iter. Total: 0.0776 s/iter. ETA=0:00:00\n",
      "\u001b[32m[07/05 18:41:07 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:08:26.766709 (0.077653 s / iter per device, on 1 devices)\n",
      "\u001b[32m[07/05 18:41:07 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:03:52 (0.035569 s / iter per device, on 1 devices)\n",
      "\u001b[32m[07/05 18:41:08 d2.evaluation.sem_seg_evaluation]: \u001b[0mOrderedDict([('sem_seg', {'mIoU': 53.7364527748025, 'fwIoU': 81.15582577175786, 'IoU-Unlabeled': nan, 'IoU-Building': 73.36062529228387, 'IoU-Fence': 25.764247338870796, 'IoU-Pedestrian': 33.95419528677877, 'IoU-Pole': 51.976942451130526, 'IoU-Road': 95.82253921539595, 'IoU-SideWalk': 75.09928738124162, 'IoU-Vegetation': 63.36190238774929, 'IoU-Vehicles': 69.38423643098314, 'IoU-Wall': 58.83473756664803, 'IoU-TrafficSign': 47.74783529143995, 'IoU-Sky': 84.34365510067121, 'IoU-TrafficLight': 55.412470123009406, 'IoU-Terrain': 23.738485838964593, 'IoU-ConstructionVehicle': 77.07772497496799, 'IoU-workzone_object': 58.16802683238781, 'IoU-Detour': 19.47278565911955, 'mACC': 70.41786223195324, 'pACC': 88.95439217313982, 'ACC-Unlabeled': nan, 'ACC-Building': 95.60296017733071, 'ACC-Fence': 44.77506618651324, 'ACC-Pedestrian': 65.13835128445714, 'ACC-Pole': 61.53306967924891, 'ACC-Road': 97.55097898492055, 'ACC-SideWalk': 87.36886916267723, 'ACC-Vegetation': 77.7047377735219, 'ACC-Vehicles': 89.47133438333938, 'ACC-Wall': 63.53100522500426, 'ACC-TrafficSign': 60.00523740394556, 'ACC-Sky': 87.32877239053144, 'ACC-TrafficLight': 66.66267205984714, 'ACC-Terrain': 24.470716432112315, 'ACC-ConstructionVehicle': 94.46023558778212, 'ACC-workzone_object': 86.99015982163003, 'ACC-Detour': 24.0916291583897})])\n",
      "\u001b[32m[07/05 18:41:08 d2.engine.defaults]: \u001b[0mEvaluation results for carla_both_clear_val in csv format:\n",
      "\u001b[32m[07/05 18:41:08 d2.evaluation.testing]: \u001b[0mcopypaste: Task: sem_seg\n",
      "\u001b[32m[07/05 18:41:08 d2.evaluation.testing]: \u001b[0mcopypaste: mIoU,fwIoU,mACC,pACC\n",
      "\u001b[32m[07/05 18:41:08 d2.evaluation.testing]: \u001b[0mcopypaste: 53.7365,81.1558,70.4179,88.9544\n"
     ]
    }
   ],
   "source": [
    "#all carla clear\n",
    "trainer_both = Detectron2Trainer('combined_clear_both_train', 'carla_both_clear_val', output_folder='./output_both_clear_40k')\n",
    "trainer_both.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a954a780",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/05 18:41:08 d2.engine.defaults]: \u001b[0mModel:\n",
      "SemanticSegmentor(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (sem_seg_head): SemSegFPNHead(\n",
      "    (p2): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "    )\n",
      "    (p3): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (1): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "    )\n",
      "    (p4): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (1): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      (2): Conv2d(\n",
      "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (3): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "    )\n",
      "    (p5): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (1): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      (2): Conv2d(\n",
      "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (3): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      (4): Conv2d(\n",
      "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (5): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "    )\n",
      "    (predictor): Conv2d(128, 17, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/05 18:41:08 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(720, 720), max_size=2048, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[07/05 18:41:08 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[07/05 18:41:08 d2.data.common]: \u001b[0mSerializing 18867 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[07/05 18:41:08 d2.data.common]: \u001b[0mSerialized dataset takes 5.94 MiB\n",
      "Last checkpoint: model_final.pth\n",
      "\u001b[32m[07/05 18:41:09 d2.checkpoint.c2_model_loading]: \u001b[0mFollowing weights matched with model:\n",
      "| Names in Model                       | Names in Checkpoint                                                                                  | Shapes                                          |\n",
      "|:-------------------------------------|:-----------------------------------------------------------------------------------------------------|:------------------------------------------------|\n",
      "| backbone.bottom_up.res2.0.conv1.*    | backbone.bottom_up.res2.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,1,1)             |\n",
      "| backbone.bottom_up.res2.0.conv2.*    | backbone.bottom_up.res2.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |\n",
      "| backbone.bottom_up.res2.0.conv3.*    | backbone.bottom_up.res2.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res2.0.shortcut.* | backbone.bottom_up.res2.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res2.1.conv1.*    | backbone.bottom_up.res2.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |\n",
      "| backbone.bottom_up.res2.1.conv2.*    | backbone.bottom_up.res2.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |\n",
      "| backbone.bottom_up.res2.1.conv3.*    | backbone.bottom_up.res2.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res2.2.conv1.*    | backbone.bottom_up.res2.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |\n",
      "| backbone.bottom_up.res2.2.conv2.*    | backbone.bottom_up.res2.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |\n",
      "| backbone.bottom_up.res2.2.conv3.*    | backbone.bottom_up.res2.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res3.0.conv1.*    | backbone.bottom_up.res3.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,256,1,1)       |\n",
      "| backbone.bottom_up.res3.0.conv2.*    | backbone.bottom_up.res3.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.0.conv3.*    | backbone.bottom_up.res3.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res3.0.shortcut.* | backbone.bottom_up.res3.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (512,) (512,) (512,) (512,) (512,256,1,1)       |\n",
      "| backbone.bottom_up.res3.1.conv1.*    | backbone.bottom_up.res3.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |\n",
      "| backbone.bottom_up.res3.1.conv2.*    | backbone.bottom_up.res3.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.1.conv3.*    | backbone.bottom_up.res3.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res3.2.conv1.*    | backbone.bottom_up.res3.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |\n",
      "| backbone.bottom_up.res3.2.conv2.*    | backbone.bottom_up.res3.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.2.conv3.*    | backbone.bottom_up.res3.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res3.3.conv1.*    | backbone.bottom_up.res3.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |\n",
      "| backbone.bottom_up.res3.3.conv2.*    | backbone.bottom_up.res3.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.3.conv3.*    | backbone.bottom_up.res3.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res4.0.conv1.*    | backbone.bottom_up.res4.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,512,1,1)       |\n",
      "| backbone.bottom_up.res4.0.conv2.*    | backbone.bottom_up.res4.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.0.conv3.*    | backbone.bottom_up.res4.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.0.shortcut.* | backbone.bottom_up.res4.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (1024,) (1024,) (1024,) (1024,) (1024,512,1,1)  |\n",
      "| backbone.bottom_up.res4.1.conv1.*    | backbone.bottom_up.res4.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.1.conv2.*    | backbone.bottom_up.res4.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.1.conv3.*    | backbone.bottom_up.res4.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.2.conv1.*    | backbone.bottom_up.res4.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.2.conv2.*    | backbone.bottom_up.res4.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.2.conv3.*    | backbone.bottom_up.res4.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.3.conv1.*    | backbone.bottom_up.res4.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.3.conv2.*    | backbone.bottom_up.res4.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.3.conv3.*    | backbone.bottom_up.res4.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.4.conv1.*    | backbone.bottom_up.res4.4.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.4.conv2.*    | backbone.bottom_up.res4.4.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.4.conv3.*    | backbone.bottom_up.res4.4.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.5.conv1.*    | backbone.bottom_up.res4.5.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.5.conv2.*    | backbone.bottom_up.res4.5.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.5.conv3.*    | backbone.bottom_up.res4.5.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res5.0.conv1.*    | backbone.bottom_up.res5.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,1024,1,1)      |\n",
      "| backbone.bottom_up.res5.0.conv2.*    | backbone.bottom_up.res5.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |\n",
      "| backbone.bottom_up.res5.0.conv3.*    | backbone.bottom_up.res5.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
      "| backbone.bottom_up.res5.0.shortcut.* | backbone.bottom_up.res5.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (2048,) (2048,) (2048,) (2048,) (2048,1024,1,1) |\n",
      "| backbone.bottom_up.res5.1.conv1.*    | backbone.bottom_up.res5.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |\n",
      "| backbone.bottom_up.res5.1.conv2.*    | backbone.bottom_up.res5.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |\n",
      "| backbone.bottom_up.res5.1.conv3.*    | backbone.bottom_up.res5.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
      "| backbone.bottom_up.res5.2.conv1.*    | backbone.bottom_up.res5.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |\n",
      "| backbone.bottom_up.res5.2.conv2.*    | backbone.bottom_up.res5.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |\n",
      "| backbone.bottom_up.res5.2.conv3.*    | backbone.bottom_up.res5.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
      "| backbone.bottom_up.stem.conv1.*      | backbone.bottom_up.stem.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}      | (64,) (64,) (64,) (64,) (64,3,7,7)              |\n",
      "| backbone.fpn_lateral2.*              | backbone.fpn_lateral2.{bias,weight}                                                                  | (256,) (256,256,1,1)                            |\n",
      "| backbone.fpn_lateral3.*              | backbone.fpn_lateral3.{bias,weight}                                                                  | (256,) (256,512,1,1)                            |\n",
      "| backbone.fpn_lateral4.*              | backbone.fpn_lateral4.{bias,weight}                                                                  | (256,) (256,1024,1,1)                           |\n",
      "| backbone.fpn_lateral5.*              | backbone.fpn_lateral5.{bias,weight}                                                                  | (256,) (256,2048,1,1)                           |\n",
      "| backbone.fpn_output2.*               | backbone.fpn_output2.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| backbone.fpn_output3.*               | backbone.fpn_output3.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| backbone.fpn_output4.*               | backbone.fpn_output4.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| backbone.fpn_output5.*               | backbone.fpn_output5.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| sem_seg_head.p2.0.*                  | sem_seg_head.p2.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p3.0.*                  | sem_seg_head.p3.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p4.0.*                  | sem_seg_head.p4.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p4.2.*                  | sem_seg_head.p4.2.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,128,3,3)                     |\n",
      "| sem_seg_head.p5.0.*                  | sem_seg_head.p5.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p5.2.*                  | sem_seg_head.p5.2.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,128,3,3)                     |\n",
      "| sem_seg_head.p5.4.*                  | sem_seg_head.p5.4.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,128,3,3)                     |\n",
      "| sem_seg_head.predictor.*             | sem_seg_head.predictor.{bias,weight}                                                                 | (17,) (17,128,1,1)                              |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/05 18:41:09 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(720, 720), max_size=2048, sample_style='choice')]\n",
      "\u001b[32m[07/05 18:41:09 d2.data.common]: \u001b[0mSerializing 699 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[07/05 18:41:09 d2.data.common]: \u001b[0mSerialized dataset takes 0.22 MiB\n",
      "\u001b[32m[07/05 18:41:09 d2.evaluation.evaluator]: \u001b[0mStart inference on 699 batches\n",
      "\u001b[32m[07/05 18:41:12 d2.evaluation.evaluator]: \u001b[0mInference done 11/699. Dataloading: 0.0018 s/iter. Inference: 0.0470 s/iter. Eval: 0.1527 s/iter. Total: 0.2014 s/iter. ETA=0:02:18\n",
      "\u001b[32m[07/05 18:41:17 d2.evaluation.evaluator]: \u001b[0mInference done 36/699. Dataloading: 0.0022 s/iter. Inference: 0.0467 s/iter. Eval: 0.1524 s/iter. Total: 0.2014 s/iter. ETA=0:02:13\n",
      "\u001b[32m[07/05 18:41:22 d2.evaluation.evaluator]: \u001b[0mInference done 61/699. Dataloading: 0.0023 s/iter. Inference: 0.0467 s/iter. Eval: 0.1530 s/iter. Total: 0.2021 s/iter. ETA=0:02:08\n",
      "\u001b[32m[07/05 18:41:27 d2.evaluation.evaluator]: \u001b[0mInference done 86/699. Dataloading: 0.0023 s/iter. Inference: 0.0467 s/iter. Eval: 0.1524 s/iter. Total: 0.2015 s/iter. ETA=0:02:03\n",
      "\u001b[32m[07/05 18:41:32 d2.evaluation.evaluator]: \u001b[0mInference done 112/699. Dataloading: 0.0023 s/iter. Inference: 0.0467 s/iter. Eval: 0.1516 s/iter. Total: 0.2006 s/iter. ETA=0:01:57\n",
      "\u001b[32m[07/05 18:41:38 d2.evaluation.evaluator]: \u001b[0mInference done 139/699. Dataloading: 0.0023 s/iter. Inference: 0.0467 s/iter. Eval: 0.1496 s/iter. Total: 0.1987 s/iter. ETA=0:01:51\n",
      "\u001b[32m[07/05 18:41:43 d2.evaluation.evaluator]: \u001b[0mInference done 165/699. Dataloading: 0.0023 s/iter. Inference: 0.0467 s/iter. Eval: 0.1491 s/iter. Total: 0.1982 s/iter. ETA=0:01:45\n",
      "\u001b[32m[07/05 18:41:48 d2.evaluation.evaluator]: \u001b[0mInference done 189/699. Dataloading: 0.0023 s/iter. Inference: 0.0467 s/iter. Eval: 0.1505 s/iter. Total: 0.1996 s/iter. ETA=0:01:41\n",
      "\u001b[32m[07/05 18:41:53 d2.evaluation.evaluator]: \u001b[0mInference done 214/699. Dataloading: 0.0023 s/iter. Inference: 0.0467 s/iter. Eval: 0.1510 s/iter. Total: 0.2001 s/iter. ETA=0:01:37\n",
      "\u001b[32m[07/05 18:41:58 d2.evaluation.evaluator]: \u001b[0mInference done 239/699. Dataloading: 0.0023 s/iter. Inference: 0.0467 s/iter. Eval: 0.1514 s/iter. Total: 0.2005 s/iter. ETA=0:01:32\n",
      "\u001b[32m[07/05 18:42:03 d2.evaluation.evaluator]: \u001b[0mInference done 264/699. Dataloading: 0.0023 s/iter. Inference: 0.0467 s/iter. Eval: 0.1514 s/iter. Total: 0.2005 s/iter. ETA=0:01:27\n",
      "\u001b[32m[07/05 18:42:08 d2.evaluation.evaluator]: \u001b[0mInference done 290/699. Dataloading: 0.0023 s/iter. Inference: 0.0467 s/iter. Eval: 0.1512 s/iter. Total: 0.2004 s/iter. ETA=0:01:21\n",
      "\u001b[32m[07/05 18:42:13 d2.evaluation.evaluator]: \u001b[0mInference done 315/699. Dataloading: 0.0023 s/iter. Inference: 0.0467 s/iter. Eval: 0.1514 s/iter. Total: 0.2005 s/iter. ETA=0:01:17\n",
      "\u001b[32m[07/05 18:42:18 d2.evaluation.evaluator]: \u001b[0mInference done 340/699. Dataloading: 0.0023 s/iter. Inference: 0.0467 s/iter. Eval: 0.1516 s/iter. Total: 0.2007 s/iter. ETA=0:01:12\n",
      "\u001b[32m[07/05 18:42:23 d2.evaluation.evaluator]: \u001b[0mInference done 365/699. Dataloading: 0.0023 s/iter. Inference: 0.0467 s/iter. Eval: 0.1517 s/iter. Total: 0.2008 s/iter. ETA=0:01:07\n",
      "\u001b[32m[07/05 18:42:28 d2.evaluation.evaluator]: \u001b[0mInference done 389/699. Dataloading: 0.0028 s/iter. Inference: 0.0467 s/iter. Eval: 0.1520 s/iter. Total: 0.2016 s/iter. ETA=0:01:02\n",
      "\u001b[32m[07/05 18:42:34 d2.evaluation.evaluator]: \u001b[0mInference done 414/699. Dataloading: 0.0027 s/iter. Inference: 0.0467 s/iter. Eval: 0.1522 s/iter. Total: 0.2018 s/iter. ETA=0:00:57\n",
      "\u001b[32m[07/05 18:42:39 d2.evaluation.evaluator]: \u001b[0mInference done 439/699. Dataloading: 0.0027 s/iter. Inference: 0.0467 s/iter. Eval: 0.1523 s/iter. Total: 0.2019 s/iter. ETA=0:00:52\n",
      "\u001b[32m[07/05 18:42:44 d2.evaluation.evaluator]: \u001b[0mInference done 465/699. Dataloading: 0.0027 s/iter. Inference: 0.0467 s/iter. Eval: 0.1518 s/iter. Total: 0.2013 s/iter. ETA=0:00:47\n",
      "\u001b[32m[07/05 18:42:49 d2.evaluation.evaluator]: \u001b[0mInference done 491/699. Dataloading: 0.0027 s/iter. Inference: 0.0467 s/iter. Eval: 0.1515 s/iter. Total: 0.2010 s/iter. ETA=0:00:41\n",
      "\u001b[32m[07/05 18:42:54 d2.evaluation.evaluator]: \u001b[0mInference done 517/699. Dataloading: 0.0026 s/iter. Inference: 0.0467 s/iter. Eval: 0.1513 s/iter. Total: 0.2008 s/iter. ETA=0:00:36\n",
      "\u001b[32m[07/05 18:42:59 d2.evaluation.evaluator]: \u001b[0mInference done 543/699. Dataloading: 0.0026 s/iter. Inference: 0.0467 s/iter. Eval: 0.1510 s/iter. Total: 0.2005 s/iter. ETA=0:00:31\n",
      "\u001b[32m[07/05 18:43:04 d2.evaluation.evaluator]: \u001b[0mInference done 568/699. Dataloading: 0.0026 s/iter. Inference: 0.0467 s/iter. Eval: 0.1512 s/iter. Total: 0.2006 s/iter. ETA=0:00:26\n",
      "\u001b[32m[07/05 18:43:09 d2.evaluation.evaluator]: \u001b[0mInference done 593/699. Dataloading: 0.0026 s/iter. Inference: 0.0467 s/iter. Eval: 0.1513 s/iter. Total: 0.2008 s/iter. ETA=0:00:21\n",
      "\u001b[32m[07/05 18:43:14 d2.evaluation.evaluator]: \u001b[0mInference done 618/699. Dataloading: 0.0026 s/iter. Inference: 0.0467 s/iter. Eval: 0.1516 s/iter. Total: 0.2010 s/iter. ETA=0:00:16\n",
      "\u001b[32m[07/05 18:43:19 d2.evaluation.evaluator]: \u001b[0mInference done 643/699. Dataloading: 0.0026 s/iter. Inference: 0.0467 s/iter. Eval: 0.1515 s/iter. Total: 0.2010 s/iter. ETA=0:00:11\n",
      "\u001b[32m[07/05 18:43:24 d2.evaluation.evaluator]: \u001b[0mInference done 669/699. Dataloading: 0.0026 s/iter. Inference: 0.0468 s/iter. Eval: 0.1512 s/iter. Total: 0.2007 s/iter. ETA=0:00:06\n",
      "\u001b[32m[07/05 18:43:29 d2.evaluation.evaluator]: \u001b[0mInference done 694/699. Dataloading: 0.0026 s/iter. Inference: 0.0468 s/iter. Eval: 0.1512 s/iter. Total: 0.2006 s/iter. ETA=0:00:01\n",
      "\u001b[32m[07/05 18:43:30 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:02:19.310548 (0.200736 s / iter per device, on 1 devices)\n",
      "\u001b[32m[07/05 18:43:30 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:32 (0.046753 s / iter per device, on 1 devices)\n",
      "\u001b[32m[07/05 18:43:30 d2.evaluation.sem_seg_evaluation]: \u001b[0mOrderedDict([('sem_seg', {'mIoU': 59.109173916664616, 'fwIoU': 90.29992091007246, 'IoU-Unlabeled': nan, 'IoU-Building': 90.85174158220632, 'IoU-Fence': 52.75508432204605, 'IoU-Pedestrian': 77.80347624257053, 'IoU-Pole': 51.466431871740916, 'IoU-Road': 96.38002808561362, 'IoU-SideWalk': 77.37134981057, 'IoU-Vegetation': 90.65411708444816, 'IoU-Vehicles': 90.53708141061355, 'IoU-Wall': 48.41082886240425, 'IoU-TrafficSign': 63.69188495893834, 'IoU-Sky': 94.13192463680893, 'IoU-TrafficLight': 52.42302694074984, 'IoU-Terrain': 59.26980685792338, 'IoU-ConstructionVehicle': nan, 'IoU-workzone_object': nan, 'IoU-Detour': nan, 'mACC': 81.06851130767284, 'pACC': 94.69178386088888, 'ACC-Unlabeled': nan, 'ACC-Building': 95.31148806447604, 'ACC-Fence': 68.70353738927103, 'ACC-Pedestrian': 88.06517819972468, 'ACC-Pole': 66.31511141807654, 'ACC-Road': 98.56870635531052, 'ACC-SideWalk': 84.6297632955071, 'ACC-Vegetation': 96.0827371463745, 'ACC-Vehicles': 95.40815464928261, 'ACC-Wall': 58.33630622919718, 'ACC-TrafficSign': 73.00335010133023, 'ACC-Sky': 97.41521759902089, 'ACC-TrafficLight': 61.86999599658589, 'ACC-Terrain': 70.18110055558941, 'ACC-ConstructionVehicle': nan, 'ACC-workzone_object': nan, 'ACC-Detour': nan})])\n",
      "\u001b[32m[07/05 18:43:30 d2.engine.defaults]: \u001b[0mEvaluation results for cityscapes_clear_val in csv format:\n",
      "\u001b[32m[07/05 18:43:30 d2.evaluation.testing]: \u001b[0mcopypaste: Task: sem_seg\n",
      "\u001b[32m[07/05 18:43:30 d2.evaluation.testing]: \u001b[0mcopypaste: mIoU,fwIoU,mACC,pACC\n",
      "\u001b[32m[07/05 18:43:30 d2.evaluation.testing]: \u001b[0mcopypaste: 59.1092,90.2999,81.0685,94.6918\n"
     ]
    }
   ],
   "source": [
    "#all cityscapes clear\n",
    "trainer_both = Detectron2Trainer('combined_clear_both_train', 'cityscapes_clear_val', output_folder='./output_both_clear_40k')\n",
    "trainer_both.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "07bed431",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/05 18:43:31 d2.engine.defaults]: \u001b[0mModel:\n",
      "SemanticSegmentor(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (sem_seg_head): SemSegFPNHead(\n",
      "    (p2): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "    )\n",
      "    (p3): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (1): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "    )\n",
      "    (p4): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (1): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      (2): Conv2d(\n",
      "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (3): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "    )\n",
      "    (p5): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (1): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      (2): Conv2d(\n",
      "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (3): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      (4): Conv2d(\n",
      "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (5): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "    )\n",
      "    (predictor): Conv2d(128, 17, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/05 18:43:31 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(720, 720), max_size=2048, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[07/05 18:43:31 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[07/05 18:43:31 d2.data.common]: \u001b[0mSerializing 18867 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[07/05 18:43:31 d2.data.common]: \u001b[0mSerialized dataset takes 5.94 MiB\n",
      "Last checkpoint: model_final.pth\n",
      "\u001b[32m[07/05 18:43:31 d2.checkpoint.c2_model_loading]: \u001b[0mFollowing weights matched with model:\n",
      "| Names in Model                       | Names in Checkpoint                                                                                  | Shapes                                          |\n",
      "|:-------------------------------------|:-----------------------------------------------------------------------------------------------------|:------------------------------------------------|\n",
      "| backbone.bottom_up.res2.0.conv1.*    | backbone.bottom_up.res2.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,1,1)             |\n",
      "| backbone.bottom_up.res2.0.conv2.*    | backbone.bottom_up.res2.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |\n",
      "| backbone.bottom_up.res2.0.conv3.*    | backbone.bottom_up.res2.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res2.0.shortcut.* | backbone.bottom_up.res2.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res2.1.conv1.*    | backbone.bottom_up.res2.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |\n",
      "| backbone.bottom_up.res2.1.conv2.*    | backbone.bottom_up.res2.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |\n",
      "| backbone.bottom_up.res2.1.conv3.*    | backbone.bottom_up.res2.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res2.2.conv1.*    | backbone.bottom_up.res2.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |\n",
      "| backbone.bottom_up.res2.2.conv2.*    | backbone.bottom_up.res2.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |\n",
      "| backbone.bottom_up.res2.2.conv3.*    | backbone.bottom_up.res2.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res3.0.conv1.*    | backbone.bottom_up.res3.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,256,1,1)       |\n",
      "| backbone.bottom_up.res3.0.conv2.*    | backbone.bottom_up.res3.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.0.conv3.*    | backbone.bottom_up.res3.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res3.0.shortcut.* | backbone.bottom_up.res3.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (512,) (512,) (512,) (512,) (512,256,1,1)       |\n",
      "| backbone.bottom_up.res3.1.conv1.*    | backbone.bottom_up.res3.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |\n",
      "| backbone.bottom_up.res3.1.conv2.*    | backbone.bottom_up.res3.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.1.conv3.*    | backbone.bottom_up.res3.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res3.2.conv1.*    | backbone.bottom_up.res3.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |\n",
      "| backbone.bottom_up.res3.2.conv2.*    | backbone.bottom_up.res3.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.2.conv3.*    | backbone.bottom_up.res3.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res3.3.conv1.*    | backbone.bottom_up.res3.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |\n",
      "| backbone.bottom_up.res3.3.conv2.*    | backbone.bottom_up.res3.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.3.conv3.*    | backbone.bottom_up.res3.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res4.0.conv1.*    | backbone.bottom_up.res4.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,512,1,1)       |\n",
      "| backbone.bottom_up.res4.0.conv2.*    | backbone.bottom_up.res4.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.0.conv3.*    | backbone.bottom_up.res4.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.0.shortcut.* | backbone.bottom_up.res4.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (1024,) (1024,) (1024,) (1024,) (1024,512,1,1)  |\n",
      "| backbone.bottom_up.res4.1.conv1.*    | backbone.bottom_up.res4.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.1.conv2.*    | backbone.bottom_up.res4.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.1.conv3.*    | backbone.bottom_up.res4.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.2.conv1.*    | backbone.bottom_up.res4.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.2.conv2.*    | backbone.bottom_up.res4.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.2.conv3.*    | backbone.bottom_up.res4.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.3.conv1.*    | backbone.bottom_up.res4.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.3.conv2.*    | backbone.bottom_up.res4.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.3.conv3.*    | backbone.bottom_up.res4.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.4.conv1.*    | backbone.bottom_up.res4.4.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.4.conv2.*    | backbone.bottom_up.res4.4.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.4.conv3.*    | backbone.bottom_up.res4.4.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.5.conv1.*    | backbone.bottom_up.res4.5.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.5.conv2.*    | backbone.bottom_up.res4.5.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.5.conv3.*    | backbone.bottom_up.res4.5.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res5.0.conv1.*    | backbone.bottom_up.res5.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,1024,1,1)      |\n",
      "| backbone.bottom_up.res5.0.conv2.*    | backbone.bottom_up.res5.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |\n",
      "| backbone.bottom_up.res5.0.conv3.*    | backbone.bottom_up.res5.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
      "| backbone.bottom_up.res5.0.shortcut.* | backbone.bottom_up.res5.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (2048,) (2048,) (2048,) (2048,) (2048,1024,1,1) |\n",
      "| backbone.bottom_up.res5.1.conv1.*    | backbone.bottom_up.res5.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |\n",
      "| backbone.bottom_up.res5.1.conv2.*    | backbone.bottom_up.res5.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |\n",
      "| backbone.bottom_up.res5.1.conv3.*    | backbone.bottom_up.res5.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
      "| backbone.bottom_up.res5.2.conv1.*    | backbone.bottom_up.res5.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |\n",
      "| backbone.bottom_up.res5.2.conv2.*    | backbone.bottom_up.res5.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |\n",
      "| backbone.bottom_up.res5.2.conv3.*    | backbone.bottom_up.res5.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
      "| backbone.bottom_up.stem.conv1.*      | backbone.bottom_up.stem.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}      | (64,) (64,) (64,) (64,) (64,3,7,7)              |\n",
      "| backbone.fpn_lateral2.*              | backbone.fpn_lateral2.{bias,weight}                                                                  | (256,) (256,256,1,1)                            |\n",
      "| backbone.fpn_lateral3.*              | backbone.fpn_lateral3.{bias,weight}                                                                  | (256,) (256,512,1,1)                            |\n",
      "| backbone.fpn_lateral4.*              | backbone.fpn_lateral4.{bias,weight}                                                                  | (256,) (256,1024,1,1)                           |\n",
      "| backbone.fpn_lateral5.*              | backbone.fpn_lateral5.{bias,weight}                                                                  | (256,) (256,2048,1,1)                           |\n",
      "| backbone.fpn_output2.*               | backbone.fpn_output2.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| backbone.fpn_output3.*               | backbone.fpn_output3.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| backbone.fpn_output4.*               | backbone.fpn_output4.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| backbone.fpn_output5.*               | backbone.fpn_output5.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| sem_seg_head.p2.0.*                  | sem_seg_head.p2.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p3.0.*                  | sem_seg_head.p3.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p4.0.*                  | sem_seg_head.p4.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p4.2.*                  | sem_seg_head.p4.2.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,128,3,3)                     |\n",
      "| sem_seg_head.p5.0.*                  | sem_seg_head.p5.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p5.2.*                  | sem_seg_head.p5.2.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,128,3,3)                     |\n",
      "| sem_seg_head.p5.4.*                  | sem_seg_head.p5.4.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,128,3,3)                     |\n",
      "| sem_seg_head.predictor.*             | sem_seg_head.predictor.{bias,weight}                                                                 | (17,) (17,128,1,1)                              |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/05 18:43:31 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(720, 720), max_size=2048, sample_style='choice')]\n",
      "\u001b[32m[07/05 18:43:31 d2.data.common]: \u001b[0mSerializing 7230 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[07/05 18:43:32 d2.data.common]: \u001b[0mSerialized dataset takes 2.25 MiB\n",
      "\u001b[32m[07/05 18:43:32 d2.evaluation.evaluator]: \u001b[0mStart inference on 7230 batches\n",
      "\u001b[32m[07/05 18:43:34 d2.evaluation.evaluator]: \u001b[0mInference done 31/7230. Dataloading: 0.0021 s/iter. Inference: 0.0350 s/iter. Eval: 0.0417 s/iter. Total: 0.0789 s/iter. ETA=0:09:27\n",
      "\u001b[32m[07/05 18:43:39 d2.evaluation.evaluator]: \u001b[0mInference done 97/7230. Dataloading: 0.0022 s/iter. Inference: 0.0351 s/iter. Eval: 0.0399 s/iter. Total: 0.0772 s/iter. ETA=0:09:10\n",
      "\u001b[32m[07/05 18:43:44 d2.evaluation.evaluator]: \u001b[0mInference done 164/7230. Dataloading: 0.0022 s/iter. Inference: 0.0351 s/iter. Eval: 0.0389 s/iter. Total: 0.0763 s/iter. ETA=0:08:59\n",
      "\u001b[32m[07/05 18:43:49 d2.evaluation.evaluator]: \u001b[0mInference done 230/7230. Dataloading: 0.0022 s/iter. Inference: 0.0352 s/iter. Eval: 0.0389 s/iter. Total: 0.0764 s/iter. ETA=0:08:54\n",
      "\u001b[32m[07/05 18:43:54 d2.evaluation.evaluator]: \u001b[0mInference done 295/7230. Dataloading: 0.0022 s/iter. Inference: 0.0352 s/iter. Eval: 0.0391 s/iter. Total: 0.0766 s/iter. ETA=0:08:51\n",
      "\u001b[32m[07/05 18:43:59 d2.evaluation.evaluator]: \u001b[0mInference done 361/7230. Dataloading: 0.0022 s/iter. Inference: 0.0352 s/iter. Eval: 0.0391 s/iter. Total: 0.0766 s/iter. ETA=0:08:45\n",
      "\u001b[32m[07/05 18:44:05 d2.evaluation.evaluator]: \u001b[0mInference done 429/7230. Dataloading: 0.0022 s/iter. Inference: 0.0352 s/iter. Eval: 0.0387 s/iter. Total: 0.0762 s/iter. ETA=0:08:38\n",
      "\u001b[32m[07/05 18:44:10 d2.evaluation.evaluator]: \u001b[0mInference done 496/7230. Dataloading: 0.0022 s/iter. Inference: 0.0353 s/iter. Eval: 0.0385 s/iter. Total: 0.0760 s/iter. ETA=0:08:32\n",
      "\u001b[32m[07/05 18:44:15 d2.evaluation.evaluator]: \u001b[0mInference done 563/7230. Dataloading: 0.0022 s/iter. Inference: 0.0353 s/iter. Eval: 0.0383 s/iter. Total: 0.0759 s/iter. ETA=0:08:26\n",
      "\u001b[32m[07/05 18:44:20 d2.evaluation.evaluator]: \u001b[0mInference done 630/7230. Dataloading: 0.0022 s/iter. Inference: 0.0353 s/iter. Eval: 0.0383 s/iter. Total: 0.0759 s/iter. ETA=0:08:20\n",
      "\u001b[32m[07/05 18:44:25 d2.evaluation.evaluator]: \u001b[0mInference done 697/7230. Dataloading: 0.0022 s/iter. Inference: 0.0353 s/iter. Eval: 0.0382 s/iter. Total: 0.0758 s/iter. ETA=0:08:15\n",
      "\u001b[32m[07/05 18:44:30 d2.evaluation.evaluator]: \u001b[0mInference done 762/7230. Dataloading: 0.0022 s/iter. Inference: 0.0353 s/iter. Eval: 0.0383 s/iter. Total: 0.0760 s/iter. ETA=0:08:11\n",
      "\u001b[32m[07/05 18:44:35 d2.evaluation.evaluator]: \u001b[0mInference done 827/7230. Dataloading: 0.0022 s/iter. Inference: 0.0353 s/iter. Eval: 0.0384 s/iter. Total: 0.0761 s/iter. ETA=0:08:07\n",
      "\u001b[32m[07/05 18:44:40 d2.evaluation.evaluator]: \u001b[0mInference done 891/7230. Dataloading: 0.0022 s/iter. Inference: 0.0353 s/iter. Eval: 0.0386 s/iter. Total: 0.0762 s/iter. ETA=0:08:03\n",
      "\u001b[32m[07/05 18:44:45 d2.evaluation.evaluator]: \u001b[0mInference done 955/7230. Dataloading: 0.0022 s/iter. Inference: 0.0354 s/iter. Eval: 0.0387 s/iter. Total: 0.0764 s/iter. ETA=0:07:59\n",
      "\u001b[32m[07/05 18:44:50 d2.evaluation.evaluator]: \u001b[0mInference done 1020/7230. Dataloading: 0.0022 s/iter. Inference: 0.0354 s/iter. Eval: 0.0387 s/iter. Total: 0.0764 s/iter. ETA=0:07:54\n",
      "\u001b[32m[07/05 18:44:55 d2.evaluation.evaluator]: \u001b[0mInference done 1086/7230. Dataloading: 0.0022 s/iter. Inference: 0.0354 s/iter. Eval: 0.0387 s/iter. Total: 0.0764 s/iter. ETA=0:07:49\n",
      "\u001b[32m[07/05 18:45:00 d2.evaluation.evaluator]: \u001b[0mInference done 1150/7230. Dataloading: 0.0022 s/iter. Inference: 0.0354 s/iter. Eval: 0.0389 s/iter. Total: 0.0766 s/iter. ETA=0:07:45\n",
      "\u001b[32m[07/05 18:45:05 d2.evaluation.evaluator]: \u001b[0mInference done 1215/7230. Dataloading: 0.0022 s/iter. Inference: 0.0354 s/iter. Eval: 0.0389 s/iter. Total: 0.0766 s/iter. ETA=0:07:40\n",
      "\u001b[32m[07/05 18:45:10 d2.evaluation.evaluator]: \u001b[0mInference done 1280/7230. Dataloading: 0.0022 s/iter. Inference: 0.0354 s/iter. Eval: 0.0389 s/iter. Total: 0.0766 s/iter. ETA=0:07:35\n",
      "\u001b[32m[07/05 18:45:15 d2.evaluation.evaluator]: \u001b[0mInference done 1345/7230. Dataloading: 0.0022 s/iter. Inference: 0.0354 s/iter. Eval: 0.0390 s/iter. Total: 0.0767 s/iter. ETA=0:07:31\n",
      "\u001b[32m[07/05 18:45:20 d2.evaluation.evaluator]: \u001b[0mInference done 1412/7230. Dataloading: 0.0022 s/iter. Inference: 0.0354 s/iter. Eval: 0.0389 s/iter. Total: 0.0766 s/iter. ETA=0:07:25\n",
      "\u001b[32m[07/05 18:45:25 d2.evaluation.evaluator]: \u001b[0mInference done 1477/7230. Dataloading: 0.0022 s/iter. Inference: 0.0354 s/iter. Eval: 0.0389 s/iter. Total: 0.0767 s/iter. ETA=0:07:20\n",
      "\u001b[32m[07/05 18:45:30 d2.evaluation.evaluator]: \u001b[0mInference done 1540/7230. Dataloading: 0.0022 s/iter. Inference: 0.0354 s/iter. Eval: 0.0391 s/iter. Total: 0.0768 s/iter. ETA=0:07:16\n",
      "\u001b[32m[07/05 18:45:35 d2.evaluation.evaluator]: \u001b[0mInference done 1605/7230. Dataloading: 0.0022 s/iter. Inference: 0.0354 s/iter. Eval: 0.0391 s/iter. Total: 0.0768 s/iter. ETA=0:07:11\n",
      "\u001b[32m[07/05 18:45:40 d2.evaluation.evaluator]: \u001b[0mInference done 1669/7230. Dataloading: 0.0022 s/iter. Inference: 0.0354 s/iter. Eval: 0.0392 s/iter. Total: 0.0769 s/iter. ETA=0:07:07\n",
      "\u001b[32m[07/05 18:45:45 d2.evaluation.evaluator]: \u001b[0mInference done 1733/7230. Dataloading: 0.0022 s/iter. Inference: 0.0354 s/iter. Eval: 0.0392 s/iter. Total: 0.0769 s/iter. ETA=0:07:02\n",
      "\u001b[32m[07/05 18:45:50 d2.evaluation.evaluator]: \u001b[0mInference done 1798/7230. Dataloading: 0.0022 s/iter. Inference: 0.0354 s/iter. Eval: 0.0392 s/iter. Total: 0.0770 s/iter. ETA=0:06:58\n",
      "\u001b[32m[07/05 18:45:55 d2.evaluation.evaluator]: \u001b[0mInference done 1861/7230. Dataloading: 0.0022 s/iter. Inference: 0.0354 s/iter. Eval: 0.0394 s/iter. Total: 0.0771 s/iter. ETA=0:06:53\n",
      "\u001b[32m[07/05 18:46:00 d2.evaluation.evaluator]: \u001b[0mInference done 1925/7230. Dataloading: 0.0022 s/iter. Inference: 0.0354 s/iter. Eval: 0.0394 s/iter. Total: 0.0771 s/iter. ETA=0:06:49\n",
      "\u001b[32m[07/05 18:46:05 d2.evaluation.evaluator]: \u001b[0mInference done 1990/7230. Dataloading: 0.0022 s/iter. Inference: 0.0354 s/iter. Eval: 0.0394 s/iter. Total: 0.0771 s/iter. ETA=0:06:44\n",
      "\u001b[32m[07/05 18:46:10 d2.evaluation.evaluator]: \u001b[0mInference done 2055/7230. Dataloading: 0.0022 s/iter. Inference: 0.0354 s/iter. Eval: 0.0394 s/iter. Total: 0.0771 s/iter. ETA=0:06:39\n",
      "\u001b[32m[07/05 18:46:15 d2.evaluation.evaluator]: \u001b[0mInference done 2121/7230. Dataloading: 0.0022 s/iter. Inference: 0.0354 s/iter. Eval: 0.0394 s/iter. Total: 0.0771 s/iter. ETA=0:06:34\n",
      "\u001b[32m[07/05 18:46:20 d2.evaluation.evaluator]: \u001b[0mInference done 2187/7230. Dataloading: 0.0022 s/iter. Inference: 0.0355 s/iter. Eval: 0.0394 s/iter. Total: 0.0771 s/iter. ETA=0:06:28\n",
      "\u001b[32m[07/05 18:46:26 d2.evaluation.evaluator]: \u001b[0mInference done 2253/7230. Dataloading: 0.0022 s/iter. Inference: 0.0355 s/iter. Eval: 0.0394 s/iter. Total: 0.0771 s/iter. ETA=0:06:23\n",
      "\u001b[32m[07/05 18:46:31 d2.evaluation.evaluator]: \u001b[0mInference done 2319/7230. Dataloading: 0.0022 s/iter. Inference: 0.0355 s/iter. Eval: 0.0393 s/iter. Total: 0.0771 s/iter. ETA=0:06:18\n",
      "\u001b[32m[07/05 18:46:36 d2.evaluation.evaluator]: \u001b[0mInference done 2385/7230. Dataloading: 0.0022 s/iter. Inference: 0.0355 s/iter. Eval: 0.0393 s/iter. Total: 0.0771 s/iter. ETA=0:06:13\n",
      "\u001b[32m[07/05 18:46:41 d2.evaluation.evaluator]: \u001b[0mInference done 2451/7230. Dataloading: 0.0022 s/iter. Inference: 0.0355 s/iter. Eval: 0.0393 s/iter. Total: 0.0771 s/iter. ETA=0:06:08\n",
      "\u001b[32m[07/05 18:46:46 d2.evaluation.evaluator]: \u001b[0mInference done 2517/7230. Dataloading: 0.0022 s/iter. Inference: 0.0355 s/iter. Eval: 0.0393 s/iter. Total: 0.0771 s/iter. ETA=0:06:03\n",
      "\u001b[32m[07/05 18:46:51 d2.evaluation.evaluator]: \u001b[0mInference done 2581/7230. Dataloading: 0.0022 s/iter. Inference: 0.0355 s/iter. Eval: 0.0393 s/iter. Total: 0.0771 s/iter. ETA=0:05:58\n",
      "\u001b[32m[07/05 18:46:56 d2.evaluation.evaluator]: \u001b[0mInference done 2647/7230. Dataloading: 0.0022 s/iter. Inference: 0.0355 s/iter. Eval: 0.0393 s/iter. Total: 0.0771 s/iter. ETA=0:05:53\n",
      "\u001b[32m[07/05 18:47:01 d2.evaluation.evaluator]: \u001b[0mInference done 2712/7230. Dataloading: 0.0022 s/iter. Inference: 0.0355 s/iter. Eval: 0.0393 s/iter. Total: 0.0771 s/iter. ETA=0:05:48\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/05 18:47:06 d2.evaluation.evaluator]: \u001b[0mInference done 2777/7230. Dataloading: 0.0022 s/iter. Inference: 0.0355 s/iter. Eval: 0.0393 s/iter. Total: 0.0771 s/iter. ETA=0:05:43\n",
      "\u001b[32m[07/05 18:47:11 d2.evaluation.evaluator]: \u001b[0mInference done 2842/7230. Dataloading: 0.0022 s/iter. Inference: 0.0355 s/iter. Eval: 0.0393 s/iter. Total: 0.0771 s/iter. ETA=0:05:38\n",
      "\u001b[32m[07/05 18:47:16 d2.evaluation.evaluator]: \u001b[0mInference done 2907/7230. Dataloading: 0.0022 s/iter. Inference: 0.0355 s/iter. Eval: 0.0393 s/iter. Total: 0.0771 s/iter. ETA=0:05:33\n",
      "\u001b[32m[07/05 18:47:21 d2.evaluation.evaluator]: \u001b[0mInference done 2972/7230. Dataloading: 0.0022 s/iter. Inference: 0.0355 s/iter. Eval: 0.0393 s/iter. Total: 0.0771 s/iter. ETA=0:05:28\n",
      "\u001b[32m[07/05 18:47:26 d2.evaluation.evaluator]: \u001b[0mInference done 3037/7230. Dataloading: 0.0022 s/iter. Inference: 0.0356 s/iter. Eval: 0.0393 s/iter. Total: 0.0771 s/iter. ETA=0:05:23\n",
      "\u001b[32m[07/05 18:47:31 d2.evaluation.evaluator]: \u001b[0mInference done 3102/7230. Dataloading: 0.0022 s/iter. Inference: 0.0356 s/iter. Eval: 0.0393 s/iter. Total: 0.0771 s/iter. ETA=0:05:18\n",
      "\u001b[32m[07/05 18:47:36 d2.evaluation.evaluator]: \u001b[0mInference done 3167/7230. Dataloading: 0.0022 s/iter. Inference: 0.0356 s/iter. Eval: 0.0393 s/iter. Total: 0.0771 s/iter. ETA=0:05:13\n",
      "\u001b[32m[07/05 18:47:41 d2.evaluation.evaluator]: \u001b[0mInference done 3232/7230. Dataloading: 0.0022 s/iter. Inference: 0.0356 s/iter. Eval: 0.0393 s/iter. Total: 0.0771 s/iter. ETA=0:05:08\n",
      "\u001b[32m[07/05 18:47:46 d2.evaluation.evaluator]: \u001b[0mInference done 3274/7230. Dataloading: 0.0022 s/iter. Inference: 0.0356 s/iter. Eval: 0.0398 s/iter. Total: 0.0777 s/iter. ETA=0:05:07\n",
      "\u001b[32m[07/05 18:47:51 d2.evaluation.evaluator]: \u001b[0mInference done 3300/7230. Dataloading: 0.0022 s/iter. Inference: 0.0357 s/iter. Eval: 0.0407 s/iter. Total: 0.0786 s/iter. ETA=0:05:09\n",
      "\u001b[32m[07/05 18:47:56 d2.evaluation.evaluator]: \u001b[0mInference done 3326/7230. Dataloading: 0.0022 s/iter. Inference: 0.0358 s/iter. Eval: 0.0415 s/iter. Total: 0.0795 s/iter. ETA=0:05:10\n",
      "\u001b[32m[07/05 18:48:01 d2.evaluation.evaluator]: \u001b[0mInference done 3352/7230. Dataloading: 0.0022 s/iter. Inference: 0.0359 s/iter. Eval: 0.0423 s/iter. Total: 0.0804 s/iter. ETA=0:05:11\n",
      "\u001b[32m[07/05 18:48:06 d2.evaluation.evaluator]: \u001b[0mInference done 3379/7230. Dataloading: 0.0022 s/iter. Inference: 0.0359 s/iter. Eval: 0.0431 s/iter. Total: 0.0813 s/iter. ETA=0:05:13\n",
      "\u001b[32m[07/05 18:48:12 d2.evaluation.evaluator]: \u001b[0mInference done 3407/7230. Dataloading: 0.0022 s/iter. Inference: 0.0360 s/iter. Eval: 0.0438 s/iter. Total: 0.0821 s/iter. ETA=0:05:13\n",
      "\u001b[32m[07/05 18:48:17 d2.evaluation.evaluator]: \u001b[0mInference done 3433/7230. Dataloading: 0.0022 s/iter. Inference: 0.0361 s/iter. Eval: 0.0446 s/iter. Total: 0.0829 s/iter. ETA=0:05:14\n",
      "\u001b[32m[07/05 18:48:22 d2.evaluation.evaluator]: \u001b[0mInference done 3459/7230. Dataloading: 0.0022 s/iter. Inference: 0.0362 s/iter. Eval: 0.0453 s/iter. Total: 0.0838 s/iter. ETA=0:05:16\n",
      "\u001b[32m[07/05 18:48:27 d2.evaluation.evaluator]: \u001b[0mInference done 3485/7230. Dataloading: 0.0022 s/iter. Inference: 0.0363 s/iter. Eval: 0.0461 s/iter. Total: 0.0847 s/iter. ETA=0:05:17\n",
      "\u001b[32m[07/05 18:48:32 d2.evaluation.evaluator]: \u001b[0mInference done 3511/7230. Dataloading: 0.0022 s/iter. Inference: 0.0363 s/iter. Eval: 0.0469 s/iter. Total: 0.0855 s/iter. ETA=0:05:17\n",
      "\u001b[32m[07/05 18:48:37 d2.evaluation.evaluator]: \u001b[0mInference done 3538/7230. Dataloading: 0.0022 s/iter. Inference: 0.0364 s/iter. Eval: 0.0476 s/iter. Total: 0.0863 s/iter. ETA=0:05:18\n",
      "\u001b[32m[07/05 18:48:42 d2.evaluation.evaluator]: \u001b[0mInference done 3564/7230. Dataloading: 0.0022 s/iter. Inference: 0.0365 s/iter. Eval: 0.0483 s/iter. Total: 0.0871 s/iter. ETA=0:05:19\n",
      "\u001b[32m[07/05 18:48:47 d2.evaluation.evaluator]: \u001b[0mInference done 3590/7230. Dataloading: 0.0022 s/iter. Inference: 0.0366 s/iter. Eval: 0.0490 s/iter. Total: 0.0879 s/iter. ETA=0:05:19\n",
      "\u001b[32m[07/05 18:48:52 d2.evaluation.evaluator]: \u001b[0mInference done 3617/7230. Dataloading: 0.0022 s/iter. Inference: 0.0366 s/iter. Eval: 0.0497 s/iter. Total: 0.0886 s/iter. ETA=0:05:20\n",
      "\u001b[32m[07/05 18:48:58 d2.evaluation.evaluator]: \u001b[0mInference done 3643/7230. Dataloading: 0.0022 s/iter. Inference: 0.0367 s/iter. Eval: 0.0504 s/iter. Total: 0.0894 s/iter. ETA=0:05:20\n",
      "\u001b[32m[07/05 18:49:03 d2.evaluation.evaluator]: \u001b[0mInference done 3669/7230. Dataloading: 0.0022 s/iter. Inference: 0.0368 s/iter. Eval: 0.0511 s/iter. Total: 0.0902 s/iter. ETA=0:05:21\n",
      "\u001b[32m[07/05 18:49:08 d2.evaluation.evaluator]: \u001b[0mInference done 3695/7230. Dataloading: 0.0022 s/iter. Inference: 0.0369 s/iter. Eval: 0.0518 s/iter. Total: 0.0909 s/iter. ETA=0:05:21\n",
      "\u001b[32m[07/05 18:49:13 d2.evaluation.evaluator]: \u001b[0mInference done 3722/7230. Dataloading: 0.0022 s/iter. Inference: 0.0369 s/iter. Eval: 0.0524 s/iter. Total: 0.0917 s/iter. ETA=0:05:21\n",
      "\u001b[32m[07/05 18:49:18 d2.evaluation.evaluator]: \u001b[0mInference done 3748/7230. Dataloading: 0.0022 s/iter. Inference: 0.0370 s/iter. Eval: 0.0531 s/iter. Total: 0.0924 s/iter. ETA=0:05:21\n",
      "\u001b[32m[07/05 18:49:23 d2.evaluation.evaluator]: \u001b[0mInference done 3774/7230. Dataloading: 0.0022 s/iter. Inference: 0.0371 s/iter. Eval: 0.0537 s/iter. Total: 0.0931 s/iter. ETA=0:05:21\n",
      "\u001b[32m[07/05 18:49:28 d2.evaluation.evaluator]: \u001b[0mInference done 3801/7230. Dataloading: 0.0022 s/iter. Inference: 0.0371 s/iter. Eval: 0.0543 s/iter. Total: 0.0938 s/iter. ETA=0:05:21\n",
      "\u001b[32m[07/05 18:49:33 d2.evaluation.evaluator]: \u001b[0mInference done 3827/7230. Dataloading: 0.0022 s/iter. Inference: 0.0372 s/iter. Eval: 0.0550 s/iter. Total: 0.0945 s/iter. ETA=0:05:21\n",
      "\u001b[32m[07/05 18:49:38 d2.evaluation.evaluator]: \u001b[0mInference done 3853/7230. Dataloading: 0.0022 s/iter. Inference: 0.0373 s/iter. Eval: 0.0556 s/iter. Total: 0.0952 s/iter. ETA=0:05:21\n",
      "\u001b[32m[07/05 18:49:44 d2.evaluation.evaluator]: \u001b[0mInference done 3879/7230. Dataloading: 0.0022 s/iter. Inference: 0.0373 s/iter. Eval: 0.0562 s/iter. Total: 0.0958 s/iter. ETA=0:05:21\n",
      "\u001b[32m[07/05 18:49:49 d2.evaluation.evaluator]: \u001b[0mInference done 3906/7230. Dataloading: 0.0022 s/iter. Inference: 0.0374 s/iter. Eval: 0.0568 s/iter. Total: 0.0965 s/iter. ETA=0:05:20\n",
      "\u001b[32m[07/05 18:49:54 d2.evaluation.evaluator]: \u001b[0mInference done 3932/7230. Dataloading: 0.0022 s/iter. Inference: 0.0375 s/iter. Eval: 0.0574 s/iter. Total: 0.0971 s/iter. ETA=0:05:20\n",
      "\u001b[32m[07/05 18:49:59 d2.evaluation.evaluator]: \u001b[0mInference done 3958/7230. Dataloading: 0.0022 s/iter. Inference: 0.0375 s/iter. Eval: 0.0580 s/iter. Total: 0.0978 s/iter. ETA=0:05:19\n",
      "\u001b[32m[07/05 18:50:04 d2.evaluation.evaluator]: \u001b[0mInference done 4020/7230. Dataloading: 0.0022 s/iter. Inference: 0.0375 s/iter. Eval: 0.0577 s/iter. Total: 0.0975 s/iter. ETA=0:05:13\n",
      "\u001b[32m[07/05 18:50:09 d2.evaluation.evaluator]: \u001b[0mInference done 4083/7230. Dataloading: 0.0022 s/iter. Inference: 0.0374 s/iter. Eval: 0.0575 s/iter. Total: 0.0972 s/iter. ETA=0:05:06\n",
      "\u001b[32m[07/05 18:50:14 d2.evaluation.evaluator]: \u001b[0mInference done 4147/7230. Dataloading: 0.0022 s/iter. Inference: 0.0374 s/iter. Eval: 0.0573 s/iter. Total: 0.0970 s/iter. ETA=0:04:58\n",
      "\u001b[32m[07/05 18:50:19 d2.evaluation.evaluator]: \u001b[0mInference done 4210/7230. Dataloading: 0.0022 s/iter. Inference: 0.0374 s/iter. Eval: 0.0570 s/iter. Total: 0.0967 s/iter. ETA=0:04:52\n",
      "\u001b[32m[07/05 18:50:24 d2.evaluation.evaluator]: \u001b[0mInference done 4273/7230. Dataloading: 0.0022 s/iter. Inference: 0.0373 s/iter. Eval: 0.0568 s/iter. Total: 0.0965 s/iter. ETA=0:04:45\n",
      "\u001b[32m[07/05 18:50:29 d2.evaluation.evaluator]: \u001b[0mInference done 4335/7230. Dataloading: 0.0022 s/iter. Inference: 0.0373 s/iter. Eval: 0.0566 s/iter. Total: 0.0963 s/iter. ETA=0:04:38\n",
      "\u001b[32m[07/05 18:50:34 d2.evaluation.evaluator]: \u001b[0mInference done 4397/7230. Dataloading: 0.0022 s/iter. Inference: 0.0373 s/iter. Eval: 0.0565 s/iter. Total: 0.0960 s/iter. ETA=0:04:32\n",
      "\u001b[32m[07/05 18:50:39 d2.evaluation.evaluator]: \u001b[0mInference done 4457/7230. Dataloading: 0.0022 s/iter. Inference: 0.0373 s/iter. Eval: 0.0563 s/iter. Total: 0.0959 s/iter. ETA=0:04:25\n",
      "\u001b[32m[07/05 18:50:44 d2.evaluation.evaluator]: \u001b[0mInference done 4518/7230. Dataloading: 0.0022 s/iter. Inference: 0.0372 s/iter. Eval: 0.0562 s/iter. Total: 0.0957 s/iter. ETA=0:04:19\n",
      "\u001b[32m[07/05 18:50:49 d2.evaluation.evaluator]: \u001b[0mInference done 4579/7230. Dataloading: 0.0022 s/iter. Inference: 0.0372 s/iter. Eval: 0.0560 s/iter. Total: 0.0955 s/iter. ETA=0:04:13\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/05 18:50:54 d2.evaluation.evaluator]: \u001b[0mInference done 4640/7230. Dataloading: 0.0022 s/iter. Inference: 0.0372 s/iter. Eval: 0.0559 s/iter. Total: 0.0953 s/iter. ETA=0:04:06\n",
      "\u001b[32m[07/05 18:50:59 d2.evaluation.evaluator]: \u001b[0mInference done 4701/7230. Dataloading: 0.0022 s/iter. Inference: 0.0372 s/iter. Eval: 0.0557 s/iter. Total: 0.0952 s/iter. ETA=0:04:00\n",
      "\u001b[32m[07/05 18:51:04 d2.evaluation.evaluator]: \u001b[0mInference done 4765/7230. Dataloading: 0.0022 s/iter. Inference: 0.0371 s/iter. Eval: 0.0555 s/iter. Total: 0.0949 s/iter. ETA=0:03:54\n",
      "\u001b[32m[07/05 18:51:09 d2.evaluation.evaluator]: \u001b[0mInference done 4830/7230. Dataloading: 0.0022 s/iter. Inference: 0.0371 s/iter. Eval: 0.0553 s/iter. Total: 0.0947 s/iter. ETA=0:03:47\n",
      "\u001b[32m[07/05 18:51:14 d2.evaluation.evaluator]: \u001b[0mInference done 4895/7230. Dataloading: 0.0022 s/iter. Inference: 0.0371 s/iter. Eval: 0.0551 s/iter. Total: 0.0945 s/iter. ETA=0:03:40\n",
      "\u001b[32m[07/05 18:51:19 d2.evaluation.evaluator]: \u001b[0mInference done 4960/7230. Dataloading: 0.0022 s/iter. Inference: 0.0371 s/iter. Eval: 0.0549 s/iter. Total: 0.0943 s/iter. ETA=0:03:33\n",
      "\u001b[32m[07/05 18:51:24 d2.evaluation.evaluator]: \u001b[0mInference done 5025/7230. Dataloading: 0.0022 s/iter. Inference: 0.0370 s/iter. Eval: 0.0547 s/iter. Total: 0.0941 s/iter. ETA=0:03:27\n",
      "\u001b[32m[07/05 18:51:29 d2.evaluation.evaluator]: \u001b[0mInference done 5090/7230. Dataloading: 0.0022 s/iter. Inference: 0.0370 s/iter. Eval: 0.0545 s/iter. Total: 0.0938 s/iter. ETA=0:03:20\n",
      "\u001b[32m[07/05 18:51:34 d2.evaluation.evaluator]: \u001b[0mInference done 5155/7230. Dataloading: 0.0022 s/iter. Inference: 0.0370 s/iter. Eval: 0.0543 s/iter. Total: 0.0936 s/iter. ETA=0:03:14\n",
      "\u001b[32m[07/05 18:51:39 d2.evaluation.evaluator]: \u001b[0mInference done 5220/7230. Dataloading: 0.0022 s/iter. Inference: 0.0370 s/iter. Eval: 0.0541 s/iter. Total: 0.0934 s/iter. ETA=0:03:07\n",
      "\u001b[32m[07/05 18:51:44 d2.evaluation.evaluator]: \u001b[0mInference done 5285/7230. Dataloading: 0.0022 s/iter. Inference: 0.0370 s/iter. Eval: 0.0540 s/iter. Total: 0.0932 s/iter. ETA=0:03:01\n",
      "\u001b[32m[07/05 18:51:50 d2.evaluation.evaluator]: \u001b[0mInference done 5349/7230. Dataloading: 0.0022 s/iter. Inference: 0.0370 s/iter. Eval: 0.0538 s/iter. Total: 0.0931 s/iter. ETA=0:02:55\n",
      "\u001b[32m[07/05 18:51:55 d2.evaluation.evaluator]: \u001b[0mInference done 5414/7230. Dataloading: 0.0022 s/iter. Inference: 0.0369 s/iter. Eval: 0.0536 s/iter. Total: 0.0929 s/iter. ETA=0:02:48\n",
      "\u001b[32m[07/05 18:52:00 d2.evaluation.evaluator]: \u001b[0mInference done 5480/7230. Dataloading: 0.0022 s/iter. Inference: 0.0369 s/iter. Eval: 0.0535 s/iter. Total: 0.0927 s/iter. ETA=0:02:42\n",
      "\u001b[32m[07/05 18:52:05 d2.evaluation.evaluator]: \u001b[0mInference done 5546/7230. Dataloading: 0.0022 s/iter. Inference: 0.0369 s/iter. Eval: 0.0533 s/iter. Total: 0.0925 s/iter. ETA=0:02:35\n",
      "\u001b[32m[07/05 18:52:10 d2.evaluation.evaluator]: \u001b[0mInference done 5611/7230. Dataloading: 0.0022 s/iter. Inference: 0.0369 s/iter. Eval: 0.0531 s/iter. Total: 0.0923 s/iter. ETA=0:02:29\n",
      "\u001b[32m[07/05 18:52:15 d2.evaluation.evaluator]: \u001b[0mInference done 5677/7230. Dataloading: 0.0022 s/iter. Inference: 0.0369 s/iter. Eval: 0.0530 s/iter. Total: 0.0921 s/iter. ETA=0:02:23\n",
      "\u001b[32m[07/05 18:52:20 d2.evaluation.evaluator]: \u001b[0mInference done 5742/7230. Dataloading: 0.0022 s/iter. Inference: 0.0369 s/iter. Eval: 0.0528 s/iter. Total: 0.0919 s/iter. ETA=0:02:16\n",
      "\u001b[32m[07/05 18:52:25 d2.evaluation.evaluator]: \u001b[0mInference done 5808/7230. Dataloading: 0.0022 s/iter. Inference: 0.0368 s/iter. Eval: 0.0526 s/iter. Total: 0.0918 s/iter. ETA=0:02:10\n",
      "\u001b[32m[07/05 18:52:30 d2.evaluation.evaluator]: \u001b[0mInference done 5875/7230. Dataloading: 0.0022 s/iter. Inference: 0.0368 s/iter. Eval: 0.0525 s/iter. Total: 0.0916 s/iter. ETA=0:02:04\n",
      "\u001b[32m[07/05 18:52:35 d2.evaluation.evaluator]: \u001b[0mInference done 5941/7230. Dataloading: 0.0022 s/iter. Inference: 0.0368 s/iter. Eval: 0.0523 s/iter. Total: 0.0914 s/iter. ETA=0:01:57\n",
      "\u001b[32m[07/05 18:52:40 d2.evaluation.evaluator]: \u001b[0mInference done 6007/7230. Dataloading: 0.0022 s/iter. Inference: 0.0368 s/iter. Eval: 0.0522 s/iter. Total: 0.0913 s/iter. ETA=0:01:51\n",
      "\u001b[32m[07/05 18:52:45 d2.evaluation.evaluator]: \u001b[0mInference done 6071/7230. Dataloading: 0.0022 s/iter. Inference: 0.0368 s/iter. Eval: 0.0520 s/iter. Total: 0.0911 s/iter. ETA=0:01:45\n",
      "\u001b[32m[07/05 18:52:50 d2.evaluation.evaluator]: \u001b[0mInference done 6136/7230. Dataloading: 0.0022 s/iter. Inference: 0.0368 s/iter. Eval: 0.0519 s/iter. Total: 0.0910 s/iter. ETA=0:01:39\n",
      "\u001b[32m[07/05 18:52:55 d2.evaluation.evaluator]: \u001b[0mInference done 6203/7230. Dataloading: 0.0022 s/iter. Inference: 0.0368 s/iter. Eval: 0.0517 s/iter. Total: 0.0908 s/iter. ETA=0:01:33\n",
      "\u001b[32m[07/05 18:53:00 d2.evaluation.evaluator]: \u001b[0mInference done 6269/7230. Dataloading: 0.0022 s/iter. Inference: 0.0368 s/iter. Eval: 0.0516 s/iter. Total: 0.0907 s/iter. ETA=0:01:27\n",
      "\u001b[32m[07/05 18:53:05 d2.evaluation.evaluator]: \u001b[0mInference done 6334/7230. Dataloading: 0.0022 s/iter. Inference: 0.0367 s/iter. Eval: 0.0515 s/iter. Total: 0.0905 s/iter. ETA=0:01:21\n",
      "\u001b[32m[07/05 18:53:10 d2.evaluation.evaluator]: \u001b[0mInference done 6398/7230. Dataloading: 0.0022 s/iter. Inference: 0.0367 s/iter. Eval: 0.0514 s/iter. Total: 0.0904 s/iter. ETA=0:01:15\n",
      "\u001b[32m[07/05 18:53:15 d2.evaluation.evaluator]: \u001b[0mInference done 6462/7230. Dataloading: 0.0022 s/iter. Inference: 0.0367 s/iter. Eval: 0.0513 s/iter. Total: 0.0903 s/iter. ETA=0:01:09\n",
      "\u001b[32m[07/05 18:53:20 d2.evaluation.evaluator]: \u001b[0mInference done 6527/7230. Dataloading: 0.0022 s/iter. Inference: 0.0367 s/iter. Eval: 0.0511 s/iter. Total: 0.0902 s/iter. ETA=0:01:03\n",
      "\u001b[32m[07/05 18:53:25 d2.evaluation.evaluator]: \u001b[0mInference done 6591/7230. Dataloading: 0.0022 s/iter. Inference: 0.0367 s/iter. Eval: 0.0510 s/iter. Total: 0.0900 s/iter. ETA=0:00:57\n",
      "\u001b[32m[07/05 18:53:30 d2.evaluation.evaluator]: \u001b[0mInference done 6656/7230. Dataloading: 0.0022 s/iter. Inference: 0.0367 s/iter. Eval: 0.0509 s/iter. Total: 0.0899 s/iter. ETA=0:00:51\n",
      "\u001b[32m[07/05 18:53:35 d2.evaluation.evaluator]: \u001b[0mInference done 6722/7230. Dataloading: 0.0022 s/iter. Inference: 0.0367 s/iter. Eval: 0.0508 s/iter. Total: 0.0898 s/iter. ETA=0:00:45\n",
      "\u001b[32m[07/05 18:53:40 d2.evaluation.evaluator]: \u001b[0mInference done 6787/7230. Dataloading: 0.0022 s/iter. Inference: 0.0367 s/iter. Eval: 0.0507 s/iter. Total: 0.0897 s/iter. ETA=0:00:39\n",
      "\u001b[32m[07/05 18:53:45 d2.evaluation.evaluator]: \u001b[0mInference done 6851/7230. Dataloading: 0.0022 s/iter. Inference: 0.0367 s/iter. Eval: 0.0506 s/iter. Total: 0.0896 s/iter. ETA=0:00:33\n",
      "\u001b[32m[07/05 18:53:50 d2.evaluation.evaluator]: \u001b[0mInference done 6913/7230. Dataloading: 0.0022 s/iter. Inference: 0.0366 s/iter. Eval: 0.0505 s/iter. Total: 0.0895 s/iter. ETA=0:00:28\n",
      "\u001b[32m[07/05 18:53:55 d2.evaluation.evaluator]: \u001b[0mInference done 6977/7230. Dataloading: 0.0022 s/iter. Inference: 0.0366 s/iter. Eval: 0.0504 s/iter. Total: 0.0894 s/iter. ETA=0:00:22\n",
      "\u001b[32m[07/05 18:54:00 d2.evaluation.evaluator]: \u001b[0mInference done 7041/7230. Dataloading: 0.0022 s/iter. Inference: 0.0366 s/iter. Eval: 0.0504 s/iter. Total: 0.0893 s/iter. ETA=0:00:16\n",
      "\u001b[32m[07/05 18:54:06 d2.evaluation.evaluator]: \u001b[0mInference done 7105/7230. Dataloading: 0.0022 s/iter. Inference: 0.0366 s/iter. Eval: 0.0503 s/iter. Total: 0.0892 s/iter. ETA=0:00:11\n",
      "\u001b[32m[07/05 18:54:11 d2.evaluation.evaluator]: \u001b[0mInference done 7171/7230. Dataloading: 0.0022 s/iter. Inference: 0.0366 s/iter. Eval: 0.0502 s/iter. Total: 0.0891 s/iter. ETA=0:00:05\n",
      "\u001b[32m[07/05 18:54:15 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:10:42.961700 (0.088991 s / iter per device, on 1 devices)\n",
      "\u001b[32m[07/05 18:54:15 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:04:24 (0.036596 s / iter per device, on 1 devices)\n",
      "\u001b[32m[07/05 18:54:16 d2.evaluation.sem_seg_evaluation]: \u001b[0mOrderedDict([('sem_seg', {'mIoU': 58.11008491674959, 'fwIoU': 82.64157505719815, 'IoU-Unlabeled': nan, 'IoU-Building': 76.775933141534, 'IoU-Fence': 31.120260731625205, 'IoU-Pedestrian': 71.08642400326166, 'IoU-Pole': 51.90466758331659, 'IoU-Road': 95.92553188019292, 'IoU-SideWalk': 75.59143433934075, 'IoU-Vegetation': 71.9016501255586, 'IoU-Vehicles': 77.61099794546813, 'IoU-Wall': 57.81166455047385, 'IoU-TrafficSign': 56.71872179278337, 'IoU-Sky': 84.71997424536167, 'IoU-TrafficLight': 54.68582109038503, 'IoU-Terrain': 27.418936746054978, 'IoU-ConstructionVehicle': 77.0649106769145, 'IoU-workzone_object': 58.06509255631046, 'IoU-Detour': 19.46942217616159, 'mACC': 73.30874842203914, 'pACC': 90.04065158420474, 'ACC-Unlabeled': nan, 'ACC-Building': 95.53545504111631, 'ACC-Fence': 50.71712393370166, 'ACC-Pedestrian': 85.85416376913386, 'ACC-Pole': 62.16232707483754, 'ACC-Road': 97.73829723521197, 'ACC-SideWalk': 86.74639794567757, 'ACC-Vegetation': 84.04677611287427, 'ACC-Vehicles': 92.07061268833479, 'ACC-Wall': 63.06942899514696, 'ACC-TrafficSign': 67.61112811338378, 'ACC-Sky': 87.71673987355582, 'ACC-TrafficLight': 65.480737844081, 'ACC-Terrain': 28.648761557768772, 'ACC-ConstructionVehicle': 94.46023558778212, 'ACC-workzone_object': 86.99015982163003, 'ACC-Detour': 24.0916291583897})])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/05 18:54:16 d2.engine.defaults]: \u001b[0mEvaluation results for combined_clear_both_val in csv format:\n",
      "\u001b[32m[07/05 18:54:16 d2.evaluation.testing]: \u001b[0mcopypaste: Task: sem_seg\n",
      "\u001b[32m[07/05 18:54:16 d2.evaluation.testing]: \u001b[0mcopypaste: mIoU,fwIoU,mACC,pACC\n",
      "\u001b[32m[07/05 18:54:16 d2.evaluation.testing]: \u001b[0mcopypaste: 58.1101,82.6416,73.3087,90.0407\n"
     ]
    }
   ],
   "source": [
    "#all clear\n",
    "trainer_both = Detectron2Trainer('combined_clear_both_train', 'combined_clear_both_val', output_folder='./output_both_clear_40k')\n",
    "trainer_both.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c0afa2c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/06 04:52:10 d2.engine.defaults]: \u001b[0mModel:\n",
      "SemanticSegmentor(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (sem_seg_head): SemSegFPNHead(\n",
      "    (p2): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "    )\n",
      "    (p3): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (1): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "    )\n",
      "    (p4): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (1): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      (2): Conv2d(\n",
      "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (3): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "    )\n",
      "    (p5): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (1): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      (2): Conv2d(\n",
      "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (3): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      (4): Conv2d(\n",
      "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (5): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "    )\n",
      "    (predictor): Conv2d(128, 17, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/06 04:52:10 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(720, 720), max_size=2048, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[07/06 04:52:10 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[07/06 04:52:10 d2.data.common]: \u001b[0mSerializing 2286 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[07/06 04:52:10 d2.data.common]: \u001b[0mSerialized dataset takes 0.84 MiB\n",
      "Last checkpoint: model_final.pth\n",
      "\u001b[32m[07/06 04:52:10 d2.checkpoint.c2_model_loading]: \u001b[0mFollowing weights matched with model:\n",
      "| Names in Model                       | Names in Checkpoint                                                                                  | Shapes                                          |\n",
      "|:-------------------------------------|:-----------------------------------------------------------------------------------------------------|:------------------------------------------------|\n",
      "| backbone.bottom_up.res2.0.conv1.*    | backbone.bottom_up.res2.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,1,1)             |\n",
      "| backbone.bottom_up.res2.0.conv2.*    | backbone.bottom_up.res2.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |\n",
      "| backbone.bottom_up.res2.0.conv3.*    | backbone.bottom_up.res2.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res2.0.shortcut.* | backbone.bottom_up.res2.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res2.1.conv1.*    | backbone.bottom_up.res2.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |\n",
      "| backbone.bottom_up.res2.1.conv2.*    | backbone.bottom_up.res2.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |\n",
      "| backbone.bottom_up.res2.1.conv3.*    | backbone.bottom_up.res2.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res2.2.conv1.*    | backbone.bottom_up.res2.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |\n",
      "| backbone.bottom_up.res2.2.conv2.*    | backbone.bottom_up.res2.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |\n",
      "| backbone.bottom_up.res2.2.conv3.*    | backbone.bottom_up.res2.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res3.0.conv1.*    | backbone.bottom_up.res3.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,256,1,1)       |\n",
      "| backbone.bottom_up.res3.0.conv2.*    | backbone.bottom_up.res3.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.0.conv3.*    | backbone.bottom_up.res3.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res3.0.shortcut.* | backbone.bottom_up.res3.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (512,) (512,) (512,) (512,) (512,256,1,1)       |\n",
      "| backbone.bottom_up.res3.1.conv1.*    | backbone.bottom_up.res3.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |\n",
      "| backbone.bottom_up.res3.1.conv2.*    | backbone.bottom_up.res3.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.1.conv3.*    | backbone.bottom_up.res3.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res3.2.conv1.*    | backbone.bottom_up.res3.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |\n",
      "| backbone.bottom_up.res3.2.conv2.*    | backbone.bottom_up.res3.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.2.conv3.*    | backbone.bottom_up.res3.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res3.3.conv1.*    | backbone.bottom_up.res3.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |\n",
      "| backbone.bottom_up.res3.3.conv2.*    | backbone.bottom_up.res3.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.3.conv3.*    | backbone.bottom_up.res3.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res4.0.conv1.*    | backbone.bottom_up.res4.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,512,1,1)       |\n",
      "| backbone.bottom_up.res4.0.conv2.*    | backbone.bottom_up.res4.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.0.conv3.*    | backbone.bottom_up.res4.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.0.shortcut.* | backbone.bottom_up.res4.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (1024,) (1024,) (1024,) (1024,) (1024,512,1,1)  |\n",
      "| backbone.bottom_up.res4.1.conv1.*    | backbone.bottom_up.res4.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.1.conv2.*    | backbone.bottom_up.res4.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.1.conv3.*    | backbone.bottom_up.res4.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.2.conv1.*    | backbone.bottom_up.res4.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.2.conv2.*    | backbone.bottom_up.res4.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.2.conv3.*    | backbone.bottom_up.res4.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.3.conv1.*    | backbone.bottom_up.res4.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.3.conv2.*    | backbone.bottom_up.res4.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.3.conv3.*    | backbone.bottom_up.res4.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.4.conv1.*    | backbone.bottom_up.res4.4.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.4.conv2.*    | backbone.bottom_up.res4.4.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.4.conv3.*    | backbone.bottom_up.res4.4.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.5.conv1.*    | backbone.bottom_up.res4.5.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.5.conv2.*    | backbone.bottom_up.res4.5.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.5.conv3.*    | backbone.bottom_up.res4.5.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res5.0.conv1.*    | backbone.bottom_up.res5.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,1024,1,1)      |\n",
      "| backbone.bottom_up.res5.0.conv2.*    | backbone.bottom_up.res5.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |\n",
      "| backbone.bottom_up.res5.0.conv3.*    | backbone.bottom_up.res5.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
      "| backbone.bottom_up.res5.0.shortcut.* | backbone.bottom_up.res5.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (2048,) (2048,) (2048,) (2048,) (2048,1024,1,1) |\n",
      "| backbone.bottom_up.res5.1.conv1.*    | backbone.bottom_up.res5.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |\n",
      "| backbone.bottom_up.res5.1.conv2.*    | backbone.bottom_up.res5.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |\n",
      "| backbone.bottom_up.res5.1.conv3.*    | backbone.bottom_up.res5.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
      "| backbone.bottom_up.res5.2.conv1.*    | backbone.bottom_up.res5.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |\n",
      "| backbone.bottom_up.res5.2.conv2.*    | backbone.bottom_up.res5.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |\n",
      "| backbone.bottom_up.res5.2.conv3.*    | backbone.bottom_up.res5.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
      "| backbone.bottom_up.stem.conv1.*      | backbone.bottom_up.stem.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}      | (64,) (64,) (64,) (64,) (64,3,7,7)              |\n",
      "| backbone.fpn_lateral2.*              | backbone.fpn_lateral2.{bias,weight}                                                                  | (256,) (256,256,1,1)                            |\n",
      "| backbone.fpn_lateral3.*              | backbone.fpn_lateral3.{bias,weight}                                                                  | (256,) (256,512,1,1)                            |\n",
      "| backbone.fpn_lateral4.*              | backbone.fpn_lateral4.{bias,weight}                                                                  | (256,) (256,1024,1,1)                           |\n",
      "| backbone.fpn_lateral5.*              | backbone.fpn_lateral5.{bias,weight}                                                                  | (256,) (256,2048,1,1)                           |\n",
      "| backbone.fpn_output2.*               | backbone.fpn_output2.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| backbone.fpn_output3.*               | backbone.fpn_output3.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| backbone.fpn_output4.*               | backbone.fpn_output4.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| backbone.fpn_output5.*               | backbone.fpn_output5.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| sem_seg_head.p2.0.*                  | sem_seg_head.p2.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p3.0.*                  | sem_seg_head.p3.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p4.0.*                  | sem_seg_head.p4.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p4.2.*                  | sem_seg_head.p4.2.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,128,3,3)                     |\n",
      "| sem_seg_head.p5.0.*                  | sem_seg_head.p5.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p5.2.*                  | sem_seg_head.p5.2.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,128,3,3)                     |\n",
      "| sem_seg_head.p5.4.*                  | sem_seg_head.p5.4.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,128,3,3)                     |\n",
      "| sem_seg_head.predictor.*             | sem_seg_head.predictor.{bias,weight}                                                                 | (17,) (17,128,1,1)                              |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/06 04:52:10 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(720, 720), max_size=2048, sample_style='choice')]\n",
      "\u001b[32m[07/06 04:52:10 d2.data.common]: \u001b[0mSerializing 2191 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[07/06 04:52:10 d2.data.common]: \u001b[0mSerialized dataset takes 0.81 MiB\n",
      "\u001b[32m[07/06 04:52:10 d2.evaluation.evaluator]: \u001b[0mStart inference on 2191 batches\n",
      "\u001b[32m[07/06 04:52:11 d2.evaluation.evaluator]: \u001b[0mInference done 11/2191. Dataloading: 0.0017 s/iter. Inference: 0.0352 s/iter. Eval: 0.0417 s/iter. Total: 0.0786 s/iter. ETA=0:02:51\n",
      "\u001b[32m[07/06 04:52:17 d2.evaluation.evaluator]: \u001b[0mInference done 77/2191. Dataloading: 0.0022 s/iter. Inference: 0.0348 s/iter. Eval: 0.0397 s/iter. Total: 0.0768 s/iter. ETA=0:02:42\n",
      "\u001b[32m[07/06 04:52:22 d2.evaluation.evaluator]: \u001b[0mInference done 143/2191. Dataloading: 0.0023 s/iter. Inference: 0.0348 s/iter. Eval: 0.0391 s/iter. Total: 0.0763 s/iter. ETA=0:02:36\n",
      "\u001b[32m[07/06 04:52:27 d2.evaluation.evaluator]: \u001b[0mInference done 210/2191. Dataloading: 0.0023 s/iter. Inference: 0.0349 s/iter. Eval: 0.0388 s/iter. Total: 0.0761 s/iter. ETA=0:02:30\n",
      "\u001b[32m[07/06 04:52:32 d2.evaluation.evaluator]: \u001b[0mInference done 276/2191. Dataloading: 0.0023 s/iter. Inference: 0.0349 s/iter. Eval: 0.0387 s/iter. Total: 0.0760 s/iter. ETA=0:02:25\n",
      "\u001b[32m[07/06 04:52:37 d2.evaluation.evaluator]: \u001b[0mInference done 342/2191. Dataloading: 0.0023 s/iter. Inference: 0.0350 s/iter. Eval: 0.0388 s/iter. Total: 0.0761 s/iter. ETA=0:02:20\n",
      "\u001b[32m[07/06 04:52:42 d2.evaluation.evaluator]: \u001b[0mInference done 408/2191. Dataloading: 0.0023 s/iter. Inference: 0.0350 s/iter. Eval: 0.0388 s/iter. Total: 0.0762 s/iter. ETA=0:02:15\n",
      "\u001b[32m[07/06 04:52:47 d2.evaluation.evaluator]: \u001b[0mInference done 474/2191. Dataloading: 0.0023 s/iter. Inference: 0.0350 s/iter. Eval: 0.0389 s/iter. Total: 0.0763 s/iter. ETA=0:02:11\n",
      "\u001b[32m[07/06 04:52:52 d2.evaluation.evaluator]: \u001b[0mInference done 539/2191. Dataloading: 0.0023 s/iter. Inference: 0.0350 s/iter. Eval: 0.0390 s/iter. Total: 0.0764 s/iter. ETA=0:02:06\n",
      "\u001b[32m[07/06 04:52:57 d2.evaluation.evaluator]: \u001b[0mInference done 602/2191. Dataloading: 0.0023 s/iter. Inference: 0.0352 s/iter. Eval: 0.0391 s/iter. Total: 0.0768 s/iter. ETA=0:02:01\n",
      "\u001b[32m[07/06 04:53:02 d2.evaluation.evaluator]: \u001b[0mInference done 666/2191. Dataloading: 0.0023 s/iter. Inference: 0.0352 s/iter. Eval: 0.0393 s/iter. Total: 0.0769 s/iter. ETA=0:01:57\n",
      "\u001b[32m[07/06 04:53:07 d2.evaluation.evaluator]: \u001b[0mInference done 732/2191. Dataloading: 0.0023 s/iter. Inference: 0.0352 s/iter. Eval: 0.0393 s/iter. Total: 0.0769 s/iter. ETA=0:01:52\n",
      "\u001b[32m[07/06 04:53:12 d2.evaluation.evaluator]: \u001b[0mInference done 798/2191. Dataloading: 0.0023 s/iter. Inference: 0.0352 s/iter. Eval: 0.0392 s/iter. Total: 0.0769 s/iter. ETA=0:01:47\n",
      "\u001b[32m[07/06 04:53:17 d2.evaluation.evaluator]: \u001b[0mInference done 864/2191. Dataloading: 0.0023 s/iter. Inference: 0.0352 s/iter. Eval: 0.0392 s/iter. Total: 0.0769 s/iter. ETA=0:01:42\n",
      "\u001b[32m[07/06 04:53:22 d2.evaluation.evaluator]: \u001b[0mInference done 929/2191. Dataloading: 0.0023 s/iter. Inference: 0.0353 s/iter. Eval: 0.0393 s/iter. Total: 0.0769 s/iter. ETA=0:01:37\n",
      "\u001b[32m[07/06 04:53:27 d2.evaluation.evaluator]: \u001b[0mInference done 994/2191. Dataloading: 0.0023 s/iter. Inference: 0.0353 s/iter. Eval: 0.0393 s/iter. Total: 0.0769 s/iter. ETA=0:01:32\n",
      "\u001b[32m[07/06 04:53:32 d2.evaluation.evaluator]: \u001b[0mInference done 1060/2191. Dataloading: 0.0023 s/iter. Inference: 0.0353 s/iter. Eval: 0.0392 s/iter. Total: 0.0769 s/iter. ETA=0:01:26\n",
      "\u001b[32m[07/06 04:53:37 d2.evaluation.evaluator]: \u001b[0mInference done 1125/2191. Dataloading: 0.0023 s/iter. Inference: 0.0353 s/iter. Eval: 0.0393 s/iter. Total: 0.0769 s/iter. ETA=0:01:22\n",
      "\u001b[32m[07/06 04:53:42 d2.evaluation.evaluator]: \u001b[0mInference done 1188/2191. Dataloading: 0.0023 s/iter. Inference: 0.0353 s/iter. Eval: 0.0394 s/iter. Total: 0.0771 s/iter. ETA=0:01:17\n",
      "\u001b[32m[07/06 04:53:47 d2.evaluation.evaluator]: \u001b[0mInference done 1250/2191. Dataloading: 0.0023 s/iter. Inference: 0.0353 s/iter. Eval: 0.0396 s/iter. Total: 0.0773 s/iter. ETA=0:01:12\n",
      "\u001b[32m[07/06 04:53:52 d2.evaluation.evaluator]: \u001b[0mInference done 1312/2191. Dataloading: 0.0023 s/iter. Inference: 0.0353 s/iter. Eval: 0.0398 s/iter. Total: 0.0774 s/iter. ETA=0:01:08\n",
      "\u001b[32m[07/06 04:53:57 d2.evaluation.evaluator]: \u001b[0mInference done 1375/2191. Dataloading: 0.0023 s/iter. Inference: 0.0353 s/iter. Eval: 0.0399 s/iter. Total: 0.0775 s/iter. ETA=0:01:03\n",
      "\u001b[32m[07/06 04:54:02 d2.evaluation.evaluator]: \u001b[0mInference done 1442/2191. Dataloading: 0.0023 s/iter. Inference: 0.0353 s/iter. Eval: 0.0398 s/iter. Total: 0.0774 s/iter. ETA=0:00:57\n",
      "\u001b[32m[07/06 04:54:07 d2.evaluation.evaluator]: \u001b[0mInference done 1508/2191. Dataloading: 0.0023 s/iter. Inference: 0.0353 s/iter. Eval: 0.0397 s/iter. Total: 0.0773 s/iter. ETA=0:00:52\n",
      "\u001b[32m[07/06 04:54:12 d2.evaluation.evaluator]: \u001b[0mInference done 1574/2191. Dataloading: 0.0023 s/iter. Inference: 0.0353 s/iter. Eval: 0.0396 s/iter. Total: 0.0773 s/iter. ETA=0:00:47\n",
      "\u001b[32m[07/06 04:54:17 d2.evaluation.evaluator]: \u001b[0mInference done 1639/2191. Dataloading: 0.0023 s/iter. Inference: 0.0353 s/iter. Eval: 0.0397 s/iter. Total: 0.0773 s/iter. ETA=0:00:42\n",
      "\u001b[32m[07/06 04:54:22 d2.evaluation.evaluator]: \u001b[0mInference done 1705/2191. Dataloading: 0.0023 s/iter. Inference: 0.0353 s/iter. Eval: 0.0396 s/iter. Total: 0.0773 s/iter. ETA=0:00:37\n",
      "\u001b[32m[07/06 04:54:27 d2.evaluation.evaluator]: \u001b[0mInference done 1771/2191. Dataloading: 0.0023 s/iter. Inference: 0.0353 s/iter. Eval: 0.0396 s/iter. Total: 0.0773 s/iter. ETA=0:00:32\n",
      "\u001b[32m[07/06 04:54:32 d2.evaluation.evaluator]: \u001b[0mInference done 1837/2191. Dataloading: 0.0023 s/iter. Inference: 0.0353 s/iter. Eval: 0.0395 s/iter. Total: 0.0772 s/iter. ETA=0:00:27\n",
      "\u001b[32m[07/06 04:54:38 d2.evaluation.evaluator]: \u001b[0mInference done 1903/2191. Dataloading: 0.0023 s/iter. Inference: 0.0353 s/iter. Eval: 0.0395 s/iter. Total: 0.0772 s/iter. ETA=0:00:22\n",
      "\u001b[32m[07/06 04:54:43 d2.evaluation.evaluator]: \u001b[0mInference done 1969/2191. Dataloading: 0.0023 s/iter. Inference: 0.0353 s/iter. Eval: 0.0395 s/iter. Total: 0.0772 s/iter. ETA=0:00:17\n",
      "\u001b[32m[07/06 04:54:48 d2.evaluation.evaluator]: \u001b[0mInference done 2035/2191. Dataloading: 0.0023 s/iter. Inference: 0.0353 s/iter. Eval: 0.0394 s/iter. Total: 0.0772 s/iter. ETA=0:00:12\n",
      "\u001b[32m[07/06 04:54:53 d2.evaluation.evaluator]: \u001b[0mInference done 2099/2191. Dataloading: 0.0023 s/iter. Inference: 0.0353 s/iter. Eval: 0.0395 s/iter. Total: 0.0772 s/iter. ETA=0:00:07\n",
      "\u001b[32m[07/06 04:54:58 d2.evaluation.evaluator]: \u001b[0mInference done 2166/2191. Dataloading: 0.0023 s/iter. Inference: 0.0353 s/iter. Eval: 0.0394 s/iter. Total: 0.0771 s/iter. ETA=0:00:01\n",
      "\u001b[32m[07/06 04:55:00 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:02:48.661016 (0.077155 s / iter per device, on 1 devices)\n",
      "\u001b[32m[07/06 04:55:00 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:01:17 (0.035341 s / iter per device, on 1 devices)\n",
      "\u001b[32m[07/06 04:55:00 d2.evaluation.sem_seg_evaluation]: \u001b[0mOrderedDict([('sem_seg', {'mIoU': 47.13831553828105, 'fwIoU': 63.869316402419415, 'IoU-Unlabeled': nan, 'IoU-Building': 51.22974920396123, 'IoU-Fence': 22.165029009901133, 'IoU-Pedestrian': 23.379534488184824, 'IoU-Pole': 46.72541920568305, 'IoU-Road': 88.13623878004965, 'IoU-SideWalk': 61.32361593793375, 'IoU-Vegetation': 55.906681752306945, 'IoU-Vehicles': 38.593360391033336, 'IoU-Wall': 45.77109594935323, 'IoU-TrafficSign': 44.69653366240339, 'IoU-Sky': 48.9326954479969, 'IoU-TrafficLight': 59.67495626174723, 'IoU-Terrain': 19.851295356934624, 'IoU-ConstructionVehicle': 84.29871170512362, 'IoU-workzone_object': 54.565953734455384, 'IoU-Detour': 8.962177725428608, 'mACC': 63.1515218936127, 'pACC': 76.16343399222188, 'ACC-Unlabeled': nan, 'ACC-Building': 96.84274647687975, 'ACC-Fence': 28.813088145730507, 'ACC-Pedestrian': 66.18988587678597, 'ACC-Pole': 55.96352024915148, 'ACC-Road': 90.91140038699567, 'ACC-SideWalk': 77.99711201963456, 'ACC-Vegetation': 65.65055155661038, 'ACC-Vehicles': 89.35426662469489, 'ACC-Wall': 57.219339688889335, 'ACC-TrafficSign': 55.78198976480767, 'ACC-Sky': 49.554235180539784, 'ACC-TrafficLight': 69.61620077567775, 'ACC-Terrain': 21.097226441711044, 'ACC-ConstructionVehicle': 91.94772961104806, 'ACC-workzone_object': 80.32038373187342, 'ACC-Detour': 13.164673766773042})])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/06 04:55:00 d2.engine.defaults]: \u001b[0mEvaluation results for carla_both_rain_val in csv format:\n",
      "\u001b[32m[07/06 04:55:00 d2.evaluation.testing]: \u001b[0mcopypaste: Task: sem_seg\n",
      "\u001b[32m[07/06 04:55:00 d2.evaluation.testing]: \u001b[0mcopypaste: mIoU,fwIoU,mACC,pACC\n",
      "\u001b[32m[07/06 04:55:00 d2.evaluation.testing]: \u001b[0mcopypaste: 47.1383,63.8693,63.1515,76.1634\n"
     ]
    }
   ],
   "source": [
    "#all carla rain\n",
    "trainer_both = Detectron2Trainer('combined_clear_both_train', 'carla_both_rain_val', output_folder='./output_both_clear_40k')\n",
    "trainer_both.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0e58e596",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/06 04:55:00 d2.engine.defaults]: \u001b[0mModel:\n",
      "SemanticSegmentor(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (sem_seg_head): SemSegFPNHead(\n",
      "    (p2): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "    )\n",
      "    (p3): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (1): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "    )\n",
      "    (p4): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (1): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      (2): Conv2d(\n",
      "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (3): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "    )\n",
      "    (p5): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (1): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      (2): Conv2d(\n",
      "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (3): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      (4): Conv2d(\n",
      "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (5): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "    )\n",
      "    (predictor): Conv2d(128, 17, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/06 04:55:00 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(720, 720), max_size=2048, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[07/06 04:55:00 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[07/06 04:55:00 d2.data.common]: \u001b[0mSerializing 2286 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[07/06 04:55:00 d2.data.common]: \u001b[0mSerialized dataset takes 0.84 MiB\n",
      "Last checkpoint: model_final.pth\n",
      "\u001b[32m[07/06 04:55:01 d2.checkpoint.c2_model_loading]: \u001b[0mFollowing weights matched with model:\n",
      "| Names in Model                       | Names in Checkpoint                                                                                  | Shapes                                          |\n",
      "|:-------------------------------------|:-----------------------------------------------------------------------------------------------------|:------------------------------------------------|\n",
      "| backbone.bottom_up.res2.0.conv1.*    | backbone.bottom_up.res2.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,1,1)             |\n",
      "| backbone.bottom_up.res2.0.conv2.*    | backbone.bottom_up.res2.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |\n",
      "| backbone.bottom_up.res2.0.conv3.*    | backbone.bottom_up.res2.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res2.0.shortcut.* | backbone.bottom_up.res2.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res2.1.conv1.*    | backbone.bottom_up.res2.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |\n",
      "| backbone.bottom_up.res2.1.conv2.*    | backbone.bottom_up.res2.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |\n",
      "| backbone.bottom_up.res2.1.conv3.*    | backbone.bottom_up.res2.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res2.2.conv1.*    | backbone.bottom_up.res2.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |\n",
      "| backbone.bottom_up.res2.2.conv2.*    | backbone.bottom_up.res2.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |\n",
      "| backbone.bottom_up.res2.2.conv3.*    | backbone.bottom_up.res2.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res3.0.conv1.*    | backbone.bottom_up.res3.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,256,1,1)       |\n",
      "| backbone.bottom_up.res3.0.conv2.*    | backbone.bottom_up.res3.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.0.conv3.*    | backbone.bottom_up.res3.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res3.0.shortcut.* | backbone.bottom_up.res3.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (512,) (512,) (512,) (512,) (512,256,1,1)       |\n",
      "| backbone.bottom_up.res3.1.conv1.*    | backbone.bottom_up.res3.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |\n",
      "| backbone.bottom_up.res3.1.conv2.*    | backbone.bottom_up.res3.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.1.conv3.*    | backbone.bottom_up.res3.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res3.2.conv1.*    | backbone.bottom_up.res3.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |\n",
      "| backbone.bottom_up.res3.2.conv2.*    | backbone.bottom_up.res3.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.2.conv3.*    | backbone.bottom_up.res3.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res3.3.conv1.*    | backbone.bottom_up.res3.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |\n",
      "| backbone.bottom_up.res3.3.conv2.*    | backbone.bottom_up.res3.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.3.conv3.*    | backbone.bottom_up.res3.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res4.0.conv1.*    | backbone.bottom_up.res4.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,512,1,1)       |\n",
      "| backbone.bottom_up.res4.0.conv2.*    | backbone.bottom_up.res4.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.0.conv3.*    | backbone.bottom_up.res4.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.0.shortcut.* | backbone.bottom_up.res4.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (1024,) (1024,) (1024,) (1024,) (1024,512,1,1)  |\n",
      "| backbone.bottom_up.res4.1.conv1.*    | backbone.bottom_up.res4.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.1.conv2.*    | backbone.bottom_up.res4.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.1.conv3.*    | backbone.bottom_up.res4.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.2.conv1.*    | backbone.bottom_up.res4.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.2.conv2.*    | backbone.bottom_up.res4.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.2.conv3.*    | backbone.bottom_up.res4.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.3.conv1.*    | backbone.bottom_up.res4.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.3.conv2.*    | backbone.bottom_up.res4.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.3.conv3.*    | backbone.bottom_up.res4.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.4.conv1.*    | backbone.bottom_up.res4.4.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.4.conv2.*    | backbone.bottom_up.res4.4.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.4.conv3.*    | backbone.bottom_up.res4.4.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.5.conv1.*    | backbone.bottom_up.res4.5.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.5.conv2.*    | backbone.bottom_up.res4.5.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.5.conv3.*    | backbone.bottom_up.res4.5.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res5.0.conv1.*    | backbone.bottom_up.res5.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,1024,1,1)      |\n",
      "| backbone.bottom_up.res5.0.conv2.*    | backbone.bottom_up.res5.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |\n",
      "| backbone.bottom_up.res5.0.conv3.*    | backbone.bottom_up.res5.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
      "| backbone.bottom_up.res5.0.shortcut.* | backbone.bottom_up.res5.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (2048,) (2048,) (2048,) (2048,) (2048,1024,1,1) |\n",
      "| backbone.bottom_up.res5.1.conv1.*    | backbone.bottom_up.res5.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |\n",
      "| backbone.bottom_up.res5.1.conv2.*    | backbone.bottom_up.res5.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |\n",
      "| backbone.bottom_up.res5.1.conv3.*    | backbone.bottom_up.res5.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
      "| backbone.bottom_up.res5.2.conv1.*    | backbone.bottom_up.res5.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |\n",
      "| backbone.bottom_up.res5.2.conv2.*    | backbone.bottom_up.res5.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |\n",
      "| backbone.bottom_up.res5.2.conv3.*    | backbone.bottom_up.res5.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
      "| backbone.bottom_up.stem.conv1.*      | backbone.bottom_up.stem.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}      | (64,) (64,) (64,) (64,) (64,3,7,7)              |\n",
      "| backbone.fpn_lateral2.*              | backbone.fpn_lateral2.{bias,weight}                                                                  | (256,) (256,256,1,1)                            |\n",
      "| backbone.fpn_lateral3.*              | backbone.fpn_lateral3.{bias,weight}                                                                  | (256,) (256,512,1,1)                            |\n",
      "| backbone.fpn_lateral4.*              | backbone.fpn_lateral4.{bias,weight}                                                                  | (256,) (256,1024,1,1)                           |\n",
      "| backbone.fpn_lateral5.*              | backbone.fpn_lateral5.{bias,weight}                                                                  | (256,) (256,2048,1,1)                           |\n",
      "| backbone.fpn_output2.*               | backbone.fpn_output2.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| backbone.fpn_output3.*               | backbone.fpn_output3.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| backbone.fpn_output4.*               | backbone.fpn_output4.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| backbone.fpn_output5.*               | backbone.fpn_output5.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| sem_seg_head.p2.0.*                  | sem_seg_head.p2.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p3.0.*                  | sem_seg_head.p3.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p4.0.*                  | sem_seg_head.p4.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p4.2.*                  | sem_seg_head.p4.2.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,128,3,3)                     |\n",
      "| sem_seg_head.p5.0.*                  | sem_seg_head.p5.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p5.2.*                  | sem_seg_head.p5.2.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,128,3,3)                     |\n",
      "| sem_seg_head.p5.4.*                  | sem_seg_head.p5.4.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,128,3,3)                     |\n",
      "| sem_seg_head.predictor.*             | sem_seg_head.predictor.{bias,weight}                                                                 | (17,) (17,128,1,1)                              |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/06 04:55:01 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(720, 720), max_size=2048, sample_style='choice')]\n",
      "\u001b[32m[07/06 04:55:01 d2.data.common]: \u001b[0mSerializing 699 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[07/06 04:55:01 d2.data.common]: \u001b[0mSerialized dataset takes 0.24 MiB\n",
      "\u001b[32m[07/06 04:55:01 d2.evaluation.evaluator]: \u001b[0mStart inference on 699 batches\n",
      "\u001b[32m[07/06 04:55:04 d2.evaluation.evaluator]: \u001b[0mInference done 11/699. Dataloading: 0.0018 s/iter. Inference: 0.0468 s/iter. Eval: 0.1554 s/iter. Total: 0.2040 s/iter. ETA=0:02:20\n",
      "\u001b[32m[07/06 04:55:09 d2.evaluation.evaluator]: \u001b[0mInference done 36/699. Dataloading: 0.0020 s/iter. Inference: 0.0467 s/iter. Eval: 0.1526 s/iter. Total: 0.2014 s/iter. ETA=0:02:13\n",
      "\u001b[32m[07/06 04:55:14 d2.evaluation.evaluator]: \u001b[0mInference done 61/699. Dataloading: 0.0020 s/iter. Inference: 0.0467 s/iter. Eval: 0.1532 s/iter. Total: 0.2020 s/iter. ETA=0:02:08\n",
      "\u001b[32m[07/06 04:55:19 d2.evaluation.evaluator]: \u001b[0mInference done 87/699. Dataloading: 0.0020 s/iter. Inference: 0.0466 s/iter. Eval: 0.1512 s/iter. Total: 0.1999 s/iter. ETA=0:02:02\n",
      "\u001b[32m[07/06 04:55:24 d2.evaluation.evaluator]: \u001b[0mInference done 113/699. Dataloading: 0.0020 s/iter. Inference: 0.0467 s/iter. Eval: 0.1493 s/iter. Total: 0.1981 s/iter. ETA=0:01:56\n",
      "\u001b[32m[07/06 04:55:29 d2.evaluation.evaluator]: \u001b[0mInference done 141/699. Dataloading: 0.0020 s/iter. Inference: 0.0464 s/iter. Eval: 0.1467 s/iter. Total: 0.1953 s/iter. ETA=0:01:48\n",
      "\u001b[32m[07/06 04:55:34 d2.evaluation.evaluator]: \u001b[0mInference done 168/699. Dataloading: 0.0020 s/iter. Inference: 0.0465 s/iter. Eval: 0.1459 s/iter. Total: 0.1944 s/iter. ETA=0:01:43\n",
      "\u001b[32m[07/06 04:55:39 d2.evaluation.evaluator]: \u001b[0mInference done 193/699. Dataloading: 0.0020 s/iter. Inference: 0.0465 s/iter. Eval: 0.1474 s/iter. Total: 0.1960 s/iter. ETA=0:01:39\n",
      "\u001b[32m[07/06 04:55:44 d2.evaluation.evaluator]: \u001b[0mInference done 218/699. Dataloading: 0.0020 s/iter. Inference: 0.0465 s/iter. Eval: 0.1481 s/iter. Total: 0.1967 s/iter. ETA=0:01:34\n",
      "\u001b[32m[07/06 04:55:49 d2.evaluation.evaluator]: \u001b[0mInference done 244/699. Dataloading: 0.0020 s/iter. Inference: 0.0466 s/iter. Eval: 0.1483 s/iter. Total: 0.1970 s/iter. ETA=0:01:29\n",
      "\u001b[32m[07/06 04:55:55 d2.evaluation.evaluator]: \u001b[0mInference done 270/699. Dataloading: 0.0020 s/iter. Inference: 0.0466 s/iter. Eval: 0.1483 s/iter. Total: 0.1970 s/iter. ETA=0:01:24\n",
      "\u001b[32m[07/06 04:56:00 d2.evaluation.evaluator]: \u001b[0mInference done 295/699. Dataloading: 0.0020 s/iter. Inference: 0.0466 s/iter. Eval: 0.1487 s/iter. Total: 0.1974 s/iter. ETA=0:01:19\n",
      "\u001b[32m[07/06 04:56:05 d2.evaluation.evaluator]: \u001b[0mInference done 320/699. Dataloading: 0.0020 s/iter. Inference: 0.0466 s/iter. Eval: 0.1490 s/iter. Total: 0.1977 s/iter. ETA=0:01:14\n",
      "\u001b[32m[07/06 04:56:10 d2.evaluation.evaluator]: \u001b[0mInference done 345/699. Dataloading: 0.0020 s/iter. Inference: 0.0466 s/iter. Eval: 0.1492 s/iter. Total: 0.1980 s/iter. ETA=0:01:10\n",
      "\u001b[32m[07/06 04:56:15 d2.evaluation.evaluator]: \u001b[0mInference done 370/699. Dataloading: 0.0020 s/iter. Inference: 0.0466 s/iter. Eval: 0.1495 s/iter. Total: 0.1983 s/iter. ETA=0:01:05\n",
      "\u001b[32m[07/06 04:56:20 d2.evaluation.evaluator]: \u001b[0mInference done 395/699. Dataloading: 0.0020 s/iter. Inference: 0.0466 s/iter. Eval: 0.1499 s/iter. Total: 0.1987 s/iter. ETA=0:01:00\n",
      "\u001b[32m[07/06 04:56:25 d2.evaluation.evaluator]: \u001b[0mInference done 420/699. Dataloading: 0.0020 s/iter. Inference: 0.0466 s/iter. Eval: 0.1500 s/iter. Total: 0.1988 s/iter. ETA=0:00:55\n",
      "\u001b[32m[07/06 04:56:30 d2.evaluation.evaluator]: \u001b[0mInference done 446/699. Dataloading: 0.0020 s/iter. Inference: 0.0467 s/iter. Eval: 0.1500 s/iter. Total: 0.1988 s/iter. ETA=0:00:50\n",
      "\u001b[32m[07/06 04:56:35 d2.evaluation.evaluator]: \u001b[0mInference done 472/699. Dataloading: 0.0020 s/iter. Inference: 0.0466 s/iter. Eval: 0.1497 s/iter. Total: 0.1985 s/iter. ETA=0:00:45\n",
      "\u001b[32m[07/06 04:56:40 d2.evaluation.evaluator]: \u001b[0mInference done 497/699. Dataloading: 0.0020 s/iter. Inference: 0.0466 s/iter. Eval: 0.1500 s/iter. Total: 0.1987 s/iter. ETA=0:00:40\n",
      "\u001b[32m[07/06 04:56:45 d2.evaluation.evaluator]: \u001b[0mInference done 523/699. Dataloading: 0.0020 s/iter. Inference: 0.0466 s/iter. Eval: 0.1500 s/iter. Total: 0.1988 s/iter. ETA=0:00:34\n",
      "\u001b[32m[07/06 04:56:50 d2.evaluation.evaluator]: \u001b[0mInference done 549/699. Dataloading: 0.0020 s/iter. Inference: 0.0466 s/iter. Eval: 0.1500 s/iter. Total: 0.1988 s/iter. ETA=0:00:29\n",
      "\u001b[32m[07/06 04:56:56 d2.evaluation.evaluator]: \u001b[0mInference done 574/699. Dataloading: 0.0020 s/iter. Inference: 0.0466 s/iter. Eval: 0.1501 s/iter. Total: 0.1989 s/iter. ETA=0:00:24\n",
      "\u001b[32m[07/06 04:57:01 d2.evaluation.evaluator]: \u001b[0mInference done 599/699. Dataloading: 0.0020 s/iter. Inference: 0.0467 s/iter. Eval: 0.1503 s/iter. Total: 0.1990 s/iter. ETA=0:00:19\n",
      "\u001b[32m[07/06 04:57:06 d2.evaluation.evaluator]: \u001b[0mInference done 624/699. Dataloading: 0.0020 s/iter. Inference: 0.0467 s/iter. Eval: 0.1504 s/iter. Total: 0.1991 s/iter. ETA=0:00:14\n",
      "\u001b[32m[07/06 04:57:11 d2.evaluation.evaluator]: \u001b[0mInference done 651/699. Dataloading: 0.0020 s/iter. Inference: 0.0467 s/iter. Eval: 0.1500 s/iter. Total: 0.1988 s/iter. ETA=0:00:09\n",
      "\u001b[32m[07/06 04:57:16 d2.evaluation.evaluator]: \u001b[0mInference done 677/699. Dataloading: 0.0020 s/iter. Inference: 0.0467 s/iter. Eval: 0.1499 s/iter. Total: 0.1987 s/iter. ETA=0:00:04\n",
      "\u001b[32m[07/06 04:57:20 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:02:18.090518 (0.198978 s / iter per device, on 1 devices)\n",
      "\u001b[32m[07/06 04:57:20 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:32 (0.046777 s / iter per device, on 1 devices)\n",
      "\u001b[32m[07/06 04:57:21 d2.evaluation.sem_seg_evaluation]: \u001b[0mOrderedDict([('sem_seg', {'mIoU': 63.68298492053618, 'fwIoU': 87.71037738279568, 'IoU-Unlabeled': nan, 'IoU-Building': 87.1203477384973, 'IoU-Fence': 45.14641956982099, 'IoU-Pedestrian': 74.3988975479838, 'IoU-Pole': 48.69026280648849, 'IoU-Road': 95.45965573006715, 'IoU-SideWalk': 74.85370356693515, 'IoU-Vegetation': 88.54424990104344, 'IoU-Vehicles': 89.10106811528166, 'IoU-Wall': 42.22215034670448, 'IoU-TrafficSign': 61.23761846941298, 'IoU-Sky': 80.96396781175213, 'IoU-TrafficLight': 49.577456500553296, 'IoU-Terrain': 54.24599078296579, 'IoU-ConstructionVehicle': nan, 'IoU-workzone_object': nan, 'IoU-Detour': nan, 'mACC': 77.99854423198417, 'pACC': 93.13637058662617, 'ACC-Unlabeled': nan, 'ACC-Building': 95.6692606124102, 'ACC-Fence': 53.77024277923167, 'ACC-Pedestrian': 86.94473297406515, 'ACC-Pole': 62.304519234525934, 'ACC-Road': 97.24618715711642, 'ACC-SideWalk': 84.82500221276965, 'ACC-Vegetation': 93.77392292290992, 'ACC-Vehicles': 94.48535919302732, 'ACC-Wall': 57.95494971572852, 'ACC-TrafficSign': 69.38663576861276, 'ACC-Sky': 83.42578290580968, 'ACC-TrafficLight': 58.410530458710085, 'ACC-Terrain': 75.78394908087674, 'ACC-ConstructionVehicle': nan, 'ACC-workzone_object': nan, 'ACC-Detour': nan})])\n",
      "\u001b[32m[07/06 04:57:21 d2.engine.defaults]: \u001b[0mEvaluation results for cityscapes_rain_val in csv format:\n",
      "\u001b[32m[07/06 04:57:21 d2.evaluation.testing]: \u001b[0mcopypaste: Task: sem_seg\n",
      "\u001b[32m[07/06 04:57:21 d2.evaluation.testing]: \u001b[0mcopypaste: mIoU,fwIoU,mACC,pACC\n",
      "\u001b[32m[07/06 04:57:21 d2.evaluation.testing]: \u001b[0mcopypaste: 63.6830,87.7104,77.9985,93.1364\n"
     ]
    }
   ],
   "source": [
    "#all cityscapes rain\n",
    "trainer_both = Detectron2Trainer('combined_clear_both_train', 'cityscapes_rain_val', output_folder='./output_both_clear_40k')\n",
    "trainer_both.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "34b6f134",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/06 04:57:21 d2.engine.defaults]: \u001b[0mModel:\n",
      "SemanticSegmentor(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (sem_seg_head): SemSegFPNHead(\n",
      "    (p2): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "    )\n",
      "    (p3): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (1): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "    )\n",
      "    (p4): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (1): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      (2): Conv2d(\n",
      "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (3): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "    )\n",
      "    (p5): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (1): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      (2): Conv2d(\n",
      "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (3): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      (4): Conv2d(\n",
      "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (5): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "    )\n",
      "    (predictor): Conv2d(128, 17, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/06 04:57:21 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(720, 720), max_size=2048, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[07/06 04:57:21 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[07/06 04:57:21 d2.data.common]: \u001b[0mSerializing 2286 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[07/06 04:57:21 d2.data.common]: \u001b[0mSerialized dataset takes 0.84 MiB\n",
      "Last checkpoint: model_final.pth\n",
      "\u001b[32m[07/06 04:57:21 d2.checkpoint.c2_model_loading]: \u001b[0mFollowing weights matched with model:\n",
      "| Names in Model                       | Names in Checkpoint                                                                                  | Shapes                                          |\n",
      "|:-------------------------------------|:-----------------------------------------------------------------------------------------------------|:------------------------------------------------|\n",
      "| backbone.bottom_up.res2.0.conv1.*    | backbone.bottom_up.res2.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,1,1)             |\n",
      "| backbone.bottom_up.res2.0.conv2.*    | backbone.bottom_up.res2.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |\n",
      "| backbone.bottom_up.res2.0.conv3.*    | backbone.bottom_up.res2.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res2.0.shortcut.* | backbone.bottom_up.res2.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res2.1.conv1.*    | backbone.bottom_up.res2.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |\n",
      "| backbone.bottom_up.res2.1.conv2.*    | backbone.bottom_up.res2.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |\n",
      "| backbone.bottom_up.res2.1.conv3.*    | backbone.bottom_up.res2.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res2.2.conv1.*    | backbone.bottom_up.res2.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |\n",
      "| backbone.bottom_up.res2.2.conv2.*    | backbone.bottom_up.res2.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |\n",
      "| backbone.bottom_up.res2.2.conv3.*    | backbone.bottom_up.res2.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res3.0.conv1.*    | backbone.bottom_up.res3.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,256,1,1)       |\n",
      "| backbone.bottom_up.res3.0.conv2.*    | backbone.bottom_up.res3.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.0.conv3.*    | backbone.bottom_up.res3.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res3.0.shortcut.* | backbone.bottom_up.res3.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (512,) (512,) (512,) (512,) (512,256,1,1)       |\n",
      "| backbone.bottom_up.res3.1.conv1.*    | backbone.bottom_up.res3.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |\n",
      "| backbone.bottom_up.res3.1.conv2.*    | backbone.bottom_up.res3.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.1.conv3.*    | backbone.bottom_up.res3.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res3.2.conv1.*    | backbone.bottom_up.res3.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |\n",
      "| backbone.bottom_up.res3.2.conv2.*    | backbone.bottom_up.res3.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.2.conv3.*    | backbone.bottom_up.res3.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res3.3.conv1.*    | backbone.bottom_up.res3.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |\n",
      "| backbone.bottom_up.res3.3.conv2.*    | backbone.bottom_up.res3.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.3.conv3.*    | backbone.bottom_up.res3.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res4.0.conv1.*    | backbone.bottom_up.res4.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,512,1,1)       |\n",
      "| backbone.bottom_up.res4.0.conv2.*    | backbone.bottom_up.res4.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.0.conv3.*    | backbone.bottom_up.res4.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.0.shortcut.* | backbone.bottom_up.res4.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (1024,) (1024,) (1024,) (1024,) (1024,512,1,1)  |\n",
      "| backbone.bottom_up.res4.1.conv1.*    | backbone.bottom_up.res4.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.1.conv2.*    | backbone.bottom_up.res4.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.1.conv3.*    | backbone.bottom_up.res4.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.2.conv1.*    | backbone.bottom_up.res4.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.2.conv2.*    | backbone.bottom_up.res4.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.2.conv3.*    | backbone.bottom_up.res4.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.3.conv1.*    | backbone.bottom_up.res4.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.3.conv2.*    | backbone.bottom_up.res4.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.3.conv3.*    | backbone.bottom_up.res4.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.4.conv1.*    | backbone.bottom_up.res4.4.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.4.conv2.*    | backbone.bottom_up.res4.4.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.4.conv3.*    | backbone.bottom_up.res4.4.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.5.conv1.*    | backbone.bottom_up.res4.5.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.5.conv2.*    | backbone.bottom_up.res4.5.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.5.conv3.*    | backbone.bottom_up.res4.5.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res5.0.conv1.*    | backbone.bottom_up.res5.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,1024,1,1)      |\n",
      "| backbone.bottom_up.res5.0.conv2.*    | backbone.bottom_up.res5.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |\n",
      "| backbone.bottom_up.res5.0.conv3.*    | backbone.bottom_up.res5.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
      "| backbone.bottom_up.res5.0.shortcut.* | backbone.bottom_up.res5.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (2048,) (2048,) (2048,) (2048,) (2048,1024,1,1) |\n",
      "| backbone.bottom_up.res5.1.conv1.*    | backbone.bottom_up.res5.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |\n",
      "| backbone.bottom_up.res5.1.conv2.*    | backbone.bottom_up.res5.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |\n",
      "| backbone.bottom_up.res5.1.conv3.*    | backbone.bottom_up.res5.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
      "| backbone.bottom_up.res5.2.conv1.*    | backbone.bottom_up.res5.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |\n",
      "| backbone.bottom_up.res5.2.conv2.*    | backbone.bottom_up.res5.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |\n",
      "| backbone.bottom_up.res5.2.conv3.*    | backbone.bottom_up.res5.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
      "| backbone.bottom_up.stem.conv1.*      | backbone.bottom_up.stem.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}      | (64,) (64,) (64,) (64,) (64,3,7,7)              |\n",
      "| backbone.fpn_lateral2.*              | backbone.fpn_lateral2.{bias,weight}                                                                  | (256,) (256,256,1,1)                            |\n",
      "| backbone.fpn_lateral3.*              | backbone.fpn_lateral3.{bias,weight}                                                                  | (256,) (256,512,1,1)                            |\n",
      "| backbone.fpn_lateral4.*              | backbone.fpn_lateral4.{bias,weight}                                                                  | (256,) (256,1024,1,1)                           |\n",
      "| backbone.fpn_lateral5.*              | backbone.fpn_lateral5.{bias,weight}                                                                  | (256,) (256,2048,1,1)                           |\n",
      "| backbone.fpn_output2.*               | backbone.fpn_output2.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| backbone.fpn_output3.*               | backbone.fpn_output3.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| backbone.fpn_output4.*               | backbone.fpn_output4.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| backbone.fpn_output5.*               | backbone.fpn_output5.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| sem_seg_head.p2.0.*                  | sem_seg_head.p2.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p3.0.*                  | sem_seg_head.p3.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p4.0.*                  | sem_seg_head.p4.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p4.2.*                  | sem_seg_head.p4.2.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,128,3,3)                     |\n",
      "| sem_seg_head.p5.0.*                  | sem_seg_head.p5.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p5.2.*                  | sem_seg_head.p5.2.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,128,3,3)                     |\n",
      "| sem_seg_head.p5.4.*                  | sem_seg_head.p5.4.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,128,3,3)                     |\n",
      "| sem_seg_head.predictor.*             | sem_seg_head.predictor.{bias,weight}                                                                 | (17,) (17,128,1,1)                              |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/06 04:57:21 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(720, 720), max_size=2048, sample_style='choice')]\n",
      "\u001b[32m[07/06 04:57:21 d2.data.common]: \u001b[0mSerializing 2890 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[07/06 04:57:21 d2.data.common]: \u001b[0mSerialized dataset takes 1.05 MiB\n",
      "\u001b[32m[07/06 04:57:21 d2.evaluation.evaluator]: \u001b[0mStart inference on 2890 batches\n",
      "\u001b[32m[07/06 04:57:23 d2.evaluation.evaluator]: \u001b[0mInference done 11/2890. Dataloading: 0.0017 s/iter. Inference: 0.0358 s/iter. Eval: 0.0425 s/iter. Total: 0.0800 s/iter. ETA=0:03:50\n",
      "\u001b[32m[07/06 04:57:28 d2.evaluation.evaluator]: \u001b[0mInference done 76/2890. Dataloading: 0.0021 s/iter. Inference: 0.0352 s/iter. Eval: 0.0401 s/iter. Total: 0.0774 s/iter. ETA=0:03:37\n",
      "\u001b[32m[07/06 04:57:33 d2.evaluation.evaluator]: \u001b[0mInference done 142/2890. Dataloading: 0.0021 s/iter. Inference: 0.0352 s/iter. Eval: 0.0396 s/iter. Total: 0.0769 s/iter. ETA=0:03:31\n",
      "\u001b[32m[07/06 04:57:38 d2.evaluation.evaluator]: \u001b[0mInference done 208/2890. Dataloading: 0.0021 s/iter. Inference: 0.0352 s/iter. Eval: 0.0395 s/iter. Total: 0.0769 s/iter. ETA=0:03:26\n",
      "\u001b[32m[07/06 04:57:43 d2.evaluation.evaluator]: \u001b[0mInference done 274/2890. Dataloading: 0.0021 s/iter. Inference: 0.0352 s/iter. Eval: 0.0395 s/iter. Total: 0.0769 s/iter. ETA=0:03:21\n",
      "\u001b[32m[07/06 04:57:48 d2.evaluation.evaluator]: \u001b[0mInference done 338/2890. Dataloading: 0.0021 s/iter. Inference: 0.0353 s/iter. Eval: 0.0397 s/iter. Total: 0.0772 s/iter. ETA=0:03:16\n",
      "\u001b[32m[07/06 04:57:53 d2.evaluation.evaluator]: \u001b[0mInference done 403/2890. Dataloading: 0.0021 s/iter. Inference: 0.0353 s/iter. Eval: 0.0398 s/iter. Total: 0.0772 s/iter. ETA=0:03:12\n",
      "\u001b[32m[07/06 04:57:58 d2.evaluation.evaluator]: \u001b[0mInference done 467/2890. Dataloading: 0.0021 s/iter. Inference: 0.0353 s/iter. Eval: 0.0399 s/iter. Total: 0.0774 s/iter. ETA=0:03:07\n",
      "\u001b[32m[07/06 04:58:03 d2.evaluation.evaluator]: \u001b[0mInference done 532/2890. Dataloading: 0.0021 s/iter. Inference: 0.0353 s/iter. Eval: 0.0400 s/iter. Total: 0.0775 s/iter. ETA=0:03:02\n",
      "\u001b[32m[07/06 04:58:08 d2.evaluation.evaluator]: \u001b[0mInference done 596/2890. Dataloading: 0.0021 s/iter. Inference: 0.0353 s/iter. Eval: 0.0402 s/iter. Total: 0.0776 s/iter. ETA=0:02:58\n",
      "\u001b[32m[07/06 04:58:13 d2.evaluation.evaluator]: \u001b[0mInference done 659/2890. Dataloading: 0.0021 s/iter. Inference: 0.0353 s/iter. Eval: 0.0404 s/iter. Total: 0.0779 s/iter. ETA=0:02:53\n",
      "\u001b[32m[07/06 04:58:18 d2.evaluation.evaluator]: \u001b[0mInference done 725/2890. Dataloading: 0.0021 s/iter. Inference: 0.0354 s/iter. Eval: 0.0402 s/iter. Total: 0.0778 s/iter. ETA=0:02:48\n",
      "\u001b[32m[07/06 04:58:23 d2.evaluation.evaluator]: \u001b[0mInference done 791/2890. Dataloading: 0.0021 s/iter. Inference: 0.0354 s/iter. Eval: 0.0401 s/iter. Total: 0.0776 s/iter. ETA=0:02:42\n",
      "\u001b[32m[07/06 04:58:28 d2.evaluation.evaluator]: \u001b[0mInference done 857/2890. Dataloading: 0.0021 s/iter. Inference: 0.0354 s/iter. Eval: 0.0400 s/iter. Total: 0.0775 s/iter. ETA=0:02:37\n",
      "\u001b[32m[07/06 04:58:33 d2.evaluation.evaluator]: \u001b[0mInference done 923/2890. Dataloading: 0.0021 s/iter. Inference: 0.0354 s/iter. Eval: 0.0399 s/iter. Total: 0.0775 s/iter. ETA=0:02:32\n",
      "\u001b[32m[07/06 04:58:38 d2.evaluation.evaluator]: \u001b[0mInference done 988/2890. Dataloading: 0.0021 s/iter. Inference: 0.0354 s/iter. Eval: 0.0398 s/iter. Total: 0.0775 s/iter. ETA=0:02:27\n",
      "\u001b[32m[07/06 04:58:43 d2.evaluation.evaluator]: \u001b[0mInference done 1054/2890. Dataloading: 0.0021 s/iter. Inference: 0.0354 s/iter. Eval: 0.0398 s/iter. Total: 0.0774 s/iter. ETA=0:02:22\n",
      "\u001b[32m[07/06 04:58:48 d2.evaluation.evaluator]: \u001b[0mInference done 1119/2890. Dataloading: 0.0022 s/iter. Inference: 0.0354 s/iter. Eval: 0.0397 s/iter. Total: 0.0774 s/iter. ETA=0:02:17\n",
      "\u001b[32m[07/06 04:58:53 d2.evaluation.evaluator]: \u001b[0mInference done 1183/2890. Dataloading: 0.0022 s/iter. Inference: 0.0354 s/iter. Eval: 0.0398 s/iter. Total: 0.0775 s/iter. ETA=0:02:12\n",
      "\u001b[32m[07/06 04:58:59 d2.evaluation.evaluator]: \u001b[0mInference done 1246/2890. Dataloading: 0.0022 s/iter. Inference: 0.0354 s/iter. Eval: 0.0399 s/iter. Total: 0.0776 s/iter. ETA=0:02:07\n",
      "\u001b[32m[07/06 04:59:04 d2.evaluation.evaluator]: \u001b[0mInference done 1309/2890. Dataloading: 0.0022 s/iter. Inference: 0.0354 s/iter. Eval: 0.0400 s/iter. Total: 0.0777 s/iter. ETA=0:02:02\n",
      "\u001b[32m[07/06 04:59:09 d2.evaluation.evaluator]: \u001b[0mInference done 1373/2890. Dataloading: 0.0022 s/iter. Inference: 0.0354 s/iter. Eval: 0.0401 s/iter. Total: 0.0778 s/iter. ETA=0:01:57\n",
      "\u001b[32m[07/06 04:59:14 d2.evaluation.evaluator]: \u001b[0mInference done 1441/2890. Dataloading: 0.0022 s/iter. Inference: 0.0354 s/iter. Eval: 0.0399 s/iter. Total: 0.0776 s/iter. ETA=0:01:52\n",
      "\u001b[32m[07/06 04:59:19 d2.evaluation.evaluator]: \u001b[0mInference done 1508/2890. Dataloading: 0.0022 s/iter. Inference: 0.0354 s/iter. Eval: 0.0398 s/iter. Total: 0.0775 s/iter. ETA=0:01:47\n",
      "\u001b[32m[07/06 04:59:24 d2.evaluation.evaluator]: \u001b[0mInference done 1575/2890. Dataloading: 0.0022 s/iter. Inference: 0.0354 s/iter. Eval: 0.0397 s/iter. Total: 0.0774 s/iter. ETA=0:01:41\n",
      "\u001b[32m[07/06 04:59:29 d2.evaluation.evaluator]: \u001b[0mInference done 1640/2890. Dataloading: 0.0022 s/iter. Inference: 0.0355 s/iter. Eval: 0.0397 s/iter. Total: 0.0774 s/iter. ETA=0:01:36\n",
      "\u001b[32m[07/06 04:59:34 d2.evaluation.evaluator]: \u001b[0mInference done 1704/2890. Dataloading: 0.0022 s/iter. Inference: 0.0355 s/iter. Eval: 0.0397 s/iter. Total: 0.0774 s/iter. ETA=0:01:31\n",
      "\u001b[32m[07/06 04:59:39 d2.evaluation.evaluator]: \u001b[0mInference done 1768/2890. Dataloading: 0.0022 s/iter. Inference: 0.0355 s/iter. Eval: 0.0397 s/iter. Total: 0.0775 s/iter. ETA=0:01:26\n",
      "\u001b[32m[07/06 04:59:44 d2.evaluation.evaluator]: \u001b[0mInference done 1833/2890. Dataloading: 0.0022 s/iter. Inference: 0.0355 s/iter. Eval: 0.0397 s/iter. Total: 0.0775 s/iter. ETA=0:01:21\n",
      "\u001b[32m[07/06 04:59:49 d2.evaluation.evaluator]: \u001b[0mInference done 1898/2890. Dataloading: 0.0022 s/iter. Inference: 0.0355 s/iter. Eval: 0.0398 s/iter. Total: 0.0775 s/iter. ETA=0:01:16\n",
      "\u001b[32m[07/06 04:59:54 d2.evaluation.evaluator]: \u001b[0mInference done 1962/2890. Dataloading: 0.0022 s/iter. Inference: 0.0355 s/iter. Eval: 0.0398 s/iter. Total: 0.0776 s/iter. ETA=0:01:11\n",
      "\u001b[32m[07/06 04:59:59 d2.evaluation.evaluator]: \u001b[0mInference done 2027/2890. Dataloading: 0.0022 s/iter. Inference: 0.0355 s/iter. Eval: 0.0398 s/iter. Total: 0.0776 s/iter. ETA=0:01:06\n",
      "\u001b[32m[07/06 05:00:04 d2.evaluation.evaluator]: \u001b[0mInference done 2090/2890. Dataloading: 0.0022 s/iter. Inference: 0.0355 s/iter. Eval: 0.0399 s/iter. Total: 0.0776 s/iter. ETA=0:01:02\n",
      "\u001b[32m[07/06 05:00:09 d2.evaluation.evaluator]: \u001b[0mInference done 2156/2890. Dataloading: 0.0022 s/iter. Inference: 0.0355 s/iter. Eval: 0.0398 s/iter. Total: 0.0776 s/iter. ETA=0:00:56\n",
      "\u001b[32m[07/06 05:00:14 d2.evaluation.evaluator]: \u001b[0mInference done 2204/2890. Dataloading: 0.0022 s/iter. Inference: 0.0356 s/iter. Eval: 0.0404 s/iter. Total: 0.0782 s/iter. ETA=0:00:53\n",
      "\u001b[32m[07/06 05:00:19 d2.evaluation.evaluator]: \u001b[0mInference done 2230/2890. Dataloading: 0.0022 s/iter. Inference: 0.0357 s/iter. Eval: 0.0416 s/iter. Total: 0.0796 s/iter. ETA=0:00:52\n",
      "\u001b[32m[07/06 05:00:24 d2.evaluation.evaluator]: \u001b[0mInference done 2256/2890. Dataloading: 0.0022 s/iter. Inference: 0.0358 s/iter. Eval: 0.0428 s/iter. Total: 0.0809 s/iter. ETA=0:00:51\n",
      "\u001b[32m[07/06 05:00:29 d2.evaluation.evaluator]: \u001b[0mInference done 2283/2890. Dataloading: 0.0022 s/iter. Inference: 0.0360 s/iter. Eval: 0.0440 s/iter. Total: 0.0822 s/iter. ETA=0:00:49\n",
      "\u001b[32m[07/06 05:00:35 d2.evaluation.evaluator]: \u001b[0mInference done 2311/2890. Dataloading: 0.0022 s/iter. Inference: 0.0361 s/iter. Eval: 0.0451 s/iter. Total: 0.0834 s/iter. ETA=0:00:48\n",
      "\u001b[32m[07/06 05:00:40 d2.evaluation.evaluator]: \u001b[0mInference done 2340/2890. Dataloading: 0.0022 s/iter. Inference: 0.0362 s/iter. Eval: 0.0461 s/iter. Total: 0.0846 s/iter. ETA=0:00:46\n",
      "\u001b[32m[07/06 05:00:45 d2.evaluation.evaluator]: \u001b[0mInference done 2366/2890. Dataloading: 0.0022 s/iter. Inference: 0.0363 s/iter. Eval: 0.0472 s/iter. Total: 0.0858 s/iter. ETA=0:00:44\n",
      "\u001b[32m[07/06 05:00:50 d2.evaluation.evaluator]: \u001b[0mInference done 2392/2890. Dataloading: 0.0022 s/iter. Inference: 0.0364 s/iter. Eval: 0.0483 s/iter. Total: 0.0870 s/iter. ETA=0:00:43\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/06 05:00:55 d2.evaluation.evaluator]: \u001b[0mInference done 2418/2890. Dataloading: 0.0022 s/iter. Inference: 0.0365 s/iter. Eval: 0.0493 s/iter. Total: 0.0882 s/iter. ETA=0:00:41\n",
      "\u001b[32m[07/06 05:01:00 d2.evaluation.evaluator]: \u001b[0mInference done 2444/2890. Dataloading: 0.0022 s/iter. Inference: 0.0366 s/iter. Eval: 0.0503 s/iter. Total: 0.0893 s/iter. ETA=0:00:39\n",
      "\u001b[32m[07/06 05:01:05 d2.evaluation.evaluator]: \u001b[0mInference done 2470/2890. Dataloading: 0.0022 s/iter. Inference: 0.0368 s/iter. Eval: 0.0513 s/iter. Total: 0.0904 s/iter. ETA=0:00:37\n",
      "\u001b[32m[07/06 05:01:10 d2.evaluation.evaluator]: \u001b[0mInference done 2496/2890. Dataloading: 0.0022 s/iter. Inference: 0.0369 s/iter. Eval: 0.0523 s/iter. Total: 0.0915 s/iter. ETA=0:00:36\n",
      "\u001b[32m[07/06 05:01:15 d2.evaluation.evaluator]: \u001b[0mInference done 2522/2890. Dataloading: 0.0022 s/iter. Inference: 0.0370 s/iter. Eval: 0.0533 s/iter. Total: 0.0926 s/iter. ETA=0:00:34\n",
      "\u001b[32m[07/06 05:01:20 d2.evaluation.evaluator]: \u001b[0mInference done 2549/2890. Dataloading: 0.0022 s/iter. Inference: 0.0371 s/iter. Eval: 0.0543 s/iter. Total: 0.0937 s/iter. ETA=0:00:31\n",
      "\u001b[32m[07/06 05:01:26 d2.evaluation.evaluator]: \u001b[0mInference done 2574/2890. Dataloading: 0.0022 s/iter. Inference: 0.0372 s/iter. Eval: 0.0552 s/iter. Total: 0.0947 s/iter. ETA=0:00:29\n",
      "\u001b[32m[07/06 05:01:31 d2.evaluation.evaluator]: \u001b[0mInference done 2600/2890. Dataloading: 0.0022 s/iter. Inference: 0.0373 s/iter. Eval: 0.0562 s/iter. Total: 0.0957 s/iter. ETA=0:00:27\n",
      "\u001b[32m[07/06 05:01:36 d2.evaluation.evaluator]: \u001b[0mInference done 2626/2890. Dataloading: 0.0022 s/iter. Inference: 0.0374 s/iter. Eval: 0.0570 s/iter. Total: 0.0967 s/iter. ETA=0:00:25\n",
      "\u001b[32m[07/06 05:01:41 d2.evaluation.evaluator]: \u001b[0mInference done 2652/2890. Dataloading: 0.0022 s/iter. Inference: 0.0374 s/iter. Eval: 0.0579 s/iter. Total: 0.0977 s/iter. ETA=0:00:23\n",
      "\u001b[32m[07/06 05:01:46 d2.evaluation.evaluator]: \u001b[0mInference done 2679/2890. Dataloading: 0.0022 s/iter. Inference: 0.0375 s/iter. Eval: 0.0587 s/iter. Total: 0.0986 s/iter. ETA=0:00:20\n",
      "\u001b[32m[07/06 05:01:51 d2.evaluation.evaluator]: \u001b[0mInference done 2705/2890. Dataloading: 0.0022 s/iter. Inference: 0.0376 s/iter. Eval: 0.0596 s/iter. Total: 0.0995 s/iter. ETA=0:00:18\n",
      "\u001b[32m[07/06 05:01:56 d2.evaluation.evaluator]: \u001b[0mInference done 2732/2890. Dataloading: 0.0022 s/iter. Inference: 0.0377 s/iter. Eval: 0.0604 s/iter. Total: 0.1004 s/iter. ETA=0:00:15\n",
      "\u001b[32m[07/06 05:02:01 d2.evaluation.evaluator]: \u001b[0mInference done 2758/2890. Dataloading: 0.0022 s/iter. Inference: 0.0378 s/iter. Eval: 0.0612 s/iter. Total: 0.1013 s/iter. ETA=0:00:13\n",
      "\u001b[32m[07/06 05:02:06 d2.evaluation.evaluator]: \u001b[0mInference done 2784/2890. Dataloading: 0.0022 s/iter. Inference: 0.0379 s/iter. Eval: 0.0620 s/iter. Total: 0.1022 s/iter. ETA=0:00:10\n",
      "\u001b[32m[07/06 05:02:11 d2.evaluation.evaluator]: \u001b[0mInference done 2810/2890. Dataloading: 0.0022 s/iter. Inference: 0.0380 s/iter. Eval: 0.0628 s/iter. Total: 0.1031 s/iter. ETA=0:00:08\n",
      "\u001b[32m[07/06 05:02:16 d2.evaluation.evaluator]: \u001b[0mInference done 2837/2890. Dataloading: 0.0022 s/iter. Inference: 0.0381 s/iter. Eval: 0.0635 s/iter. Total: 0.1039 s/iter. ETA=0:00:05\n",
      "\u001b[32m[07/06 05:02:22 d2.evaluation.evaluator]: \u001b[0mInference done 2864/2890. Dataloading: 0.0022 s/iter. Inference: 0.0381 s/iter. Eval: 0.0643 s/iter. Total: 0.1047 s/iter. ETA=0:00:02\n",
      "\u001b[32m[07/06 05:02:27 d2.evaluation.evaluator]: \u001b[0mInference done 2890/2890. Dataloading: 0.0022 s/iter. Inference: 0.0382 s/iter. Eval: 0.0650 s/iter. Total: 0.1055 s/iter. ETA=0:00:00\n",
      "\u001b[32m[07/06 05:02:27 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:05:04.534520 (0.105558 s / iter per device, on 1 devices)\n",
      "\u001b[32m[07/06 05:02:27 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:01:50 (0.038222 s / iter per device, on 1 devices)\n",
      "\u001b[32m[07/06 05:02:27 d2.evaluation.sem_seg_evaluation]: \u001b[0mOrderedDict([('sem_seg', {'mIoU': 56.173875237957304, 'fwIoU': 72.22311261132562, 'IoU-Unlabeled': nan, 'IoU-Building': 63.533048093839405, 'IoU-Fence': 32.777053514771204, 'IoU-Pedestrian': 70.00662959706055, 'IoU-Pole': 47.356763287529446, 'IoU-Road': 91.05868316173056, 'IoU-SideWalk': 67.18710003254003, 'IoU-Vegetation': 74.95661344845819, 'IoU-Vehicles': 65.26272926889334, 'IoU-Wall': 44.89688149783068, 'IoU-TrafficSign': 57.75990665058638, 'IoU-Sky': 52.39275141993336, 'IoU-TrafficLight': 54.746085905933526, 'IoU-Terrain': 29.61304490244498, 'IoU-ConstructionVehicle': 84.29871170512362, 'IoU-workzone_object': 53.97382359521299, 'IoU-Detour': 8.962177725428608, 'mACC': 68.26697539947148, 'pACC': 83.12595959692685, 'ACC-Unlabeled': nan, 'ACC-Building': 96.28756313997413, 'ACC-Fence': 40.881701712877856, 'ACC-Pedestrian': 86.16790665253222, 'ACC-Pole': 57.91064960741349, 'ACC-Road': 93.45827865957878, 'ACC-SideWalk': 81.15094559263537, 'ACC-Vegetation': 82.76475888177625, 'ACC-Vehicles': 92.99490239886427, 'ACC-Wall': 57.38808107823588, 'ACC-TrafficSign': 66.73846245244047, 'ACC-Sky': 53.15690043939243, 'ACC-TrafficLight': 64.17404676382696, 'ACC-Terrain': 33.76462190230106, 'ACC-ConstructionVehicle': 91.94772961104806, 'ACC-workzone_object': 80.32038373187342, 'ACC-Detour': 13.164673766773042})])\n",
      "\u001b[32m[07/06 05:02:27 d2.engine.defaults]: \u001b[0mEvaluation results for combined_both_rain_val in csv format:\n",
      "\u001b[32m[07/06 05:02:27 d2.evaluation.testing]: \u001b[0mcopypaste: Task: sem_seg\n",
      "\u001b[32m[07/06 05:02:27 d2.evaluation.testing]: \u001b[0mcopypaste: mIoU,fwIoU,mACC,pACC\n",
      "\u001b[32m[07/06 05:02:27 d2.evaluation.testing]: \u001b[0mcopypaste: 56.1739,72.2231,68.2670,83.1260\n"
     ]
    }
   ],
   "source": [
    "#all rain\n",
    "trainer_both = Detectron2Trainer('combined_clear_both_train', 'combined_both_rain_val', output_folder='./output_both_clear_40k')\n",
    "trainer_both.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "2d119eb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/05 19:16:00 d2.engine.defaults]: \u001b[0mModel:\n",
      "SemanticSegmentor(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (sem_seg_head): SemSegFPNHead(\n",
      "    (p2): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "    )\n",
      "    (p3): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (1): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "    )\n",
      "    (p4): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (1): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      (2): Conv2d(\n",
      "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (3): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "    )\n",
      "    (p5): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (1): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      (2): Conv2d(\n",
      "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (3): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      (4): Conv2d(\n",
      "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (5): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "    )\n",
      "    (predictor): Conv2d(128, 17, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/05 19:16:00 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(720, 720), max_size=2048, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[07/05 19:16:00 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[07/05 19:16:00 d2.data.common]: \u001b[0mSerializing 18867 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[07/05 19:16:00 d2.data.common]: \u001b[0mSerialized dataset takes 5.94 MiB\n",
      "Last checkpoint: model_final.pth\n",
      "\u001b[32m[07/05 19:16:00 d2.checkpoint.c2_model_loading]: \u001b[0mFollowing weights matched with model:\n",
      "| Names in Model                       | Names in Checkpoint                                                                                  | Shapes                                          |\n",
      "|:-------------------------------------|:-----------------------------------------------------------------------------------------------------|:------------------------------------------------|\n",
      "| backbone.bottom_up.res2.0.conv1.*    | backbone.bottom_up.res2.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,1,1)             |\n",
      "| backbone.bottom_up.res2.0.conv2.*    | backbone.bottom_up.res2.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |\n",
      "| backbone.bottom_up.res2.0.conv3.*    | backbone.bottom_up.res2.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res2.0.shortcut.* | backbone.bottom_up.res2.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res2.1.conv1.*    | backbone.bottom_up.res2.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |\n",
      "| backbone.bottom_up.res2.1.conv2.*    | backbone.bottom_up.res2.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |\n",
      "| backbone.bottom_up.res2.1.conv3.*    | backbone.bottom_up.res2.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res2.2.conv1.*    | backbone.bottom_up.res2.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |\n",
      "| backbone.bottom_up.res2.2.conv2.*    | backbone.bottom_up.res2.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |\n",
      "| backbone.bottom_up.res2.2.conv3.*    | backbone.bottom_up.res2.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res3.0.conv1.*    | backbone.bottom_up.res3.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,256,1,1)       |\n",
      "| backbone.bottom_up.res3.0.conv2.*    | backbone.bottom_up.res3.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.0.conv3.*    | backbone.bottom_up.res3.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res3.0.shortcut.* | backbone.bottom_up.res3.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (512,) (512,) (512,) (512,) (512,256,1,1)       |\n",
      "| backbone.bottom_up.res3.1.conv1.*    | backbone.bottom_up.res3.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |\n",
      "| backbone.bottom_up.res3.1.conv2.*    | backbone.bottom_up.res3.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.1.conv3.*    | backbone.bottom_up.res3.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res3.2.conv1.*    | backbone.bottom_up.res3.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |\n",
      "| backbone.bottom_up.res3.2.conv2.*    | backbone.bottom_up.res3.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.2.conv3.*    | backbone.bottom_up.res3.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res3.3.conv1.*    | backbone.bottom_up.res3.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |\n",
      "| backbone.bottom_up.res3.3.conv2.*    | backbone.bottom_up.res3.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.3.conv3.*    | backbone.bottom_up.res3.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res4.0.conv1.*    | backbone.bottom_up.res4.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,512,1,1)       |\n",
      "| backbone.bottom_up.res4.0.conv2.*    | backbone.bottom_up.res4.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.0.conv3.*    | backbone.bottom_up.res4.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.0.shortcut.* | backbone.bottom_up.res4.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (1024,) (1024,) (1024,) (1024,) (1024,512,1,1)  |\n",
      "| backbone.bottom_up.res4.1.conv1.*    | backbone.bottom_up.res4.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.1.conv2.*    | backbone.bottom_up.res4.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.1.conv3.*    | backbone.bottom_up.res4.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.2.conv1.*    | backbone.bottom_up.res4.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.2.conv2.*    | backbone.bottom_up.res4.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.2.conv3.*    | backbone.bottom_up.res4.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.3.conv1.*    | backbone.bottom_up.res4.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.3.conv2.*    | backbone.bottom_up.res4.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.3.conv3.*    | backbone.bottom_up.res4.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.4.conv1.*    | backbone.bottom_up.res4.4.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.4.conv2.*    | backbone.bottom_up.res4.4.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.4.conv3.*    | backbone.bottom_up.res4.4.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.5.conv1.*    | backbone.bottom_up.res4.5.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.5.conv2.*    | backbone.bottom_up.res4.5.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.5.conv3.*    | backbone.bottom_up.res4.5.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res5.0.conv1.*    | backbone.bottom_up.res5.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,1024,1,1)      |\n",
      "| backbone.bottom_up.res5.0.conv2.*    | backbone.bottom_up.res5.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |\n",
      "| backbone.bottom_up.res5.0.conv3.*    | backbone.bottom_up.res5.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
      "| backbone.bottom_up.res5.0.shortcut.* | backbone.bottom_up.res5.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (2048,) (2048,) (2048,) (2048,) (2048,1024,1,1) |\n",
      "| backbone.bottom_up.res5.1.conv1.*    | backbone.bottom_up.res5.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |\n",
      "| backbone.bottom_up.res5.1.conv2.*    | backbone.bottom_up.res5.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |\n",
      "| backbone.bottom_up.res5.1.conv3.*    | backbone.bottom_up.res5.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
      "| backbone.bottom_up.res5.2.conv1.*    | backbone.bottom_up.res5.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |\n",
      "| backbone.bottom_up.res5.2.conv2.*    | backbone.bottom_up.res5.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |\n",
      "| backbone.bottom_up.res5.2.conv3.*    | backbone.bottom_up.res5.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
      "| backbone.bottom_up.stem.conv1.*      | backbone.bottom_up.stem.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}      | (64,) (64,) (64,) (64,) (64,3,7,7)              |\n",
      "| backbone.fpn_lateral2.*              | backbone.fpn_lateral2.{bias,weight}                                                                  | (256,) (256,256,1,1)                            |\n",
      "| backbone.fpn_lateral3.*              | backbone.fpn_lateral3.{bias,weight}                                                                  | (256,) (256,512,1,1)                            |\n",
      "| backbone.fpn_lateral4.*              | backbone.fpn_lateral4.{bias,weight}                                                                  | (256,) (256,1024,1,1)                           |\n",
      "| backbone.fpn_lateral5.*              | backbone.fpn_lateral5.{bias,weight}                                                                  | (256,) (256,2048,1,1)                           |\n",
      "| backbone.fpn_output2.*               | backbone.fpn_output2.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| backbone.fpn_output3.*               | backbone.fpn_output3.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| backbone.fpn_output4.*               | backbone.fpn_output4.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| backbone.fpn_output5.*               | backbone.fpn_output5.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| sem_seg_head.p2.0.*                  | sem_seg_head.p2.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p3.0.*                  | sem_seg_head.p3.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p4.0.*                  | sem_seg_head.p4.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p4.2.*                  | sem_seg_head.p4.2.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,128,3,3)                     |\n",
      "| sem_seg_head.p5.0.*                  | sem_seg_head.p5.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p5.2.*                  | sem_seg_head.p5.2.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,128,3,3)                     |\n",
      "| sem_seg_head.p5.4.*                  | sem_seg_head.p5.4.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,128,3,3)                     |\n",
      "| sem_seg_head.predictor.*             | sem_seg_head.predictor.{bias,weight}                                                                 | (17,) (17,128,1,1)                              |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/05 19:16:00 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(720, 720), max_size=2048, sample_style='choice')]\n",
      "\u001b[32m[07/05 19:16:00 d2.data.common]: \u001b[0mSerializing 14460 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[07/05 19:16:00 d2.data.common]: \u001b[0mSerialized dataset takes 4.48 MiB\n",
      "\u001b[32m[07/05 19:16:00 d2.evaluation.evaluator]: \u001b[0mStart inference on 14460 batches\n",
      "\u001b[32m[07/05 19:16:02 d2.evaluation.evaluator]: \u001b[0mInference done 11/14460. Dataloading: 0.0022 s/iter. Inference: 0.0386 s/iter. Eval: 0.0462 s/iter. Total: 0.0870 s/iter. ETA=0:20:57\n",
      "\u001b[32m[07/05 19:16:07 d2.evaluation.evaluator]: \u001b[0mInference done 71/14460. Dataloading: 0.0025 s/iter. Inference: 0.0353 s/iter. Eval: 0.0458 s/iter. Total: 0.0837 s/iter. ETA=0:20:04\n",
      "\u001b[32m[07/05 19:16:12 d2.evaluation.evaluator]: \u001b[0mInference done 133/14460. Dataloading: 0.0025 s/iter. Inference: 0.0352 s/iter. Eval: 0.0447 s/iter. Total: 0.0824 s/iter. ETA=0:19:40\n",
      "\u001b[32m[07/05 19:16:17 d2.evaluation.evaluator]: \u001b[0mInference done 197/14460. Dataloading: 0.0025 s/iter. Inference: 0.0351 s/iter. Eval: 0.0436 s/iter. Total: 0.0812 s/iter. ETA=0:19:18\n",
      "\u001b[32m[07/05 19:16:22 d2.evaluation.evaluator]: \u001b[0mInference done 261/14460. Dataloading: 0.0024 s/iter. Inference: 0.0351 s/iter. Eval: 0.0428 s/iter. Total: 0.0805 s/iter. ETA=0:19:02\n",
      "\u001b[32m[07/05 19:16:27 d2.evaluation.evaluator]: \u001b[0mInference done 326/14460. Dataloading: 0.0025 s/iter. Inference: 0.0352 s/iter. Eval: 0.0421 s/iter. Total: 0.0799 s/iter. ETA=0:18:48\n",
      "\u001b[32m[07/05 19:16:32 d2.evaluation.evaluator]: \u001b[0mInference done 392/14460. Dataloading: 0.0024 s/iter. Inference: 0.0352 s/iter. Eval: 0.0416 s/iter. Total: 0.0793 s/iter. ETA=0:18:35\n",
      "\u001b[32m[07/05 19:16:37 d2.evaluation.evaluator]: \u001b[0mInference done 457/14460. Dataloading: 0.0024 s/iter. Inference: 0.0352 s/iter. Eval: 0.0413 s/iter. Total: 0.0791 s/iter. ETA=0:18:26\n",
      "\u001b[32m[07/05 19:16:42 d2.evaluation.evaluator]: \u001b[0mInference done 522/14460. Dataloading: 0.0024 s/iter. Inference: 0.0352 s/iter. Eval: 0.0411 s/iter. Total: 0.0788 s/iter. ETA=0:18:18\n",
      "\u001b[32m[07/05 19:16:47 d2.evaluation.evaluator]: \u001b[0mInference done 587/14460. Dataloading: 0.0024 s/iter. Inference: 0.0352 s/iter. Eval: 0.0409 s/iter. Total: 0.0786 s/iter. ETA=0:18:10\n",
      "\u001b[32m[07/05 19:16:52 d2.evaluation.evaluator]: \u001b[0mInference done 653/14460. Dataloading: 0.0024 s/iter. Inference: 0.0352 s/iter. Eval: 0.0408 s/iter. Total: 0.0785 s/iter. ETA=0:18:03\n",
      "\u001b[32m[07/05 19:16:57 d2.evaluation.evaluator]: \u001b[0mInference done 718/14460. Dataloading: 0.0024 s/iter. Inference: 0.0352 s/iter. Eval: 0.0406 s/iter. Total: 0.0783 s/iter. ETA=0:17:56\n",
      "\u001b[32m[07/05 19:17:02 d2.evaluation.evaluator]: \u001b[0mInference done 784/14460. Dataloading: 0.0024 s/iter. Inference: 0.0352 s/iter. Eval: 0.0405 s/iter. Total: 0.0782 s/iter. ETA=0:17:49\n",
      "\u001b[32m[07/05 19:17:07 d2.evaluation.evaluator]: \u001b[0mInference done 850/14460. Dataloading: 0.0024 s/iter. Inference: 0.0353 s/iter. Eval: 0.0404 s/iter. Total: 0.0781 s/iter. ETA=0:17:42\n",
      "\u001b[32m[07/05 19:17:12 d2.evaluation.evaluator]: \u001b[0mInference done 915/14460. Dataloading: 0.0024 s/iter. Inference: 0.0353 s/iter. Eval: 0.0403 s/iter. Total: 0.0780 s/iter. ETA=0:17:36\n",
      "\u001b[32m[07/05 19:17:17 d2.evaluation.evaluator]: \u001b[0mInference done 981/14460. Dataloading: 0.0024 s/iter. Inference: 0.0353 s/iter. Eval: 0.0402 s/iter. Total: 0.0779 s/iter. ETA=0:17:29\n",
      "\u001b[32m[07/05 19:17:22 d2.evaluation.evaluator]: \u001b[0mInference done 1046/14460. Dataloading: 0.0023 s/iter. Inference: 0.0353 s/iter. Eval: 0.0401 s/iter. Total: 0.0778 s/iter. ETA=0:17:24\n",
      "\u001b[32m[07/05 19:17:27 d2.evaluation.evaluator]: \u001b[0mInference done 1112/14460. Dataloading: 0.0023 s/iter. Inference: 0.0353 s/iter. Eval: 0.0401 s/iter. Total: 0.0778 s/iter. ETA=0:17:18\n",
      "\u001b[32m[07/05 19:17:32 d2.evaluation.evaluator]: \u001b[0mInference done 1177/14460. Dataloading: 0.0023 s/iter. Inference: 0.0353 s/iter. Eval: 0.0400 s/iter. Total: 0.0777 s/iter. ETA=0:17:12\n",
      "\u001b[32m[07/05 19:17:37 d2.evaluation.evaluator]: \u001b[0mInference done 1242/14460. Dataloading: 0.0023 s/iter. Inference: 0.0353 s/iter. Eval: 0.0400 s/iter. Total: 0.0777 s/iter. ETA=0:17:07\n",
      "\u001b[32m[07/05 19:17:42 d2.evaluation.evaluator]: \u001b[0mInference done 1307/14460. Dataloading: 0.0023 s/iter. Inference: 0.0353 s/iter. Eval: 0.0400 s/iter. Total: 0.0777 s/iter. ETA=0:17:02\n",
      "\u001b[32m[07/05 19:17:47 d2.evaluation.evaluator]: \u001b[0mInference done 1373/14460. Dataloading: 0.0023 s/iter. Inference: 0.0353 s/iter. Eval: 0.0400 s/iter. Total: 0.0777 s/iter. ETA=0:16:56\n",
      "\u001b[32m[07/05 19:17:52 d2.evaluation.evaluator]: \u001b[0mInference done 1438/14460. Dataloading: 0.0023 s/iter. Inference: 0.0353 s/iter. Eval: 0.0400 s/iter. Total: 0.0777 s/iter. ETA=0:16:51\n",
      "\u001b[32m[07/05 19:17:57 d2.evaluation.evaluator]: \u001b[0mInference done 1502/14460. Dataloading: 0.0023 s/iter. Inference: 0.0353 s/iter. Eval: 0.0400 s/iter. Total: 0.0777 s/iter. ETA=0:16:47\n",
      "\u001b[32m[07/05 19:18:03 d2.evaluation.evaluator]: \u001b[0mInference done 1567/14460. Dataloading: 0.0023 s/iter. Inference: 0.0353 s/iter. Eval: 0.0400 s/iter. Total: 0.0777 s/iter. ETA=0:16:41\n",
      "\u001b[32m[07/05 19:18:08 d2.evaluation.evaluator]: \u001b[0mInference done 1632/14460. Dataloading: 0.0023 s/iter. Inference: 0.0353 s/iter. Eval: 0.0399 s/iter. Total: 0.0777 s/iter. ETA=0:16:36\n",
      "\u001b[32m[07/05 19:18:13 d2.evaluation.evaluator]: \u001b[0mInference done 1696/14460. Dataloading: 0.0023 s/iter. Inference: 0.0353 s/iter. Eval: 0.0400 s/iter. Total: 0.0777 s/iter. ETA=0:16:31\n",
      "\u001b[32m[07/05 19:18:18 d2.evaluation.evaluator]: \u001b[0mInference done 1760/14460. Dataloading: 0.0023 s/iter. Inference: 0.0353 s/iter. Eval: 0.0400 s/iter. Total: 0.0777 s/iter. ETA=0:16:27\n",
      "\u001b[32m[07/05 19:18:23 d2.evaluation.evaluator]: \u001b[0mInference done 1824/14460. Dataloading: 0.0023 s/iter. Inference: 0.0353 s/iter. Eval: 0.0400 s/iter. Total: 0.0778 s/iter. ETA=0:16:22\n",
      "\u001b[32m[07/05 19:18:28 d2.evaluation.evaluator]: \u001b[0mInference done 1889/14460. Dataloading: 0.0023 s/iter. Inference: 0.0353 s/iter. Eval: 0.0400 s/iter. Total: 0.0778 s/iter. ETA=0:16:17\n",
      "\u001b[32m[07/05 19:18:33 d2.evaluation.evaluator]: \u001b[0mInference done 1952/14460. Dataloading: 0.0023 s/iter. Inference: 0.0353 s/iter. Eval: 0.0401 s/iter. Total: 0.0778 s/iter. ETA=0:16:13\n",
      "\u001b[32m[07/05 19:18:38 d2.evaluation.evaluator]: \u001b[0mInference done 2018/14460. Dataloading: 0.0023 s/iter. Inference: 0.0353 s/iter. Eval: 0.0401 s/iter. Total: 0.0778 s/iter. ETA=0:16:08\n",
      "\u001b[32m[07/05 19:18:43 d2.evaluation.evaluator]: \u001b[0mInference done 2082/14460. Dataloading: 0.0023 s/iter. Inference: 0.0353 s/iter. Eval: 0.0401 s/iter. Total: 0.0778 s/iter. ETA=0:16:03\n",
      "\u001b[32m[07/05 19:18:48 d2.evaluation.evaluator]: \u001b[0mInference done 2147/14460. Dataloading: 0.0023 s/iter. Inference: 0.0354 s/iter. Eval: 0.0401 s/iter. Total: 0.0778 s/iter. ETA=0:15:58\n",
      "\u001b[32m[07/05 19:18:53 d2.evaluation.evaluator]: \u001b[0mInference done 2212/14460. Dataloading: 0.0023 s/iter. Inference: 0.0354 s/iter. Eval: 0.0401 s/iter. Total: 0.0778 s/iter. ETA=0:15:53\n",
      "\u001b[32m[07/05 19:18:58 d2.evaluation.evaluator]: \u001b[0mInference done 2276/14460. Dataloading: 0.0023 s/iter. Inference: 0.0354 s/iter. Eval: 0.0401 s/iter. Total: 0.0778 s/iter. ETA=0:15:48\n",
      "\u001b[32m[07/05 19:19:03 d2.evaluation.evaluator]: \u001b[0mInference done 2341/14460. Dataloading: 0.0023 s/iter. Inference: 0.0354 s/iter. Eval: 0.0401 s/iter. Total: 0.0778 s/iter. ETA=0:15:43\n",
      "\u001b[32m[07/05 19:19:08 d2.evaluation.evaluator]: \u001b[0mInference done 2405/14460. Dataloading: 0.0023 s/iter. Inference: 0.0354 s/iter. Eval: 0.0401 s/iter. Total: 0.0778 s/iter. ETA=0:15:38\n",
      "\u001b[32m[07/05 19:19:13 d2.evaluation.evaluator]: \u001b[0mInference done 2470/14460. Dataloading: 0.0023 s/iter. Inference: 0.0354 s/iter. Eval: 0.0401 s/iter. Total: 0.0778 s/iter. ETA=0:15:33\n",
      "\u001b[32m[07/05 19:19:18 d2.evaluation.evaluator]: \u001b[0mInference done 2533/14460. Dataloading: 0.0023 s/iter. Inference: 0.0354 s/iter. Eval: 0.0401 s/iter. Total: 0.0779 s/iter. ETA=0:15:28\n",
      "\u001b[32m[07/05 19:19:23 d2.evaluation.evaluator]: \u001b[0mInference done 2597/14460. Dataloading: 0.0023 s/iter. Inference: 0.0354 s/iter. Eval: 0.0401 s/iter. Total: 0.0779 s/iter. ETA=0:15:24\n",
      "\u001b[32m[07/05 19:19:28 d2.evaluation.evaluator]: \u001b[0mInference done 2660/14460. Dataloading: 0.0023 s/iter. Inference: 0.0354 s/iter. Eval: 0.0402 s/iter. Total: 0.0779 s/iter. ETA=0:15:19\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/05 19:19:33 d2.evaluation.evaluator]: \u001b[0mInference done 2724/14460. Dataloading: 0.0023 s/iter. Inference: 0.0354 s/iter. Eval: 0.0402 s/iter. Total: 0.0780 s/iter. ETA=0:15:15\n",
      "\u001b[32m[07/05 19:19:38 d2.evaluation.evaluator]: \u001b[0mInference done 2790/14460. Dataloading: 0.0023 s/iter. Inference: 0.0354 s/iter. Eval: 0.0401 s/iter. Total: 0.0779 s/iter. ETA=0:15:09\n",
      "\u001b[32m[07/05 19:19:43 d2.evaluation.evaluator]: \u001b[0mInference done 2855/14460. Dataloading: 0.0023 s/iter. Inference: 0.0354 s/iter. Eval: 0.0401 s/iter. Total: 0.0779 s/iter. ETA=0:15:04\n",
      "\u001b[32m[07/05 19:19:48 d2.evaluation.evaluator]: \u001b[0mInference done 2920/14460. Dataloading: 0.0023 s/iter. Inference: 0.0354 s/iter. Eval: 0.0401 s/iter. Total: 0.0779 s/iter. ETA=0:14:59\n",
      "\u001b[32m[07/05 19:19:53 d2.evaluation.evaluator]: \u001b[0mInference done 2983/14460. Dataloading: 0.0023 s/iter. Inference: 0.0354 s/iter. Eval: 0.0401 s/iter. Total: 0.0780 s/iter. ETA=0:14:54\n",
      "\u001b[32m[07/05 19:19:58 d2.evaluation.evaluator]: \u001b[0mInference done 3047/14460. Dataloading: 0.0023 s/iter. Inference: 0.0354 s/iter. Eval: 0.0402 s/iter. Total: 0.0780 s/iter. ETA=0:14:49\n",
      "\u001b[32m[07/05 19:20:03 d2.evaluation.evaluator]: \u001b[0mInference done 3110/14460. Dataloading: 0.0023 s/iter. Inference: 0.0354 s/iter. Eval: 0.0402 s/iter. Total: 0.0780 s/iter. ETA=0:14:45\n",
      "\u001b[32m[07/05 19:20:08 d2.evaluation.evaluator]: \u001b[0mInference done 3173/14460. Dataloading: 0.0023 s/iter. Inference: 0.0354 s/iter. Eval: 0.0402 s/iter. Total: 0.0781 s/iter. ETA=0:14:40\n",
      "\u001b[32m[07/05 19:20:13 d2.evaluation.evaluator]: \u001b[0mInference done 3239/14460. Dataloading: 0.0023 s/iter. Inference: 0.0354 s/iter. Eval: 0.0402 s/iter. Total: 0.0780 s/iter. ETA=0:14:35\n",
      "\u001b[32m[07/05 19:20:18 d2.evaluation.evaluator]: \u001b[0mInference done 3303/14460. Dataloading: 0.0023 s/iter. Inference: 0.0354 s/iter. Eval: 0.0402 s/iter. Total: 0.0780 s/iter. ETA=0:14:30\n",
      "\u001b[32m[07/05 19:20:23 d2.evaluation.evaluator]: \u001b[0mInference done 3366/14460. Dataloading: 0.0023 s/iter. Inference: 0.0354 s/iter. Eval: 0.0402 s/iter. Total: 0.0781 s/iter. ETA=0:14:25\n",
      "\u001b[32m[07/05 19:20:29 d2.evaluation.evaluator]: \u001b[0mInference done 3429/14460. Dataloading: 0.0023 s/iter. Inference: 0.0354 s/iter. Eval: 0.0403 s/iter. Total: 0.0781 s/iter. ETA=0:14:21\n",
      "\u001b[32m[07/05 19:20:34 d2.evaluation.evaluator]: \u001b[0mInference done 3494/14460. Dataloading: 0.0023 s/iter. Inference: 0.0354 s/iter. Eval: 0.0403 s/iter. Total: 0.0781 s/iter. ETA=0:14:16\n",
      "\u001b[32m[07/05 19:20:39 d2.evaluation.evaluator]: \u001b[0mInference done 3559/14460. Dataloading: 0.0023 s/iter. Inference: 0.0354 s/iter. Eval: 0.0402 s/iter. Total: 0.0781 s/iter. ETA=0:14:10\n",
      "\u001b[32m[07/05 19:20:44 d2.evaluation.evaluator]: \u001b[0mInference done 3622/14460. Dataloading: 0.0023 s/iter. Inference: 0.0354 s/iter. Eval: 0.0403 s/iter. Total: 0.0781 s/iter. ETA=0:14:06\n",
      "\u001b[32m[07/05 19:20:49 d2.evaluation.evaluator]: \u001b[0mInference done 3685/14460. Dataloading: 0.0023 s/iter. Inference: 0.0354 s/iter. Eval: 0.0403 s/iter. Total: 0.0781 s/iter. ETA=0:14:01\n",
      "\u001b[32m[07/05 19:20:54 d2.evaluation.evaluator]: \u001b[0mInference done 3747/14460. Dataloading: 0.0023 s/iter. Inference: 0.0354 s/iter. Eval: 0.0404 s/iter. Total: 0.0782 s/iter. ETA=0:13:57\n",
      "\u001b[32m[07/05 19:20:59 d2.evaluation.evaluator]: \u001b[0mInference done 3812/14460. Dataloading: 0.0023 s/iter. Inference: 0.0354 s/iter. Eval: 0.0404 s/iter. Total: 0.0782 s/iter. ETA=0:13:52\n",
      "\u001b[32m[07/05 19:21:04 d2.evaluation.evaluator]: \u001b[0mInference done 3876/14460. Dataloading: 0.0023 s/iter. Inference: 0.0354 s/iter. Eval: 0.0404 s/iter. Total: 0.0782 s/iter. ETA=0:13:47\n",
      "\u001b[32m[07/05 19:21:09 d2.evaluation.evaluator]: \u001b[0mInference done 3941/14460. Dataloading: 0.0023 s/iter. Inference: 0.0354 s/iter. Eval: 0.0404 s/iter. Total: 0.0782 s/iter. ETA=0:13:42\n",
      "\u001b[32m[07/05 19:21:14 d2.evaluation.evaluator]: \u001b[0mInference done 4006/14460. Dataloading: 0.0023 s/iter. Inference: 0.0354 s/iter. Eval: 0.0404 s/iter. Total: 0.0782 s/iter. ETA=0:13:37\n",
      "\u001b[32m[07/05 19:21:19 d2.evaluation.evaluator]: \u001b[0mInference done 4071/14460. Dataloading: 0.0023 s/iter. Inference: 0.0354 s/iter. Eval: 0.0403 s/iter. Total: 0.0781 s/iter. ETA=0:13:31\n",
      "\u001b[32m[07/05 19:21:24 d2.evaluation.evaluator]: \u001b[0mInference done 4137/14460. Dataloading: 0.0023 s/iter. Inference: 0.0354 s/iter. Eval: 0.0403 s/iter. Total: 0.0781 s/iter. ETA=0:13:26\n",
      "\u001b[32m[07/05 19:21:29 d2.evaluation.evaluator]: \u001b[0mInference done 4202/14460. Dataloading: 0.0023 s/iter. Inference: 0.0354 s/iter. Eval: 0.0403 s/iter. Total: 0.0781 s/iter. ETA=0:13:21\n",
      "\u001b[32m[07/05 19:21:34 d2.evaluation.evaluator]: \u001b[0mInference done 4268/14460. Dataloading: 0.0023 s/iter. Inference: 0.0354 s/iter. Eval: 0.0403 s/iter. Total: 0.0781 s/iter. ETA=0:13:15\n",
      "\u001b[32m[07/05 19:21:39 d2.evaluation.evaluator]: \u001b[0mInference done 4334/14460. Dataloading: 0.0023 s/iter. Inference: 0.0354 s/iter. Eval: 0.0403 s/iter. Total: 0.0781 s/iter. ETA=0:13:10\n",
      "\u001b[32m[07/05 19:21:44 d2.evaluation.evaluator]: \u001b[0mInference done 4399/14460. Dataloading: 0.0023 s/iter. Inference: 0.0354 s/iter. Eval: 0.0402 s/iter. Total: 0.0781 s/iter. ETA=0:13:05\n",
      "\u001b[32m[07/05 19:21:49 d2.evaluation.evaluator]: \u001b[0mInference done 4465/14460. Dataloading: 0.0023 s/iter. Inference: 0.0354 s/iter. Eval: 0.0402 s/iter. Total: 0.0780 s/iter. ETA=0:12:59\n",
      "\u001b[32m[07/05 19:21:54 d2.evaluation.evaluator]: \u001b[0mInference done 4531/14460. Dataloading: 0.0023 s/iter. Inference: 0.0354 s/iter. Eval: 0.0402 s/iter. Total: 0.0780 s/iter. ETA=0:12:54\n",
      "\u001b[32m[07/05 19:21:59 d2.evaluation.evaluator]: \u001b[0mInference done 4594/14460. Dataloading: 0.0024 s/iter. Inference: 0.0354 s/iter. Eval: 0.0402 s/iter. Total: 0.0780 s/iter. ETA=0:12:49\n",
      "\u001b[32m[07/05 19:22:04 d2.evaluation.evaluator]: \u001b[0mInference done 4659/14460. Dataloading: 0.0023 s/iter. Inference: 0.0354 s/iter. Eval: 0.0402 s/iter. Total: 0.0780 s/iter. ETA=0:12:44\n",
      "\u001b[32m[07/05 19:22:09 d2.evaluation.evaluator]: \u001b[0mInference done 4724/14460. Dataloading: 0.0023 s/iter. Inference: 0.0354 s/iter. Eval: 0.0402 s/iter. Total: 0.0780 s/iter. ETA=0:12:39\n",
      "\u001b[32m[07/05 19:22:14 d2.evaluation.evaluator]: \u001b[0mInference done 4789/14460. Dataloading: 0.0023 s/iter. Inference: 0.0354 s/iter. Eval: 0.0402 s/iter. Total: 0.0780 s/iter. ETA=0:12:34\n",
      "\u001b[32m[07/05 19:22:19 d2.evaluation.evaluator]: \u001b[0mInference done 4854/14460. Dataloading: 0.0023 s/iter. Inference: 0.0354 s/iter. Eval: 0.0402 s/iter. Total: 0.0780 s/iter. ETA=0:12:29\n",
      "\u001b[32m[07/05 19:22:24 d2.evaluation.evaluator]: \u001b[0mInference done 4919/14460. Dataloading: 0.0023 s/iter. Inference: 0.0354 s/iter. Eval: 0.0402 s/iter. Total: 0.0780 s/iter. ETA=0:12:24\n",
      "\u001b[32m[07/05 19:22:29 d2.evaluation.evaluator]: \u001b[0mInference done 4983/14460. Dataloading: 0.0023 s/iter. Inference: 0.0354 s/iter. Eval: 0.0402 s/iter. Total: 0.0780 s/iter. ETA=0:12:19\n",
      "\u001b[32m[07/05 19:22:34 d2.evaluation.evaluator]: \u001b[0mInference done 5048/14460. Dataloading: 0.0023 s/iter. Inference: 0.0354 s/iter. Eval: 0.0402 s/iter. Total: 0.0780 s/iter. ETA=0:12:14\n",
      "\u001b[32m[07/05 19:22:40 d2.evaluation.evaluator]: \u001b[0mInference done 5114/14460. Dataloading: 0.0023 s/iter. Inference: 0.0354 s/iter. Eval: 0.0401 s/iter. Total: 0.0780 s/iter. ETA=0:12:08\n",
      "\u001b[32m[07/05 19:22:45 d2.evaluation.evaluator]: \u001b[0mInference done 5179/14460. Dataloading: 0.0023 s/iter. Inference: 0.0354 s/iter. Eval: 0.0401 s/iter. Total: 0.0780 s/iter. ETA=0:12:03\n",
      "\u001b[32m[07/05 19:22:50 d2.evaluation.evaluator]: \u001b[0mInference done 5244/14460. Dataloading: 0.0023 s/iter. Inference: 0.0354 s/iter. Eval: 0.0401 s/iter. Total: 0.0780 s/iter. ETA=0:11:58\n",
      "\u001b[32m[07/05 19:22:55 d2.evaluation.evaluator]: \u001b[0mInference done 5308/14460. Dataloading: 0.0023 s/iter. Inference: 0.0354 s/iter. Eval: 0.0401 s/iter. Total: 0.0780 s/iter. ETA=0:11:53\n",
      "\u001b[32m[07/05 19:23:00 d2.evaluation.evaluator]: \u001b[0mInference done 5373/14460. Dataloading: 0.0023 s/iter. Inference: 0.0354 s/iter. Eval: 0.0401 s/iter. Total: 0.0780 s/iter. ETA=0:11:48\n",
      "\u001b[32m[07/05 19:23:05 d2.evaluation.evaluator]: \u001b[0mInference done 5438/14460. Dataloading: 0.0023 s/iter. Inference: 0.0354 s/iter. Eval: 0.0401 s/iter. Total: 0.0780 s/iter. ETA=0:11:43\n",
      "\u001b[32m[07/05 19:23:10 d2.evaluation.evaluator]: \u001b[0mInference done 5503/14460. Dataloading: 0.0023 s/iter. Inference: 0.0354 s/iter. Eval: 0.0401 s/iter. Total: 0.0779 s/iter. ETA=0:11:38\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/05 19:23:15 d2.evaluation.evaluator]: \u001b[0mInference done 5569/14460. Dataloading: 0.0023 s/iter. Inference: 0.0354 s/iter. Eval: 0.0401 s/iter. Total: 0.0779 s/iter. ETA=0:11:32\n",
      "\u001b[32m[07/05 19:23:20 d2.evaluation.evaluator]: \u001b[0mInference done 5634/14460. Dataloading: 0.0023 s/iter. Inference: 0.0354 s/iter. Eval: 0.0401 s/iter. Total: 0.0779 s/iter. ETA=0:11:27\n",
      "\u001b[32m[07/05 19:23:25 d2.evaluation.evaluator]: \u001b[0mInference done 5700/14460. Dataloading: 0.0023 s/iter. Inference: 0.0354 s/iter. Eval: 0.0401 s/iter. Total: 0.0779 s/iter. ETA=0:11:22\n",
      "\u001b[32m[07/05 19:23:30 d2.evaluation.evaluator]: \u001b[0mInference done 5766/14460. Dataloading: 0.0023 s/iter. Inference: 0.0354 s/iter. Eval: 0.0401 s/iter. Total: 0.0779 s/iter. ETA=0:11:17\n",
      "\u001b[32m[07/05 19:23:35 d2.evaluation.evaluator]: \u001b[0mInference done 5832/14460. Dataloading: 0.0023 s/iter. Inference: 0.0354 s/iter. Eval: 0.0401 s/iter. Total: 0.0779 s/iter. ETA=0:11:12\n",
      "\u001b[32m[07/05 19:23:40 d2.evaluation.evaluator]: \u001b[0mInference done 5898/14460. Dataloading: 0.0023 s/iter. Inference: 0.0354 s/iter. Eval: 0.0400 s/iter. Total: 0.0779 s/iter. ETA=0:11:06\n",
      "\u001b[32m[07/05 19:23:45 d2.evaluation.evaluator]: \u001b[0mInference done 5965/14460. Dataloading: 0.0023 s/iter. Inference: 0.0354 s/iter. Eval: 0.0400 s/iter. Total: 0.0778 s/iter. ETA=0:11:01\n",
      "\u001b[32m[07/05 19:23:50 d2.evaluation.evaluator]: \u001b[0mInference done 6031/14460. Dataloading: 0.0023 s/iter. Inference: 0.0354 s/iter. Eval: 0.0400 s/iter. Total: 0.0778 s/iter. ETA=0:10:55\n",
      "\u001b[32m[07/05 19:23:55 d2.evaluation.evaluator]: \u001b[0mInference done 6096/14460. Dataloading: 0.0023 s/iter. Inference: 0.0354 s/iter. Eval: 0.0400 s/iter. Total: 0.0778 s/iter. ETA=0:10:50\n",
      "\u001b[32m[07/05 19:24:00 d2.evaluation.evaluator]: \u001b[0mInference done 6162/14460. Dataloading: 0.0023 s/iter. Inference: 0.0354 s/iter. Eval: 0.0400 s/iter. Total: 0.0778 s/iter. ETA=0:10:45\n",
      "\u001b[32m[07/05 19:24:05 d2.evaluation.evaluator]: \u001b[0mInference done 6229/14460. Dataloading: 0.0023 s/iter. Inference: 0.0354 s/iter. Eval: 0.0399 s/iter. Total: 0.0778 s/iter. ETA=0:10:40\n",
      "\u001b[32m[07/05 19:24:10 d2.evaluation.evaluator]: \u001b[0mInference done 6295/14460. Dataloading: 0.0023 s/iter. Inference: 0.0354 s/iter. Eval: 0.0399 s/iter. Total: 0.0778 s/iter. ETA=0:10:34\n",
      "\u001b[32m[07/05 19:24:15 d2.evaluation.evaluator]: \u001b[0mInference done 6361/14460. Dataloading: 0.0023 s/iter. Inference: 0.0354 s/iter. Eval: 0.0399 s/iter. Total: 0.0777 s/iter. ETA=0:10:29\n",
      "\u001b[32m[07/05 19:24:20 d2.evaluation.evaluator]: \u001b[0mInference done 6426/14460. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0399 s/iter. Total: 0.0777 s/iter. ETA=0:10:24\n",
      "\u001b[32m[07/05 19:24:25 d2.evaluation.evaluator]: \u001b[0mInference done 6491/14460. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0399 s/iter. Total: 0.0777 s/iter. ETA=0:10:19\n",
      "\u001b[32m[07/05 19:24:31 d2.evaluation.evaluator]: \u001b[0mInference done 6521/14460. Dataloading: 0.0024 s/iter. Inference: 0.0355 s/iter. Eval: 0.0403 s/iter. Total: 0.0782 s/iter. ETA=0:10:20\n",
      "\u001b[32m[07/05 19:24:36 d2.evaluation.evaluator]: \u001b[0mInference done 6547/14460. Dataloading: 0.0024 s/iter. Inference: 0.0355 s/iter. Eval: 0.0407 s/iter. Total: 0.0787 s/iter. ETA=0:10:22\n",
      "\u001b[32m[07/05 19:24:41 d2.evaluation.evaluator]: \u001b[0mInference done 6572/14460. Dataloading: 0.0024 s/iter. Inference: 0.0355 s/iter. Eval: 0.0411 s/iter. Total: 0.0791 s/iter. ETA=0:10:24\n",
      "\u001b[32m[07/05 19:24:46 d2.evaluation.evaluator]: \u001b[0mInference done 6598/14460. Dataloading: 0.0024 s/iter. Inference: 0.0356 s/iter. Eval: 0.0415 s/iter. Total: 0.0796 s/iter. ETA=0:10:25\n",
      "\u001b[32m[07/05 19:24:51 d2.evaluation.evaluator]: \u001b[0mInference done 6624/14460. Dataloading: 0.0024 s/iter. Inference: 0.0356 s/iter. Eval: 0.0420 s/iter. Total: 0.0801 s/iter. ETA=0:10:27\n",
      "\u001b[32m[07/05 19:24:56 d2.evaluation.evaluator]: \u001b[0mInference done 6650/14460. Dataloading: 0.0024 s/iter. Inference: 0.0357 s/iter. Eval: 0.0424 s/iter. Total: 0.0805 s/iter. ETA=0:10:28\n",
      "\u001b[32m[07/05 19:25:01 d2.evaluation.evaluator]: \u001b[0mInference done 6676/14460. Dataloading: 0.0024 s/iter. Inference: 0.0357 s/iter. Eval: 0.0428 s/iter. Total: 0.0810 s/iter. ETA=0:10:30\n",
      "\u001b[32m[07/05 19:25:06 d2.evaluation.evaluator]: \u001b[0mInference done 6702/14460. Dataloading: 0.0024 s/iter. Inference: 0.0358 s/iter. Eval: 0.0432 s/iter. Total: 0.0814 s/iter. ETA=0:10:31\n",
      "\u001b[32m[07/05 19:25:11 d2.evaluation.evaluator]: \u001b[0mInference done 6730/14460. Dataloading: 0.0024 s/iter. Inference: 0.0358 s/iter. Eval: 0.0436 s/iter. Total: 0.0818 s/iter. ETA=0:10:32\n",
      "\u001b[32m[07/05 19:25:17 d2.evaluation.evaluator]: \u001b[0mInference done 6757/14460. Dataloading: 0.0024 s/iter. Inference: 0.0358 s/iter. Eval: 0.0439 s/iter. Total: 0.0823 s/iter. ETA=0:10:33\n",
      "\u001b[32m[07/05 19:25:22 d2.evaluation.evaluator]: \u001b[0mInference done 6786/14460. Dataloading: 0.0024 s/iter. Inference: 0.0359 s/iter. Eval: 0.0443 s/iter. Total: 0.0827 s/iter. ETA=0:10:34\n",
      "\u001b[32m[07/05 19:25:27 d2.evaluation.evaluator]: \u001b[0mInference done 6814/14460. Dataloading: 0.0024 s/iter. Inference: 0.0359 s/iter. Eval: 0.0447 s/iter. Total: 0.0831 s/iter. ETA=0:10:35\n",
      "\u001b[32m[07/05 19:25:32 d2.evaluation.evaluator]: \u001b[0mInference done 6841/14460. Dataloading: 0.0024 s/iter. Inference: 0.0360 s/iter. Eval: 0.0451 s/iter. Total: 0.0835 s/iter. ETA=0:10:36\n",
      "\u001b[32m[07/05 19:25:37 d2.evaluation.evaluator]: \u001b[0mInference done 6866/14460. Dataloading: 0.0024 s/iter. Inference: 0.0360 s/iter. Eval: 0.0455 s/iter. Total: 0.0840 s/iter. ETA=0:10:37\n",
      "\u001b[32m[07/05 19:25:42 d2.evaluation.evaluator]: \u001b[0mInference done 6892/14460. Dataloading: 0.0024 s/iter. Inference: 0.0361 s/iter. Eval: 0.0459 s/iter. Total: 0.0844 s/iter. ETA=0:10:38\n",
      "\u001b[32m[07/05 19:25:47 d2.evaluation.evaluator]: \u001b[0mInference done 6918/14460. Dataloading: 0.0024 s/iter. Inference: 0.0361 s/iter. Eval: 0.0462 s/iter. Total: 0.0848 s/iter. ETA=0:10:39\n",
      "\u001b[32m[07/05 19:25:53 d2.evaluation.evaluator]: \u001b[0mInference done 6944/14460. Dataloading: 0.0024 s/iter. Inference: 0.0361 s/iter. Eval: 0.0466 s/iter. Total: 0.0852 s/iter. ETA=0:10:40\n",
      "\u001b[32m[07/05 19:25:58 d2.evaluation.evaluator]: \u001b[0mInference done 6969/14460. Dataloading: 0.0024 s/iter. Inference: 0.0362 s/iter. Eval: 0.0470 s/iter. Total: 0.0857 s/iter. ETA=0:10:41\n",
      "\u001b[32m[07/05 19:26:03 d2.evaluation.evaluator]: \u001b[0mInference done 6995/14460. Dataloading: 0.0024 s/iter. Inference: 0.0362 s/iter. Eval: 0.0474 s/iter. Total: 0.0861 s/iter. ETA=0:10:42\n",
      "\u001b[32m[07/05 19:26:08 d2.evaluation.evaluator]: \u001b[0mInference done 7021/14460. Dataloading: 0.0024 s/iter. Inference: 0.0363 s/iter. Eval: 0.0477 s/iter. Total: 0.0865 s/iter. ETA=0:10:43\n",
      "\u001b[32m[07/05 19:26:13 d2.evaluation.evaluator]: \u001b[0mInference done 7047/14460. Dataloading: 0.0024 s/iter. Inference: 0.0363 s/iter. Eval: 0.0481 s/iter. Total: 0.0869 s/iter. ETA=0:10:43\n",
      "\u001b[32m[07/05 19:26:18 d2.evaluation.evaluator]: \u001b[0mInference done 7074/14460. Dataloading: 0.0024 s/iter. Inference: 0.0363 s/iter. Eval: 0.0484 s/iter. Total: 0.0873 s/iter. ETA=0:10:44\n",
      "\u001b[32m[07/05 19:26:23 d2.evaluation.evaluator]: \u001b[0mInference done 7100/14460. Dataloading: 0.0024 s/iter. Inference: 0.0364 s/iter. Eval: 0.0488 s/iter. Total: 0.0876 s/iter. ETA=0:10:45\n",
      "\u001b[32m[07/05 19:26:28 d2.evaluation.evaluator]: \u001b[0mInference done 7126/14460. Dataloading: 0.0024 s/iter. Inference: 0.0364 s/iter. Eval: 0.0491 s/iter. Total: 0.0880 s/iter. ETA=0:10:45\n",
      "\u001b[32m[07/05 19:26:33 d2.evaluation.evaluator]: \u001b[0mInference done 7152/14460. Dataloading: 0.0024 s/iter. Inference: 0.0364 s/iter. Eval: 0.0495 s/iter. Total: 0.0884 s/iter. ETA=0:10:46\n",
      "\u001b[32m[07/05 19:26:38 d2.evaluation.evaluator]: \u001b[0mInference done 7178/14460. Dataloading: 0.0024 s/iter. Inference: 0.0365 s/iter. Eval: 0.0499 s/iter. Total: 0.0888 s/iter. ETA=0:10:46\n",
      "\u001b[32m[07/05 19:26:43 d2.evaluation.evaluator]: \u001b[0mInference done 7204/14460. Dataloading: 0.0024 s/iter. Inference: 0.0365 s/iter. Eval: 0.0502 s/iter. Total: 0.0892 s/iter. ETA=0:10:47\n",
      "\u001b[32m[07/05 19:26:48 d2.evaluation.evaluator]: \u001b[0mInference done 7230/14460. Dataloading: 0.0024 s/iter. Inference: 0.0366 s/iter. Eval: 0.0506 s/iter. Total: 0.0896 s/iter. ETA=0:10:47\n",
      "\u001b[32m[07/05 19:26:54 d2.evaluation.evaluator]: \u001b[0mInference done 7255/14460. Dataloading: 0.0024 s/iter. Inference: 0.0366 s/iter. Eval: 0.0509 s/iter. Total: 0.0900 s/iter. ETA=0:10:48\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/05 19:26:59 d2.evaluation.evaluator]: \u001b[0mInference done 7281/14460. Dataloading: 0.0024 s/iter. Inference: 0.0366 s/iter. Eval: 0.0513 s/iter. Total: 0.0904 s/iter. ETA=0:10:48\n",
      "\u001b[32m[07/05 19:27:04 d2.evaluation.evaluator]: \u001b[0mInference done 7306/14460. Dataloading: 0.0024 s/iter. Inference: 0.0367 s/iter. Eval: 0.0516 s/iter. Total: 0.0907 s/iter. ETA=0:10:49\n",
      "\u001b[32m[07/05 19:27:09 d2.evaluation.evaluator]: \u001b[0mInference done 7332/14460. Dataloading: 0.0024 s/iter. Inference: 0.0367 s/iter. Eval: 0.0519 s/iter. Total: 0.0911 s/iter. ETA=0:10:49\n",
      "\u001b[32m[07/05 19:27:14 d2.evaluation.evaluator]: \u001b[0mInference done 7358/14460. Dataloading: 0.0024 s/iter. Inference: 0.0367 s/iter. Eval: 0.0523 s/iter. Total: 0.0915 s/iter. ETA=0:10:49\n",
      "\u001b[32m[07/05 19:27:19 d2.evaluation.evaluator]: \u001b[0mInference done 7384/14460. Dataloading: 0.0024 s/iter. Inference: 0.0368 s/iter. Eval: 0.0526 s/iter. Total: 0.0919 s/iter. ETA=0:10:49\n",
      "\u001b[32m[07/05 19:27:24 d2.evaluation.evaluator]: \u001b[0mInference done 7410/14460. Dataloading: 0.0024 s/iter. Inference: 0.0368 s/iter. Eval: 0.0529 s/iter. Total: 0.0922 s/iter. ETA=0:10:50\n",
      "\u001b[32m[07/05 19:27:29 d2.evaluation.evaluator]: \u001b[0mInference done 7436/14460. Dataloading: 0.0024 s/iter. Inference: 0.0368 s/iter. Eval: 0.0533 s/iter. Total: 0.0926 s/iter. ETA=0:10:50\n",
      "\u001b[32m[07/05 19:27:34 d2.evaluation.evaluator]: \u001b[0mInference done 7463/14460. Dataloading: 0.0024 s/iter. Inference: 0.0369 s/iter. Eval: 0.0536 s/iter. Total: 0.0929 s/iter. ETA=0:10:50\n",
      "\u001b[32m[07/05 19:27:39 d2.evaluation.evaluator]: \u001b[0mInference done 7489/14460. Dataloading: 0.0024 s/iter. Inference: 0.0369 s/iter. Eval: 0.0539 s/iter. Total: 0.0933 s/iter. ETA=0:10:50\n",
      "\u001b[32m[07/05 19:27:45 d2.evaluation.evaluator]: \u001b[0mInference done 7515/14460. Dataloading: 0.0024 s/iter. Inference: 0.0369 s/iter. Eval: 0.0542 s/iter. Total: 0.0937 s/iter. ETA=0:10:50\n",
      "\u001b[32m[07/05 19:27:50 d2.evaluation.evaluator]: \u001b[0mInference done 7541/14460. Dataloading: 0.0024 s/iter. Inference: 0.0370 s/iter. Eval: 0.0546 s/iter. Total: 0.0940 s/iter. ETA=0:10:50\n",
      "\u001b[32m[07/05 19:27:55 d2.evaluation.evaluator]: \u001b[0mInference done 7568/14460. Dataloading: 0.0024 s/iter. Inference: 0.0370 s/iter. Eval: 0.0549 s/iter. Total: 0.0944 s/iter. ETA=0:10:50\n",
      "\u001b[32m[07/05 19:28:00 d2.evaluation.evaluator]: \u001b[0mInference done 7595/14460. Dataloading: 0.0024 s/iter. Inference: 0.0371 s/iter. Eval: 0.0552 s/iter. Total: 0.0947 s/iter. ETA=0:10:50\n",
      "\u001b[32m[07/05 19:28:05 d2.evaluation.evaluator]: \u001b[0mInference done 7621/14460. Dataloading: 0.0024 s/iter. Inference: 0.0371 s/iter. Eval: 0.0555 s/iter. Total: 0.0951 s/iter. ETA=0:10:50\n",
      "\u001b[32m[07/05 19:28:10 d2.evaluation.evaluator]: \u001b[0mInference done 7648/14460. Dataloading: 0.0024 s/iter. Inference: 0.0371 s/iter. Eval: 0.0558 s/iter. Total: 0.0954 s/iter. ETA=0:10:49\n",
      "\u001b[32m[07/05 19:28:15 d2.evaluation.evaluator]: \u001b[0mInference done 7674/14460. Dataloading: 0.0024 s/iter. Inference: 0.0372 s/iter. Eval: 0.0561 s/iter. Total: 0.0957 s/iter. ETA=0:10:49\n",
      "\u001b[32m[07/05 19:28:21 d2.evaluation.evaluator]: \u001b[0mInference done 7700/14460. Dataloading: 0.0024 s/iter. Inference: 0.0372 s/iter. Eval: 0.0564 s/iter. Total: 0.0961 s/iter. ETA=0:10:49\n",
      "\u001b[32m[07/05 19:28:26 d2.evaluation.evaluator]: \u001b[0mInference done 7726/14460. Dataloading: 0.0024 s/iter. Inference: 0.0372 s/iter. Eval: 0.0567 s/iter. Total: 0.0964 s/iter. ETA=0:10:49\n",
      "\u001b[32m[07/05 19:28:31 d2.evaluation.evaluator]: \u001b[0mInference done 7751/14460. Dataloading: 0.0024 s/iter. Inference: 0.0372 s/iter. Eval: 0.0570 s/iter. Total: 0.0968 s/iter. ETA=0:10:49\n",
      "\u001b[32m[07/05 19:28:36 d2.evaluation.evaluator]: \u001b[0mInference done 7777/14460. Dataloading: 0.0024 s/iter. Inference: 0.0373 s/iter. Eval: 0.0574 s/iter. Total: 0.0971 s/iter. ETA=0:10:49\n",
      "\u001b[32m[07/05 19:28:41 d2.evaluation.evaluator]: \u001b[0mInference done 7803/14460. Dataloading: 0.0024 s/iter. Inference: 0.0373 s/iter. Eval: 0.0576 s/iter. Total: 0.0974 s/iter. ETA=0:10:48\n",
      "\u001b[32m[07/05 19:28:46 d2.evaluation.evaluator]: \u001b[0mInference done 7829/14460. Dataloading: 0.0024 s/iter. Inference: 0.0373 s/iter. Eval: 0.0579 s/iter. Total: 0.0978 s/iter. ETA=0:10:48\n",
      "\u001b[32m[07/05 19:28:51 d2.evaluation.evaluator]: \u001b[0mInference done 7855/14460. Dataloading: 0.0024 s/iter. Inference: 0.0374 s/iter. Eval: 0.0582 s/iter. Total: 0.0981 s/iter. ETA=0:10:47\n",
      "\u001b[32m[07/05 19:28:56 d2.evaluation.evaluator]: \u001b[0mInference done 7881/14460. Dataloading: 0.0024 s/iter. Inference: 0.0374 s/iter. Eval: 0.0585 s/iter. Total: 0.0984 s/iter. ETA=0:10:47\n",
      "\u001b[32m[07/05 19:29:01 d2.evaluation.evaluator]: \u001b[0mInference done 7907/14460. Dataloading: 0.0024 s/iter. Inference: 0.0374 s/iter. Eval: 0.0588 s/iter. Total: 0.0987 s/iter. ETA=0:10:47\n",
      "\u001b[32m[07/05 19:29:06 d2.evaluation.evaluator]: \u001b[0mInference done 7960/14460. Dataloading: 0.0024 s/iter. Inference: 0.0374 s/iter. Eval: 0.0588 s/iter. Total: 0.0987 s/iter. ETA=0:10:41\n",
      "\u001b[32m[07/05 19:29:11 d2.evaluation.evaluator]: \u001b[0mInference done 8025/14460. Dataloading: 0.0024 s/iter. Inference: 0.0374 s/iter. Eval: 0.0587 s/iter. Total: 0.0985 s/iter. ETA=0:10:34\n",
      "\u001b[32m[07/05 19:29:17 d2.evaluation.evaluator]: \u001b[0mInference done 8089/14460. Dataloading: 0.0024 s/iter. Inference: 0.0374 s/iter. Eval: 0.0585 s/iter. Total: 0.0984 s/iter. ETA=0:10:26\n",
      "\u001b[32m[07/05 19:29:22 d2.evaluation.evaluator]: \u001b[0mInference done 8154/14460. Dataloading: 0.0024 s/iter. Inference: 0.0374 s/iter. Eval: 0.0584 s/iter. Total: 0.0982 s/iter. ETA=0:10:19\n",
      "\u001b[32m[07/05 19:29:27 d2.evaluation.evaluator]: \u001b[0mInference done 8219/14460. Dataloading: 0.0024 s/iter. Inference: 0.0374 s/iter. Eval: 0.0582 s/iter. Total: 0.0981 s/iter. ETA=0:10:12\n",
      "\u001b[32m[07/05 19:29:32 d2.evaluation.evaluator]: \u001b[0mInference done 8284/14460. Dataloading: 0.0024 s/iter. Inference: 0.0373 s/iter. Eval: 0.0581 s/iter. Total: 0.0979 s/iter. ETA=0:10:04\n",
      "\u001b[32m[07/05 19:29:37 d2.evaluation.evaluator]: \u001b[0mInference done 8349/14460. Dataloading: 0.0024 s/iter. Inference: 0.0373 s/iter. Eval: 0.0580 s/iter. Total: 0.0978 s/iter. ETA=0:09:57\n",
      "\u001b[32m[07/05 19:29:42 d2.evaluation.evaluator]: \u001b[0mInference done 8413/14460. Dataloading: 0.0024 s/iter. Inference: 0.0373 s/iter. Eval: 0.0578 s/iter. Total: 0.0976 s/iter. ETA=0:09:50\n",
      "\u001b[32m[07/05 19:29:47 d2.evaluation.evaluator]: \u001b[0mInference done 8476/14460. Dataloading: 0.0024 s/iter. Inference: 0.0373 s/iter. Eval: 0.0577 s/iter. Total: 0.0975 s/iter. ETA=0:09:43\n",
      "\u001b[32m[07/05 19:29:52 d2.evaluation.evaluator]: \u001b[0mInference done 8538/14460. Dataloading: 0.0024 s/iter. Inference: 0.0373 s/iter. Eval: 0.0576 s/iter. Total: 0.0974 s/iter. ETA=0:09:36\n",
      "\u001b[32m[07/05 19:29:57 d2.evaluation.evaluator]: \u001b[0mInference done 8597/14460. Dataloading: 0.0024 s/iter. Inference: 0.0373 s/iter. Eval: 0.0575 s/iter. Total: 0.0973 s/iter. ETA=0:09:30\n",
      "\u001b[32m[07/05 19:30:02 d2.evaluation.evaluator]: \u001b[0mInference done 8660/14460. Dataloading: 0.0024 s/iter. Inference: 0.0373 s/iter. Eval: 0.0574 s/iter. Total: 0.0971 s/iter. ETA=0:09:23\n",
      "\u001b[32m[07/05 19:30:07 d2.evaluation.evaluator]: \u001b[0mInference done 8722/14460. Dataloading: 0.0024 s/iter. Inference: 0.0373 s/iter. Eval: 0.0573 s/iter. Total: 0.0970 s/iter. ETA=0:09:16\n",
      "\u001b[32m[07/05 19:30:12 d2.evaluation.evaluator]: \u001b[0mInference done 8784/14460. Dataloading: 0.0024 s/iter. Inference: 0.0373 s/iter. Eval: 0.0572 s/iter. Total: 0.0969 s/iter. ETA=0:09:10\n",
      "\u001b[32m[07/05 19:30:17 d2.evaluation.evaluator]: \u001b[0mInference done 8845/14460. Dataloading: 0.0024 s/iter. Inference: 0.0372 s/iter. Eval: 0.0571 s/iter. Total: 0.0968 s/iter. ETA=0:09:03\n",
      "\u001b[32m[07/05 19:30:22 d2.evaluation.evaluator]: \u001b[0mInference done 8906/14460. Dataloading: 0.0024 s/iter. Inference: 0.0372 s/iter. Eval: 0.0570 s/iter. Total: 0.0967 s/iter. ETA=0:08:57\n",
      "\u001b[32m[07/05 19:30:27 d2.evaluation.evaluator]: \u001b[0mInference done 8968/14460. Dataloading: 0.0024 s/iter. Inference: 0.0372 s/iter. Eval: 0.0570 s/iter. Total: 0.0966 s/iter. ETA=0:08:50\n",
      "\u001b[32m[07/05 19:30:32 d2.evaluation.evaluator]: \u001b[0mInference done 9030/14460. Dataloading: 0.0024 s/iter. Inference: 0.0372 s/iter. Eval: 0.0569 s/iter. Total: 0.0965 s/iter. ETA=0:08:44\n",
      "\u001b[32m[07/05 19:30:37 d2.evaluation.evaluator]: \u001b[0mInference done 9091/14460. Dataloading: 0.0024 s/iter. Inference: 0.0372 s/iter. Eval: 0.0568 s/iter. Total: 0.0964 s/iter. ETA=0:08:37\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/05 19:30:42 d2.evaluation.evaluator]: \u001b[0mInference done 9153/14460. Dataloading: 0.0024 s/iter. Inference: 0.0372 s/iter. Eval: 0.0567 s/iter. Total: 0.0963 s/iter. ETA=0:08:31\n",
      "\u001b[32m[07/05 19:30:47 d2.evaluation.evaluator]: \u001b[0mInference done 9215/14460. Dataloading: 0.0024 s/iter. Inference: 0.0372 s/iter. Eval: 0.0566 s/iter. Total: 0.0962 s/iter. ETA=0:08:24\n",
      "\u001b[32m[07/05 19:30:52 d2.evaluation.evaluator]: \u001b[0mInference done 9276/14460. Dataloading: 0.0024 s/iter. Inference: 0.0372 s/iter. Eval: 0.0565 s/iter. Total: 0.0961 s/iter. ETA=0:08:18\n",
      "\u001b[32m[07/05 19:30:57 d2.evaluation.evaluator]: \u001b[0mInference done 9337/14460. Dataloading: 0.0024 s/iter. Inference: 0.0371 s/iter. Eval: 0.0564 s/iter. Total: 0.0960 s/iter. ETA=0:08:12\n",
      "\u001b[32m[07/05 19:31:02 d2.evaluation.evaluator]: \u001b[0mInference done 9398/14460. Dataloading: 0.0024 s/iter. Inference: 0.0371 s/iter. Eval: 0.0564 s/iter. Total: 0.0959 s/iter. ETA=0:08:05\n",
      "\u001b[32m[07/05 19:31:07 d2.evaluation.evaluator]: \u001b[0mInference done 9461/14460. Dataloading: 0.0024 s/iter. Inference: 0.0371 s/iter. Eval: 0.0563 s/iter. Total: 0.0958 s/iter. ETA=0:07:59\n",
      "\u001b[32m[07/05 19:31:12 d2.evaluation.evaluator]: \u001b[0mInference done 9528/14460. Dataloading: 0.0024 s/iter. Inference: 0.0371 s/iter. Eval: 0.0561 s/iter. Total: 0.0957 s/iter. ETA=0:07:51\n",
      "\u001b[32m[07/05 19:31:18 d2.evaluation.evaluator]: \u001b[0mInference done 9594/14460. Dataloading: 0.0024 s/iter. Inference: 0.0371 s/iter. Eval: 0.0560 s/iter. Total: 0.0956 s/iter. ETA=0:07:45\n",
      "\u001b[32m[07/05 19:31:23 d2.evaluation.evaluator]: \u001b[0mInference done 9659/14460. Dataloading: 0.0024 s/iter. Inference: 0.0371 s/iter. Eval: 0.0559 s/iter. Total: 0.0954 s/iter. ETA=0:07:38\n",
      "\u001b[32m[07/05 19:31:28 d2.evaluation.evaluator]: \u001b[0mInference done 9723/14460. Dataloading: 0.0024 s/iter. Inference: 0.0371 s/iter. Eval: 0.0558 s/iter. Total: 0.0953 s/iter. ETA=0:07:31\n",
      "\u001b[32m[07/05 19:31:33 d2.evaluation.evaluator]: \u001b[0mInference done 9789/14460. Dataloading: 0.0024 s/iter. Inference: 0.0371 s/iter. Eval: 0.0557 s/iter. Total: 0.0952 s/iter. ETA=0:07:24\n",
      "\u001b[32m[07/05 19:31:38 d2.evaluation.evaluator]: \u001b[0mInference done 9854/14460. Dataloading: 0.0024 s/iter. Inference: 0.0371 s/iter. Eval: 0.0556 s/iter. Total: 0.0951 s/iter. ETA=0:07:17\n",
      "\u001b[32m[07/05 19:31:43 d2.evaluation.evaluator]: \u001b[0mInference done 9918/14460. Dataloading: 0.0024 s/iter. Inference: 0.0370 s/iter. Eval: 0.0555 s/iter. Total: 0.0950 s/iter. ETA=0:07:11\n",
      "\u001b[32m[07/05 19:31:48 d2.evaluation.evaluator]: \u001b[0mInference done 9983/14460. Dataloading: 0.0024 s/iter. Inference: 0.0370 s/iter. Eval: 0.0554 s/iter. Total: 0.0949 s/iter. ETA=0:07:04\n",
      "\u001b[32m[07/05 19:31:53 d2.evaluation.evaluator]: \u001b[0mInference done 10048/14460. Dataloading: 0.0024 s/iter. Inference: 0.0370 s/iter. Eval: 0.0553 s/iter. Total: 0.0948 s/iter. ETA=0:06:58\n",
      "\u001b[32m[07/05 19:31:58 d2.evaluation.evaluator]: \u001b[0mInference done 10111/14460. Dataloading: 0.0024 s/iter. Inference: 0.0370 s/iter. Eval: 0.0552 s/iter. Total: 0.0947 s/iter. ETA=0:06:51\n",
      "\u001b[32m[07/05 19:32:03 d2.evaluation.evaluator]: \u001b[0mInference done 10177/14460. Dataloading: 0.0024 s/iter. Inference: 0.0370 s/iter. Eval: 0.0551 s/iter. Total: 0.0945 s/iter. ETA=0:06:44\n",
      "\u001b[32m[07/05 19:32:08 d2.evaluation.evaluator]: \u001b[0mInference done 10243/14460. Dataloading: 0.0024 s/iter. Inference: 0.0370 s/iter. Eval: 0.0550 s/iter. Total: 0.0944 s/iter. ETA=0:06:38\n",
      "\u001b[32m[07/05 19:32:13 d2.evaluation.evaluator]: \u001b[0mInference done 10309/14460. Dataloading: 0.0024 s/iter. Inference: 0.0370 s/iter. Eval: 0.0549 s/iter. Total: 0.0943 s/iter. ETA=0:06:31\n",
      "\u001b[32m[07/05 19:32:18 d2.evaluation.evaluator]: \u001b[0mInference done 10374/14460. Dataloading: 0.0024 s/iter. Inference: 0.0370 s/iter. Eval: 0.0548 s/iter. Total: 0.0942 s/iter. ETA=0:06:24\n",
      "\u001b[32m[07/05 19:32:23 d2.evaluation.evaluator]: \u001b[0mInference done 10440/14460. Dataloading: 0.0024 s/iter. Inference: 0.0370 s/iter. Eval: 0.0547 s/iter. Total: 0.0941 s/iter. ETA=0:06:18\n",
      "\u001b[32m[07/05 19:32:28 d2.evaluation.evaluator]: \u001b[0mInference done 10504/14460. Dataloading: 0.0024 s/iter. Inference: 0.0370 s/iter. Eval: 0.0546 s/iter. Total: 0.0940 s/iter. ETA=0:06:11\n",
      "\u001b[32m[07/05 19:32:33 d2.evaluation.evaluator]: \u001b[0mInference done 10568/14460. Dataloading: 0.0024 s/iter. Inference: 0.0370 s/iter. Eval: 0.0545 s/iter. Total: 0.0939 s/iter. ETA=0:06:05\n",
      "\u001b[32m[07/05 19:32:38 d2.evaluation.evaluator]: \u001b[0mInference done 10630/14460. Dataloading: 0.0024 s/iter. Inference: 0.0369 s/iter. Eval: 0.0544 s/iter. Total: 0.0938 s/iter. ETA=0:05:59\n",
      "\u001b[32m[07/05 19:32:43 d2.evaluation.evaluator]: \u001b[0mInference done 10694/14460. Dataloading: 0.0024 s/iter. Inference: 0.0369 s/iter. Eval: 0.0544 s/iter. Total: 0.0937 s/iter. ETA=0:05:53\n",
      "\u001b[32m[07/05 19:32:48 d2.evaluation.evaluator]: \u001b[0mInference done 10758/14460. Dataloading: 0.0024 s/iter. Inference: 0.0369 s/iter. Eval: 0.0543 s/iter. Total: 0.0936 s/iter. ETA=0:05:46\n",
      "\u001b[32m[07/05 19:32:53 d2.evaluation.evaluator]: \u001b[0mInference done 10823/14460. Dataloading: 0.0024 s/iter. Inference: 0.0369 s/iter. Eval: 0.0542 s/iter. Total: 0.0936 s/iter. ETA=0:05:40\n",
      "\u001b[32m[07/05 19:32:58 d2.evaluation.evaluator]: \u001b[0mInference done 10888/14460. Dataloading: 0.0024 s/iter. Inference: 0.0369 s/iter. Eval: 0.0541 s/iter. Total: 0.0935 s/iter. ETA=0:05:33\n",
      "\u001b[32m[07/05 19:33:03 d2.evaluation.evaluator]: \u001b[0mInference done 10954/14460. Dataloading: 0.0024 s/iter. Inference: 0.0369 s/iter. Eval: 0.0540 s/iter. Total: 0.0934 s/iter. ETA=0:05:27\n",
      "\u001b[32m[07/05 19:33:08 d2.evaluation.evaluator]: \u001b[0mInference done 11020/14460. Dataloading: 0.0024 s/iter. Inference: 0.0369 s/iter. Eval: 0.0539 s/iter. Total: 0.0932 s/iter. ETA=0:05:20\n",
      "\u001b[32m[07/05 19:33:13 d2.evaluation.evaluator]: \u001b[0mInference done 11086/14460. Dataloading: 0.0024 s/iter. Inference: 0.0369 s/iter. Eval: 0.0538 s/iter. Total: 0.0931 s/iter. ETA=0:05:14\n",
      "\u001b[32m[07/05 19:33:18 d2.evaluation.evaluator]: \u001b[0mInference done 11151/14460. Dataloading: 0.0024 s/iter. Inference: 0.0369 s/iter. Eval: 0.0537 s/iter. Total: 0.0931 s/iter. ETA=0:05:07\n",
      "\u001b[32m[07/05 19:33:23 d2.evaluation.evaluator]: \u001b[0mInference done 11216/14460. Dataloading: 0.0024 s/iter. Inference: 0.0369 s/iter. Eval: 0.0537 s/iter. Total: 0.0930 s/iter. ETA=0:05:01\n",
      "\u001b[32m[07/05 19:33:28 d2.evaluation.evaluator]: \u001b[0mInference done 11280/14460. Dataloading: 0.0024 s/iter. Inference: 0.0369 s/iter. Eval: 0.0536 s/iter. Total: 0.0929 s/iter. ETA=0:04:55\n",
      "\u001b[32m[07/05 19:33:33 d2.evaluation.evaluator]: \u001b[0mInference done 11346/14460. Dataloading: 0.0024 s/iter. Inference: 0.0369 s/iter. Eval: 0.0535 s/iter. Total: 0.0928 s/iter. ETA=0:04:48\n",
      "\u001b[32m[07/05 19:33:38 d2.evaluation.evaluator]: \u001b[0mInference done 11410/14460. Dataloading: 0.0024 s/iter. Inference: 0.0369 s/iter. Eval: 0.0534 s/iter. Total: 0.0927 s/iter. ETA=0:04:42\n",
      "\u001b[32m[07/05 19:33:43 d2.evaluation.evaluator]: \u001b[0mInference done 11474/14460. Dataloading: 0.0024 s/iter. Inference: 0.0368 s/iter. Eval: 0.0533 s/iter. Total: 0.0926 s/iter. ETA=0:04:36\n",
      "\u001b[32m[07/05 19:33:48 d2.evaluation.evaluator]: \u001b[0mInference done 11540/14460. Dataloading: 0.0024 s/iter. Inference: 0.0368 s/iter. Eval: 0.0533 s/iter. Total: 0.0925 s/iter. ETA=0:04:30\n",
      "\u001b[32m[07/05 19:33:54 d2.evaluation.evaluator]: \u001b[0mInference done 11605/14460. Dataloading: 0.0024 s/iter. Inference: 0.0368 s/iter. Eval: 0.0532 s/iter. Total: 0.0924 s/iter. ETA=0:04:23\n",
      "\u001b[32m[07/05 19:33:59 d2.evaluation.evaluator]: \u001b[0mInference done 11671/14460. Dataloading: 0.0024 s/iter. Inference: 0.0368 s/iter. Eval: 0.0531 s/iter. Total: 0.0924 s/iter. ETA=0:04:17\n",
      "\u001b[32m[07/05 19:34:04 d2.evaluation.evaluator]: \u001b[0mInference done 11738/14460. Dataloading: 0.0024 s/iter. Inference: 0.0368 s/iter. Eval: 0.0530 s/iter. Total: 0.0923 s/iter. ETA=0:04:11\n",
      "\u001b[32m[07/05 19:34:09 d2.evaluation.evaluator]: \u001b[0mInference done 11803/14460. Dataloading: 0.0024 s/iter. Inference: 0.0368 s/iter. Eval: 0.0529 s/iter. Total: 0.0922 s/iter. ETA=0:04:04\n",
      "\u001b[32m[07/05 19:34:14 d2.evaluation.evaluator]: \u001b[0mInference done 11869/14460. Dataloading: 0.0024 s/iter. Inference: 0.0368 s/iter. Eval: 0.0529 s/iter. Total: 0.0921 s/iter. ETA=0:03:58\n",
      "\u001b[32m[07/05 19:34:19 d2.evaluation.evaluator]: \u001b[0mInference done 11935/14460. Dataloading: 0.0024 s/iter. Inference: 0.0368 s/iter. Eval: 0.0528 s/iter. Total: 0.0920 s/iter. ETA=0:03:52\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/05 19:34:24 d2.evaluation.evaluator]: \u001b[0mInference done 12000/14460. Dataloading: 0.0024 s/iter. Inference: 0.0368 s/iter. Eval: 0.0527 s/iter. Total: 0.0919 s/iter. ETA=0:03:46\n",
      "\u001b[32m[07/05 19:34:29 d2.evaluation.evaluator]: \u001b[0mInference done 12066/14460. Dataloading: 0.0024 s/iter. Inference: 0.0368 s/iter. Eval: 0.0526 s/iter. Total: 0.0918 s/iter. ETA=0:03:39\n",
      "\u001b[32m[07/05 19:34:34 d2.evaluation.evaluator]: \u001b[0mInference done 12133/14460. Dataloading: 0.0024 s/iter. Inference: 0.0368 s/iter. Eval: 0.0525 s/iter. Total: 0.0918 s/iter. ETA=0:03:33\n",
      "\u001b[32m[07/05 19:34:39 d2.evaluation.evaluator]: \u001b[0mInference done 12199/14460. Dataloading: 0.0024 s/iter. Inference: 0.0368 s/iter. Eval: 0.0525 s/iter. Total: 0.0917 s/iter. ETA=0:03:27\n",
      "\u001b[32m[07/05 19:34:44 d2.evaluation.evaluator]: \u001b[0mInference done 12263/14460. Dataloading: 0.0024 s/iter. Inference: 0.0368 s/iter. Eval: 0.0524 s/iter. Total: 0.0916 s/iter. ETA=0:03:21\n",
      "\u001b[32m[07/05 19:34:49 d2.evaluation.evaluator]: \u001b[0mInference done 12329/14460. Dataloading: 0.0024 s/iter. Inference: 0.0368 s/iter. Eval: 0.0523 s/iter. Total: 0.0915 s/iter. ETA=0:03:15\n",
      "\u001b[32m[07/05 19:34:54 d2.evaluation.evaluator]: \u001b[0mInference done 12394/14460. Dataloading: 0.0024 s/iter. Inference: 0.0367 s/iter. Eval: 0.0523 s/iter. Total: 0.0914 s/iter. ETA=0:03:08\n",
      "\u001b[32m[07/05 19:34:59 d2.evaluation.evaluator]: \u001b[0mInference done 12460/14460. Dataloading: 0.0024 s/iter. Inference: 0.0367 s/iter. Eval: 0.0522 s/iter. Total: 0.0914 s/iter. ETA=0:03:02\n",
      "\u001b[32m[07/05 19:35:04 d2.evaluation.evaluator]: \u001b[0mInference done 12527/14460. Dataloading: 0.0024 s/iter. Inference: 0.0367 s/iter. Eval: 0.0521 s/iter. Total: 0.0913 s/iter. ETA=0:02:56\n",
      "\u001b[32m[07/05 19:35:09 d2.evaluation.evaluator]: \u001b[0mInference done 12594/14460. Dataloading: 0.0023 s/iter. Inference: 0.0367 s/iter. Eval: 0.0520 s/iter. Total: 0.0912 s/iter. ETA=0:02:50\n",
      "\u001b[32m[07/05 19:35:14 d2.evaluation.evaluator]: \u001b[0mInference done 12660/14460. Dataloading: 0.0023 s/iter. Inference: 0.0367 s/iter. Eval: 0.0520 s/iter. Total: 0.0911 s/iter. ETA=0:02:44\n",
      "\u001b[32m[07/05 19:35:19 d2.evaluation.evaluator]: \u001b[0mInference done 12725/14460. Dataloading: 0.0023 s/iter. Inference: 0.0367 s/iter. Eval: 0.0519 s/iter. Total: 0.0911 s/iter. ETA=0:02:37\n",
      "\u001b[32m[07/05 19:35:24 d2.evaluation.evaluator]: \u001b[0mInference done 12790/14460. Dataloading: 0.0023 s/iter. Inference: 0.0367 s/iter. Eval: 0.0518 s/iter. Total: 0.0910 s/iter. ETA=0:02:31\n",
      "\u001b[32m[07/05 19:35:29 d2.evaluation.evaluator]: \u001b[0mInference done 12854/14460. Dataloading: 0.0023 s/iter. Inference: 0.0367 s/iter. Eval: 0.0518 s/iter. Total: 0.0909 s/iter. ETA=0:02:26\n",
      "\u001b[32m[07/05 19:35:34 d2.evaluation.evaluator]: \u001b[0mInference done 12918/14460. Dataloading: 0.0023 s/iter. Inference: 0.0367 s/iter. Eval: 0.0517 s/iter. Total: 0.0909 s/iter. ETA=0:02:20\n",
      "\u001b[32m[07/05 19:35:40 d2.evaluation.evaluator]: \u001b[0mInference done 12982/14460. Dataloading: 0.0023 s/iter. Inference: 0.0367 s/iter. Eval: 0.0517 s/iter. Total: 0.0908 s/iter. ETA=0:02:14\n",
      "\u001b[32m[07/05 19:35:45 d2.evaluation.evaluator]: \u001b[0mInference done 13046/14460. Dataloading: 0.0023 s/iter. Inference: 0.0367 s/iter. Eval: 0.0516 s/iter. Total: 0.0907 s/iter. ETA=0:02:08\n",
      "\u001b[32m[07/05 19:35:50 d2.evaluation.evaluator]: \u001b[0mInference done 13111/14460. Dataloading: 0.0023 s/iter. Inference: 0.0367 s/iter. Eval: 0.0516 s/iter. Total: 0.0907 s/iter. ETA=0:02:02\n",
      "\u001b[32m[07/05 19:35:55 d2.evaluation.evaluator]: \u001b[0mInference done 13176/14460. Dataloading: 0.0023 s/iter. Inference: 0.0367 s/iter. Eval: 0.0515 s/iter. Total: 0.0906 s/iter. ETA=0:01:56\n",
      "\u001b[32m[07/05 19:36:00 d2.evaluation.evaluator]: \u001b[0mInference done 13241/14460. Dataloading: 0.0023 s/iter. Inference: 0.0367 s/iter. Eval: 0.0515 s/iter. Total: 0.0906 s/iter. ETA=0:01:50\n",
      "\u001b[32m[07/05 19:36:05 d2.evaluation.evaluator]: \u001b[0mInference done 13306/14460. Dataloading: 0.0023 s/iter. Inference: 0.0367 s/iter. Eval: 0.0514 s/iter. Total: 0.0905 s/iter. ETA=0:01:44\n",
      "\u001b[32m[07/05 19:36:10 d2.evaluation.evaluator]: \u001b[0mInference done 13371/14460. Dataloading: 0.0023 s/iter. Inference: 0.0367 s/iter. Eval: 0.0513 s/iter. Total: 0.0904 s/iter. ETA=0:01:38\n",
      "\u001b[32m[07/05 19:36:15 d2.evaluation.evaluator]: \u001b[0mInference done 13436/14460. Dataloading: 0.0023 s/iter. Inference: 0.0367 s/iter. Eval: 0.0513 s/iter. Total: 0.0904 s/iter. ETA=0:01:32\n",
      "\u001b[32m[07/05 19:36:20 d2.evaluation.evaluator]: \u001b[0mInference done 13497/14460. Dataloading: 0.0024 s/iter. Inference: 0.0366 s/iter. Eval: 0.0512 s/iter. Total: 0.0903 s/iter. ETA=0:01:26\n",
      "\u001b[32m[07/05 19:36:25 d2.evaluation.evaluator]: \u001b[0mInference done 13561/14460. Dataloading: 0.0024 s/iter. Inference: 0.0366 s/iter. Eval: 0.0512 s/iter. Total: 0.0903 s/iter. ETA=0:01:21\n",
      "\u001b[32m[07/05 19:36:30 d2.evaluation.evaluator]: \u001b[0mInference done 13625/14460. Dataloading: 0.0024 s/iter. Inference: 0.0366 s/iter. Eval: 0.0511 s/iter. Total: 0.0902 s/iter. ETA=0:01:15\n",
      "\u001b[32m[07/05 19:36:35 d2.evaluation.evaluator]: \u001b[0mInference done 13687/14460. Dataloading: 0.0024 s/iter. Inference: 0.0366 s/iter. Eval: 0.0511 s/iter. Total: 0.0902 s/iter. ETA=0:01:09\n",
      "\u001b[32m[07/05 19:36:40 d2.evaluation.evaluator]: \u001b[0mInference done 13749/14460. Dataloading: 0.0024 s/iter. Inference: 0.0366 s/iter. Eval: 0.0511 s/iter. Total: 0.0901 s/iter. ETA=0:01:04\n",
      "\u001b[32m[07/05 19:36:45 d2.evaluation.evaluator]: \u001b[0mInference done 13811/14460. Dataloading: 0.0024 s/iter. Inference: 0.0366 s/iter. Eval: 0.0510 s/iter. Total: 0.0901 s/iter. ETA=0:00:58\n",
      "\u001b[32m[07/05 19:36:50 d2.evaluation.evaluator]: \u001b[0mInference done 13872/14460. Dataloading: 0.0024 s/iter. Inference: 0.0366 s/iter. Eval: 0.0510 s/iter. Total: 0.0901 s/iter. ETA=0:00:52\n",
      "\u001b[32m[07/05 19:36:55 d2.evaluation.evaluator]: \u001b[0mInference done 13936/14460. Dataloading: 0.0024 s/iter. Inference: 0.0366 s/iter. Eval: 0.0510 s/iter. Total: 0.0900 s/iter. ETA=0:00:47\n",
      "\u001b[32m[07/05 19:37:00 d2.evaluation.evaluator]: \u001b[0mInference done 14001/14460. Dataloading: 0.0024 s/iter. Inference: 0.0366 s/iter. Eval: 0.0509 s/iter. Total: 0.0900 s/iter. ETA=0:00:41\n",
      "\u001b[32m[07/05 19:37:05 d2.evaluation.evaluator]: \u001b[0mInference done 14065/14460. Dataloading: 0.0024 s/iter. Inference: 0.0366 s/iter. Eval: 0.0509 s/iter. Total: 0.0899 s/iter. ETA=0:00:35\n",
      "\u001b[32m[07/05 19:37:10 d2.evaluation.evaluator]: \u001b[0mInference done 14129/14460. Dataloading: 0.0024 s/iter. Inference: 0.0366 s/iter. Eval: 0.0508 s/iter. Total: 0.0898 s/iter. ETA=0:00:29\n",
      "\u001b[32m[07/05 19:37:15 d2.evaluation.evaluator]: \u001b[0mInference done 14194/14460. Dataloading: 0.0024 s/iter. Inference: 0.0366 s/iter. Eval: 0.0508 s/iter. Total: 0.0898 s/iter. ETA=0:00:23\n",
      "\u001b[32m[07/05 19:37:20 d2.evaluation.evaluator]: \u001b[0mInference done 14258/14460. Dataloading: 0.0024 s/iter. Inference: 0.0366 s/iter. Eval: 0.0507 s/iter. Total: 0.0897 s/iter. ETA=0:00:18\n",
      "\u001b[32m[07/05 19:37:25 d2.evaluation.evaluator]: \u001b[0mInference done 14324/14460. Dataloading: 0.0024 s/iter. Inference: 0.0366 s/iter. Eval: 0.0507 s/iter. Total: 0.0897 s/iter. ETA=0:00:12\n",
      "\u001b[32m[07/05 19:37:30 d2.evaluation.evaluator]: \u001b[0mInference done 14390/14460. Dataloading: 0.0024 s/iter. Inference: 0.0366 s/iter. Eval: 0.0506 s/iter. Total: 0.0896 s/iter. ETA=0:00:06\n",
      "\u001b[32m[07/05 19:37:35 d2.evaluation.evaluator]: \u001b[0mInference done 14455/14460. Dataloading: 0.0024 s/iter. Inference: 0.0366 s/iter. Eval: 0.0506 s/iter. Total: 0.0896 s/iter. ETA=0:00:00\n",
      "\u001b[32m[07/05 19:37:36 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:21:34.663616 (0.089565 s / iter per device, on 1 devices)\n",
      "\u001b[32m[07/05 19:37:36 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:08:48 (0.036568 s / iter per device, on 1 devices)\n",
      "\u001b[32m[07/05 19:37:38 d2.evaluation.sem_seg_evaluation]: \u001b[0mOrderedDict([('sem_seg', {'mIoU': 54.54468386057454, 'fwIoU': 77.0930515006018, 'IoU-Unlabeled': nan, 'IoU-Building': 68.05348484065458, 'IoU-Fence': 29.173937634876694, 'IoU-Pedestrian': 69.56697980957625, 'IoU-Pole': 50.158430902587135, 'IoU-Road': 94.55153718889208, 'IoU-SideWalk': 69.77794922824755, 'IoU-Vegetation': 68.68777777950137, 'IoU-Vehicles': 73.14312616982924, 'IoU-Wall': 54.23160922030497, 'IoU-TrafficSign': 56.23624066887689, 'IoU-Sky': 71.7875047406401, 'IoU-TrafficLight': 56.702879283895726, 'IoU-Terrain': 24.362557376634765, 'IoU-ConstructionVehicle': 73.9596850454089, 'IoU-workzone_object': 53.089660245684975, 'IoU-Detour': 13.77626549415586, 'mACC': 71.20275344358994, 'pACC': 86.38341005199719, 'ACC-Unlabeled': nan, 'ACC-Building': 95.49822525483854, 'ACC-Fence': 50.88171504785433, 'ACC-Pedestrian': 85.55759335743576, 'ACC-Pole': 61.38561229231316, 'ACC-Road': 96.94648650220795, 'ACC-SideWalk': 80.41873605512971, 'ACC-Vegetation': 79.2398543566387, 'ACC-Vehicles': 91.85966928147246, 'ACC-Wall': 61.71085695169927, 'ACC-TrafficSign': 67.2496675225397, 'ACC-Sky': 75.07681898873044, 'ACC-TrafficLight': 67.951715673166, 'ACC-Terrain': 25.413312520998133, 'ACC-ConstructionVehicle': 94.7960972835061, 'ACC-workzone_object': 85.66014315271427, 'ACC-Detour': 19.597550856194523})])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/05 19:37:38 d2.engine.defaults]: \u001b[0mEvaluation results for combined_all_night_val in csv format:\n",
      "\u001b[32m[07/05 19:37:38 d2.evaluation.testing]: \u001b[0mcopypaste: Task: sem_seg\n",
      "\u001b[32m[07/05 19:37:38 d2.evaluation.testing]: \u001b[0mcopypaste: mIoU,fwIoU,mACC,pACC\n",
      "\u001b[32m[07/05 19:37:38 d2.evaluation.testing]: \u001b[0mcopypaste: 54.5447,77.0931,71.2028,86.3834\n"
     ]
    }
   ],
   "source": [
    "#all\n",
    "trainer_both = Detectron2Trainer('combined_clear_both_train', 'combined_all_night_val', output_folder='./output_both_clear_40k')\n",
    "trainer_both.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2959502d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "ac185179",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/05 21:25:31 d2.engine.defaults]: \u001b[0mModel:\n",
      "SemanticSegmentor(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (sem_seg_head): SemSegFPNHead(\n",
      "    (p2): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "    )\n",
      "    (p3): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (1): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "    )\n",
      "    (p4): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (1): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      (2): Conv2d(\n",
      "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (3): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "    )\n",
      "    (p5): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (1): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      (2): Conv2d(\n",
      "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (3): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      (4): Conv2d(\n",
      "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (5): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "    )\n",
      "    (predictor): Conv2d(128, 17, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/05 21:25:31 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(720, 720), max_size=2048, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[07/05 21:25:31 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[07/05 21:25:31 d2.data.common]: \u001b[0mSerializing 37734 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[07/05 21:25:31 d2.data.common]: \u001b[0mSerialized dataset takes 11.85 MiB\n",
      "Last checkpoint: model_final.pth\n",
      "\u001b[32m[07/05 21:25:32 d2.checkpoint.c2_model_loading]: \u001b[0mFollowing weights matched with model:\n",
      "| Names in Model                       | Names in Checkpoint                                                                                  | Shapes                                          |\n",
      "|:-------------------------------------|:-----------------------------------------------------------------------------------------------------|:------------------------------------------------|\n",
      "| backbone.bottom_up.res2.0.conv1.*    | backbone.bottom_up.res2.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,1,1)             |\n",
      "| backbone.bottom_up.res2.0.conv2.*    | backbone.bottom_up.res2.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |\n",
      "| backbone.bottom_up.res2.0.conv3.*    | backbone.bottom_up.res2.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res2.0.shortcut.* | backbone.bottom_up.res2.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res2.1.conv1.*    | backbone.bottom_up.res2.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |\n",
      "| backbone.bottom_up.res2.1.conv2.*    | backbone.bottom_up.res2.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |\n",
      "| backbone.bottom_up.res2.1.conv3.*    | backbone.bottom_up.res2.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res2.2.conv1.*    | backbone.bottom_up.res2.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |\n",
      "| backbone.bottom_up.res2.2.conv2.*    | backbone.bottom_up.res2.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |\n",
      "| backbone.bottom_up.res2.2.conv3.*    | backbone.bottom_up.res2.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res3.0.conv1.*    | backbone.bottom_up.res3.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,256,1,1)       |\n",
      "| backbone.bottom_up.res3.0.conv2.*    | backbone.bottom_up.res3.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.0.conv3.*    | backbone.bottom_up.res3.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res3.0.shortcut.* | backbone.bottom_up.res3.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (512,) (512,) (512,) (512,) (512,256,1,1)       |\n",
      "| backbone.bottom_up.res3.1.conv1.*    | backbone.bottom_up.res3.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |\n",
      "| backbone.bottom_up.res3.1.conv2.*    | backbone.bottom_up.res3.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.1.conv3.*    | backbone.bottom_up.res3.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res3.2.conv1.*    | backbone.bottom_up.res3.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |\n",
      "| backbone.bottom_up.res3.2.conv2.*    | backbone.bottom_up.res3.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.2.conv3.*    | backbone.bottom_up.res3.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res3.3.conv1.*    | backbone.bottom_up.res3.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |\n",
      "| backbone.bottom_up.res3.3.conv2.*    | backbone.bottom_up.res3.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.3.conv3.*    | backbone.bottom_up.res3.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res4.0.conv1.*    | backbone.bottom_up.res4.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,512,1,1)       |\n",
      "| backbone.bottom_up.res4.0.conv2.*    | backbone.bottom_up.res4.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.0.conv3.*    | backbone.bottom_up.res4.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.0.shortcut.* | backbone.bottom_up.res4.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (1024,) (1024,) (1024,) (1024,) (1024,512,1,1)  |\n",
      "| backbone.bottom_up.res4.1.conv1.*    | backbone.bottom_up.res4.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.1.conv2.*    | backbone.bottom_up.res4.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.1.conv3.*    | backbone.bottom_up.res4.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.2.conv1.*    | backbone.bottom_up.res4.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.2.conv2.*    | backbone.bottom_up.res4.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.2.conv3.*    | backbone.bottom_up.res4.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.3.conv1.*    | backbone.bottom_up.res4.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.3.conv2.*    | backbone.bottom_up.res4.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.3.conv3.*    | backbone.bottom_up.res4.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.4.conv1.*    | backbone.bottom_up.res4.4.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.4.conv2.*    | backbone.bottom_up.res4.4.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.4.conv3.*    | backbone.bottom_up.res4.4.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.5.conv1.*    | backbone.bottom_up.res4.5.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.5.conv2.*    | backbone.bottom_up.res4.5.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.5.conv3.*    | backbone.bottom_up.res4.5.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res5.0.conv1.*    | backbone.bottom_up.res5.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,1024,1,1)      |\n",
      "| backbone.bottom_up.res5.0.conv2.*    | backbone.bottom_up.res5.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |\n",
      "| backbone.bottom_up.res5.0.conv3.*    | backbone.bottom_up.res5.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
      "| backbone.bottom_up.res5.0.shortcut.* | backbone.bottom_up.res5.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (2048,) (2048,) (2048,) (2048,) (2048,1024,1,1) |\n",
      "| backbone.bottom_up.res5.1.conv1.*    | backbone.bottom_up.res5.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |\n",
      "| backbone.bottom_up.res5.1.conv2.*    | backbone.bottom_up.res5.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |\n",
      "| backbone.bottom_up.res5.1.conv3.*    | backbone.bottom_up.res5.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
      "| backbone.bottom_up.res5.2.conv1.*    | backbone.bottom_up.res5.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |\n",
      "| backbone.bottom_up.res5.2.conv2.*    | backbone.bottom_up.res5.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |\n",
      "| backbone.bottom_up.res5.2.conv3.*    | backbone.bottom_up.res5.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
      "| backbone.bottom_up.stem.conv1.*      | backbone.bottom_up.stem.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}      | (64,) (64,) (64,) (64,) (64,3,7,7)              |\n",
      "| backbone.fpn_lateral2.*              | backbone.fpn_lateral2.{bias,weight}                                                                  | (256,) (256,256,1,1)                            |\n",
      "| backbone.fpn_lateral3.*              | backbone.fpn_lateral3.{bias,weight}                                                                  | (256,) (256,512,1,1)                            |\n",
      "| backbone.fpn_lateral4.*              | backbone.fpn_lateral4.{bias,weight}                                                                  | (256,) (256,1024,1,1)                           |\n",
      "| backbone.fpn_lateral5.*              | backbone.fpn_lateral5.{bias,weight}                                                                  | (256,) (256,2048,1,1)                           |\n",
      "| backbone.fpn_output2.*               | backbone.fpn_output2.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| backbone.fpn_output3.*               | backbone.fpn_output3.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| backbone.fpn_output4.*               | backbone.fpn_output4.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| backbone.fpn_output5.*               | backbone.fpn_output5.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| sem_seg_head.p2.0.*                  | sem_seg_head.p2.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p3.0.*                  | sem_seg_head.p3.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p4.0.*                  | sem_seg_head.p4.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p4.2.*                  | sem_seg_head.p4.2.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,128,3,3)                     |\n",
      "| sem_seg_head.p5.0.*                  | sem_seg_head.p5.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p5.2.*                  | sem_seg_head.p5.2.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,128,3,3)                     |\n",
      "| sem_seg_head.p5.4.*                  | sem_seg_head.p5.4.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,128,3,3)                     |\n",
      "| sem_seg_head.predictor.*             | sem_seg_head.predictor.{bias,weight}                                                                 | (17,) (17,128,1,1)                              |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/05 21:25:32 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(720, 720), max_size=2048, sample_style='choice')]\n",
      "\u001b[32m[07/05 21:25:32 d2.data.common]: \u001b[0mSerializing 6531 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[07/05 21:25:32 d2.data.common]: \u001b[0mSerialized dataset takes 2.03 MiB\n",
      "\u001b[32m[07/05 21:25:32 d2.evaluation.evaluator]: \u001b[0mStart inference on 6531 batches\n",
      "\u001b[32m[07/05 21:25:33 d2.evaluation.evaluator]: \u001b[0mInference done 11/6531. Dataloading: 0.0016 s/iter. Inference: 0.0356 s/iter. Eval: 0.0440 s/iter. Total: 0.0813 s/iter. ETA=0:08:50\n",
      "\u001b[32m[07/05 21:25:38 d2.evaluation.evaluator]: \u001b[0mInference done 75/6531. Dataloading: 0.0021 s/iter. Inference: 0.0350 s/iter. Eval: 0.0415 s/iter. Total: 0.0787 s/iter. ETA=0:08:27\n",
      "\u001b[32m[07/05 21:25:43 d2.evaluation.evaluator]: \u001b[0mInference done 142/6531. Dataloading: 0.0021 s/iter. Inference: 0.0350 s/iter. Eval: 0.0397 s/iter. Total: 0.0769 s/iter. ETA=0:08:11\n",
      "\u001b[32m[07/05 21:25:48 d2.evaluation.evaluator]: \u001b[0mInference done 209/6531. Dataloading: 0.0021 s/iter. Inference: 0.0350 s/iter. Eval: 0.0389 s/iter. Total: 0.0761 s/iter. ETA=0:08:01\n",
      "\u001b[32m[07/05 21:25:53 d2.evaluation.evaluator]: \u001b[0mInference done 276/6531. Dataloading: 0.0022 s/iter. Inference: 0.0351 s/iter. Eval: 0.0385 s/iter. Total: 0.0758 s/iter. ETA=0:07:54\n",
      "\u001b[32m[07/05 21:25:58 d2.evaluation.evaluator]: \u001b[0mInference done 342/6531. Dataloading: 0.0022 s/iter. Inference: 0.0351 s/iter. Eval: 0.0385 s/iter. Total: 0.0758 s/iter. ETA=0:07:49\n",
      "\u001b[32m[07/05 21:26:03 d2.evaluation.evaluator]: \u001b[0mInference done 409/6531. Dataloading: 0.0022 s/iter. Inference: 0.0351 s/iter. Eval: 0.0384 s/iter. Total: 0.0758 s/iter. ETA=0:07:43\n",
      "\u001b[32m[07/05 21:26:08 d2.evaluation.evaluator]: \u001b[0mInference done 476/6531. Dataloading: 0.0022 s/iter. Inference: 0.0351 s/iter. Eval: 0.0383 s/iter. Total: 0.0757 s/iter. ETA=0:07:38\n",
      "\u001b[32m[07/05 21:26:13 d2.evaluation.evaluator]: \u001b[0mInference done 543/6531. Dataloading: 0.0022 s/iter. Inference: 0.0351 s/iter. Eval: 0.0383 s/iter. Total: 0.0757 s/iter. ETA=0:07:33\n",
      "\u001b[32m[07/05 21:26:18 d2.evaluation.evaluator]: \u001b[0mInference done 609/6531. Dataloading: 0.0022 s/iter. Inference: 0.0352 s/iter. Eval: 0.0383 s/iter. Total: 0.0757 s/iter. ETA=0:07:28\n",
      "\u001b[32m[07/05 21:26:23 d2.evaluation.evaluator]: \u001b[0mInference done 676/6531. Dataloading: 0.0022 s/iter. Inference: 0.0352 s/iter. Eval: 0.0383 s/iter. Total: 0.0757 s/iter. ETA=0:07:23\n",
      "\u001b[32m[07/05 21:26:28 d2.evaluation.evaluator]: \u001b[0mInference done 742/6531. Dataloading: 0.0022 s/iter. Inference: 0.0352 s/iter. Eval: 0.0384 s/iter. Total: 0.0758 s/iter. ETA=0:07:18\n",
      "\u001b[32m[07/05 21:26:33 d2.evaluation.evaluator]: \u001b[0mInference done 808/6531. Dataloading: 0.0022 s/iter. Inference: 0.0352 s/iter. Eval: 0.0383 s/iter. Total: 0.0758 s/iter. ETA=0:07:13\n",
      "\u001b[32m[07/05 21:26:38 d2.evaluation.evaluator]: \u001b[0mInference done 874/6531. Dataloading: 0.0022 s/iter. Inference: 0.0352 s/iter. Eval: 0.0384 s/iter. Total: 0.0759 s/iter. ETA=0:07:09\n",
      "\u001b[32m[07/05 21:26:43 d2.evaluation.evaluator]: \u001b[0mInference done 939/6531. Dataloading: 0.0022 s/iter. Inference: 0.0352 s/iter. Eval: 0.0385 s/iter. Total: 0.0760 s/iter. ETA=0:07:05\n",
      "\u001b[32m[07/05 21:26:48 d2.evaluation.evaluator]: \u001b[0mInference done 1004/6531. Dataloading: 0.0022 s/iter. Inference: 0.0352 s/iter. Eval: 0.0387 s/iter. Total: 0.0762 s/iter. ETA=0:07:00\n",
      "\u001b[32m[07/05 21:26:54 d2.evaluation.evaluator]: \u001b[0mInference done 1068/6531. Dataloading: 0.0024 s/iter. Inference: 0.0352 s/iter. Eval: 0.0387 s/iter. Total: 0.0763 s/iter. ETA=0:06:56\n",
      "\u001b[32m[07/05 21:26:59 d2.evaluation.evaluator]: \u001b[0mInference done 1135/6531. Dataloading: 0.0024 s/iter. Inference: 0.0353 s/iter. Eval: 0.0386 s/iter. Total: 0.0763 s/iter. ETA=0:06:51\n",
      "\u001b[32m[07/05 21:27:04 d2.evaluation.evaluator]: \u001b[0mInference done 1202/6531. Dataloading: 0.0023 s/iter. Inference: 0.0353 s/iter. Eval: 0.0386 s/iter. Total: 0.0763 s/iter. ETA=0:06:46\n",
      "\u001b[32m[07/05 21:27:09 d2.evaluation.evaluator]: \u001b[0mInference done 1268/6531. Dataloading: 0.0023 s/iter. Inference: 0.0353 s/iter. Eval: 0.0385 s/iter. Total: 0.0762 s/iter. ETA=0:06:41\n",
      "\u001b[32m[07/05 21:27:14 d2.evaluation.evaluator]: \u001b[0mInference done 1334/6531. Dataloading: 0.0023 s/iter. Inference: 0.0353 s/iter. Eval: 0.0385 s/iter. Total: 0.0762 s/iter. ETA=0:06:36\n",
      "\u001b[32m[07/05 21:27:19 d2.evaluation.evaluator]: \u001b[0mInference done 1402/6531. Dataloading: 0.0023 s/iter. Inference: 0.0353 s/iter. Eval: 0.0384 s/iter. Total: 0.0761 s/iter. ETA=0:06:30\n",
      "\u001b[32m[07/05 21:27:24 d2.evaluation.evaluator]: \u001b[0mInference done 1469/6531. Dataloading: 0.0023 s/iter. Inference: 0.0353 s/iter. Eval: 0.0383 s/iter. Total: 0.0761 s/iter. ETA=0:06:24\n",
      "\u001b[32m[07/05 21:27:29 d2.evaluation.evaluator]: \u001b[0mInference done 1535/6531. Dataloading: 0.0023 s/iter. Inference: 0.0353 s/iter. Eval: 0.0384 s/iter. Total: 0.0761 s/iter. ETA=0:06:20\n",
      "\u001b[32m[07/05 21:27:34 d2.evaluation.evaluator]: \u001b[0mInference done 1602/6531. Dataloading: 0.0023 s/iter. Inference: 0.0353 s/iter. Eval: 0.0383 s/iter. Total: 0.0760 s/iter. ETA=0:06:14\n",
      "\u001b[32m[07/05 21:27:39 d2.evaluation.evaluator]: \u001b[0mInference done 1668/6531. Dataloading: 0.0023 s/iter. Inference: 0.0353 s/iter. Eval: 0.0383 s/iter. Total: 0.0761 s/iter. ETA=0:06:09\n",
      "\u001b[32m[07/05 21:27:44 d2.evaluation.evaluator]: \u001b[0mInference done 1734/6531. Dataloading: 0.0023 s/iter. Inference: 0.0354 s/iter. Eval: 0.0384 s/iter. Total: 0.0761 s/iter. ETA=0:06:05\n",
      "\u001b[32m[07/05 21:27:49 d2.evaluation.evaluator]: \u001b[0mInference done 1801/6531. Dataloading: 0.0023 s/iter. Inference: 0.0354 s/iter. Eval: 0.0383 s/iter. Total: 0.0761 s/iter. ETA=0:05:59\n",
      "\u001b[32m[07/05 21:27:54 d2.evaluation.evaluator]: \u001b[0mInference done 1865/6531. Dataloading: 0.0023 s/iter. Inference: 0.0354 s/iter. Eval: 0.0384 s/iter. Total: 0.0761 s/iter. ETA=0:05:55\n",
      "\u001b[32m[07/05 21:27:59 d2.evaluation.evaluator]: \u001b[0mInference done 1931/6531. Dataloading: 0.0023 s/iter. Inference: 0.0354 s/iter. Eval: 0.0384 s/iter. Total: 0.0762 s/iter. ETA=0:05:50\n",
      "\u001b[32m[07/05 21:28:04 d2.evaluation.evaluator]: \u001b[0mInference done 1998/6531. Dataloading: 0.0023 s/iter. Inference: 0.0354 s/iter. Eval: 0.0384 s/iter. Total: 0.0762 s/iter. ETA=0:05:45\n",
      "\u001b[32m[07/05 21:28:09 d2.evaluation.evaluator]: \u001b[0mInference done 2065/6531. Dataloading: 0.0023 s/iter. Inference: 0.0354 s/iter. Eval: 0.0384 s/iter. Total: 0.0761 s/iter. ETA=0:05:39\n",
      "\u001b[32m[07/05 21:28:14 d2.evaluation.evaluator]: \u001b[0mInference done 2132/6531. Dataloading: 0.0023 s/iter. Inference: 0.0354 s/iter. Eval: 0.0383 s/iter. Total: 0.0761 s/iter. ETA=0:05:34\n",
      "\u001b[32m[07/05 21:28:19 d2.evaluation.evaluator]: \u001b[0mInference done 2199/6531. Dataloading: 0.0023 s/iter. Inference: 0.0354 s/iter. Eval: 0.0383 s/iter. Total: 0.0761 s/iter. ETA=0:05:29\n",
      "\u001b[32m[07/05 21:28:24 d2.evaluation.evaluator]: \u001b[0mInference done 2266/6531. Dataloading: 0.0023 s/iter. Inference: 0.0354 s/iter. Eval: 0.0383 s/iter. Total: 0.0760 s/iter. ETA=0:05:24\n",
      "\u001b[32m[07/05 21:28:29 d2.evaluation.evaluator]: \u001b[0mInference done 2333/6531. Dataloading: 0.0023 s/iter. Inference: 0.0354 s/iter. Eval: 0.0382 s/iter. Total: 0.0760 s/iter. ETA=0:05:19\n",
      "\u001b[32m[07/05 21:28:34 d2.evaluation.evaluator]: \u001b[0mInference done 2400/6531. Dataloading: 0.0023 s/iter. Inference: 0.0354 s/iter. Eval: 0.0382 s/iter. Total: 0.0760 s/iter. ETA=0:05:13\n",
      "\u001b[32m[07/05 21:28:39 d2.evaluation.evaluator]: \u001b[0mInference done 2467/6531. Dataloading: 0.0023 s/iter. Inference: 0.0354 s/iter. Eval: 0.0382 s/iter. Total: 0.0760 s/iter. ETA=0:05:08\n",
      "\u001b[32m[07/05 21:28:44 d2.evaluation.evaluator]: \u001b[0mInference done 2534/6531. Dataloading: 0.0023 s/iter. Inference: 0.0354 s/iter. Eval: 0.0382 s/iter. Total: 0.0760 s/iter. ETA=0:05:03\n",
      "\u001b[32m[07/05 21:28:50 d2.evaluation.evaluator]: \u001b[0mInference done 2601/6531. Dataloading: 0.0023 s/iter. Inference: 0.0354 s/iter. Eval: 0.0381 s/iter. Total: 0.0759 s/iter. ETA=0:04:58\n",
      "\u001b[32m[07/05 21:28:55 d2.evaluation.evaluator]: \u001b[0mInference done 2668/6531. Dataloading: 0.0023 s/iter. Inference: 0.0354 s/iter. Eval: 0.0381 s/iter. Total: 0.0759 s/iter. ETA=0:04:53\n",
      "\u001b[32m[07/05 21:29:00 d2.evaluation.evaluator]: \u001b[0mInference done 2735/6531. Dataloading: 0.0023 s/iter. Inference: 0.0354 s/iter. Eval: 0.0381 s/iter. Total: 0.0759 s/iter. ETA=0:04:48\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/05 21:29:05 d2.evaluation.evaluator]: \u001b[0mInference done 2802/6531. Dataloading: 0.0023 s/iter. Inference: 0.0354 s/iter. Eval: 0.0381 s/iter. Total: 0.0759 s/iter. ETA=0:04:42\n",
      "\u001b[32m[07/05 21:29:10 d2.evaluation.evaluator]: \u001b[0mInference done 2869/6531. Dataloading: 0.0023 s/iter. Inference: 0.0354 s/iter. Eval: 0.0380 s/iter. Total: 0.0759 s/iter. ETA=0:04:37\n",
      "\u001b[32m[07/05 21:29:15 d2.evaluation.evaluator]: \u001b[0mInference done 2936/6531. Dataloading: 0.0023 s/iter. Inference: 0.0354 s/iter. Eval: 0.0380 s/iter. Total: 0.0758 s/iter. ETA=0:04:32\n",
      "\u001b[32m[07/05 21:29:20 d2.evaluation.evaluator]: \u001b[0mInference done 3003/6531. Dataloading: 0.0023 s/iter. Inference: 0.0354 s/iter. Eval: 0.0380 s/iter. Total: 0.0758 s/iter. ETA=0:04:27\n",
      "\u001b[32m[07/05 21:29:25 d2.evaluation.evaluator]: \u001b[0mInference done 3069/6531. Dataloading: 0.0023 s/iter. Inference: 0.0354 s/iter. Eval: 0.0380 s/iter. Total: 0.0759 s/iter. ETA=0:04:22\n",
      "\u001b[32m[07/05 21:29:30 d2.evaluation.evaluator]: \u001b[0mInference done 3134/6531. Dataloading: 0.0023 s/iter. Inference: 0.0354 s/iter. Eval: 0.0380 s/iter. Total: 0.0759 s/iter. ETA=0:04:17\n",
      "\u001b[32m[07/05 21:29:35 d2.evaluation.evaluator]: \u001b[0mInference done 3199/6531. Dataloading: 0.0023 s/iter. Inference: 0.0354 s/iter. Eval: 0.0381 s/iter. Total: 0.0759 s/iter. ETA=0:04:12\n",
      "\u001b[32m[07/05 21:29:40 d2.evaluation.evaluator]: \u001b[0mInference done 3264/6531. Dataloading: 0.0023 s/iter. Inference: 0.0354 s/iter. Eval: 0.0381 s/iter. Total: 0.0759 s/iter. ETA=0:04:08\n",
      "\u001b[32m[07/05 21:29:45 d2.evaluation.evaluator]: \u001b[0mInference done 3329/6531. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0381 s/iter. Total: 0.0760 s/iter. ETA=0:04:03\n",
      "\u001b[32m[07/05 21:29:50 d2.evaluation.evaluator]: \u001b[0mInference done 3394/6531. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0382 s/iter. Total: 0.0760 s/iter. ETA=0:03:58\n",
      "\u001b[32m[07/05 21:29:55 d2.evaluation.evaluator]: \u001b[0mInference done 3459/6531. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0382 s/iter. Total: 0.0760 s/iter. ETA=0:03:53\n",
      "\u001b[32m[07/05 21:30:00 d2.evaluation.evaluator]: \u001b[0mInference done 3524/6531. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0382 s/iter. Total: 0.0760 s/iter. ETA=0:03:48\n",
      "\u001b[32m[07/05 21:30:05 d2.evaluation.evaluator]: \u001b[0mInference done 3588/6531. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0382 s/iter. Total: 0.0761 s/iter. ETA=0:03:43\n",
      "\u001b[32m[07/05 21:30:10 d2.evaluation.evaluator]: \u001b[0mInference done 3652/6531. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0383 s/iter. Total: 0.0761 s/iter. ETA=0:03:39\n",
      "\u001b[32m[07/05 21:30:15 d2.evaluation.evaluator]: \u001b[0mInference done 3716/6531. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0383 s/iter. Total: 0.0762 s/iter. ETA=0:03:34\n",
      "\u001b[32m[07/05 21:30:20 d2.evaluation.evaluator]: \u001b[0mInference done 3780/6531. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0384 s/iter. Total: 0.0762 s/iter. ETA=0:03:29\n",
      "\u001b[32m[07/05 21:30:25 d2.evaluation.evaluator]: \u001b[0mInference done 3845/6531. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0384 s/iter. Total: 0.0763 s/iter. ETA=0:03:24\n",
      "\u001b[32m[07/05 21:30:30 d2.evaluation.evaluator]: \u001b[0mInference done 3909/6531. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0385 s/iter. Total: 0.0763 s/iter. ETA=0:03:20\n",
      "\u001b[32m[07/05 21:30:35 d2.evaluation.evaluator]: \u001b[0mInference done 3973/6531. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0385 s/iter. Total: 0.0763 s/iter. ETA=0:03:15\n",
      "\u001b[32m[07/05 21:30:40 d2.evaluation.evaluator]: \u001b[0mInference done 4038/6531. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0385 s/iter. Total: 0.0764 s/iter. ETA=0:03:10\n",
      "\u001b[32m[07/05 21:30:45 d2.evaluation.evaluator]: \u001b[0mInference done 4101/6531. Dataloading: 0.0024 s/iter. Inference: 0.0355 s/iter. Eval: 0.0385 s/iter. Total: 0.0764 s/iter. ETA=0:03:05\n",
      "\u001b[32m[07/05 21:30:50 d2.evaluation.evaluator]: \u001b[0mInference done 4165/6531. Dataloading: 0.0024 s/iter. Inference: 0.0355 s/iter. Eval: 0.0385 s/iter. Total: 0.0765 s/iter. ETA=0:03:00\n",
      "\u001b[32m[07/05 21:30:56 d2.evaluation.evaluator]: \u001b[0mInference done 4230/6531. Dataloading: 0.0024 s/iter. Inference: 0.0355 s/iter. Eval: 0.0386 s/iter. Total: 0.0765 s/iter. ETA=0:02:55\n",
      "\u001b[32m[07/05 21:31:01 d2.evaluation.evaluator]: \u001b[0mInference done 4295/6531. Dataloading: 0.0024 s/iter. Inference: 0.0355 s/iter. Eval: 0.0386 s/iter. Total: 0.0765 s/iter. ETA=0:02:51\n",
      "\u001b[32m[07/05 21:31:06 d2.evaluation.evaluator]: \u001b[0mInference done 4360/6531. Dataloading: 0.0024 s/iter. Inference: 0.0355 s/iter. Eval: 0.0386 s/iter. Total: 0.0765 s/iter. ETA=0:02:46\n",
      "\u001b[32m[07/05 21:31:11 d2.evaluation.evaluator]: \u001b[0mInference done 4425/6531. Dataloading: 0.0024 s/iter. Inference: 0.0355 s/iter. Eval: 0.0386 s/iter. Total: 0.0765 s/iter. ETA=0:02:41\n",
      "\u001b[32m[07/05 21:31:16 d2.evaluation.evaluator]: \u001b[0mInference done 4490/6531. Dataloading: 0.0024 s/iter. Inference: 0.0355 s/iter. Eval: 0.0386 s/iter. Total: 0.0765 s/iter. ETA=0:02:36\n",
      "\u001b[32m[07/05 21:31:21 d2.evaluation.evaluator]: \u001b[0mInference done 4555/6531. Dataloading: 0.0024 s/iter. Inference: 0.0355 s/iter. Eval: 0.0386 s/iter. Total: 0.0765 s/iter. ETA=0:02:31\n",
      "\u001b[32m[07/05 21:31:26 d2.evaluation.evaluator]: \u001b[0mInference done 4619/6531. Dataloading: 0.0024 s/iter. Inference: 0.0355 s/iter. Eval: 0.0387 s/iter. Total: 0.0766 s/iter. ETA=0:02:26\n",
      "\u001b[32m[07/05 21:31:31 d2.evaluation.evaluator]: \u001b[0mInference done 4684/6531. Dataloading: 0.0024 s/iter. Inference: 0.0355 s/iter. Eval: 0.0387 s/iter. Total: 0.0766 s/iter. ETA=0:02:21\n",
      "\u001b[32m[07/05 21:31:36 d2.evaluation.evaluator]: \u001b[0mInference done 4749/6531. Dataloading: 0.0024 s/iter. Inference: 0.0355 s/iter. Eval: 0.0387 s/iter. Total: 0.0766 s/iter. ETA=0:02:16\n",
      "\u001b[32m[07/05 21:31:41 d2.evaluation.evaluator]: \u001b[0mInference done 4815/6531. Dataloading: 0.0024 s/iter. Inference: 0.0355 s/iter. Eval: 0.0387 s/iter. Total: 0.0766 s/iter. ETA=0:02:11\n",
      "\u001b[32m[07/05 21:31:46 d2.evaluation.evaluator]: \u001b[0mInference done 4881/6531. Dataloading: 0.0024 s/iter. Inference: 0.0355 s/iter. Eval: 0.0387 s/iter. Total: 0.0766 s/iter. ETA=0:02:06\n",
      "\u001b[32m[07/05 21:31:51 d2.evaluation.evaluator]: \u001b[0mInference done 4946/6531. Dataloading: 0.0024 s/iter. Inference: 0.0355 s/iter. Eval: 0.0387 s/iter. Total: 0.0766 s/iter. ETA=0:02:01\n",
      "\u001b[32m[07/05 21:31:56 d2.evaluation.evaluator]: \u001b[0mInference done 5011/6531. Dataloading: 0.0024 s/iter. Inference: 0.0355 s/iter. Eval: 0.0387 s/iter. Total: 0.0766 s/iter. ETA=0:01:56\n",
      "\u001b[32m[07/05 21:32:01 d2.evaluation.evaluator]: \u001b[0mInference done 5077/6531. Dataloading: 0.0024 s/iter. Inference: 0.0355 s/iter. Eval: 0.0387 s/iter. Total: 0.0766 s/iter. ETA=0:01:51\n",
      "\u001b[32m[07/05 21:32:06 d2.evaluation.evaluator]: \u001b[0mInference done 5143/6531. Dataloading: 0.0024 s/iter. Inference: 0.0355 s/iter. Eval: 0.0387 s/iter. Total: 0.0766 s/iter. ETA=0:01:46\n",
      "\u001b[32m[07/05 21:32:11 d2.evaluation.evaluator]: \u001b[0mInference done 5209/6531. Dataloading: 0.0024 s/iter. Inference: 0.0355 s/iter. Eval: 0.0387 s/iter. Total: 0.0766 s/iter. ETA=0:01:41\n",
      "\u001b[32m[07/05 21:32:16 d2.evaluation.evaluator]: \u001b[0mInference done 5274/6531. Dataloading: 0.0024 s/iter. Inference: 0.0355 s/iter. Eval: 0.0387 s/iter. Total: 0.0766 s/iter. ETA=0:01:36\n",
      "\u001b[32m[07/05 21:32:21 d2.evaluation.evaluator]: \u001b[0mInference done 5338/6531. Dataloading: 0.0024 s/iter. Inference: 0.0355 s/iter. Eval: 0.0387 s/iter. Total: 0.0766 s/iter. ETA=0:01:31\n",
      "\u001b[32m[07/05 21:32:26 d2.evaluation.evaluator]: \u001b[0mInference done 5403/6531. Dataloading: 0.0024 s/iter. Inference: 0.0355 s/iter. Eval: 0.0387 s/iter. Total: 0.0766 s/iter. ETA=0:01:26\n",
      "\u001b[32m[07/05 21:32:31 d2.evaluation.evaluator]: \u001b[0mInference done 5469/6531. Dataloading: 0.0024 s/iter. Inference: 0.0355 s/iter. Eval: 0.0387 s/iter. Total: 0.0766 s/iter. ETA=0:01:21\n",
      "\u001b[32m[07/05 21:32:36 d2.evaluation.evaluator]: \u001b[0mInference done 5534/6531. Dataloading: 0.0024 s/iter. Inference: 0.0355 s/iter. Eval: 0.0387 s/iter. Total: 0.0766 s/iter. ETA=0:01:16\n",
      "\u001b[32m[07/05 21:32:41 d2.evaluation.evaluator]: \u001b[0mInference done 5599/6531. Dataloading: 0.0024 s/iter. Inference: 0.0355 s/iter. Eval: 0.0387 s/iter. Total: 0.0767 s/iter. ETA=0:01:11\n",
      "\u001b[32m[07/05 21:32:46 d2.evaluation.evaluator]: \u001b[0mInference done 5664/6531. Dataloading: 0.0024 s/iter. Inference: 0.0355 s/iter. Eval: 0.0388 s/iter. Total: 0.0767 s/iter. ETA=0:01:06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/05 21:32:51 d2.evaluation.evaluator]: \u001b[0mInference done 5728/6531. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0388 s/iter. Total: 0.0767 s/iter. ETA=0:01:01\n",
      "\u001b[32m[07/05 21:32:56 d2.evaluation.evaluator]: \u001b[0mInference done 5791/6531. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0388 s/iter. Total: 0.0767 s/iter. ETA=0:00:56\n",
      "\u001b[32m[07/05 21:33:01 d2.evaluation.evaluator]: \u001b[0mInference done 5856/6531. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0388 s/iter. Total: 0.0767 s/iter. ETA=0:00:51\n",
      "\u001b[32m[07/05 21:33:06 d2.evaluation.evaluator]: \u001b[0mInference done 5921/6531. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0388 s/iter. Total: 0.0767 s/iter. ETA=0:00:46\n",
      "\u001b[32m[07/05 21:33:11 d2.evaluation.evaluator]: \u001b[0mInference done 5986/6531. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0388 s/iter. Total: 0.0767 s/iter. ETA=0:00:41\n",
      "\u001b[32m[07/05 21:33:16 d2.evaluation.evaluator]: \u001b[0mInference done 6050/6531. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0389 s/iter. Total: 0.0768 s/iter. ETA=0:00:36\n",
      "\u001b[32m[07/05 21:33:21 d2.evaluation.evaluator]: \u001b[0mInference done 6114/6531. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0389 s/iter. Total: 0.0768 s/iter. ETA=0:00:32\n",
      "\u001b[32m[07/05 21:33:27 d2.evaluation.evaluator]: \u001b[0mInference done 6178/6531. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0389 s/iter. Total: 0.0768 s/iter. ETA=0:00:27\n",
      "\u001b[32m[07/05 21:33:32 d2.evaluation.evaluator]: \u001b[0mInference done 6240/6531. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0389 s/iter. Total: 0.0768 s/iter. ETA=0:00:22\n",
      "\u001b[32m[07/05 21:33:37 d2.evaluation.evaluator]: \u001b[0mInference done 6305/6531. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0389 s/iter. Total: 0.0769 s/iter. ETA=0:00:17\n",
      "\u001b[32m[07/05 21:33:42 d2.evaluation.evaluator]: \u001b[0mInference done 6370/6531. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0390 s/iter. Total: 0.0769 s/iter. ETA=0:00:12\n",
      "\u001b[32m[07/05 21:33:47 d2.evaluation.evaluator]: \u001b[0mInference done 6435/6531. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0390 s/iter. Total: 0.0769 s/iter. ETA=0:00:07\n",
      "\u001b[32m[07/05 21:33:52 d2.evaluation.evaluator]: \u001b[0mInference done 6502/6531. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0389 s/iter. Total: 0.0768 s/iter. ETA=0:00:02\n",
      "\u001b[32m[07/05 21:33:54 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:08:21.579618 (0.076859 s / iter per device, on 1 devices)\n",
      "\u001b[32m[07/05 21:33:54 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:03:51 (0.035486 s / iter per device, on 1 devices)\n",
      "\u001b[32m[07/05 21:33:55 d2.evaluation.sem_seg_evaluation]: \u001b[0mOrderedDict([('sem_seg', {'mIoU': 52.62254868897439, 'fwIoU': 79.54156817525944, 'IoU-Unlabeled': nan, 'IoU-Building': 69.8926855929057, 'IoU-Fence': 27.921905564708588, 'IoU-Pedestrian': 33.34862927328569, 'IoU-Pole': 53.33439376496403, 'IoU-Road': 95.66309014849892, 'IoU-SideWalk': 70.78649185986093, 'IoU-Vegetation': 63.92291559432819, 'IoU-Vehicles': 76.6466296687789, 'IoU-Wall': 58.28505012861771, 'IoU-TrafficSign': 50.069475497562586, 'IoU-Sky': 80.22918914957893, 'IoU-TrafficLight': 56.40868243877328, 'IoU-Terrain': 22.41025627014495, 'IoU-ConstructionVehicle': 56.639731861243234, 'IoU-workzone_object': 64.23457513287423, 'IoU-Detour': 14.78962576643879, 'mACC': 69.39284794709566, 'pACC': 87.8995599509259, 'ACC-Unlabeled': nan, 'ACC-Building': 95.7058868172878, 'ACC-Fence': 45.216266551659906, 'ACC-Pedestrian': 62.11101034204274, 'ACC-Pole': 62.01885607794968, 'ACC-Road': 97.36088959409099, 'ACC-SideWalk': 89.25165627551836, 'ACC-Vegetation': 77.5432606962878, 'ACC-Vehicles': 88.27149804289107, 'ACC-Wall': 64.83737101376535, 'ACC-TrafficSign': 59.472419713274995, 'ACC-Sky': 82.76955376645066, 'ACC-TrafficLight': 66.25209474690752, 'ACC-Terrain': 23.105280709171264, 'ACC-ConstructionVehicle': 94.23643823966336, 'ACC-workzone_object': 86.30291533928155, 'ACC-Detour': 15.830169227287586})])\n",
      "\u001b[32m[07/05 21:33:55 d2.engine.defaults]: \u001b[0mEvaluation results for carla_both_clear_val in csv format:\n",
      "\u001b[32m[07/05 21:33:55 d2.evaluation.testing]: \u001b[0mcopypaste: Task: sem_seg\n",
      "\u001b[32m[07/05 21:33:55 d2.evaluation.testing]: \u001b[0mcopypaste: mIoU,fwIoU,mACC,pACC\n",
      "\u001b[32m[07/05 21:33:55 d2.evaluation.testing]: \u001b[0mcopypaste: 52.6225,79.5416,69.3928,87.8996\n"
     ]
    }
   ],
   "source": [
    "trainer_both = Detectron2Trainer('combined_all_night_train', 'carla_both_clear_val', output_folder='./output_both_40k')\n",
    "trainer_both.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "e59d666f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/05 21:33:55 d2.engine.defaults]: \u001b[0mModel:\n",
      "SemanticSegmentor(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (sem_seg_head): SemSegFPNHead(\n",
      "    (p2): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "    )\n",
      "    (p3): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (1): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "    )\n",
      "    (p4): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (1): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      (2): Conv2d(\n",
      "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (3): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "    )\n",
      "    (p5): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (1): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      (2): Conv2d(\n",
      "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (3): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      (4): Conv2d(\n",
      "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (5): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "    )\n",
      "    (predictor): Conv2d(128, 17, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/05 21:33:55 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(720, 720), max_size=2048, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[07/05 21:33:55 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[07/05 21:33:55 d2.data.common]: \u001b[0mSerializing 37734 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[07/05 21:33:55 d2.data.common]: \u001b[0mSerialized dataset takes 11.85 MiB\n",
      "Last checkpoint: model_final.pth\n",
      "\u001b[32m[07/05 21:33:56 d2.checkpoint.c2_model_loading]: \u001b[0mFollowing weights matched with model:\n",
      "| Names in Model                       | Names in Checkpoint                                                                                  | Shapes                                          |\n",
      "|:-------------------------------------|:-----------------------------------------------------------------------------------------------------|:------------------------------------------------|\n",
      "| backbone.bottom_up.res2.0.conv1.*    | backbone.bottom_up.res2.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,1,1)             |\n",
      "| backbone.bottom_up.res2.0.conv2.*    | backbone.bottom_up.res2.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |\n",
      "| backbone.bottom_up.res2.0.conv3.*    | backbone.bottom_up.res2.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res2.0.shortcut.* | backbone.bottom_up.res2.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res2.1.conv1.*    | backbone.bottom_up.res2.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |\n",
      "| backbone.bottom_up.res2.1.conv2.*    | backbone.bottom_up.res2.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |\n",
      "| backbone.bottom_up.res2.1.conv3.*    | backbone.bottom_up.res2.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res2.2.conv1.*    | backbone.bottom_up.res2.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |\n",
      "| backbone.bottom_up.res2.2.conv2.*    | backbone.bottom_up.res2.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |\n",
      "| backbone.bottom_up.res2.2.conv3.*    | backbone.bottom_up.res2.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res3.0.conv1.*    | backbone.bottom_up.res3.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,256,1,1)       |\n",
      "| backbone.bottom_up.res3.0.conv2.*    | backbone.bottom_up.res3.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.0.conv3.*    | backbone.bottom_up.res3.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res3.0.shortcut.* | backbone.bottom_up.res3.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (512,) (512,) (512,) (512,) (512,256,1,1)       |\n",
      "| backbone.bottom_up.res3.1.conv1.*    | backbone.bottom_up.res3.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |\n",
      "| backbone.bottom_up.res3.1.conv2.*    | backbone.bottom_up.res3.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.1.conv3.*    | backbone.bottom_up.res3.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res3.2.conv1.*    | backbone.bottom_up.res3.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |\n",
      "| backbone.bottom_up.res3.2.conv2.*    | backbone.bottom_up.res3.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.2.conv3.*    | backbone.bottom_up.res3.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res3.3.conv1.*    | backbone.bottom_up.res3.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |\n",
      "| backbone.bottom_up.res3.3.conv2.*    | backbone.bottom_up.res3.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.3.conv3.*    | backbone.bottom_up.res3.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res4.0.conv1.*    | backbone.bottom_up.res4.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,512,1,1)       |\n",
      "| backbone.bottom_up.res4.0.conv2.*    | backbone.bottom_up.res4.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.0.conv3.*    | backbone.bottom_up.res4.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.0.shortcut.* | backbone.bottom_up.res4.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (1024,) (1024,) (1024,) (1024,) (1024,512,1,1)  |\n",
      "| backbone.bottom_up.res4.1.conv1.*    | backbone.bottom_up.res4.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.1.conv2.*    | backbone.bottom_up.res4.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.1.conv3.*    | backbone.bottom_up.res4.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.2.conv1.*    | backbone.bottom_up.res4.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.2.conv2.*    | backbone.bottom_up.res4.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.2.conv3.*    | backbone.bottom_up.res4.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.3.conv1.*    | backbone.bottom_up.res4.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.3.conv2.*    | backbone.bottom_up.res4.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.3.conv3.*    | backbone.bottom_up.res4.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.4.conv1.*    | backbone.bottom_up.res4.4.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.4.conv2.*    | backbone.bottom_up.res4.4.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.4.conv3.*    | backbone.bottom_up.res4.4.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.5.conv1.*    | backbone.bottom_up.res4.5.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.5.conv2.*    | backbone.bottom_up.res4.5.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.5.conv3.*    | backbone.bottom_up.res4.5.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res5.0.conv1.*    | backbone.bottom_up.res5.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,1024,1,1)      |\n",
      "| backbone.bottom_up.res5.0.conv2.*    | backbone.bottom_up.res5.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |\n",
      "| backbone.bottom_up.res5.0.conv3.*    | backbone.bottom_up.res5.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
      "| backbone.bottom_up.res5.0.shortcut.* | backbone.bottom_up.res5.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (2048,) (2048,) (2048,) (2048,) (2048,1024,1,1) |\n",
      "| backbone.bottom_up.res5.1.conv1.*    | backbone.bottom_up.res5.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |\n",
      "| backbone.bottom_up.res5.1.conv2.*    | backbone.bottom_up.res5.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |\n",
      "| backbone.bottom_up.res5.1.conv3.*    | backbone.bottom_up.res5.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
      "| backbone.bottom_up.res5.2.conv1.*    | backbone.bottom_up.res5.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |\n",
      "| backbone.bottom_up.res5.2.conv2.*    | backbone.bottom_up.res5.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |\n",
      "| backbone.bottom_up.res5.2.conv3.*    | backbone.bottom_up.res5.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
      "| backbone.bottom_up.stem.conv1.*      | backbone.bottom_up.stem.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}      | (64,) (64,) (64,) (64,) (64,3,7,7)              |\n",
      "| backbone.fpn_lateral2.*              | backbone.fpn_lateral2.{bias,weight}                                                                  | (256,) (256,256,1,1)                            |\n",
      "| backbone.fpn_lateral3.*              | backbone.fpn_lateral3.{bias,weight}                                                                  | (256,) (256,512,1,1)                            |\n",
      "| backbone.fpn_lateral4.*              | backbone.fpn_lateral4.{bias,weight}                                                                  | (256,) (256,1024,1,1)                           |\n",
      "| backbone.fpn_lateral5.*              | backbone.fpn_lateral5.{bias,weight}                                                                  | (256,) (256,2048,1,1)                           |\n",
      "| backbone.fpn_output2.*               | backbone.fpn_output2.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| backbone.fpn_output3.*               | backbone.fpn_output3.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| backbone.fpn_output4.*               | backbone.fpn_output4.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| backbone.fpn_output5.*               | backbone.fpn_output5.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| sem_seg_head.p2.0.*                  | sem_seg_head.p2.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p3.0.*                  | sem_seg_head.p3.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p4.0.*                  | sem_seg_head.p4.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p4.2.*                  | sem_seg_head.p4.2.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,128,3,3)                     |\n",
      "| sem_seg_head.p5.0.*                  | sem_seg_head.p5.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p5.2.*                  | sem_seg_head.p5.2.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,128,3,3)                     |\n",
      "| sem_seg_head.p5.4.*                  | sem_seg_head.p5.4.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,128,3,3)                     |\n",
      "| sem_seg_head.predictor.*             | sem_seg_head.predictor.{bias,weight}                                                                 | (17,) (17,128,1,1)                              |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/05 21:33:56 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(720, 720), max_size=2048, sample_style='choice')]\n",
      "\u001b[32m[07/05 21:33:56 d2.data.common]: \u001b[0mSerializing 699 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[07/05 21:33:56 d2.data.common]: \u001b[0mSerialized dataset takes 0.22 MiB\n",
      "\u001b[32m[07/05 21:33:56 d2.evaluation.evaluator]: \u001b[0mStart inference on 699 batches\n",
      "\u001b[32m[07/05 21:33:59 d2.evaluation.evaluator]: \u001b[0mInference done 11/699. Dataloading: 0.0019 s/iter. Inference: 0.0469 s/iter. Eval: 0.1485 s/iter. Total: 0.1974 s/iter. ETA=0:02:15\n",
      "\u001b[32m[07/05 21:34:04 d2.evaluation.evaluator]: \u001b[0mInference done 37/699. Dataloading: 0.0022 s/iter. Inference: 0.0468 s/iter. Eval: 0.1474 s/iter. Total: 0.1965 s/iter. ETA=0:02:10\n",
      "\u001b[32m[07/05 21:34:09 d2.evaluation.evaluator]: \u001b[0mInference done 63/699. Dataloading: 0.0023 s/iter. Inference: 0.0466 s/iter. Eval: 0.1464 s/iter. Total: 0.1954 s/iter. ETA=0:02:04\n",
      "\u001b[32m[07/05 21:34:14 d2.evaluation.evaluator]: \u001b[0mInference done 89/699. Dataloading: 0.0023 s/iter. Inference: 0.0467 s/iter. Eval: 0.1461 s/iter. Total: 0.1951 s/iter. ETA=0:01:59\n",
      "\u001b[32m[07/05 21:34:19 d2.evaluation.evaluator]: \u001b[0mInference done 116/699. Dataloading: 0.0023 s/iter. Inference: 0.0464 s/iter. Eval: 0.1446 s/iter. Total: 0.1934 s/iter. ETA=0:01:52\n",
      "\u001b[32m[07/05 21:34:24 d2.evaluation.evaluator]: \u001b[0mInference done 144/699. Dataloading: 0.0023 s/iter. Inference: 0.0464 s/iter. Eval: 0.1426 s/iter. Total: 0.1914 s/iter. ETA=0:01:46\n",
      "\u001b[32m[07/05 21:34:29 d2.evaluation.evaluator]: \u001b[0mInference done 171/699. Dataloading: 0.0023 s/iter. Inference: 0.0465 s/iter. Eval: 0.1422 s/iter. Total: 0.1911 s/iter. ETA=0:01:40\n",
      "\u001b[32m[07/05 21:34:34 d2.evaluation.evaluator]: \u001b[0mInference done 196/699. Dataloading: 0.0023 s/iter. Inference: 0.0465 s/iter. Eval: 0.1435 s/iter. Total: 0.1924 s/iter. ETA=0:01:36\n",
      "\u001b[32m[07/05 21:34:39 d2.evaluation.evaluator]: \u001b[0mInference done 222/699. Dataloading: 0.0023 s/iter. Inference: 0.0465 s/iter. Eval: 0.1442 s/iter. Total: 0.1931 s/iter. ETA=0:01:32\n",
      "\u001b[32m[07/05 21:34:44 d2.evaluation.evaluator]: \u001b[0mInference done 248/699. Dataloading: 0.0023 s/iter. Inference: 0.0466 s/iter. Eval: 0.1445 s/iter. Total: 0.1935 s/iter. ETA=0:01:27\n",
      "\u001b[32m[07/05 21:34:49 d2.evaluation.evaluator]: \u001b[0mInference done 274/699. Dataloading: 0.0023 s/iter. Inference: 0.0466 s/iter. Eval: 0.1445 s/iter. Total: 0.1935 s/iter. ETA=0:01:22\n",
      "\u001b[32m[07/05 21:34:55 d2.evaluation.evaluator]: \u001b[0mInference done 301/699. Dataloading: 0.0023 s/iter. Inference: 0.0466 s/iter. Eval: 0.1444 s/iter. Total: 0.1933 s/iter. ETA=0:01:16\n",
      "\u001b[32m[07/05 21:35:00 d2.evaluation.evaluator]: \u001b[0mInference done 327/699. Dataloading: 0.0023 s/iter. Inference: 0.0466 s/iter. Eval: 0.1447 s/iter. Total: 0.1937 s/iter. ETA=0:01:12\n",
      "\u001b[32m[07/05 21:35:05 d2.evaluation.evaluator]: \u001b[0mInference done 353/699. Dataloading: 0.0023 s/iter. Inference: 0.0466 s/iter. Eval: 0.1448 s/iter. Total: 0.1938 s/iter. ETA=0:01:07\n",
      "\u001b[32m[07/05 21:35:10 d2.evaluation.evaluator]: \u001b[0mInference done 379/699. Dataloading: 0.0023 s/iter. Inference: 0.0466 s/iter. Eval: 0.1452 s/iter. Total: 0.1942 s/iter. ETA=0:01:02\n",
      "\u001b[32m[07/05 21:35:15 d2.evaluation.evaluator]: \u001b[0mInference done 404/699. Dataloading: 0.0023 s/iter. Inference: 0.0466 s/iter. Eval: 0.1456 s/iter. Total: 0.1946 s/iter. ETA=0:00:57\n",
      "\u001b[32m[07/05 21:35:20 d2.evaluation.evaluator]: \u001b[0mInference done 431/699. Dataloading: 0.0023 s/iter. Inference: 0.0466 s/iter. Eval: 0.1455 s/iter. Total: 0.1945 s/iter. ETA=0:00:52\n",
      "\u001b[32m[07/05 21:35:25 d2.evaluation.evaluator]: \u001b[0mInference done 457/699. Dataloading: 0.0023 s/iter. Inference: 0.0466 s/iter. Eval: 0.1455 s/iter. Total: 0.1945 s/iter. ETA=0:00:47\n",
      "\u001b[32m[07/05 21:35:30 d2.evaluation.evaluator]: \u001b[0mInference done 484/699. Dataloading: 0.0023 s/iter. Inference: 0.0466 s/iter. Eval: 0.1453 s/iter. Total: 0.1943 s/iter. ETA=0:00:41\n",
      "\u001b[32m[07/05 21:35:36 d2.evaluation.evaluator]: \u001b[0mInference done 510/699. Dataloading: 0.0023 s/iter. Inference: 0.0466 s/iter. Eval: 0.1456 s/iter. Total: 0.1946 s/iter. ETA=0:00:36\n",
      "\u001b[32m[07/05 21:35:41 d2.evaluation.evaluator]: \u001b[0mInference done 536/699. Dataloading: 0.0023 s/iter. Inference: 0.0466 s/iter. Eval: 0.1456 s/iter. Total: 0.1946 s/iter. ETA=0:00:31\n",
      "\u001b[32m[07/05 21:35:46 d2.evaluation.evaluator]: \u001b[0mInference done 562/699. Dataloading: 0.0023 s/iter. Inference: 0.0466 s/iter. Eval: 0.1457 s/iter. Total: 0.1947 s/iter. ETA=0:00:26\n",
      "\u001b[32m[07/05 21:35:51 d2.evaluation.evaluator]: \u001b[0mInference done 588/699. Dataloading: 0.0023 s/iter. Inference: 0.0466 s/iter. Eval: 0.1459 s/iter. Total: 0.1949 s/iter. ETA=0:00:21\n",
      "\u001b[32m[07/05 21:35:56 d2.evaluation.evaluator]: \u001b[0mInference done 614/699. Dataloading: 0.0023 s/iter. Inference: 0.0466 s/iter. Eval: 0.1460 s/iter. Total: 0.1950 s/iter. ETA=0:00:16\n",
      "\u001b[32m[07/05 21:36:01 d2.evaluation.evaluator]: \u001b[0mInference done 640/699. Dataloading: 0.0023 s/iter. Inference: 0.0466 s/iter. Eval: 0.1461 s/iter. Total: 0.1951 s/iter. ETA=0:00:11\n",
      "\u001b[32m[07/05 21:36:06 d2.evaluation.evaluator]: \u001b[0mInference done 667/699. Dataloading: 0.0023 s/iter. Inference: 0.0466 s/iter. Eval: 0.1458 s/iter. Total: 0.1949 s/iter. ETA=0:00:06\n",
      "\u001b[32m[07/05 21:36:12 d2.evaluation.evaluator]: \u001b[0mInference done 693/699. Dataloading: 0.0023 s/iter. Inference: 0.0466 s/iter. Eval: 0.1460 s/iter. Total: 0.1950 s/iter. ETA=0:00:01\n",
      "\u001b[32m[07/05 21:36:13 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:02:15.445942 (0.195167 s / iter per device, on 1 devices)\n",
      "\u001b[32m[07/05 21:36:13 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:32 (0.046628 s / iter per device, on 1 devices)\n",
      "\u001b[32m[07/05 21:36:13 d2.evaluation.sem_seg_evaluation]: \u001b[0mOrderedDict([('sem_seg', {'mIoU': 62.89248653530076, 'fwIoU': 90.34391309182091, 'IoU-Unlabeled': nan, 'IoU-Building': 90.74915164175378, 'IoU-Fence': 51.67114209409185, 'IoU-Pedestrian': 77.02938087793967, 'IoU-Pole': 51.41697762053553, 'IoU-Road': 96.53018822329807, 'IoU-SideWalk': 78.09232939426133, 'IoU-Vegetation': 90.67063875263185, 'IoU-Vehicles': 90.30386663393595, 'IoU-Wall': 46.82984356668758, 'IoU-TrafficSign': 63.57947076679865, 'IoU-Sky': 94.29392972554764, 'IoU-TrafficLight': 51.78223956217939, 'IoU-Terrain': 60.438139169850004, 'IoU-ConstructionVehicle': nan, 'IoU-workzone_object': nan, 'IoU-Detour': nan, 'mACC': 80.96261096341627, 'pACC': 94.70473128365184, 'ACC-Unlabeled': nan, 'ACC-Building': 95.4960110148136, 'ACC-Fence': 70.9044092635115, 'ACC-Pedestrian': 86.96905203207237, 'ACC-Pole': 65.59038568381516, 'ACC-Road': 98.61234654396748, 'ACC-SideWalk': 85.58164249392559, 'ACC-Vegetation': 95.79928160092422, 'ACC-Vehicles': 94.98057374182733, 'ACC-Wall': 56.05426120385447, 'ACC-TrafficSign': 73.48669805444733, 'ACC-Sky': 97.18795445022307, 'ACC-TrafficLight': 60.31132780182973, 'ACC-Terrain': 71.53999863919978, 'ACC-ConstructionVehicle': nan, 'ACC-workzone_object': nan, 'ACC-Detour': nan})])\n",
      "\u001b[32m[07/05 21:36:13 d2.engine.defaults]: \u001b[0mEvaluation results for cityscapes_clear_val in csv format:\n",
      "\u001b[32m[07/05 21:36:13 d2.evaluation.testing]: \u001b[0mcopypaste: Task: sem_seg\n",
      "\u001b[32m[07/05 21:36:13 d2.evaluation.testing]: \u001b[0mcopypaste: mIoU,fwIoU,mACC,pACC\n",
      "\u001b[32m[07/05 21:36:13 d2.evaluation.testing]: \u001b[0mcopypaste: 62.8925,90.3439,80.9626,94.7047\n"
     ]
    }
   ],
   "source": [
    "trainer_both = Detectron2Trainer('combined_all_night_train', 'cityscapes_clear_val', output_folder='./output_both_40k')\n",
    "trainer_both.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "55d5dd27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/05 21:36:13 d2.engine.defaults]: \u001b[0mModel:\n",
      "SemanticSegmentor(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (sem_seg_head): SemSegFPNHead(\n",
      "    (p2): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "    )\n",
      "    (p3): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (1): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "    )\n",
      "    (p4): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (1): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      (2): Conv2d(\n",
      "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (3): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "    )\n",
      "    (p5): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (1): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      (2): Conv2d(\n",
      "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (3): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      (4): Conv2d(\n",
      "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (5): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "    )\n",
      "    (predictor): Conv2d(128, 17, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/05 21:36:13 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(720, 720), max_size=2048, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[07/05 21:36:13 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[07/05 21:36:13 d2.data.common]: \u001b[0mSerializing 37734 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[07/05 21:36:13 d2.data.common]: \u001b[0mSerialized dataset takes 11.85 MiB\n",
      "Last checkpoint: model_final.pth\n",
      "\u001b[32m[07/05 21:36:14 d2.checkpoint.c2_model_loading]: \u001b[0mFollowing weights matched with model:\n",
      "| Names in Model                       | Names in Checkpoint                                                                                  | Shapes                                          |\n",
      "|:-------------------------------------|:-----------------------------------------------------------------------------------------------------|:------------------------------------------------|\n",
      "| backbone.bottom_up.res2.0.conv1.*    | backbone.bottom_up.res2.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,1,1)             |\n",
      "| backbone.bottom_up.res2.0.conv2.*    | backbone.bottom_up.res2.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |\n",
      "| backbone.bottom_up.res2.0.conv3.*    | backbone.bottom_up.res2.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res2.0.shortcut.* | backbone.bottom_up.res2.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res2.1.conv1.*    | backbone.bottom_up.res2.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |\n",
      "| backbone.bottom_up.res2.1.conv2.*    | backbone.bottom_up.res2.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |\n",
      "| backbone.bottom_up.res2.1.conv3.*    | backbone.bottom_up.res2.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res2.2.conv1.*    | backbone.bottom_up.res2.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |\n",
      "| backbone.bottom_up.res2.2.conv2.*    | backbone.bottom_up.res2.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |\n",
      "| backbone.bottom_up.res2.2.conv3.*    | backbone.bottom_up.res2.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res3.0.conv1.*    | backbone.bottom_up.res3.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,256,1,1)       |\n",
      "| backbone.bottom_up.res3.0.conv2.*    | backbone.bottom_up.res3.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.0.conv3.*    | backbone.bottom_up.res3.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res3.0.shortcut.* | backbone.bottom_up.res3.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (512,) (512,) (512,) (512,) (512,256,1,1)       |\n",
      "| backbone.bottom_up.res3.1.conv1.*    | backbone.bottom_up.res3.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |\n",
      "| backbone.bottom_up.res3.1.conv2.*    | backbone.bottom_up.res3.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.1.conv3.*    | backbone.bottom_up.res3.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res3.2.conv1.*    | backbone.bottom_up.res3.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |\n",
      "| backbone.bottom_up.res3.2.conv2.*    | backbone.bottom_up.res3.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.2.conv3.*    | backbone.bottom_up.res3.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res3.3.conv1.*    | backbone.bottom_up.res3.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |\n",
      "| backbone.bottom_up.res3.3.conv2.*    | backbone.bottom_up.res3.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.3.conv3.*    | backbone.bottom_up.res3.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res4.0.conv1.*    | backbone.bottom_up.res4.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,512,1,1)       |\n",
      "| backbone.bottom_up.res4.0.conv2.*    | backbone.bottom_up.res4.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.0.conv3.*    | backbone.bottom_up.res4.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.0.shortcut.* | backbone.bottom_up.res4.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (1024,) (1024,) (1024,) (1024,) (1024,512,1,1)  |\n",
      "| backbone.bottom_up.res4.1.conv1.*    | backbone.bottom_up.res4.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.1.conv2.*    | backbone.bottom_up.res4.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.1.conv3.*    | backbone.bottom_up.res4.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.2.conv1.*    | backbone.bottom_up.res4.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.2.conv2.*    | backbone.bottom_up.res4.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.2.conv3.*    | backbone.bottom_up.res4.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.3.conv1.*    | backbone.bottom_up.res4.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.3.conv2.*    | backbone.bottom_up.res4.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.3.conv3.*    | backbone.bottom_up.res4.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.4.conv1.*    | backbone.bottom_up.res4.4.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.4.conv2.*    | backbone.bottom_up.res4.4.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.4.conv3.*    | backbone.bottom_up.res4.4.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.5.conv1.*    | backbone.bottom_up.res4.5.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.5.conv2.*    | backbone.bottom_up.res4.5.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.5.conv3.*    | backbone.bottom_up.res4.5.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res5.0.conv1.*    | backbone.bottom_up.res5.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,1024,1,1)      |\n",
      "| backbone.bottom_up.res5.0.conv2.*    | backbone.bottom_up.res5.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |\n",
      "| backbone.bottom_up.res5.0.conv3.*    | backbone.bottom_up.res5.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
      "| backbone.bottom_up.res5.0.shortcut.* | backbone.bottom_up.res5.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (2048,) (2048,) (2048,) (2048,) (2048,1024,1,1) |\n",
      "| backbone.bottom_up.res5.1.conv1.*    | backbone.bottom_up.res5.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |\n",
      "| backbone.bottom_up.res5.1.conv2.*    | backbone.bottom_up.res5.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |\n",
      "| backbone.bottom_up.res5.1.conv3.*    | backbone.bottom_up.res5.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
      "| backbone.bottom_up.res5.2.conv1.*    | backbone.bottom_up.res5.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |\n",
      "| backbone.bottom_up.res5.2.conv2.*    | backbone.bottom_up.res5.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |\n",
      "| backbone.bottom_up.res5.2.conv3.*    | backbone.bottom_up.res5.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
      "| backbone.bottom_up.stem.conv1.*      | backbone.bottom_up.stem.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}      | (64,) (64,) (64,) (64,) (64,3,7,7)              |\n",
      "| backbone.fpn_lateral2.*              | backbone.fpn_lateral2.{bias,weight}                                                                  | (256,) (256,256,1,1)                            |\n",
      "| backbone.fpn_lateral3.*              | backbone.fpn_lateral3.{bias,weight}                                                                  | (256,) (256,512,1,1)                            |\n",
      "| backbone.fpn_lateral4.*              | backbone.fpn_lateral4.{bias,weight}                                                                  | (256,) (256,1024,1,1)                           |\n",
      "| backbone.fpn_lateral5.*              | backbone.fpn_lateral5.{bias,weight}                                                                  | (256,) (256,2048,1,1)                           |\n",
      "| backbone.fpn_output2.*               | backbone.fpn_output2.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| backbone.fpn_output3.*               | backbone.fpn_output3.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| backbone.fpn_output4.*               | backbone.fpn_output4.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| backbone.fpn_output5.*               | backbone.fpn_output5.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| sem_seg_head.p2.0.*                  | sem_seg_head.p2.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p3.0.*                  | sem_seg_head.p3.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p4.0.*                  | sem_seg_head.p4.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p4.2.*                  | sem_seg_head.p4.2.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,128,3,3)                     |\n",
      "| sem_seg_head.p5.0.*                  | sem_seg_head.p5.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p5.2.*                  | sem_seg_head.p5.2.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,128,3,3)                     |\n",
      "| sem_seg_head.p5.4.*                  | sem_seg_head.p5.4.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,128,3,3)                     |\n",
      "| sem_seg_head.predictor.*             | sem_seg_head.predictor.{bias,weight}                                                                 | (17,) (17,128,1,1)                              |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/05 21:36:14 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(720, 720), max_size=2048, sample_style='choice')]\n",
      "\u001b[32m[07/05 21:36:14 d2.data.common]: \u001b[0mSerializing 7230 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[07/05 21:36:14 d2.data.common]: \u001b[0mSerialized dataset takes 2.25 MiB\n",
      "\u001b[32m[07/05 21:36:14 d2.evaluation.evaluator]: \u001b[0mStart inference on 7230 batches\n",
      "\u001b[32m[07/05 21:36:17 d2.evaluation.evaluator]: \u001b[0mInference done 28/7230. Dataloading: 0.0022 s/iter. Inference: 0.0356 s/iter. Eval: 0.0424 s/iter. Total: 0.0802 s/iter. ETA=0:09:37\n",
      "\u001b[32m[07/05 21:36:22 d2.evaluation.evaluator]: \u001b[0mInference done 93/7230. Dataloading: 0.0022 s/iter. Inference: 0.0353 s/iter. Eval: 0.0405 s/iter. Total: 0.0781 s/iter. ETA=0:09:17\n",
      "\u001b[32m[07/05 21:36:27 d2.evaluation.evaluator]: \u001b[0mInference done 159/7230. Dataloading: 0.0022 s/iter. Inference: 0.0352 s/iter. Eval: 0.0396 s/iter. Total: 0.0771 s/iter. ETA=0:09:05\n",
      "\u001b[32m[07/05 21:36:32 d2.evaluation.evaluator]: \u001b[0mInference done 226/7230. Dataloading: 0.0022 s/iter. Inference: 0.0352 s/iter. Eval: 0.0390 s/iter. Total: 0.0765 s/iter. ETA=0:08:55\n",
      "\u001b[32m[07/05 21:36:37 d2.evaluation.evaluator]: \u001b[0mInference done 293/7230. Dataloading: 0.0022 s/iter. Inference: 0.0352 s/iter. Eval: 0.0386 s/iter. Total: 0.0761 s/iter. ETA=0:08:48\n",
      "\u001b[32m[07/05 21:36:42 d2.evaluation.evaluator]: \u001b[0mInference done 360/7230. Dataloading: 0.0022 s/iter. Inference: 0.0352 s/iter. Eval: 0.0383 s/iter. Total: 0.0759 s/iter. ETA=0:08:41\n",
      "\u001b[32m[07/05 21:36:47 d2.evaluation.evaluator]: \u001b[0mInference done 426/7230. Dataloading: 0.0022 s/iter. Inference: 0.0353 s/iter. Eval: 0.0383 s/iter. Total: 0.0759 s/iter. ETA=0:08:36\n",
      "\u001b[32m[07/05 21:36:52 d2.evaluation.evaluator]: \u001b[0mInference done 494/7230. Dataloading: 0.0022 s/iter. Inference: 0.0353 s/iter. Eval: 0.0381 s/iter. Total: 0.0757 s/iter. ETA=0:08:29\n",
      "\u001b[32m[07/05 21:36:57 d2.evaluation.evaluator]: \u001b[0mInference done 560/7230. Dataloading: 0.0026 s/iter. Inference: 0.0353 s/iter. Eval: 0.0379 s/iter. Total: 0.0758 s/iter. ETA=0:08:25\n",
      "\u001b[32m[07/05 21:37:02 d2.evaluation.evaluator]: \u001b[0mInference done 628/7230. Dataloading: 0.0025 s/iter. Inference: 0.0353 s/iter. Eval: 0.0378 s/iter. Total: 0.0757 s/iter. ETA=0:08:19\n",
      "\u001b[32m[07/05 21:37:07 d2.evaluation.evaluator]: \u001b[0mInference done 696/7230. Dataloading: 0.0025 s/iter. Inference: 0.0353 s/iter. Eval: 0.0376 s/iter. Total: 0.0755 s/iter. ETA=0:08:13\n",
      "\u001b[32m[07/05 21:37:12 d2.evaluation.evaluator]: \u001b[0mInference done 763/7230. Dataloading: 0.0025 s/iter. Inference: 0.0353 s/iter. Eval: 0.0376 s/iter. Total: 0.0754 s/iter. ETA=0:08:07\n",
      "\u001b[32m[07/05 21:37:17 d2.evaluation.evaluator]: \u001b[0mInference done 831/7230. Dataloading: 0.0025 s/iter. Inference: 0.0353 s/iter. Eval: 0.0375 s/iter. Total: 0.0754 s/iter. ETA=0:08:02\n",
      "\u001b[32m[07/05 21:37:22 d2.evaluation.evaluator]: \u001b[0mInference done 898/7230. Dataloading: 0.0024 s/iter. Inference: 0.0353 s/iter. Eval: 0.0375 s/iter. Total: 0.0753 s/iter. ETA=0:07:57\n",
      "\u001b[32m[07/05 21:37:27 d2.evaluation.evaluator]: \u001b[0mInference done 964/7230. Dataloading: 0.0024 s/iter. Inference: 0.0353 s/iter. Eval: 0.0376 s/iter. Total: 0.0754 s/iter. ETA=0:07:52\n",
      "\u001b[32m[07/05 21:37:32 d2.evaluation.evaluator]: \u001b[0mInference done 1030/7230. Dataloading: 0.0024 s/iter. Inference: 0.0353 s/iter. Eval: 0.0376 s/iter. Total: 0.0755 s/iter. ETA=0:07:47\n",
      "\u001b[32m[07/05 21:37:37 d2.evaluation.evaluator]: \u001b[0mInference done 1097/7230. Dataloading: 0.0024 s/iter. Inference: 0.0354 s/iter. Eval: 0.0376 s/iter. Total: 0.0754 s/iter. ETA=0:07:42\n",
      "\u001b[32m[07/05 21:37:42 d2.evaluation.evaluator]: \u001b[0mInference done 1162/7230. Dataloading: 0.0024 s/iter. Inference: 0.0354 s/iter. Eval: 0.0377 s/iter. Total: 0.0756 s/iter. ETA=0:07:38\n",
      "\u001b[32m[07/05 21:37:47 d2.evaluation.evaluator]: \u001b[0mInference done 1228/7230. Dataloading: 0.0024 s/iter. Inference: 0.0354 s/iter. Eval: 0.0378 s/iter. Total: 0.0756 s/iter. ETA=0:07:33\n",
      "\u001b[32m[07/05 21:37:52 d2.evaluation.evaluator]: \u001b[0mInference done 1294/7230. Dataloading: 0.0024 s/iter. Inference: 0.0354 s/iter. Eval: 0.0378 s/iter. Total: 0.0757 s/iter. ETA=0:07:29\n",
      "\u001b[32m[07/05 21:37:57 d2.evaluation.evaluator]: \u001b[0mInference done 1360/7230. Dataloading: 0.0024 s/iter. Inference: 0.0354 s/iter. Eval: 0.0379 s/iter. Total: 0.0757 s/iter. ETA=0:07:24\n",
      "\u001b[32m[07/05 21:38:02 d2.evaluation.evaluator]: \u001b[0mInference done 1427/7230. Dataloading: 0.0024 s/iter. Inference: 0.0354 s/iter. Eval: 0.0379 s/iter. Total: 0.0757 s/iter. ETA=0:07:19\n",
      "\u001b[32m[07/05 21:38:07 d2.evaluation.evaluator]: \u001b[0mInference done 1493/7230. Dataloading: 0.0024 s/iter. Inference: 0.0354 s/iter. Eval: 0.0379 s/iter. Total: 0.0758 s/iter. ETA=0:07:14\n",
      "\u001b[32m[07/05 21:38:12 d2.evaluation.evaluator]: \u001b[0mInference done 1558/7230. Dataloading: 0.0024 s/iter. Inference: 0.0354 s/iter. Eval: 0.0380 s/iter. Total: 0.0758 s/iter. ETA=0:07:10\n",
      "\u001b[32m[07/05 21:38:17 d2.evaluation.evaluator]: \u001b[0mInference done 1623/7230. Dataloading: 0.0024 s/iter. Inference: 0.0354 s/iter. Eval: 0.0380 s/iter. Total: 0.0759 s/iter. ETA=0:07:05\n",
      "\u001b[32m[07/05 21:38:23 d2.evaluation.evaluator]: \u001b[0mInference done 1687/7230. Dataloading: 0.0024 s/iter. Inference: 0.0354 s/iter. Eval: 0.0381 s/iter. Total: 0.0760 s/iter. ETA=0:07:01\n",
      "\u001b[32m[07/05 21:38:28 d2.evaluation.evaluator]: \u001b[0mInference done 1752/7230. Dataloading: 0.0024 s/iter. Inference: 0.0354 s/iter. Eval: 0.0382 s/iter. Total: 0.0760 s/iter. ETA=0:06:56\n",
      "\u001b[32m[07/05 21:38:33 d2.evaluation.evaluator]: \u001b[0mInference done 1818/7230. Dataloading: 0.0023 s/iter. Inference: 0.0354 s/iter. Eval: 0.0382 s/iter. Total: 0.0760 s/iter. ETA=0:06:51\n",
      "\u001b[32m[07/05 21:38:38 d2.evaluation.evaluator]: \u001b[0mInference done 1882/7230. Dataloading: 0.0023 s/iter. Inference: 0.0354 s/iter. Eval: 0.0383 s/iter. Total: 0.0761 s/iter. ETA=0:06:47\n",
      "\u001b[32m[07/05 21:38:43 d2.evaluation.evaluator]: \u001b[0mInference done 1948/7230. Dataloading: 0.0023 s/iter. Inference: 0.0354 s/iter. Eval: 0.0383 s/iter. Total: 0.0762 s/iter. ETA=0:06:42\n",
      "\u001b[32m[07/05 21:38:48 d2.evaluation.evaluator]: \u001b[0mInference done 2014/7230. Dataloading: 0.0023 s/iter. Inference: 0.0354 s/iter. Eval: 0.0383 s/iter. Total: 0.0762 s/iter. ETA=0:06:37\n",
      "\u001b[32m[07/05 21:38:53 d2.evaluation.evaluator]: \u001b[0mInference done 2079/7230. Dataloading: 0.0023 s/iter. Inference: 0.0354 s/iter. Eval: 0.0384 s/iter. Total: 0.0762 s/iter. ETA=0:06:32\n",
      "\u001b[32m[07/05 21:38:58 d2.evaluation.evaluator]: \u001b[0mInference done 2144/7230. Dataloading: 0.0023 s/iter. Inference: 0.0354 s/iter. Eval: 0.0384 s/iter. Total: 0.0762 s/iter. ETA=0:06:27\n",
      "\u001b[32m[07/05 21:39:03 d2.evaluation.evaluator]: \u001b[0mInference done 2210/7230. Dataloading: 0.0023 s/iter. Inference: 0.0354 s/iter. Eval: 0.0384 s/iter. Total: 0.0763 s/iter. ETA=0:06:22\n",
      "\u001b[32m[07/05 21:39:08 d2.evaluation.evaluator]: \u001b[0mInference done 2275/7230. Dataloading: 0.0023 s/iter. Inference: 0.0354 s/iter. Eval: 0.0384 s/iter. Total: 0.0763 s/iter. ETA=0:06:17\n",
      "\u001b[32m[07/05 21:39:13 d2.evaluation.evaluator]: \u001b[0mInference done 2341/7230. Dataloading: 0.0023 s/iter. Inference: 0.0354 s/iter. Eval: 0.0384 s/iter. Total: 0.0763 s/iter. ETA=0:06:12\n",
      "\u001b[32m[07/05 21:39:18 d2.evaluation.evaluator]: \u001b[0mInference done 2407/7230. Dataloading: 0.0023 s/iter. Inference: 0.0354 s/iter. Eval: 0.0384 s/iter. Total: 0.0763 s/iter. ETA=0:06:07\n",
      "\u001b[32m[07/05 21:39:23 d2.evaluation.evaluator]: \u001b[0mInference done 2473/7230. Dataloading: 0.0023 s/iter. Inference: 0.0354 s/iter. Eval: 0.0384 s/iter. Total: 0.0763 s/iter. ETA=0:06:02\n",
      "\u001b[32m[07/05 21:39:28 d2.evaluation.evaluator]: \u001b[0mInference done 2539/7230. Dataloading: 0.0023 s/iter. Inference: 0.0354 s/iter. Eval: 0.0384 s/iter. Total: 0.0763 s/iter. ETA=0:05:57\n",
      "\u001b[32m[07/05 21:39:33 d2.evaluation.evaluator]: \u001b[0mInference done 2605/7230. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0384 s/iter. Total: 0.0763 s/iter. ETA=0:05:52\n",
      "\u001b[32m[07/05 21:39:38 d2.evaluation.evaluator]: \u001b[0mInference done 2671/7230. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0384 s/iter. Total: 0.0763 s/iter. ETA=0:05:47\n",
      "\u001b[32m[07/05 21:39:43 d2.evaluation.evaluator]: \u001b[0mInference done 2737/7230. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0384 s/iter. Total: 0.0763 s/iter. ETA=0:05:42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/05 21:39:48 d2.evaluation.evaluator]: \u001b[0mInference done 2803/7230. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0384 s/iter. Total: 0.0763 s/iter. ETA=0:05:37\n",
      "\u001b[32m[07/05 21:39:53 d2.evaluation.evaluator]: \u001b[0mInference done 2869/7230. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0384 s/iter. Total: 0.0763 s/iter. ETA=0:05:32\n",
      "\u001b[32m[07/05 21:39:58 d2.evaluation.evaluator]: \u001b[0mInference done 2935/7230. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0384 s/iter. Total: 0.0763 s/iter. ETA=0:05:27\n",
      "\u001b[32m[07/05 21:40:03 d2.evaluation.evaluator]: \u001b[0mInference done 3001/7230. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0384 s/iter. Total: 0.0763 s/iter. ETA=0:05:22\n",
      "\u001b[32m[07/05 21:40:08 d2.evaluation.evaluator]: \u001b[0mInference done 3067/7230. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0384 s/iter. Total: 0.0763 s/iter. ETA=0:05:17\n",
      "\u001b[32m[07/05 21:40:13 d2.evaluation.evaluator]: \u001b[0mInference done 3133/7230. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0384 s/iter. Total: 0.0763 s/iter. ETA=0:05:12\n",
      "\u001b[32m[07/05 21:40:18 d2.evaluation.evaluator]: \u001b[0mInference done 3199/7230. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0384 s/iter. Total: 0.0763 s/iter. ETA=0:05:07\n",
      "\u001b[32m[07/05 21:40:24 d2.evaluation.evaluator]: \u001b[0mInference done 3261/7230. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0385 s/iter. Total: 0.0764 s/iter. ETA=0:05:03\n",
      "\u001b[32m[07/05 21:40:29 d2.evaluation.evaluator]: \u001b[0mInference done 3288/7230. Dataloading: 0.0023 s/iter. Inference: 0.0356 s/iter. Eval: 0.0394 s/iter. Total: 0.0774 s/iter. ETA=0:05:05\n",
      "\u001b[32m[07/05 21:40:34 d2.evaluation.evaluator]: \u001b[0mInference done 3314/7230. Dataloading: 0.0023 s/iter. Inference: 0.0357 s/iter. Eval: 0.0403 s/iter. Total: 0.0783 s/iter. ETA=0:05:06\n",
      "\u001b[32m[07/05 21:40:39 d2.evaluation.evaluator]: \u001b[0mInference done 3340/7230. Dataloading: 0.0023 s/iter. Inference: 0.0357 s/iter. Eval: 0.0411 s/iter. Total: 0.0792 s/iter. ETA=0:05:08\n",
      "\u001b[32m[07/05 21:40:44 d2.evaluation.evaluator]: \u001b[0mInference done 3367/7230. Dataloading: 0.0023 s/iter. Inference: 0.0358 s/iter. Eval: 0.0419 s/iter. Total: 0.0801 s/iter. ETA=0:05:09\n",
      "\u001b[32m[07/05 21:40:49 d2.evaluation.evaluator]: \u001b[0mInference done 3394/7230. Dataloading: 0.0023 s/iter. Inference: 0.0359 s/iter. Eval: 0.0426 s/iter. Total: 0.0809 s/iter. ETA=0:05:10\n",
      "\u001b[32m[07/05 21:40:54 d2.evaluation.evaluator]: \u001b[0mInference done 3422/7230. Dataloading: 0.0023 s/iter. Inference: 0.0360 s/iter. Eval: 0.0434 s/iter. Total: 0.0818 s/iter. ETA=0:05:11\n",
      "\u001b[32m[07/05 21:40:59 d2.evaluation.evaluator]: \u001b[0mInference done 3447/7230. Dataloading: 0.0023 s/iter. Inference: 0.0361 s/iter. Eval: 0.0442 s/iter. Total: 0.0827 s/iter. ETA=0:05:12\n",
      "\u001b[32m[07/05 21:41:04 d2.evaluation.evaluator]: \u001b[0mInference done 3473/7230. Dataloading: 0.0023 s/iter. Inference: 0.0362 s/iter. Eval: 0.0450 s/iter. Total: 0.0835 s/iter. ETA=0:05:13\n",
      "\u001b[32m[07/05 21:41:10 d2.evaluation.evaluator]: \u001b[0mInference done 3499/7230. Dataloading: 0.0023 s/iter. Inference: 0.0362 s/iter. Eval: 0.0457 s/iter. Total: 0.0844 s/iter. ETA=0:05:14\n",
      "\u001b[32m[07/05 21:41:15 d2.evaluation.evaluator]: \u001b[0mInference done 3525/7230. Dataloading: 0.0023 s/iter. Inference: 0.0363 s/iter. Eval: 0.0465 s/iter. Total: 0.0852 s/iter. ETA=0:05:15\n",
      "\u001b[32m[07/05 21:41:20 d2.evaluation.evaluator]: \u001b[0mInference done 3552/7230. Dataloading: 0.0023 s/iter. Inference: 0.0364 s/iter. Eval: 0.0472 s/iter. Total: 0.0860 s/iter. ETA=0:05:16\n",
      "\u001b[32m[07/05 21:41:25 d2.evaluation.evaluator]: \u001b[0mInference done 3579/7230. Dataloading: 0.0023 s/iter. Inference: 0.0365 s/iter. Eval: 0.0479 s/iter. Total: 0.0868 s/iter. ETA=0:05:16\n",
      "\u001b[32m[07/05 21:41:30 d2.evaluation.evaluator]: \u001b[0mInference done 3605/7230. Dataloading: 0.0023 s/iter. Inference: 0.0365 s/iter. Eval: 0.0486 s/iter. Total: 0.0875 s/iter. ETA=0:05:17\n",
      "\u001b[32m[07/05 21:41:35 d2.evaluation.evaluator]: \u001b[0mInference done 3632/7230. Dataloading: 0.0023 s/iter. Inference: 0.0366 s/iter. Eval: 0.0493 s/iter. Total: 0.0883 s/iter. ETA=0:05:17\n",
      "\u001b[32m[07/05 21:41:40 d2.evaluation.evaluator]: \u001b[0mInference done 3658/7230. Dataloading: 0.0023 s/iter. Inference: 0.0367 s/iter. Eval: 0.0500 s/iter. Total: 0.0891 s/iter. ETA=0:05:18\n",
      "\u001b[32m[07/05 21:41:45 d2.evaluation.evaluator]: \u001b[0mInference done 3685/7230. Dataloading: 0.0023 s/iter. Inference: 0.0368 s/iter. Eval: 0.0506 s/iter. Total: 0.0898 s/iter. ETA=0:05:18\n",
      "\u001b[32m[07/05 21:41:50 d2.evaluation.evaluator]: \u001b[0mInference done 3711/7230. Dataloading: 0.0024 s/iter. Inference: 0.0368 s/iter. Eval: 0.0512 s/iter. Total: 0.0906 s/iter. ETA=0:05:18\n",
      "\u001b[32m[07/05 21:41:55 d2.evaluation.evaluator]: \u001b[0mInference done 3738/7230. Dataloading: 0.0024 s/iter. Inference: 0.0369 s/iter. Eval: 0.0519 s/iter. Total: 0.0912 s/iter. ETA=0:05:18\n",
      "\u001b[32m[07/05 21:42:00 d2.evaluation.evaluator]: \u001b[0mInference done 3764/7230. Dataloading: 0.0024 s/iter. Inference: 0.0370 s/iter. Eval: 0.0525 s/iter. Total: 0.0919 s/iter. ETA=0:05:18\n",
      "\u001b[32m[07/05 21:42:05 d2.evaluation.evaluator]: \u001b[0mInference done 3791/7230. Dataloading: 0.0024 s/iter. Inference: 0.0370 s/iter. Eval: 0.0531 s/iter. Total: 0.0926 s/iter. ETA=0:05:18\n",
      "\u001b[32m[07/05 21:42:10 d2.evaluation.evaluator]: \u001b[0mInference done 3817/7230. Dataloading: 0.0024 s/iter. Inference: 0.0371 s/iter. Eval: 0.0537 s/iter. Total: 0.0933 s/iter. ETA=0:05:18\n",
      "\u001b[32m[07/05 21:42:15 d2.evaluation.evaluator]: \u001b[0mInference done 3843/7230. Dataloading: 0.0024 s/iter. Inference: 0.0372 s/iter. Eval: 0.0544 s/iter. Total: 0.0940 s/iter. ETA=0:05:18\n",
      "\u001b[32m[07/05 21:42:20 d2.evaluation.evaluator]: \u001b[0mInference done 3869/7230. Dataloading: 0.0024 s/iter. Inference: 0.0372 s/iter. Eval: 0.0550 s/iter. Total: 0.0947 s/iter. ETA=0:05:18\n",
      "\u001b[32m[07/05 21:42:26 d2.evaluation.evaluator]: \u001b[0mInference done 3896/7230. Dataloading: 0.0024 s/iter. Inference: 0.0373 s/iter. Eval: 0.0556 s/iter. Total: 0.0953 s/iter. ETA=0:05:17\n",
      "\u001b[32m[07/05 21:42:31 d2.evaluation.evaluator]: \u001b[0mInference done 3924/7230. Dataloading: 0.0024 s/iter. Inference: 0.0374 s/iter. Eval: 0.0561 s/iter. Total: 0.0960 s/iter. ETA=0:05:17\n",
      "\u001b[32m[07/05 21:42:36 d2.evaluation.evaluator]: \u001b[0mInference done 3950/7230. Dataloading: 0.0024 s/iter. Inference: 0.0374 s/iter. Eval: 0.0567 s/iter. Total: 0.0966 s/iter. ETA=0:05:16\n",
      "\u001b[32m[07/05 21:42:41 d2.evaluation.evaluator]: \u001b[0mInference done 4004/7230. Dataloading: 0.0024 s/iter. Inference: 0.0374 s/iter. Eval: 0.0567 s/iter. Total: 0.0966 s/iter. ETA=0:05:11\n",
      "\u001b[32m[07/05 21:42:46 d2.evaluation.evaluator]: \u001b[0mInference done 4069/7230. Dataloading: 0.0024 s/iter. Inference: 0.0374 s/iter. Eval: 0.0564 s/iter. Total: 0.0963 s/iter. ETA=0:05:04\n",
      "\u001b[32m[07/05 21:42:51 d2.evaluation.evaluator]: \u001b[0mInference done 4134/7230. Dataloading: 0.0024 s/iter. Inference: 0.0374 s/iter. Eval: 0.0561 s/iter. Total: 0.0960 s/iter. ETA=0:04:57\n",
      "\u001b[32m[07/05 21:42:56 d2.evaluation.evaluator]: \u001b[0mInference done 4199/7230. Dataloading: 0.0024 s/iter. Inference: 0.0373 s/iter. Eval: 0.0559 s/iter. Total: 0.0957 s/iter. ETA=0:04:50\n",
      "\u001b[32m[07/05 21:43:01 d2.evaluation.evaluator]: \u001b[0mInference done 4264/7230. Dataloading: 0.0024 s/iter. Inference: 0.0373 s/iter. Eval: 0.0557 s/iter. Total: 0.0954 s/iter. ETA=0:04:42\n",
      "\u001b[32m[07/05 21:43:06 d2.evaluation.evaluator]: \u001b[0mInference done 4328/7230. Dataloading: 0.0024 s/iter. Inference: 0.0373 s/iter. Eval: 0.0554 s/iter. Total: 0.0952 s/iter. ETA=0:04:36\n",
      "\u001b[32m[07/05 21:43:11 d2.evaluation.evaluator]: \u001b[0mInference done 4392/7230. Dataloading: 0.0024 s/iter. Inference: 0.0372 s/iter. Eval: 0.0552 s/iter. Total: 0.0949 s/iter. ETA=0:04:29\n",
      "\u001b[32m[07/05 21:43:16 d2.evaluation.evaluator]: \u001b[0mInference done 4456/7230. Dataloading: 0.0024 s/iter. Inference: 0.0372 s/iter. Eval: 0.0550 s/iter. Total: 0.0947 s/iter. ETA=0:04:22\n",
      "\u001b[32m[07/05 21:43:21 d2.evaluation.evaluator]: \u001b[0mInference done 4521/7230. Dataloading: 0.0024 s/iter. Inference: 0.0372 s/iter. Eval: 0.0548 s/iter. Total: 0.0944 s/iter. ETA=0:04:15\n",
      "\u001b[32m[07/05 21:43:26 d2.evaluation.evaluator]: \u001b[0mInference done 4585/7230. Dataloading: 0.0024 s/iter. Inference: 0.0372 s/iter. Eval: 0.0546 s/iter. Total: 0.0942 s/iter. ETA=0:04:09\n",
      "\u001b[32m[07/05 21:43:31 d2.evaluation.evaluator]: \u001b[0mInference done 4649/7230. Dataloading: 0.0024 s/iter. Inference: 0.0371 s/iter. Eval: 0.0544 s/iter. Total: 0.0940 s/iter. ETA=0:04:02\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/05 21:43:36 d2.evaluation.evaluator]: \u001b[0mInference done 4713/7230. Dataloading: 0.0024 s/iter. Inference: 0.0371 s/iter. Eval: 0.0542 s/iter. Total: 0.0938 s/iter. ETA=0:03:56\n",
      "\u001b[32m[07/05 21:43:41 d2.evaluation.evaluator]: \u001b[0mInference done 4779/7230. Dataloading: 0.0024 s/iter. Inference: 0.0371 s/iter. Eval: 0.0540 s/iter. Total: 0.0935 s/iter. ETA=0:03:49\n",
      "\u001b[32m[07/05 21:43:46 d2.evaluation.evaluator]: \u001b[0mInference done 4846/7230. Dataloading: 0.0024 s/iter. Inference: 0.0371 s/iter. Eval: 0.0538 s/iter. Total: 0.0933 s/iter. ETA=0:03:42\n",
      "\u001b[32m[07/05 21:43:51 d2.evaluation.evaluator]: \u001b[0mInference done 4912/7230. Dataloading: 0.0024 s/iter. Inference: 0.0370 s/iter. Eval: 0.0536 s/iter. Total: 0.0931 s/iter. ETA=0:03:35\n",
      "\u001b[32m[07/05 21:43:56 d2.evaluation.evaluator]: \u001b[0mInference done 4978/7230. Dataloading: 0.0024 s/iter. Inference: 0.0370 s/iter. Eval: 0.0534 s/iter. Total: 0.0928 s/iter. ETA=0:03:29\n",
      "\u001b[32m[07/05 21:44:01 d2.evaluation.evaluator]: \u001b[0mInference done 5045/7230. Dataloading: 0.0024 s/iter. Inference: 0.0370 s/iter. Eval: 0.0532 s/iter. Total: 0.0926 s/iter. ETA=0:03:22\n",
      "\u001b[32m[07/05 21:44:06 d2.evaluation.evaluator]: \u001b[0mInference done 5111/7230. Dataloading: 0.0024 s/iter. Inference: 0.0370 s/iter. Eval: 0.0530 s/iter. Total: 0.0924 s/iter. ETA=0:03:15\n",
      "\u001b[32m[07/05 21:44:11 d2.evaluation.evaluator]: \u001b[0mInference done 5177/7230. Dataloading: 0.0024 s/iter. Inference: 0.0370 s/iter. Eval: 0.0528 s/iter. Total: 0.0922 s/iter. ETA=0:03:09\n",
      "\u001b[32m[07/05 21:44:17 d2.evaluation.evaluator]: \u001b[0mInference done 5243/7230. Dataloading: 0.0024 s/iter. Inference: 0.0369 s/iter. Eval: 0.0526 s/iter. Total: 0.0920 s/iter. ETA=0:03:02\n",
      "\u001b[32m[07/05 21:44:22 d2.evaluation.evaluator]: \u001b[0mInference done 5309/7230. Dataloading: 0.0024 s/iter. Inference: 0.0369 s/iter. Eval: 0.0524 s/iter. Total: 0.0918 s/iter. ETA=0:02:56\n",
      "\u001b[32m[07/05 21:44:27 d2.evaluation.evaluator]: \u001b[0mInference done 5375/7230. Dataloading: 0.0024 s/iter. Inference: 0.0369 s/iter. Eval: 0.0522 s/iter. Total: 0.0916 s/iter. ETA=0:02:49\n",
      "\u001b[32m[07/05 21:44:32 d2.evaluation.evaluator]: \u001b[0mInference done 5442/7230. Dataloading: 0.0024 s/iter. Inference: 0.0369 s/iter. Eval: 0.0521 s/iter. Total: 0.0914 s/iter. ETA=0:02:43\n",
      "\u001b[32m[07/05 21:44:37 d2.evaluation.evaluator]: \u001b[0mInference done 5508/7230. Dataloading: 0.0024 s/iter. Inference: 0.0369 s/iter. Eval: 0.0519 s/iter. Total: 0.0912 s/iter. ETA=0:02:37\n",
      "\u001b[32m[07/05 21:44:42 d2.evaluation.evaluator]: \u001b[0mInference done 5574/7230. Dataloading: 0.0024 s/iter. Inference: 0.0369 s/iter. Eval: 0.0517 s/iter. Total: 0.0910 s/iter. ETA=0:02:30\n",
      "\u001b[32m[07/05 21:44:47 d2.evaluation.evaluator]: \u001b[0mInference done 5640/7230. Dataloading: 0.0024 s/iter. Inference: 0.0368 s/iter. Eval: 0.0516 s/iter. Total: 0.0909 s/iter. ETA=0:02:24\n",
      "\u001b[32m[07/05 21:44:52 d2.evaluation.evaluator]: \u001b[0mInference done 5706/7230. Dataloading: 0.0024 s/iter. Inference: 0.0368 s/iter. Eval: 0.0514 s/iter. Total: 0.0907 s/iter. ETA=0:02:18\n",
      "\u001b[32m[07/05 21:44:57 d2.evaluation.evaluator]: \u001b[0mInference done 5772/7230. Dataloading: 0.0024 s/iter. Inference: 0.0368 s/iter. Eval: 0.0513 s/iter. Total: 0.0905 s/iter. ETA=0:02:12\n",
      "\u001b[32m[07/05 21:45:02 d2.evaluation.evaluator]: \u001b[0mInference done 5838/7230. Dataloading: 0.0024 s/iter. Inference: 0.0368 s/iter. Eval: 0.0511 s/iter. Total: 0.0904 s/iter. ETA=0:02:05\n",
      "\u001b[32m[07/05 21:45:07 d2.evaluation.evaluator]: \u001b[0mInference done 5905/7230. Dataloading: 0.0024 s/iter. Inference: 0.0368 s/iter. Eval: 0.0510 s/iter. Total: 0.0902 s/iter. ETA=0:01:59\n",
      "\u001b[32m[07/05 21:45:12 d2.evaluation.evaluator]: \u001b[0mInference done 5972/7230. Dataloading: 0.0024 s/iter. Inference: 0.0368 s/iter. Eval: 0.0508 s/iter. Total: 0.0901 s/iter. ETA=0:01:53\n",
      "\u001b[32m[07/05 21:45:17 d2.evaluation.evaluator]: \u001b[0mInference done 6037/7230. Dataloading: 0.0024 s/iter. Inference: 0.0368 s/iter. Eval: 0.0507 s/iter. Total: 0.0899 s/iter. ETA=0:01:47\n",
      "\u001b[32m[07/05 21:45:22 d2.evaluation.evaluator]: \u001b[0mInference done 6103/7230. Dataloading: 0.0024 s/iter. Inference: 0.0367 s/iter. Eval: 0.0506 s/iter. Total: 0.0898 s/iter. ETA=0:01:41\n",
      "\u001b[32m[07/05 21:45:27 d2.evaluation.evaluator]: \u001b[0mInference done 6169/7230. Dataloading: 0.0024 s/iter. Inference: 0.0367 s/iter. Eval: 0.0504 s/iter. Total: 0.0896 s/iter. ETA=0:01:35\n",
      "\u001b[32m[07/05 21:45:32 d2.evaluation.evaluator]: \u001b[0mInference done 6235/7230. Dataloading: 0.0024 s/iter. Inference: 0.0367 s/iter. Eval: 0.0503 s/iter. Total: 0.0895 s/iter. ETA=0:01:29\n",
      "\u001b[32m[07/05 21:45:37 d2.evaluation.evaluator]: \u001b[0mInference done 6301/7230. Dataloading: 0.0024 s/iter. Inference: 0.0367 s/iter. Eval: 0.0502 s/iter. Total: 0.0893 s/iter. ETA=0:01:23\n",
      "\u001b[32m[07/05 21:45:42 d2.evaluation.evaluator]: \u001b[0mInference done 6367/7230. Dataloading: 0.0024 s/iter. Inference: 0.0367 s/iter. Eval: 0.0501 s/iter. Total: 0.0892 s/iter. ETA=0:01:16\n",
      "\u001b[32m[07/05 21:45:47 d2.evaluation.evaluator]: \u001b[0mInference done 6433/7230. Dataloading: 0.0024 s/iter. Inference: 0.0367 s/iter. Eval: 0.0500 s/iter. Total: 0.0891 s/iter. ETA=0:01:11\n",
      "\u001b[32m[07/05 21:45:52 d2.evaluation.evaluator]: \u001b[0mInference done 6498/7230. Dataloading: 0.0024 s/iter. Inference: 0.0367 s/iter. Eval: 0.0498 s/iter. Total: 0.0890 s/iter. ETA=0:01:05\n",
      "\u001b[32m[07/05 21:45:57 d2.evaluation.evaluator]: \u001b[0mInference done 6565/7230. Dataloading: 0.0024 s/iter. Inference: 0.0367 s/iter. Eval: 0.0497 s/iter. Total: 0.0888 s/iter. ETA=0:00:59\n",
      "\u001b[32m[07/05 21:46:02 d2.evaluation.evaluator]: \u001b[0mInference done 6632/7230. Dataloading: 0.0024 s/iter. Inference: 0.0367 s/iter. Eval: 0.0496 s/iter. Total: 0.0887 s/iter. ETA=0:00:53\n",
      "\u001b[32m[07/05 21:46:08 d2.evaluation.evaluator]: \u001b[0mInference done 6699/7230. Dataloading: 0.0024 s/iter. Inference: 0.0366 s/iter. Eval: 0.0495 s/iter. Total: 0.0886 s/iter. ETA=0:00:47\n",
      "\u001b[32m[07/05 21:46:13 d2.evaluation.evaluator]: \u001b[0mInference done 6764/7230. Dataloading: 0.0024 s/iter. Inference: 0.0366 s/iter. Eval: 0.0494 s/iter. Total: 0.0885 s/iter. ETA=0:00:41\n",
      "\u001b[32m[07/05 21:46:18 d2.evaluation.evaluator]: \u001b[0mInference done 6828/7230. Dataloading: 0.0024 s/iter. Inference: 0.0366 s/iter. Eval: 0.0493 s/iter. Total: 0.0884 s/iter. ETA=0:00:35\n",
      "\u001b[32m[07/05 21:46:23 d2.evaluation.evaluator]: \u001b[0mInference done 6891/7230. Dataloading: 0.0024 s/iter. Inference: 0.0366 s/iter. Eval: 0.0492 s/iter. Total: 0.0883 s/iter. ETA=0:00:29\n",
      "\u001b[32m[07/05 21:46:28 d2.evaluation.evaluator]: \u001b[0mInference done 6954/7230. Dataloading: 0.0024 s/iter. Inference: 0.0366 s/iter. Eval: 0.0492 s/iter. Total: 0.0882 s/iter. ETA=0:00:24\n",
      "\u001b[32m[07/05 21:46:33 d2.evaluation.evaluator]: \u001b[0mInference done 7019/7230. Dataloading: 0.0024 s/iter. Inference: 0.0366 s/iter. Eval: 0.0491 s/iter. Total: 0.0881 s/iter. ETA=0:00:18\n",
      "\u001b[32m[07/05 21:46:38 d2.evaluation.evaluator]: \u001b[0mInference done 7084/7230. Dataloading: 0.0024 s/iter. Inference: 0.0366 s/iter. Eval: 0.0490 s/iter. Total: 0.0880 s/iter. ETA=0:00:12\n",
      "\u001b[32m[07/05 21:46:43 d2.evaluation.evaluator]: \u001b[0mInference done 7150/7230. Dataloading: 0.0024 s/iter. Inference: 0.0366 s/iter. Eval: 0.0489 s/iter. Total: 0.0879 s/iter. ETA=0:00:07\n",
      "\u001b[32m[07/05 21:46:48 d2.evaluation.evaluator]: \u001b[0mInference done 7217/7230. Dataloading: 0.0024 s/iter. Inference: 0.0366 s/iter. Eval: 0.0488 s/iter. Total: 0.0878 s/iter. ETA=0:00:01\n",
      "\u001b[32m[07/05 21:46:49 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:10:34.154497 (0.087772 s / iter per device, on 1 devices)\n",
      "\u001b[32m[07/05 21:46:49 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:04:24 (0.036565 s / iter per device, on 1 devices)\n",
      "\u001b[32m[07/05 21:46:50 d2.evaluation.sem_seg_evaluation]: \u001b[0mOrderedDict([('sem_seg', {'mIoU': 56.84485903343276, 'fwIoU': 81.3216115565641, 'IoU-Unlabeled': nan, 'IoU-Building': 73.81507043768084, 'IoU-Fence': 33.11620814018532, 'IoU-Pedestrian': 70.49008735030816, 'IoU-Pole': 53.061094270133616, 'IoU-Road': 95.82317298435179, 'IoU-SideWalk': 72.2737781691554, 'IoU-Vegetation': 72.33697329252966, 'IoU-Vehicles': 82.32304878663493, 'IoU-Wall': 57.197172042896064, 'IoU-TrafficSign': 57.8852033988575, 'IoU-Sky': 80.7696884783418, 'IoU-TrafficLight': 55.27492383388368, 'IoU-Terrain': 26.347524356771835, 'IoU-ConstructionVehicle': 56.63788013211336, 'IoU-workzone_object': 64.22115212807414, 'IoU-Detour': 14.78962576643879, 'mACC': 72.4448157333671, 'pACC': 89.18798190403521, 'ACC-Unlabeled': nan, 'ACC-Building': 95.65727944111252, 'ACC-Fence': 51.59529620710431, 'ACC-Pedestrian': 84.57179535560296, 'ACC-Pole': 62.4888250871716, 'ACC-Road': 97.59122704298565, 'ACC-SideWalk': 88.4176330373462, 'ACC-Vegetation': 83.84320565505463, 'ACC-Vehicles': 91.20888777841245, 'ACC-Wall': 64.05694567713783, 'ACC-TrafficSign': 67.67292327223021, 'ACC-Sky': 83.32414663905278, 'ACC-TrafficLight': 64.78702687509688, 'ACC-Terrain': 27.532336859333135, 'ACC-ConstructionVehicle': 94.23643823966336, 'ACC-workzone_object': 86.30291533928155, 'ACC-Detour': 15.830169227287586})])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/05 21:46:50 d2.engine.defaults]: \u001b[0mEvaluation results for combined_clear_both_val in csv format:\n",
      "\u001b[32m[07/05 21:46:50 d2.evaluation.testing]: \u001b[0mcopypaste: Task: sem_seg\n",
      "\u001b[32m[07/05 21:46:50 d2.evaluation.testing]: \u001b[0mcopypaste: mIoU,fwIoU,mACC,pACC\n",
      "\u001b[32m[07/05 21:46:50 d2.evaluation.testing]: \u001b[0mcopypaste: 56.8449,81.3216,72.4448,89.1880\n"
     ]
    }
   ],
   "source": [
    "trainer_both = Detectron2Trainer('combined_all_night_train', 'combined_clear_both_val', output_folder='./output_both_40k')\n",
    "trainer_both.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3593a800",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/06 04:13:46 d2.engine.defaults]: \u001b[0mModel:\n",
      "SemanticSegmentor(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (sem_seg_head): SemSegFPNHead(\n",
      "    (p2): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "    )\n",
      "    (p3): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (1): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "    )\n",
      "    (p4): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (1): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      (2): Conv2d(\n",
      "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (3): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "    )\n",
      "    (p5): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (1): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      (2): Conv2d(\n",
      "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (3): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      (4): Conv2d(\n",
      "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (5): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "    )\n",
      "    (predictor): Conv2d(128, 17, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/06 04:13:46 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(720, 720), max_size=2048, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[07/06 04:13:46 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[07/06 04:13:46 d2.data.common]: \u001b[0mSerializing 4560 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[07/06 04:13:46 d2.data.common]: \u001b[0mSerialized dataset takes 1.68 MiB\n",
      "Last checkpoint: model_final.pth\n",
      "\u001b[32m[07/06 04:13:47 d2.checkpoint.c2_model_loading]: \u001b[0mFollowing weights matched with model:\n",
      "| Names in Model                       | Names in Checkpoint                                                                                  | Shapes                                          |\n",
      "|:-------------------------------------|:-----------------------------------------------------------------------------------------------------|:------------------------------------------------|\n",
      "| backbone.bottom_up.res2.0.conv1.*    | backbone.bottom_up.res2.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,1,1)             |\n",
      "| backbone.bottom_up.res2.0.conv2.*    | backbone.bottom_up.res2.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |\n",
      "| backbone.bottom_up.res2.0.conv3.*    | backbone.bottom_up.res2.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res2.0.shortcut.* | backbone.bottom_up.res2.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res2.1.conv1.*    | backbone.bottom_up.res2.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |\n",
      "| backbone.bottom_up.res2.1.conv2.*    | backbone.bottom_up.res2.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |\n",
      "| backbone.bottom_up.res2.1.conv3.*    | backbone.bottom_up.res2.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res2.2.conv1.*    | backbone.bottom_up.res2.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |\n",
      "| backbone.bottom_up.res2.2.conv2.*    | backbone.bottom_up.res2.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |\n",
      "| backbone.bottom_up.res2.2.conv3.*    | backbone.bottom_up.res2.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res3.0.conv1.*    | backbone.bottom_up.res3.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,256,1,1)       |\n",
      "| backbone.bottom_up.res3.0.conv2.*    | backbone.bottom_up.res3.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.0.conv3.*    | backbone.bottom_up.res3.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res3.0.shortcut.* | backbone.bottom_up.res3.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (512,) (512,) (512,) (512,) (512,256,1,1)       |\n",
      "| backbone.bottom_up.res3.1.conv1.*    | backbone.bottom_up.res3.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |\n",
      "| backbone.bottom_up.res3.1.conv2.*    | backbone.bottom_up.res3.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.1.conv3.*    | backbone.bottom_up.res3.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res3.2.conv1.*    | backbone.bottom_up.res3.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |\n",
      "| backbone.bottom_up.res3.2.conv2.*    | backbone.bottom_up.res3.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.2.conv3.*    | backbone.bottom_up.res3.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res3.3.conv1.*    | backbone.bottom_up.res3.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |\n",
      "| backbone.bottom_up.res3.3.conv2.*    | backbone.bottom_up.res3.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.3.conv3.*    | backbone.bottom_up.res3.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res4.0.conv1.*    | backbone.bottom_up.res4.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,512,1,1)       |\n",
      "| backbone.bottom_up.res4.0.conv2.*    | backbone.bottom_up.res4.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.0.conv3.*    | backbone.bottom_up.res4.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.0.shortcut.* | backbone.bottom_up.res4.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (1024,) (1024,) (1024,) (1024,) (1024,512,1,1)  |\n",
      "| backbone.bottom_up.res4.1.conv1.*    | backbone.bottom_up.res4.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.1.conv2.*    | backbone.bottom_up.res4.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.1.conv3.*    | backbone.bottom_up.res4.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.2.conv1.*    | backbone.bottom_up.res4.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.2.conv2.*    | backbone.bottom_up.res4.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.2.conv3.*    | backbone.bottom_up.res4.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.3.conv1.*    | backbone.bottom_up.res4.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.3.conv2.*    | backbone.bottom_up.res4.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.3.conv3.*    | backbone.bottom_up.res4.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.4.conv1.*    | backbone.bottom_up.res4.4.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.4.conv2.*    | backbone.bottom_up.res4.4.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.4.conv3.*    | backbone.bottom_up.res4.4.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.5.conv1.*    | backbone.bottom_up.res4.5.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.5.conv2.*    | backbone.bottom_up.res4.5.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.5.conv3.*    | backbone.bottom_up.res4.5.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res5.0.conv1.*    | backbone.bottom_up.res5.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,1024,1,1)      |\n",
      "| backbone.bottom_up.res5.0.conv2.*    | backbone.bottom_up.res5.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |\n",
      "| backbone.bottom_up.res5.0.conv3.*    | backbone.bottom_up.res5.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
      "| backbone.bottom_up.res5.0.shortcut.* | backbone.bottom_up.res5.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (2048,) (2048,) (2048,) (2048,) (2048,1024,1,1) |\n",
      "| backbone.bottom_up.res5.1.conv1.*    | backbone.bottom_up.res5.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |\n",
      "| backbone.bottom_up.res5.1.conv2.*    | backbone.bottom_up.res5.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |\n",
      "| backbone.bottom_up.res5.1.conv3.*    | backbone.bottom_up.res5.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
      "| backbone.bottom_up.res5.2.conv1.*    | backbone.bottom_up.res5.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |\n",
      "| backbone.bottom_up.res5.2.conv2.*    | backbone.bottom_up.res5.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |\n",
      "| backbone.bottom_up.res5.2.conv3.*    | backbone.bottom_up.res5.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
      "| backbone.bottom_up.stem.conv1.*      | backbone.bottom_up.stem.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}      | (64,) (64,) (64,) (64,) (64,3,7,7)              |\n",
      "| backbone.fpn_lateral2.*              | backbone.fpn_lateral2.{bias,weight}                                                                  | (256,) (256,256,1,1)                            |\n",
      "| backbone.fpn_lateral3.*              | backbone.fpn_lateral3.{bias,weight}                                                                  | (256,) (256,512,1,1)                            |\n",
      "| backbone.fpn_lateral4.*              | backbone.fpn_lateral4.{bias,weight}                                                                  | (256,) (256,1024,1,1)                           |\n",
      "| backbone.fpn_lateral5.*              | backbone.fpn_lateral5.{bias,weight}                                                                  | (256,) (256,2048,1,1)                           |\n",
      "| backbone.fpn_output2.*               | backbone.fpn_output2.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| backbone.fpn_output3.*               | backbone.fpn_output3.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| backbone.fpn_output4.*               | backbone.fpn_output4.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| backbone.fpn_output5.*               | backbone.fpn_output5.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| sem_seg_head.p2.0.*                  | sem_seg_head.p2.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p3.0.*                  | sem_seg_head.p3.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p4.0.*                  | sem_seg_head.p4.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p4.2.*                  | sem_seg_head.p4.2.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,128,3,3)                     |\n",
      "| sem_seg_head.p5.0.*                  | sem_seg_head.p5.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p5.2.*                  | sem_seg_head.p5.2.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,128,3,3)                     |\n",
      "| sem_seg_head.p5.4.*                  | sem_seg_head.p5.4.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,128,3,3)                     |\n",
      "| sem_seg_head.predictor.*             | sem_seg_head.predictor.{bias,weight}                                                                 | (17,) (17,128,1,1)                              |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/06 04:13:47 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(720, 720), max_size=2048, sample_style='choice')]\n",
      "\u001b[32m[07/06 04:13:47 d2.data.common]: \u001b[0mSerializing 2185 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[07/06 04:13:47 d2.data.common]: \u001b[0mSerialized dataset takes 0.81 MiB\n",
      "\u001b[32m[07/06 04:13:47 d2.evaluation.evaluator]: \u001b[0mStart inference on 2185 batches\n",
      "\u001b[32m[07/06 04:13:48 d2.evaluation.evaluator]: \u001b[0mInference done 11/2185. Dataloading: 0.0017 s/iter. Inference: 0.0349 s/iter. Eval: 0.0409 s/iter. Total: 0.0776 s/iter. ETA=0:02:48\n",
      "\u001b[32m[07/06 04:13:53 d2.evaluation.evaluator]: \u001b[0mInference done 79/2185. Dataloading: 0.0021 s/iter. Inference: 0.0348 s/iter. Eval: 0.0376 s/iter. Total: 0.0745 s/iter. ETA=0:02:36\n",
      "\u001b[32m[07/06 04:13:58 d2.evaluation.evaluator]: \u001b[0mInference done 147/2185. Dataloading: 0.0021 s/iter. Inference: 0.0348 s/iter. Eval: 0.0372 s/iter. Total: 0.0742 s/iter. ETA=0:02:31\n",
      "\u001b[32m[07/06 04:14:03 d2.evaluation.evaluator]: \u001b[0mInference done 213/2185. Dataloading: 0.0022 s/iter. Inference: 0.0348 s/iter. Eval: 0.0378 s/iter. Total: 0.0749 s/iter. ETA=0:02:27\n",
      "\u001b[32m[07/06 04:14:08 d2.evaluation.evaluator]: \u001b[0mInference done 279/2185. Dataloading: 0.0022 s/iter. Inference: 0.0349 s/iter. Eval: 0.0381 s/iter. Total: 0.0752 s/iter. ETA=0:02:23\n",
      "\u001b[32m[07/06 04:14:13 d2.evaluation.evaluator]: \u001b[0mInference done 345/2185. Dataloading: 0.0022 s/iter. Inference: 0.0349 s/iter. Eval: 0.0384 s/iter. Total: 0.0755 s/iter. ETA=0:02:18\n",
      "\u001b[32m[07/06 04:14:18 d2.evaluation.evaluator]: \u001b[0mInference done 411/2185. Dataloading: 0.0022 s/iter. Inference: 0.0349 s/iter. Eval: 0.0385 s/iter. Total: 0.0756 s/iter. ETA=0:02:14\n",
      "\u001b[32m[07/06 04:14:23 d2.evaluation.evaluator]: \u001b[0mInference done 478/2185. Dataloading: 0.0022 s/iter. Inference: 0.0349 s/iter. Eval: 0.0384 s/iter. Total: 0.0756 s/iter. ETA=0:02:09\n",
      "\u001b[32m[07/06 04:14:29 d2.evaluation.evaluator]: \u001b[0mInference done 545/2185. Dataloading: 0.0022 s/iter. Inference: 0.0350 s/iter. Eval: 0.0384 s/iter. Total: 0.0756 s/iter. ETA=0:02:03\n",
      "\u001b[32m[07/06 04:14:34 d2.evaluation.evaluator]: \u001b[0mInference done 612/2185. Dataloading: 0.0022 s/iter. Inference: 0.0350 s/iter. Eval: 0.0383 s/iter. Total: 0.0755 s/iter. ETA=0:01:58\n",
      "\u001b[32m[07/06 04:14:39 d2.evaluation.evaluator]: \u001b[0mInference done 678/2185. Dataloading: 0.0022 s/iter. Inference: 0.0350 s/iter. Eval: 0.0383 s/iter. Total: 0.0756 s/iter. ETA=0:01:53\n",
      "\u001b[32m[07/06 04:14:44 d2.evaluation.evaluator]: \u001b[0mInference done 745/2185. Dataloading: 0.0022 s/iter. Inference: 0.0350 s/iter. Eval: 0.0383 s/iter. Total: 0.0756 s/iter. ETA=0:01:48\n",
      "\u001b[32m[07/06 04:14:49 d2.evaluation.evaluator]: \u001b[0mInference done 810/2185. Dataloading: 0.0022 s/iter. Inference: 0.0351 s/iter. Eval: 0.0383 s/iter. Total: 0.0758 s/iter. ETA=0:01:44\n",
      "\u001b[32m[07/06 04:14:54 d2.evaluation.evaluator]: \u001b[0mInference done 877/2185. Dataloading: 0.0022 s/iter. Inference: 0.0352 s/iter. Eval: 0.0382 s/iter. Total: 0.0757 s/iter. ETA=0:01:39\n",
      "\u001b[32m[07/06 04:14:59 d2.evaluation.evaluator]: \u001b[0mInference done 944/2185. Dataloading: 0.0022 s/iter. Inference: 0.0352 s/iter. Eval: 0.0382 s/iter. Total: 0.0756 s/iter. ETA=0:01:33\n",
      "\u001b[32m[07/06 04:15:04 d2.evaluation.evaluator]: \u001b[0mInference done 1011/2185. Dataloading: 0.0022 s/iter. Inference: 0.0352 s/iter. Eval: 0.0381 s/iter. Total: 0.0756 s/iter. ETA=0:01:28\n",
      "\u001b[32m[07/06 04:15:09 d2.evaluation.evaluator]: \u001b[0mInference done 1078/2185. Dataloading: 0.0022 s/iter. Inference: 0.0352 s/iter. Eval: 0.0381 s/iter. Total: 0.0756 s/iter. ETA=0:01:23\n",
      "\u001b[32m[07/06 04:15:14 d2.evaluation.evaluator]: \u001b[0mInference done 1144/2185. Dataloading: 0.0022 s/iter. Inference: 0.0352 s/iter. Eval: 0.0382 s/iter. Total: 0.0757 s/iter. ETA=0:01:18\n",
      "\u001b[32m[07/06 04:15:19 d2.evaluation.evaluator]: \u001b[0mInference done 1209/2185. Dataloading: 0.0022 s/iter. Inference: 0.0352 s/iter. Eval: 0.0383 s/iter. Total: 0.0758 s/iter. ETA=0:01:13\n",
      "\u001b[32m[07/06 04:15:24 d2.evaluation.evaluator]: \u001b[0mInference done 1272/2185. Dataloading: 0.0022 s/iter. Inference: 0.0352 s/iter. Eval: 0.0385 s/iter. Total: 0.0760 s/iter. ETA=0:01:09\n",
      "\u001b[32m[07/06 04:15:29 d2.evaluation.evaluator]: \u001b[0mInference done 1336/2185. Dataloading: 0.0022 s/iter. Inference: 0.0352 s/iter. Eval: 0.0386 s/iter. Total: 0.0762 s/iter. ETA=0:01:04\n",
      "\u001b[32m[07/06 04:15:34 d2.evaluation.evaluator]: \u001b[0mInference done 1405/2185. Dataloading: 0.0022 s/iter. Inference: 0.0352 s/iter. Eval: 0.0385 s/iter. Total: 0.0760 s/iter. ETA=0:00:59\n",
      "\u001b[32m[07/06 04:15:39 d2.evaluation.evaluator]: \u001b[0mInference done 1474/2185. Dataloading: 0.0022 s/iter. Inference: 0.0352 s/iter. Eval: 0.0383 s/iter. Total: 0.0758 s/iter. ETA=0:00:53\n",
      "\u001b[32m[07/06 04:15:44 d2.evaluation.evaluator]: \u001b[0mInference done 1542/2185. Dataloading: 0.0022 s/iter. Inference: 0.0352 s/iter. Eval: 0.0382 s/iter. Total: 0.0758 s/iter. ETA=0:00:48\n",
      "\u001b[32m[07/06 04:15:49 d2.evaluation.evaluator]: \u001b[0mInference done 1609/2185. Dataloading: 0.0022 s/iter. Inference: 0.0352 s/iter. Eval: 0.0382 s/iter. Total: 0.0757 s/iter. ETA=0:00:43\n",
      "\u001b[32m[07/06 04:15:54 d2.evaluation.evaluator]: \u001b[0mInference done 1676/2185. Dataloading: 0.0022 s/iter. Inference: 0.0353 s/iter. Eval: 0.0381 s/iter. Total: 0.0757 s/iter. ETA=0:00:38\n",
      "\u001b[32m[07/06 04:15:59 d2.evaluation.evaluator]: \u001b[0mInference done 1743/2185. Dataloading: 0.0022 s/iter. Inference: 0.0353 s/iter. Eval: 0.0381 s/iter. Total: 0.0756 s/iter. ETA=0:00:33\n",
      "\u001b[32m[07/06 04:16:04 d2.evaluation.evaluator]: \u001b[0mInference done 1810/2185. Dataloading: 0.0022 s/iter. Inference: 0.0353 s/iter. Eval: 0.0380 s/iter. Total: 0.0756 s/iter. ETA=0:00:28\n",
      "\u001b[32m[07/06 04:16:09 d2.evaluation.evaluator]: \u001b[0mInference done 1877/2185. Dataloading: 0.0022 s/iter. Inference: 0.0353 s/iter. Eval: 0.0380 s/iter. Total: 0.0756 s/iter. ETA=0:00:23\n",
      "\u001b[32m[07/06 04:16:14 d2.evaluation.evaluator]: \u001b[0mInference done 1944/2185. Dataloading: 0.0023 s/iter. Inference: 0.0353 s/iter. Eval: 0.0380 s/iter. Total: 0.0756 s/iter. ETA=0:00:18\n",
      "\u001b[32m[07/06 04:16:19 d2.evaluation.evaluator]: \u001b[0mInference done 2010/2185. Dataloading: 0.0023 s/iter. Inference: 0.0353 s/iter. Eval: 0.0380 s/iter. Total: 0.0756 s/iter. ETA=0:00:13\n",
      "\u001b[32m[07/06 04:16:24 d2.evaluation.evaluator]: \u001b[0mInference done 2074/2185. Dataloading: 0.0023 s/iter. Inference: 0.0353 s/iter. Eval: 0.0381 s/iter. Total: 0.0757 s/iter. ETA=0:00:08\n",
      "\u001b[32m[07/06 04:16:29 d2.evaluation.evaluator]: \u001b[0mInference done 2141/2185. Dataloading: 0.0023 s/iter. Inference: 0.0353 s/iter. Eval: 0.0381 s/iter. Total: 0.0757 s/iter. ETA=0:00:03\n",
      "\u001b[32m[07/06 04:16:33 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:02:45.129949 (0.075748 s / iter per device, on 1 devices)\n",
      "\u001b[32m[07/06 04:16:33 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:01:16 (0.035313 s / iter per device, on 1 devices)\n",
      "\u001b[32m[07/06 04:16:33 d2.evaluation.sem_seg_evaluation]: \u001b[0mOrderedDict([('sem_seg', {'mIoU': 43.55543738322471, 'fwIoU': 59.94481251385007, 'IoU-Unlabeled': nan, 'IoU-Building': 43.75050965825139, 'IoU-Fence': 18.42902897370798, 'IoU-Pedestrian': 10.776665064213693, 'IoU-Pole': 42.02068580663671, 'IoU-Road': 90.81603532082674, 'IoU-SideWalk': 51.55972295488177, 'IoU-Vegetation': 47.4960528416038, 'IoU-Vehicles': 56.1401638417104, 'IoU-Wall': 42.57817218610018, 'IoU-TrafficSign': 47.88356252830046, 'IoU-Sky': 37.50555183564166, 'IoU-TrafficLight': 61.093640596017536, 'IoU-Terrain': 16.7654284336874, 'IoU-ConstructionVehicle': 63.942068354045034, 'IoU-workzone_object': 64.39499797847968, 'IoU-Detour': 1.7347117574908009, 'mACC': 59.39605901708005, 'pACC': 72.71568541628771, 'ACC-Unlabeled': nan, 'ACC-Building': 96.11931273577441, 'ACC-Fence': 22.806603624188195, 'ACC-Pedestrian': 65.68462943673877, 'ACC-Pole': 48.718627904922485, 'ACC-Road': 94.26693056238736, 'ACC-SideWalk': 71.15756942011483, 'ACC-Vegetation': 53.39214465121316, 'ACC-Vehicles': 84.20418375358972, 'ACC-Wall': 49.75632542628654, 'ACC-TrafficSign': 57.95869112810037, 'ACC-Sky': 37.819319043133795, 'ACC-TrafficLight': 73.03898426246077, 'ACC-Terrain': 18.081811940872903, 'ACC-ConstructionVehicle': 92.59337214326348, 'ACC-workzone_object': 82.90883188281386, 'ACC-Detour': 1.8296063574200703})])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/06 04:16:33 d2.engine.defaults]: \u001b[0mEvaluation results for carla_both_rain_val in csv format:\n",
      "\u001b[32m[07/06 04:16:33 d2.evaluation.testing]: \u001b[0mcopypaste: Task: sem_seg\n",
      "\u001b[32m[07/06 04:16:33 d2.evaluation.testing]: \u001b[0mcopypaste: mIoU,fwIoU,mACC,pACC\n",
      "\u001b[32m[07/06 04:16:33 d2.evaluation.testing]: \u001b[0mcopypaste: 43.5554,59.9448,59.3961,72.7157\n"
     ]
    }
   ],
   "source": [
    "trainer_both = Detectron2Trainer('combined_all_night_train', 'carla_both_rain_val', output_folder='./output_both_40k')\n",
    "trainer_both.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d53d8948",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/06 04:16:34 d2.engine.defaults]: \u001b[0mModel:\n",
      "SemanticSegmentor(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (sem_seg_head): SemSegFPNHead(\n",
      "    (p2): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "    )\n",
      "    (p3): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (1): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "    )\n",
      "    (p4): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (1): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      (2): Conv2d(\n",
      "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (3): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "    )\n",
      "    (p5): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (1): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      (2): Conv2d(\n",
      "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (3): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      (4): Conv2d(\n",
      "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (5): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "    )\n",
      "    (predictor): Conv2d(128, 17, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/06 04:16:34 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(720, 720), max_size=2048, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[07/06 04:16:34 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[07/06 04:16:34 d2.data.common]: \u001b[0mSerializing 4560 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[07/06 04:16:34 d2.data.common]: \u001b[0mSerialized dataset takes 1.68 MiB\n",
      "Last checkpoint: model_final.pth\n",
      "\u001b[32m[07/06 04:16:34 d2.checkpoint.c2_model_loading]: \u001b[0mFollowing weights matched with model:\n",
      "| Names in Model                       | Names in Checkpoint                                                                                  | Shapes                                          |\n",
      "|:-------------------------------------|:-----------------------------------------------------------------------------------------------------|:------------------------------------------------|\n",
      "| backbone.bottom_up.res2.0.conv1.*    | backbone.bottom_up.res2.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,1,1)             |\n",
      "| backbone.bottom_up.res2.0.conv2.*    | backbone.bottom_up.res2.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |\n",
      "| backbone.bottom_up.res2.0.conv3.*    | backbone.bottom_up.res2.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res2.0.shortcut.* | backbone.bottom_up.res2.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res2.1.conv1.*    | backbone.bottom_up.res2.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |\n",
      "| backbone.bottom_up.res2.1.conv2.*    | backbone.bottom_up.res2.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |\n",
      "| backbone.bottom_up.res2.1.conv3.*    | backbone.bottom_up.res2.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res2.2.conv1.*    | backbone.bottom_up.res2.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |\n",
      "| backbone.bottom_up.res2.2.conv2.*    | backbone.bottom_up.res2.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |\n",
      "| backbone.bottom_up.res2.2.conv3.*    | backbone.bottom_up.res2.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res3.0.conv1.*    | backbone.bottom_up.res3.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,256,1,1)       |\n",
      "| backbone.bottom_up.res3.0.conv2.*    | backbone.bottom_up.res3.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.0.conv3.*    | backbone.bottom_up.res3.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res3.0.shortcut.* | backbone.bottom_up.res3.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (512,) (512,) (512,) (512,) (512,256,1,1)       |\n",
      "| backbone.bottom_up.res3.1.conv1.*    | backbone.bottom_up.res3.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |\n",
      "| backbone.bottom_up.res3.1.conv2.*    | backbone.bottom_up.res3.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.1.conv3.*    | backbone.bottom_up.res3.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res3.2.conv1.*    | backbone.bottom_up.res3.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |\n",
      "| backbone.bottom_up.res3.2.conv2.*    | backbone.bottom_up.res3.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.2.conv3.*    | backbone.bottom_up.res3.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res3.3.conv1.*    | backbone.bottom_up.res3.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |\n",
      "| backbone.bottom_up.res3.3.conv2.*    | backbone.bottom_up.res3.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.3.conv3.*    | backbone.bottom_up.res3.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res4.0.conv1.*    | backbone.bottom_up.res4.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,512,1,1)       |\n",
      "| backbone.bottom_up.res4.0.conv2.*    | backbone.bottom_up.res4.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.0.conv3.*    | backbone.bottom_up.res4.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.0.shortcut.* | backbone.bottom_up.res4.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (1024,) (1024,) (1024,) (1024,) (1024,512,1,1)  |\n",
      "| backbone.bottom_up.res4.1.conv1.*    | backbone.bottom_up.res4.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.1.conv2.*    | backbone.bottom_up.res4.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.1.conv3.*    | backbone.bottom_up.res4.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.2.conv1.*    | backbone.bottom_up.res4.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.2.conv2.*    | backbone.bottom_up.res4.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.2.conv3.*    | backbone.bottom_up.res4.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.3.conv1.*    | backbone.bottom_up.res4.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.3.conv2.*    | backbone.bottom_up.res4.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.3.conv3.*    | backbone.bottom_up.res4.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.4.conv1.*    | backbone.bottom_up.res4.4.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.4.conv2.*    | backbone.bottom_up.res4.4.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.4.conv3.*    | backbone.bottom_up.res4.4.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.5.conv1.*    | backbone.bottom_up.res4.5.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.5.conv2.*    | backbone.bottom_up.res4.5.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.5.conv3.*    | backbone.bottom_up.res4.5.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res5.0.conv1.*    | backbone.bottom_up.res5.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,1024,1,1)      |\n",
      "| backbone.bottom_up.res5.0.conv2.*    | backbone.bottom_up.res5.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |\n",
      "| backbone.bottom_up.res5.0.conv3.*    | backbone.bottom_up.res5.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
      "| backbone.bottom_up.res5.0.shortcut.* | backbone.bottom_up.res5.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (2048,) (2048,) (2048,) (2048,) (2048,1024,1,1) |\n",
      "| backbone.bottom_up.res5.1.conv1.*    | backbone.bottom_up.res5.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |\n",
      "| backbone.bottom_up.res5.1.conv2.*    | backbone.bottom_up.res5.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |\n",
      "| backbone.bottom_up.res5.1.conv3.*    | backbone.bottom_up.res5.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
      "| backbone.bottom_up.res5.2.conv1.*    | backbone.bottom_up.res5.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |\n",
      "| backbone.bottom_up.res5.2.conv2.*    | backbone.bottom_up.res5.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |\n",
      "| backbone.bottom_up.res5.2.conv3.*    | backbone.bottom_up.res5.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
      "| backbone.bottom_up.stem.conv1.*      | backbone.bottom_up.stem.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}      | (64,) (64,) (64,) (64,) (64,3,7,7)              |\n",
      "| backbone.fpn_lateral2.*              | backbone.fpn_lateral2.{bias,weight}                                                                  | (256,) (256,256,1,1)                            |\n",
      "| backbone.fpn_lateral3.*              | backbone.fpn_lateral3.{bias,weight}                                                                  | (256,) (256,512,1,1)                            |\n",
      "| backbone.fpn_lateral4.*              | backbone.fpn_lateral4.{bias,weight}                                                                  | (256,) (256,1024,1,1)                           |\n",
      "| backbone.fpn_lateral5.*              | backbone.fpn_lateral5.{bias,weight}                                                                  | (256,) (256,2048,1,1)                           |\n",
      "| backbone.fpn_output2.*               | backbone.fpn_output2.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| backbone.fpn_output3.*               | backbone.fpn_output3.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| backbone.fpn_output4.*               | backbone.fpn_output4.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| backbone.fpn_output5.*               | backbone.fpn_output5.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| sem_seg_head.p2.0.*                  | sem_seg_head.p2.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p3.0.*                  | sem_seg_head.p3.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p4.0.*                  | sem_seg_head.p4.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p4.2.*                  | sem_seg_head.p4.2.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,128,3,3)                     |\n",
      "| sem_seg_head.p5.0.*                  | sem_seg_head.p5.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p5.2.*                  | sem_seg_head.p5.2.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,128,3,3)                     |\n",
      "| sem_seg_head.p5.4.*                  | sem_seg_head.p5.4.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,128,3,3)                     |\n",
      "| sem_seg_head.predictor.*             | sem_seg_head.predictor.{bias,weight}                                                                 | (17,) (17,128,1,1)                              |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/06 04:16:34 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(720, 720), max_size=2048, sample_style='choice')]\n",
      "\u001b[32m[07/06 04:16:34 d2.data.common]: \u001b[0mSerializing 699 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[07/06 04:16:34 d2.data.common]: \u001b[0mSerialized dataset takes 0.24 MiB\n",
      "\u001b[32m[07/06 04:16:34 d2.evaluation.evaluator]: \u001b[0mStart inference on 699 batches\n",
      "\u001b[32m[07/06 04:16:37 d2.evaluation.evaluator]: \u001b[0mInference done 11/699. Dataloading: 0.0018 s/iter. Inference: 0.0470 s/iter. Eval: 0.1572 s/iter. Total: 0.2060 s/iter. ETA=0:02:21\n",
      "\u001b[32m[07/06 04:16:42 d2.evaluation.evaluator]: \u001b[0mInference done 37/699. Dataloading: 0.0020 s/iter. Inference: 0.0469 s/iter. Eval: 0.1525 s/iter. Total: 0.2015 s/iter. ETA=0:02:13\n",
      "\u001b[32m[07/06 04:16:47 d2.evaluation.evaluator]: \u001b[0mInference done 63/699. Dataloading: 0.0021 s/iter. Inference: 0.0469 s/iter. Eval: 0.1517 s/iter. Total: 0.2007 s/iter. ETA=0:02:07\n",
      "\u001b[32m[07/06 04:16:52 d2.evaluation.evaluator]: \u001b[0mInference done 89/699. Dataloading: 0.0021 s/iter. Inference: 0.0468 s/iter. Eval: 0.1500 s/iter. Total: 0.1991 s/iter. ETA=0:02:01\n",
      "\u001b[32m[07/06 04:16:57 d2.evaluation.evaluator]: \u001b[0mInference done 115/699. Dataloading: 0.0021 s/iter. Inference: 0.0468 s/iter. Eval: 0.1489 s/iter. Total: 0.1979 s/iter. ETA=0:01:55\n",
      "\u001b[32m[07/06 04:17:02 d2.evaluation.evaluator]: \u001b[0mInference done 142/699. Dataloading: 0.0021 s/iter. Inference: 0.0468 s/iter. Eval: 0.1475 s/iter. Total: 0.1965 s/iter. ETA=0:01:49\n",
      "\u001b[32m[07/06 04:17:07 d2.evaluation.evaluator]: \u001b[0mInference done 168/699. Dataloading: 0.0021 s/iter. Inference: 0.0468 s/iter. Eval: 0.1470 s/iter. Total: 0.1960 s/iter. ETA=0:01:44\n",
      "\u001b[32m[07/06 04:17:13 d2.evaluation.evaluator]: \u001b[0mInference done 193/699. Dataloading: 0.0021 s/iter. Inference: 0.0468 s/iter. Eval: 0.1485 s/iter. Total: 0.1974 s/iter. ETA=0:01:39\n",
      "\u001b[32m[07/06 04:17:18 d2.evaluation.evaluator]: \u001b[0mInference done 218/699. Dataloading: 0.0021 s/iter. Inference: 0.0468 s/iter. Eval: 0.1493 s/iter. Total: 0.1983 s/iter. ETA=0:01:35\n",
      "\u001b[32m[07/06 04:17:23 d2.evaluation.evaluator]: \u001b[0mInference done 243/699. Dataloading: 0.0021 s/iter. Inference: 0.0468 s/iter. Eval: 0.1499 s/iter. Total: 0.1989 s/iter. ETA=0:01:30\n",
      "\u001b[32m[07/06 04:17:28 d2.evaluation.evaluator]: \u001b[0mInference done 268/699. Dataloading: 0.0021 s/iter. Inference: 0.0468 s/iter. Eval: 0.1501 s/iter. Total: 0.1991 s/iter. ETA=0:01:25\n",
      "\u001b[32m[07/06 04:17:33 d2.evaluation.evaluator]: \u001b[0mInference done 293/699. Dataloading: 0.0021 s/iter. Inference: 0.0468 s/iter. Eval: 0.1502 s/iter. Total: 0.1992 s/iter. ETA=0:01:20\n",
      "\u001b[32m[07/06 04:17:38 d2.evaluation.evaluator]: \u001b[0mInference done 318/699. Dataloading: 0.0021 s/iter. Inference: 0.0468 s/iter. Eval: 0.1506 s/iter. Total: 0.1996 s/iter. ETA=0:01:16\n",
      "\u001b[32m[07/06 04:17:43 d2.evaluation.evaluator]: \u001b[0mInference done 343/699. Dataloading: 0.0021 s/iter. Inference: 0.0468 s/iter. Eval: 0.1511 s/iter. Total: 0.2001 s/iter. ETA=0:01:11\n",
      "\u001b[32m[07/06 04:17:48 d2.evaluation.evaluator]: \u001b[0mInference done 368/699. Dataloading: 0.0021 s/iter. Inference: 0.0468 s/iter. Eval: 0.1512 s/iter. Total: 0.2002 s/iter. ETA=0:01:06\n",
      "\u001b[32m[07/06 04:17:53 d2.evaluation.evaluator]: \u001b[0mInference done 393/699. Dataloading: 0.0021 s/iter. Inference: 0.0468 s/iter. Eval: 0.1515 s/iter. Total: 0.2005 s/iter. ETA=0:01:01\n",
      "\u001b[32m[07/06 04:17:58 d2.evaluation.evaluator]: \u001b[0mInference done 419/699. Dataloading: 0.0021 s/iter. Inference: 0.0468 s/iter. Eval: 0.1514 s/iter. Total: 0.2004 s/iter. ETA=0:00:56\n",
      "\u001b[32m[07/06 04:18:03 d2.evaluation.evaluator]: \u001b[0mInference done 444/699. Dataloading: 0.0021 s/iter. Inference: 0.0468 s/iter. Eval: 0.1514 s/iter. Total: 0.2004 s/iter. ETA=0:00:51\n",
      "\u001b[32m[07/06 04:18:09 d2.evaluation.evaluator]: \u001b[0mInference done 470/699. Dataloading: 0.0021 s/iter. Inference: 0.0468 s/iter. Eval: 0.1512 s/iter. Total: 0.2002 s/iter. ETA=0:00:45\n",
      "\u001b[32m[07/06 04:18:14 d2.evaluation.evaluator]: \u001b[0mInference done 495/699. Dataloading: 0.0021 s/iter. Inference: 0.0468 s/iter. Eval: 0.1513 s/iter. Total: 0.2003 s/iter. ETA=0:00:40\n",
      "\u001b[32m[07/06 04:18:19 d2.evaluation.evaluator]: \u001b[0mInference done 521/699. Dataloading: 0.0021 s/iter. Inference: 0.0468 s/iter. Eval: 0.1512 s/iter. Total: 0.2002 s/iter. ETA=0:00:35\n",
      "\u001b[32m[07/06 04:18:24 d2.evaluation.evaluator]: \u001b[0mInference done 547/699. Dataloading: 0.0021 s/iter. Inference: 0.0468 s/iter. Eval: 0.1512 s/iter. Total: 0.2002 s/iter. ETA=0:00:30\n",
      "\u001b[32m[07/06 04:18:29 d2.evaluation.evaluator]: \u001b[0mInference done 572/699. Dataloading: 0.0021 s/iter. Inference: 0.0468 s/iter. Eval: 0.1512 s/iter. Total: 0.2002 s/iter. ETA=0:00:25\n",
      "\u001b[32m[07/06 04:18:34 d2.evaluation.evaluator]: \u001b[0mInference done 597/699. Dataloading: 0.0021 s/iter. Inference: 0.0468 s/iter. Eval: 0.1513 s/iter. Total: 0.2003 s/iter. ETA=0:00:20\n",
      "\u001b[32m[07/06 04:18:39 d2.evaluation.evaluator]: \u001b[0mInference done 622/699. Dataloading: 0.0021 s/iter. Inference: 0.0468 s/iter. Eval: 0.1515 s/iter. Total: 0.2005 s/iter. ETA=0:00:15\n",
      "\u001b[32m[07/06 04:18:44 d2.evaluation.evaluator]: \u001b[0mInference done 648/699. Dataloading: 0.0021 s/iter. Inference: 0.0468 s/iter. Eval: 0.1514 s/iter. Total: 0.2004 s/iter. ETA=0:00:10\n",
      "\u001b[32m[07/06 04:18:49 d2.evaluation.evaluator]: \u001b[0mInference done 674/699. Dataloading: 0.0021 s/iter. Inference: 0.0468 s/iter. Eval: 0.1512 s/iter. Total: 0.2002 s/iter. ETA=0:00:05\n",
      "\u001b[32m[07/06 04:18:54 d2.evaluation.evaluator]: \u001b[0mInference done 699/699. Dataloading: 0.0021 s/iter. Inference: 0.0468 s/iter. Eval: 0.1513 s/iter. Total: 0.2003 s/iter. ETA=0:00:00\n",
      "\u001b[32m[07/06 04:18:55 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:02:19.101384 (0.200434 s / iter per device, on 1 devices)\n",
      "\u001b[32m[07/06 04:18:55 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:32 (0.046802 s / iter per device, on 1 devices)\n",
      "\u001b[32m[07/06 04:18:55 d2.evaluation.sem_seg_evaluation]: \u001b[0mOrderedDict([('sem_seg', {'mIoU': 60.814583340002336, 'fwIoU': 85.7080407726317, 'IoU-Unlabeled': nan, 'IoU-Building': 84.64569442435425, 'IoU-Fence': 41.43642452181284, 'IoU-Pedestrian': 68.54623225225644, 'IoU-Pole': 45.53918879356494, 'IoU-Road': 94.56329019863429, 'IoU-SideWalk': 72.24931235346288, 'IoU-Vegetation': 84.85526470473711, 'IoU-Vehicles': 87.19719431156746, 'IoU-Wall': 36.395339292655564, 'IoU-TrafficSign': 57.54211674823323, 'IoU-Sky': 83.90153382213192, 'IoU-TrafficLight': 45.47961201395894, 'IoU-Terrain': 49.052963322662976, 'IoU-ConstructionVehicle': nan, 'IoU-workzone_object': nan, 'IoU-Detour': nan, 'mACC': 75.55976652147038, 'pACC': 91.87851104228275, 'ACC-Unlabeled': nan, 'ACC-Building': 95.74043518630991, 'ACC-Fence': 50.29579401559619, 'ACC-Pedestrian': 86.4713398311357, 'ACC-Pole': 57.901690789425764, 'ACC-Road': 96.46353601076152, 'ACC-SideWalk': 83.30676791960431, 'ACC-Vegetation': 90.02312350233422, 'ACC-Vehicles': 92.18016291389887, 'ACC-Wall': 52.419601907697086, 'ACC-TrafficSign': 63.625967699023, 'ACC-Sky': 86.43663592647061, 'ACC-TrafficLight': 51.766384933973264, 'ACC-Terrain': 75.64552414288453, 'ACC-ConstructionVehicle': nan, 'ACC-workzone_object': nan, 'ACC-Detour': nan})])\n",
      "\u001b[32m[07/06 04:18:55 d2.engine.defaults]: \u001b[0mEvaluation results for cityscapes_rain_val in csv format:\n",
      "\u001b[32m[07/06 04:18:55 d2.evaluation.testing]: \u001b[0mcopypaste: Task: sem_seg\n",
      "\u001b[32m[07/06 04:18:55 d2.evaluation.testing]: \u001b[0mcopypaste: mIoU,fwIoU,mACC,pACC\n",
      "\u001b[32m[07/06 04:18:55 d2.evaluation.testing]: \u001b[0mcopypaste: 60.8146,85.7080,75.5598,91.8785\n"
     ]
    }
   ],
   "source": [
    "trainer_both = Detectron2Trainer('combined_all_night_train', 'cityscapes_rain_val', output_folder='./output_both_40k')\n",
    "trainer_both.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c9c4a92a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/06 04:18:55 d2.engine.defaults]: \u001b[0mModel:\n",
      "SemanticSegmentor(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (sem_seg_head): SemSegFPNHead(\n",
      "    (p2): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "    )\n",
      "    (p3): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (1): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "    )\n",
      "    (p4): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (1): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      (2): Conv2d(\n",
      "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (3): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "    )\n",
      "    (p5): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (1): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      (2): Conv2d(\n",
      "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (3): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      (4): Conv2d(\n",
      "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (5): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "    )\n",
      "    (predictor): Conv2d(128, 17, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/06 04:18:55 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(720, 720), max_size=2048, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[07/06 04:18:55 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[07/06 04:18:55 d2.data.common]: \u001b[0mSerializing 4560 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[07/06 04:18:55 d2.data.common]: \u001b[0mSerialized dataset takes 1.68 MiB\n",
      "Last checkpoint: model_final.pth\n",
      "\u001b[32m[07/06 04:18:56 d2.checkpoint.c2_model_loading]: \u001b[0mFollowing weights matched with model:\n",
      "| Names in Model                       | Names in Checkpoint                                                                                  | Shapes                                          |\n",
      "|:-------------------------------------|:-----------------------------------------------------------------------------------------------------|:------------------------------------------------|\n",
      "| backbone.bottom_up.res2.0.conv1.*    | backbone.bottom_up.res2.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,1,1)             |\n",
      "| backbone.bottom_up.res2.0.conv2.*    | backbone.bottom_up.res2.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |\n",
      "| backbone.bottom_up.res2.0.conv3.*    | backbone.bottom_up.res2.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res2.0.shortcut.* | backbone.bottom_up.res2.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res2.1.conv1.*    | backbone.bottom_up.res2.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |\n",
      "| backbone.bottom_up.res2.1.conv2.*    | backbone.bottom_up.res2.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |\n",
      "| backbone.bottom_up.res2.1.conv3.*    | backbone.bottom_up.res2.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res2.2.conv1.*    | backbone.bottom_up.res2.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |\n",
      "| backbone.bottom_up.res2.2.conv2.*    | backbone.bottom_up.res2.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |\n",
      "| backbone.bottom_up.res2.2.conv3.*    | backbone.bottom_up.res2.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res3.0.conv1.*    | backbone.bottom_up.res3.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,256,1,1)       |\n",
      "| backbone.bottom_up.res3.0.conv2.*    | backbone.bottom_up.res3.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.0.conv3.*    | backbone.bottom_up.res3.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res3.0.shortcut.* | backbone.bottom_up.res3.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (512,) (512,) (512,) (512,) (512,256,1,1)       |\n",
      "| backbone.bottom_up.res3.1.conv1.*    | backbone.bottom_up.res3.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |\n",
      "| backbone.bottom_up.res3.1.conv2.*    | backbone.bottom_up.res3.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.1.conv3.*    | backbone.bottom_up.res3.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res3.2.conv1.*    | backbone.bottom_up.res3.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |\n",
      "| backbone.bottom_up.res3.2.conv2.*    | backbone.bottom_up.res3.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.2.conv3.*    | backbone.bottom_up.res3.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res3.3.conv1.*    | backbone.bottom_up.res3.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |\n",
      "| backbone.bottom_up.res3.3.conv2.*    | backbone.bottom_up.res3.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.3.conv3.*    | backbone.bottom_up.res3.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res4.0.conv1.*    | backbone.bottom_up.res4.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,512,1,1)       |\n",
      "| backbone.bottom_up.res4.0.conv2.*    | backbone.bottom_up.res4.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.0.conv3.*    | backbone.bottom_up.res4.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.0.shortcut.* | backbone.bottom_up.res4.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (1024,) (1024,) (1024,) (1024,) (1024,512,1,1)  |\n",
      "| backbone.bottom_up.res4.1.conv1.*    | backbone.bottom_up.res4.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.1.conv2.*    | backbone.bottom_up.res4.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.1.conv3.*    | backbone.bottom_up.res4.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.2.conv1.*    | backbone.bottom_up.res4.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.2.conv2.*    | backbone.bottom_up.res4.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.2.conv3.*    | backbone.bottom_up.res4.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.3.conv1.*    | backbone.bottom_up.res4.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.3.conv2.*    | backbone.bottom_up.res4.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.3.conv3.*    | backbone.bottom_up.res4.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.4.conv1.*    | backbone.bottom_up.res4.4.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.4.conv2.*    | backbone.bottom_up.res4.4.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.4.conv3.*    | backbone.bottom_up.res4.4.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.5.conv1.*    | backbone.bottom_up.res4.5.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.5.conv2.*    | backbone.bottom_up.res4.5.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.5.conv3.*    | backbone.bottom_up.res4.5.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res5.0.conv1.*    | backbone.bottom_up.res5.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,1024,1,1)      |\n",
      "| backbone.bottom_up.res5.0.conv2.*    | backbone.bottom_up.res5.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |\n",
      "| backbone.bottom_up.res5.0.conv3.*    | backbone.bottom_up.res5.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
      "| backbone.bottom_up.res5.0.shortcut.* | backbone.bottom_up.res5.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (2048,) (2048,) (2048,) (2048,) (2048,1024,1,1) |\n",
      "| backbone.bottom_up.res5.1.conv1.*    | backbone.bottom_up.res5.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |\n",
      "| backbone.bottom_up.res5.1.conv2.*    | backbone.bottom_up.res5.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |\n",
      "| backbone.bottom_up.res5.1.conv3.*    | backbone.bottom_up.res5.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
      "| backbone.bottom_up.res5.2.conv1.*    | backbone.bottom_up.res5.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |\n",
      "| backbone.bottom_up.res5.2.conv2.*    | backbone.bottom_up.res5.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |\n",
      "| backbone.bottom_up.res5.2.conv3.*    | backbone.bottom_up.res5.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
      "| backbone.bottom_up.stem.conv1.*      | backbone.bottom_up.stem.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}      | (64,) (64,) (64,) (64,) (64,3,7,7)              |\n",
      "| backbone.fpn_lateral2.*              | backbone.fpn_lateral2.{bias,weight}                                                                  | (256,) (256,256,1,1)                            |\n",
      "| backbone.fpn_lateral3.*              | backbone.fpn_lateral3.{bias,weight}                                                                  | (256,) (256,512,1,1)                            |\n",
      "| backbone.fpn_lateral4.*              | backbone.fpn_lateral4.{bias,weight}                                                                  | (256,) (256,1024,1,1)                           |\n",
      "| backbone.fpn_lateral5.*              | backbone.fpn_lateral5.{bias,weight}                                                                  | (256,) (256,2048,1,1)                           |\n",
      "| backbone.fpn_output2.*               | backbone.fpn_output2.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| backbone.fpn_output3.*               | backbone.fpn_output3.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| backbone.fpn_output4.*               | backbone.fpn_output4.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| backbone.fpn_output5.*               | backbone.fpn_output5.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| sem_seg_head.p2.0.*                  | sem_seg_head.p2.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p3.0.*                  | sem_seg_head.p3.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p4.0.*                  | sem_seg_head.p4.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p4.2.*                  | sem_seg_head.p4.2.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,128,3,3)                     |\n",
      "| sem_seg_head.p5.0.*                  | sem_seg_head.p5.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p5.2.*                  | sem_seg_head.p5.2.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,128,3,3)                     |\n",
      "| sem_seg_head.p5.4.*                  | sem_seg_head.p5.4.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,128,3,3)                     |\n",
      "| sem_seg_head.predictor.*             | sem_seg_head.predictor.{bias,weight}                                                                 | (17,) (17,128,1,1)                              |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/06 04:18:56 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(720, 720), max_size=2048, sample_style='choice')]\n",
      "\u001b[32m[07/06 04:18:56 d2.data.common]: \u001b[0mSerializing 2884 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[07/06 04:18:56 d2.data.common]: \u001b[0mSerialized dataset takes 1.05 MiB\n",
      "\u001b[32m[07/06 04:18:56 d2.evaluation.evaluator]: \u001b[0mStart inference on 2884 batches\n",
      "\u001b[32m[07/06 04:18:59 d2.evaluation.evaluator]: \u001b[0mInference done 45/2884. Dataloading: 0.0021 s/iter. Inference: 0.0353 s/iter. Eval: 0.0401 s/iter. Total: 0.0775 s/iter. ETA=0:03:40\n",
      "\u001b[32m[07/06 04:19:05 d2.evaluation.evaluator]: \u001b[0mInference done 111/2884. Dataloading: 0.0022 s/iter. Inference: 0.0352 s/iter. Eval: 0.0394 s/iter. Total: 0.0768 s/iter. ETA=0:03:33\n",
      "\u001b[32m[07/06 04:19:10 d2.evaluation.evaluator]: \u001b[0mInference done 177/2884. Dataloading: 0.0022 s/iter. Inference: 0.0352 s/iter. Eval: 0.0390 s/iter. Total: 0.0765 s/iter. ETA=0:03:27\n",
      "\u001b[32m[07/06 04:19:15 d2.evaluation.evaluator]: \u001b[0mInference done 243/2884. Dataloading: 0.0022 s/iter. Inference: 0.0352 s/iter. Eval: 0.0390 s/iter. Total: 0.0765 s/iter. ETA=0:03:22\n",
      "\u001b[32m[07/06 04:19:20 d2.evaluation.evaluator]: \u001b[0mInference done 308/2884. Dataloading: 0.0022 s/iter. Inference: 0.0352 s/iter. Eval: 0.0391 s/iter. Total: 0.0766 s/iter. ETA=0:03:17\n",
      "\u001b[32m[07/06 04:19:25 d2.evaluation.evaluator]: \u001b[0mInference done 373/2884. Dataloading: 0.0022 s/iter. Inference: 0.0353 s/iter. Eval: 0.0393 s/iter. Total: 0.0768 s/iter. ETA=0:03:12\n",
      "\u001b[32m[07/06 04:19:30 d2.evaluation.evaluator]: \u001b[0mInference done 438/2884. Dataloading: 0.0022 s/iter. Inference: 0.0353 s/iter. Eval: 0.0394 s/iter. Total: 0.0769 s/iter. ETA=0:03:08\n",
      "\u001b[32m[07/06 04:19:35 d2.evaluation.evaluator]: \u001b[0mInference done 505/2884. Dataloading: 0.0022 s/iter. Inference: 0.0353 s/iter. Eval: 0.0391 s/iter. Total: 0.0767 s/iter. ETA=0:03:02\n",
      "\u001b[32m[07/06 04:19:40 d2.evaluation.evaluator]: \u001b[0mInference done 571/2884. Dataloading: 0.0022 s/iter. Inference: 0.0353 s/iter. Eval: 0.0390 s/iter. Total: 0.0766 s/iter. ETA=0:02:57\n",
      "\u001b[32m[07/06 04:19:45 d2.evaluation.evaluator]: \u001b[0mInference done 637/2884. Dataloading: 0.0022 s/iter. Inference: 0.0353 s/iter. Eval: 0.0390 s/iter. Total: 0.0766 s/iter. ETA=0:02:52\n",
      "\u001b[32m[07/06 04:19:50 d2.evaluation.evaluator]: \u001b[0mInference done 704/2884. Dataloading: 0.0022 s/iter. Inference: 0.0353 s/iter. Eval: 0.0388 s/iter. Total: 0.0765 s/iter. ETA=0:02:46\n",
      "\u001b[32m[07/06 04:19:55 d2.evaluation.evaluator]: \u001b[0mInference done 770/2884. Dataloading: 0.0022 s/iter. Inference: 0.0353 s/iter. Eval: 0.0388 s/iter. Total: 0.0764 s/iter. ETA=0:02:41\n",
      "\u001b[32m[07/06 04:20:00 d2.evaluation.evaluator]: \u001b[0mInference done 837/2884. Dataloading: 0.0022 s/iter. Inference: 0.0353 s/iter. Eval: 0.0387 s/iter. Total: 0.0763 s/iter. ETA=0:02:36\n",
      "\u001b[32m[07/06 04:20:05 d2.evaluation.evaluator]: \u001b[0mInference done 904/2884. Dataloading: 0.0022 s/iter. Inference: 0.0353 s/iter. Eval: 0.0386 s/iter. Total: 0.0762 s/iter. ETA=0:02:30\n",
      "\u001b[32m[07/06 04:20:10 d2.evaluation.evaluator]: \u001b[0mInference done 971/2884. Dataloading: 0.0022 s/iter. Inference: 0.0354 s/iter. Eval: 0.0385 s/iter. Total: 0.0762 s/iter. ETA=0:02:25\n",
      "\u001b[32m[07/06 04:20:15 d2.evaluation.evaluator]: \u001b[0mInference done 1038/2884. Dataloading: 0.0022 s/iter. Inference: 0.0354 s/iter. Eval: 0.0384 s/iter. Total: 0.0761 s/iter. ETA=0:02:20\n",
      "\u001b[32m[07/06 04:20:20 d2.evaluation.evaluator]: \u001b[0mInference done 1105/2884. Dataloading: 0.0023 s/iter. Inference: 0.0354 s/iter. Eval: 0.0383 s/iter. Total: 0.0760 s/iter. ETA=0:02:15\n",
      "\u001b[32m[07/06 04:20:25 d2.evaluation.evaluator]: \u001b[0mInference done 1172/2884. Dataloading: 0.0023 s/iter. Inference: 0.0354 s/iter. Eval: 0.0383 s/iter. Total: 0.0760 s/iter. ETA=0:02:10\n",
      "\u001b[32m[07/06 04:20:30 d2.evaluation.evaluator]: \u001b[0mInference done 1236/2884. Dataloading: 0.0023 s/iter. Inference: 0.0354 s/iter. Eval: 0.0384 s/iter. Total: 0.0761 s/iter. ETA=0:02:05\n",
      "\u001b[32m[07/06 04:20:35 d2.evaluation.evaluator]: \u001b[0mInference done 1301/2884. Dataloading: 0.0023 s/iter. Inference: 0.0354 s/iter. Eval: 0.0384 s/iter. Total: 0.0762 s/iter. ETA=0:02:00\n",
      "\u001b[32m[07/06 04:20:40 d2.evaluation.evaluator]: \u001b[0mInference done 1367/2884. Dataloading: 0.0023 s/iter. Inference: 0.0354 s/iter. Eval: 0.0384 s/iter. Total: 0.0762 s/iter. ETA=0:01:55\n",
      "\u001b[32m[07/06 04:20:45 d2.evaluation.evaluator]: \u001b[0mInference done 1436/2884. Dataloading: 0.0023 s/iter. Inference: 0.0354 s/iter. Eval: 0.0383 s/iter. Total: 0.0760 s/iter. ETA=0:01:50\n",
      "\u001b[32m[07/06 04:20:50 d2.evaluation.evaluator]: \u001b[0mInference done 1504/2884. Dataloading: 0.0023 s/iter. Inference: 0.0354 s/iter. Eval: 0.0382 s/iter. Total: 0.0759 s/iter. ETA=0:01:44\n",
      "\u001b[32m[07/06 04:20:55 d2.evaluation.evaluator]: \u001b[0mInference done 1571/2884. Dataloading: 0.0023 s/iter. Inference: 0.0354 s/iter. Eval: 0.0381 s/iter. Total: 0.0759 s/iter. ETA=0:01:39\n",
      "\u001b[32m[07/06 04:21:00 d2.evaluation.evaluator]: \u001b[0mInference done 1639/2884. Dataloading: 0.0023 s/iter. Inference: 0.0354 s/iter. Eval: 0.0381 s/iter. Total: 0.0758 s/iter. ETA=0:01:34\n",
      "\u001b[32m[07/06 04:21:05 d2.evaluation.evaluator]: \u001b[0mInference done 1707/2884. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0380 s/iter. Total: 0.0758 s/iter. ETA=0:01:29\n",
      "\u001b[32m[07/06 04:21:10 d2.evaluation.evaluator]: \u001b[0mInference done 1775/2884. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0379 s/iter. Total: 0.0757 s/iter. ETA=0:01:23\n",
      "\u001b[32m[07/06 04:21:15 d2.evaluation.evaluator]: \u001b[0mInference done 1843/2884. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0378 s/iter. Total: 0.0756 s/iter. ETA=0:01:18\n",
      "\u001b[32m[07/06 04:21:20 d2.evaluation.evaluator]: \u001b[0mInference done 1910/2884. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0378 s/iter. Total: 0.0756 s/iter. ETA=0:01:13\n",
      "\u001b[32m[07/06 04:21:25 d2.evaluation.evaluator]: \u001b[0mInference done 1977/2884. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0378 s/iter. Total: 0.0756 s/iter. ETA=0:01:08\n",
      "\u001b[32m[07/06 04:21:31 d2.evaluation.evaluator]: \u001b[0mInference done 2044/2884. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0378 s/iter. Total: 0.0756 s/iter. ETA=0:01:03\n",
      "\u001b[32m[07/06 04:21:36 d2.evaluation.evaluator]: \u001b[0mInference done 2111/2884. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0377 s/iter. Total: 0.0756 s/iter. ETA=0:00:58\n",
      "\u001b[32m[07/06 04:21:41 d2.evaluation.evaluator]: \u001b[0mInference done 2179/2884. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0377 s/iter. Total: 0.0755 s/iter. ETA=0:00:53\n",
      "\u001b[32m[07/06 04:21:46 d2.evaluation.evaluator]: \u001b[0mInference done 2209/2884. Dataloading: 0.0023 s/iter. Inference: 0.0356 s/iter. Eval: 0.0389 s/iter. Total: 0.0768 s/iter. ETA=0:00:51\n",
      "\u001b[32m[07/06 04:21:51 d2.evaluation.evaluator]: \u001b[0mInference done 2235/2884. Dataloading: 0.0023 s/iter. Inference: 0.0357 s/iter. Eval: 0.0402 s/iter. Total: 0.0782 s/iter. ETA=0:00:50\n",
      "\u001b[32m[07/06 04:21:56 d2.evaluation.evaluator]: \u001b[0mInference done 2261/2884. Dataloading: 0.0023 s/iter. Inference: 0.0358 s/iter. Eval: 0.0414 s/iter. Total: 0.0796 s/iter. ETA=0:00:49\n",
      "\u001b[32m[07/06 04:22:01 d2.evaluation.evaluator]: \u001b[0mInference done 2287/2884. Dataloading: 0.0023 s/iter. Inference: 0.0360 s/iter. Eval: 0.0426 s/iter. Total: 0.0809 s/iter. ETA=0:00:48\n",
      "\u001b[32m[07/06 04:22:06 d2.evaluation.evaluator]: \u001b[0mInference done 2314/2884. Dataloading: 0.0023 s/iter. Inference: 0.0361 s/iter. Eval: 0.0438 s/iter. Total: 0.0822 s/iter. ETA=0:00:46\n",
      "\u001b[32m[07/06 04:22:11 d2.evaluation.evaluator]: \u001b[0mInference done 2341/2884. Dataloading: 0.0022 s/iter. Inference: 0.0362 s/iter. Eval: 0.0449 s/iter. Total: 0.0834 s/iter. ETA=0:00:45\n",
      "\u001b[32m[07/06 04:22:16 d2.evaluation.evaluator]: \u001b[0mInference done 2366/2884. Dataloading: 0.0022 s/iter. Inference: 0.0363 s/iter. Eval: 0.0461 s/iter. Total: 0.0847 s/iter. ETA=0:00:43\n",
      "\u001b[32m[07/06 04:22:21 d2.evaluation.evaluator]: \u001b[0mInference done 2391/2884. Dataloading: 0.0022 s/iter. Inference: 0.0364 s/iter. Eval: 0.0472 s/iter. Total: 0.0860 s/iter. ETA=0:00:42\n",
      "\u001b[32m[07/06 04:22:27 d2.evaluation.evaluator]: \u001b[0mInference done 2416/2884. Dataloading: 0.0022 s/iter. Inference: 0.0365 s/iter. Eval: 0.0483 s/iter. Total: 0.0872 s/iter. ETA=0:00:40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/06 04:22:32 d2.evaluation.evaluator]: \u001b[0mInference done 2441/2884. Dataloading: 0.0022 s/iter. Inference: 0.0367 s/iter. Eval: 0.0494 s/iter. Total: 0.0884 s/iter. ETA=0:00:39\n",
      "\u001b[32m[07/06 04:22:37 d2.evaluation.evaluator]: \u001b[0mInference done 2466/2884. Dataloading: 0.0023 s/iter. Inference: 0.0368 s/iter. Eval: 0.0504 s/iter. Total: 0.0895 s/iter. ETA=0:00:37\n",
      "\u001b[32m[07/06 04:22:42 d2.evaluation.evaluator]: \u001b[0mInference done 2491/2884. Dataloading: 0.0023 s/iter. Inference: 0.0369 s/iter. Eval: 0.0514 s/iter. Total: 0.0907 s/iter. ETA=0:00:35\n",
      "\u001b[32m[07/06 04:22:47 d2.evaluation.evaluator]: \u001b[0mInference done 2516/2884. Dataloading: 0.0023 s/iter. Inference: 0.0370 s/iter. Eval: 0.0525 s/iter. Total: 0.0918 s/iter. ETA=0:00:33\n",
      "\u001b[32m[07/06 04:22:52 d2.evaluation.evaluator]: \u001b[0mInference done 2542/2884. Dataloading: 0.0023 s/iter. Inference: 0.0371 s/iter. Eval: 0.0535 s/iter. Total: 0.0929 s/iter. ETA=0:00:31\n",
      "\u001b[32m[07/06 04:22:57 d2.evaluation.evaluator]: \u001b[0mInference done 2566/2884. Dataloading: 0.0023 s/iter. Inference: 0.0371 s/iter. Eval: 0.0545 s/iter. Total: 0.0940 s/iter. ETA=0:00:29\n",
      "\u001b[32m[07/06 04:23:02 d2.evaluation.evaluator]: \u001b[0mInference done 2591/2884. Dataloading: 0.0023 s/iter. Inference: 0.0372 s/iter. Eval: 0.0554 s/iter. Total: 0.0950 s/iter. ETA=0:00:27\n",
      "\u001b[32m[07/06 04:23:07 d2.evaluation.evaluator]: \u001b[0mInference done 2616/2884. Dataloading: 0.0023 s/iter. Inference: 0.0373 s/iter. Eval: 0.0563 s/iter. Total: 0.0960 s/iter. ETA=0:00:25\n",
      "\u001b[32m[07/06 04:23:12 d2.evaluation.evaluator]: \u001b[0mInference done 2641/2884. Dataloading: 0.0023 s/iter. Inference: 0.0374 s/iter. Eval: 0.0573 s/iter. Total: 0.0970 s/iter. ETA=0:00:23\n",
      "\u001b[32m[07/06 04:23:17 d2.evaluation.evaluator]: \u001b[0mInference done 2667/2884. Dataloading: 0.0023 s/iter. Inference: 0.0375 s/iter. Eval: 0.0582 s/iter. Total: 0.0980 s/iter. ETA=0:00:21\n",
      "\u001b[32m[07/06 04:23:22 d2.evaluation.evaluator]: \u001b[0mInference done 2692/2884. Dataloading: 0.0023 s/iter. Inference: 0.0376 s/iter. Eval: 0.0591 s/iter. Total: 0.0990 s/iter. ETA=0:00:19\n",
      "\u001b[32m[07/06 04:23:28 d2.evaluation.evaluator]: \u001b[0mInference done 2718/2884. Dataloading: 0.0023 s/iter. Inference: 0.0377 s/iter. Eval: 0.0599 s/iter. Total: 0.1000 s/iter. ETA=0:00:16\n",
      "\u001b[32m[07/06 04:23:33 d2.evaluation.evaluator]: \u001b[0mInference done 2743/2884. Dataloading: 0.0023 s/iter. Inference: 0.0378 s/iter. Eval: 0.0608 s/iter. Total: 0.1009 s/iter. ETA=0:00:14\n",
      "\u001b[32m[07/06 04:23:38 d2.evaluation.evaluator]: \u001b[0mInference done 2768/2884. Dataloading: 0.0023 s/iter. Inference: 0.0379 s/iter. Eval: 0.0616 s/iter. Total: 0.1018 s/iter. ETA=0:00:11\n",
      "\u001b[32m[07/06 04:23:43 d2.evaluation.evaluator]: \u001b[0mInference done 2793/2884. Dataloading: 0.0023 s/iter. Inference: 0.0379 s/iter. Eval: 0.0625 s/iter. Total: 0.1027 s/iter. ETA=0:00:09\n",
      "\u001b[32m[07/06 04:23:48 d2.evaluation.evaluator]: \u001b[0mInference done 2817/2884. Dataloading: 0.0023 s/iter. Inference: 0.0380 s/iter. Eval: 0.0633 s/iter. Total: 0.1036 s/iter. ETA=0:00:06\n",
      "\u001b[32m[07/06 04:23:53 d2.evaluation.evaluator]: \u001b[0mInference done 2843/2884. Dataloading: 0.0023 s/iter. Inference: 0.0381 s/iter. Eval: 0.0641 s/iter. Total: 0.1045 s/iter. ETA=0:00:04\n",
      "\u001b[32m[07/06 04:23:58 d2.evaluation.evaluator]: \u001b[0mInference done 2868/2884. Dataloading: 0.0023 s/iter. Inference: 0.0382 s/iter. Eval: 0.0649 s/iter. Total: 0.1054 s/iter. ETA=0:00:01\n",
      "\u001b[32m[07/06 04:24:02 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:05:05.112456 (0.105979 s / iter per device, on 1 devices)\n",
      "\u001b[32m[07/06 04:24:02 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:01:50 (0.038212 s / iter per device, on 1 devices)\n",
      "\u001b[32m[07/06 04:24:02 d2.evaluation.sem_seg_evaluation]: \u001b[0mOrderedDict([('sem_seg', {'mIoU': 52.31738844349895, 'fwIoU': 69.09060706915815, 'IoU-Unlabeled': nan, 'IoU-Building': 56.741269840029, 'IoU-Fence': 29.876444810311913, 'IoU-Pedestrian': 60.14042575238514, 'IoU-Pole': 43.21585647459651, 'IoU-Road': 92.30922143999595, 'IoU-SideWalk': 60.34366948301684, 'IoU-Vegetation': 69.74153314668153, 'IoU-Vehicles': 75.93478559915455, 'IoU-Wall': 40.904500528333436, 'IoU-TrafficSign': 55.62583251419792, 'IoU-Sky': 42.50929767753491, 'IoU-TrafficLight': 53.39438851961776, 'IoU-Terrain': 26.2961486208916, 'IoU-ConstructionVehicle': 63.942068354045034, 'IoU-workzone_object': 64.36806057770026, 'IoU-Detour': 1.7347117574908009, 'mACC': 64.64037871861738, 'pACC': 80.59096127547075, 'ACC-Unlabeled': nan, 'ACC-Building': 95.93939719766293, 'ACC-Fence': 36.61701298194646, 'ACC-Pedestrian': 85.76368155772107, 'ACC-Pole': 51.65078623108895, 'ACC-Road': 95.15139882355066, 'ACC-SideWalk': 76.85500341039693, 'ACC-Vegetation': 75.71193973900235, 'ACC-Vehicles': 89.89719021237964, 'ACC-Wall': 50.37274379872072, 'ACC-TrafficSign': 62.580874076280004, 'ACC-Sky': 42.9631957562754, 'ACC-TrafficLight': 62.28834652310814, 'ACC-Terrain': 31.122678806247432, 'ACC-ConstructionVehicle': 92.59337214326348, 'ACC-workzone_object': 82.90883188281386, 'ACC-Detour': 1.8296063574200703})])\n",
      "\u001b[32m[07/06 04:24:02 d2.engine.defaults]: \u001b[0mEvaluation results for combined_both_rain_val in csv format:\n",
      "\u001b[32m[07/06 04:24:02 d2.evaluation.testing]: \u001b[0mcopypaste: Task: sem_seg\n",
      "\u001b[32m[07/06 04:24:02 d2.evaluation.testing]: \u001b[0mcopypaste: mIoU,fwIoU,mACC,pACC\n",
      "\u001b[32m[07/06 04:24:02 d2.evaluation.testing]: \u001b[0mcopypaste: 52.3174,69.0906,64.6404,80.5910\n"
     ]
    }
   ],
   "source": [
    "trainer_both = Detectron2Trainer('combined_all_night_train', 'combined_both_rain_val', output_folder='./output_both_40k')\n",
    "trainer_both.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "08d0896b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/05 22:13:49 d2.engine.defaults]: \u001b[0mModel:\n",
      "SemanticSegmentor(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (sem_seg_head): SemSegFPNHead(\n",
      "    (p2): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "    )\n",
      "    (p3): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (1): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "    )\n",
      "    (p4): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (1): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      (2): Conv2d(\n",
      "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (3): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "    )\n",
      "    (p5): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (1): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      (2): Conv2d(\n",
      "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (3): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      (4): Conv2d(\n",
      "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (5): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "    )\n",
      "    (predictor): Conv2d(128, 17, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/05 22:13:49 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(720, 720), max_size=2048, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[07/05 22:13:49 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[07/05 22:13:49 d2.data.common]: \u001b[0mSerializing 37734 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[07/05 22:13:49 d2.data.common]: \u001b[0mSerialized dataset takes 11.85 MiB\n",
      "Last checkpoint: model_final.pth\n",
      "\u001b[32m[07/05 22:13:50 d2.checkpoint.c2_model_loading]: \u001b[0mFollowing weights matched with model:\n",
      "| Names in Model                       | Names in Checkpoint                                                                                  | Shapes                                          |\n",
      "|:-------------------------------------|:-----------------------------------------------------------------------------------------------------|:------------------------------------------------|\n",
      "| backbone.bottom_up.res2.0.conv1.*    | backbone.bottom_up.res2.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,1,1)             |\n",
      "| backbone.bottom_up.res2.0.conv2.*    | backbone.bottom_up.res2.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |\n",
      "| backbone.bottom_up.res2.0.conv3.*    | backbone.bottom_up.res2.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res2.0.shortcut.* | backbone.bottom_up.res2.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res2.1.conv1.*    | backbone.bottom_up.res2.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |\n",
      "| backbone.bottom_up.res2.1.conv2.*    | backbone.bottom_up.res2.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |\n",
      "| backbone.bottom_up.res2.1.conv3.*    | backbone.bottom_up.res2.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res2.2.conv1.*    | backbone.bottom_up.res2.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |\n",
      "| backbone.bottom_up.res2.2.conv2.*    | backbone.bottom_up.res2.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |\n",
      "| backbone.bottom_up.res2.2.conv3.*    | backbone.bottom_up.res2.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res3.0.conv1.*    | backbone.bottom_up.res3.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,256,1,1)       |\n",
      "| backbone.bottom_up.res3.0.conv2.*    | backbone.bottom_up.res3.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.0.conv3.*    | backbone.bottom_up.res3.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res3.0.shortcut.* | backbone.bottom_up.res3.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (512,) (512,) (512,) (512,) (512,256,1,1)       |\n",
      "| backbone.bottom_up.res3.1.conv1.*    | backbone.bottom_up.res3.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |\n",
      "| backbone.bottom_up.res3.1.conv2.*    | backbone.bottom_up.res3.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.1.conv3.*    | backbone.bottom_up.res3.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res3.2.conv1.*    | backbone.bottom_up.res3.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |\n",
      "| backbone.bottom_up.res3.2.conv2.*    | backbone.bottom_up.res3.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.2.conv3.*    | backbone.bottom_up.res3.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res3.3.conv1.*    | backbone.bottom_up.res3.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |\n",
      "| backbone.bottom_up.res3.3.conv2.*    | backbone.bottom_up.res3.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.3.conv3.*    | backbone.bottom_up.res3.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res4.0.conv1.*    | backbone.bottom_up.res4.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,512,1,1)       |\n",
      "| backbone.bottom_up.res4.0.conv2.*    | backbone.bottom_up.res4.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.0.conv3.*    | backbone.bottom_up.res4.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.0.shortcut.* | backbone.bottom_up.res4.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (1024,) (1024,) (1024,) (1024,) (1024,512,1,1)  |\n",
      "| backbone.bottom_up.res4.1.conv1.*    | backbone.bottom_up.res4.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.1.conv2.*    | backbone.bottom_up.res4.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.1.conv3.*    | backbone.bottom_up.res4.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.2.conv1.*    | backbone.bottom_up.res4.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.2.conv2.*    | backbone.bottom_up.res4.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.2.conv3.*    | backbone.bottom_up.res4.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.3.conv1.*    | backbone.bottom_up.res4.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.3.conv2.*    | backbone.bottom_up.res4.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.3.conv3.*    | backbone.bottom_up.res4.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.4.conv1.*    | backbone.bottom_up.res4.4.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.4.conv2.*    | backbone.bottom_up.res4.4.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.4.conv3.*    | backbone.bottom_up.res4.4.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.5.conv1.*    | backbone.bottom_up.res4.5.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.5.conv2.*    | backbone.bottom_up.res4.5.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.5.conv3.*    | backbone.bottom_up.res4.5.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res5.0.conv1.*    | backbone.bottom_up.res5.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,1024,1,1)      |\n",
      "| backbone.bottom_up.res5.0.conv2.*    | backbone.bottom_up.res5.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |\n",
      "| backbone.bottom_up.res5.0.conv3.*    | backbone.bottom_up.res5.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
      "| backbone.bottom_up.res5.0.shortcut.* | backbone.bottom_up.res5.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (2048,) (2048,) (2048,) (2048,) (2048,1024,1,1) |\n",
      "| backbone.bottom_up.res5.1.conv1.*    | backbone.bottom_up.res5.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |\n",
      "| backbone.bottom_up.res5.1.conv2.*    | backbone.bottom_up.res5.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |\n",
      "| backbone.bottom_up.res5.1.conv3.*    | backbone.bottom_up.res5.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
      "| backbone.bottom_up.res5.2.conv1.*    | backbone.bottom_up.res5.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |\n",
      "| backbone.bottom_up.res5.2.conv2.*    | backbone.bottom_up.res5.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |\n",
      "| backbone.bottom_up.res5.2.conv3.*    | backbone.bottom_up.res5.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
      "| backbone.bottom_up.stem.conv1.*      | backbone.bottom_up.stem.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}      | (64,) (64,) (64,) (64,) (64,3,7,7)              |\n",
      "| backbone.fpn_lateral2.*              | backbone.fpn_lateral2.{bias,weight}                                                                  | (256,) (256,256,1,1)                            |\n",
      "| backbone.fpn_lateral3.*              | backbone.fpn_lateral3.{bias,weight}                                                                  | (256,) (256,512,1,1)                            |\n",
      "| backbone.fpn_lateral4.*              | backbone.fpn_lateral4.{bias,weight}                                                                  | (256,) (256,1024,1,1)                           |\n",
      "| backbone.fpn_lateral5.*              | backbone.fpn_lateral5.{bias,weight}                                                                  | (256,) (256,2048,1,1)                           |\n",
      "| backbone.fpn_output2.*               | backbone.fpn_output2.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| backbone.fpn_output3.*               | backbone.fpn_output3.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| backbone.fpn_output4.*               | backbone.fpn_output4.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| backbone.fpn_output5.*               | backbone.fpn_output5.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| sem_seg_head.p2.0.*                  | sem_seg_head.p2.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p3.0.*                  | sem_seg_head.p3.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p4.0.*                  | sem_seg_head.p4.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p4.2.*                  | sem_seg_head.p4.2.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,128,3,3)                     |\n",
      "| sem_seg_head.p5.0.*                  | sem_seg_head.p5.0.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,256,3,3)                     |\n",
      "| sem_seg_head.p5.2.*                  | sem_seg_head.p5.2.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,128,3,3)                     |\n",
      "| sem_seg_head.p5.4.*                  | sem_seg_head.p5.4.{norm.bias,norm.weight,weight}                                                     | (128,) (128,) (128,128,3,3)                     |\n",
      "| sem_seg_head.predictor.*             | sem_seg_head.predictor.{bias,weight}                                                                 | (17,) (17,128,1,1)                              |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/05 22:13:50 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(720, 720), max_size=2048, sample_style='choice')]\n",
      "\u001b[32m[07/05 22:13:50 d2.data.common]: \u001b[0mSerializing 14460 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[07/05 22:13:50 d2.data.common]: \u001b[0mSerialized dataset takes 4.48 MiB\n",
      "\u001b[32m[07/05 22:13:50 d2.evaluation.evaluator]: \u001b[0mStart inference on 14460 batches\n",
      "\u001b[32m[07/05 22:13:51 d2.evaluation.evaluator]: \u001b[0mInference done 11/14460. Dataloading: 0.0017 s/iter. Inference: 0.0371 s/iter. Eval: 0.0419 s/iter. Total: 0.0808 s/iter. ETA=0:19:27\n",
      "\u001b[32m[07/05 22:13:56 d2.evaluation.evaluator]: \u001b[0mInference done 73/14460. Dataloading: 0.0021 s/iter. Inference: 0.0349 s/iter. Eval: 0.0437 s/iter. Total: 0.0808 s/iter. ETA=0:19:22\n",
      "\u001b[32m[07/05 22:14:01 d2.evaluation.evaluator]: \u001b[0mInference done 138/14460. Dataloading: 0.0021 s/iter. Inference: 0.0349 s/iter. Eval: 0.0420 s/iter. Total: 0.0790 s/iter. ETA=0:18:51\n",
      "\u001b[32m[07/05 22:14:06 d2.evaluation.evaluator]: \u001b[0mInference done 204/14460. Dataloading: 0.0021 s/iter. Inference: 0.0349 s/iter. Eval: 0.0409 s/iter. Total: 0.0780 s/iter. ETA=0:18:32\n",
      "\u001b[32m[07/05 22:14:11 d2.evaluation.evaluator]: \u001b[0mInference done 271/14460. Dataloading: 0.0021 s/iter. Inference: 0.0349 s/iter. Eval: 0.0403 s/iter. Total: 0.0774 s/iter. ETA=0:18:18\n",
      "\u001b[32m[07/05 22:14:16 d2.evaluation.evaluator]: \u001b[0mInference done 338/14460. Dataloading: 0.0021 s/iter. Inference: 0.0349 s/iter. Eval: 0.0399 s/iter. Total: 0.0771 s/iter. ETA=0:18:08\n",
      "\u001b[32m[07/05 22:14:21 d2.evaluation.evaluator]: \u001b[0mInference done 404/14460. Dataloading: 0.0021 s/iter. Inference: 0.0350 s/iter. Eval: 0.0397 s/iter. Total: 0.0769 s/iter. ETA=0:18:01\n",
      "\u001b[32m[07/05 22:14:26 d2.evaluation.evaluator]: \u001b[0mInference done 469/14460. Dataloading: 0.0022 s/iter. Inference: 0.0350 s/iter. Eval: 0.0398 s/iter. Total: 0.0770 s/iter. ETA=0:17:57\n",
      "\u001b[32m[07/05 22:14:31 d2.evaluation.evaluator]: \u001b[0mInference done 536/14460. Dataloading: 0.0022 s/iter. Inference: 0.0350 s/iter. Eval: 0.0396 s/iter. Total: 0.0768 s/iter. ETA=0:17:49\n",
      "\u001b[32m[07/05 22:14:36 d2.evaluation.evaluator]: \u001b[0mInference done 601/14460. Dataloading: 0.0022 s/iter. Inference: 0.0350 s/iter. Eval: 0.0396 s/iter. Total: 0.0769 s/iter. ETA=0:17:45\n",
      "\u001b[32m[07/05 22:14:41 d2.evaluation.evaluator]: \u001b[0mInference done 667/14460. Dataloading: 0.0022 s/iter. Inference: 0.0350 s/iter. Eval: 0.0395 s/iter. Total: 0.0768 s/iter. ETA=0:17:38\n",
      "\u001b[32m[07/05 22:14:46 d2.evaluation.evaluator]: \u001b[0mInference done 733/14460. Dataloading: 0.0022 s/iter. Inference: 0.0351 s/iter. Eval: 0.0394 s/iter. Total: 0.0768 s/iter. ETA=0:17:33\n",
      "\u001b[32m[07/05 22:14:51 d2.evaluation.evaluator]: \u001b[0mInference done 800/14460. Dataloading: 0.0022 s/iter. Inference: 0.0351 s/iter. Eval: 0.0392 s/iter. Total: 0.0766 s/iter. ETA=0:17:26\n",
      "\u001b[32m[07/05 22:14:56 d2.evaluation.evaluator]: \u001b[0mInference done 867/14460. Dataloading: 0.0022 s/iter. Inference: 0.0351 s/iter. Eval: 0.0391 s/iter. Total: 0.0765 s/iter. ETA=0:17:19\n",
      "\u001b[32m[07/05 22:15:02 d2.evaluation.evaluator]: \u001b[0mInference done 934/14460. Dataloading: 0.0022 s/iter. Inference: 0.0351 s/iter. Eval: 0.0390 s/iter. Total: 0.0764 s/iter. ETA=0:17:12\n",
      "\u001b[32m[07/05 22:15:07 d2.evaluation.evaluator]: \u001b[0mInference done 1002/14460. Dataloading: 0.0022 s/iter. Inference: 0.0351 s/iter. Eval: 0.0388 s/iter. Total: 0.0762 s/iter. ETA=0:17:05\n",
      "\u001b[32m[07/05 22:15:12 d2.evaluation.evaluator]: \u001b[0mInference done 1070/14460. Dataloading: 0.0022 s/iter. Inference: 0.0351 s/iter. Eval: 0.0387 s/iter. Total: 0.0761 s/iter. ETA=0:16:59\n",
      "\u001b[32m[07/05 22:15:17 d2.evaluation.evaluator]: \u001b[0mInference done 1136/14460. Dataloading: 0.0022 s/iter. Inference: 0.0352 s/iter. Eval: 0.0387 s/iter. Total: 0.0761 s/iter. ETA=0:16:54\n",
      "\u001b[32m[07/05 22:15:22 d2.evaluation.evaluator]: \u001b[0mInference done 1202/14460. Dataloading: 0.0022 s/iter. Inference: 0.0352 s/iter. Eval: 0.0387 s/iter. Total: 0.0762 s/iter. ETA=0:16:49\n",
      "\u001b[32m[07/05 22:15:27 d2.evaluation.evaluator]: \u001b[0mInference done 1267/14460. Dataloading: 0.0022 s/iter. Inference: 0.0352 s/iter. Eval: 0.0388 s/iter. Total: 0.0762 s/iter. ETA=0:16:45\n",
      "\u001b[32m[07/05 22:15:32 d2.evaluation.evaluator]: \u001b[0mInference done 1333/14460. Dataloading: 0.0022 s/iter. Inference: 0.0352 s/iter. Eval: 0.0387 s/iter. Total: 0.0762 s/iter. ETA=0:16:40\n",
      "\u001b[32m[07/05 22:15:37 d2.evaluation.evaluator]: \u001b[0mInference done 1399/14460. Dataloading: 0.0022 s/iter. Inference: 0.0352 s/iter. Eval: 0.0387 s/iter. Total: 0.0762 s/iter. ETA=0:16:35\n",
      "\u001b[32m[07/05 22:15:42 d2.evaluation.evaluator]: \u001b[0mInference done 1464/14460. Dataloading: 0.0022 s/iter. Inference: 0.0352 s/iter. Eval: 0.0387 s/iter. Total: 0.0763 s/iter. ETA=0:16:31\n",
      "\u001b[32m[07/05 22:15:47 d2.evaluation.evaluator]: \u001b[0mInference done 1530/14460. Dataloading: 0.0022 s/iter. Inference: 0.0352 s/iter. Eval: 0.0387 s/iter. Total: 0.0763 s/iter. ETA=0:16:26\n",
      "\u001b[32m[07/05 22:15:52 d2.evaluation.evaluator]: \u001b[0mInference done 1597/14460. Dataloading: 0.0022 s/iter. Inference: 0.0352 s/iter. Eval: 0.0387 s/iter. Total: 0.0762 s/iter. ETA=0:16:20\n",
      "\u001b[32m[07/05 22:15:57 d2.evaluation.evaluator]: \u001b[0mInference done 1664/14460. Dataloading: 0.0022 s/iter. Inference: 0.0353 s/iter. Eval: 0.0386 s/iter. Total: 0.0762 s/iter. ETA=0:16:14\n",
      "\u001b[32m[07/05 22:16:02 d2.evaluation.evaluator]: \u001b[0mInference done 1729/14460. Dataloading: 0.0022 s/iter. Inference: 0.0353 s/iter. Eval: 0.0387 s/iter. Total: 0.0762 s/iter. ETA=0:16:10\n",
      "\u001b[32m[07/05 22:16:07 d2.evaluation.evaluator]: \u001b[0mInference done 1795/14460. Dataloading: 0.0022 s/iter. Inference: 0.0353 s/iter. Eval: 0.0387 s/iter. Total: 0.0762 s/iter. ETA=0:16:05\n",
      "\u001b[32m[07/05 22:16:12 d2.evaluation.evaluator]: \u001b[0mInference done 1859/14460. Dataloading: 0.0022 s/iter. Inference: 0.0353 s/iter. Eval: 0.0387 s/iter. Total: 0.0763 s/iter. ETA=0:16:01\n",
      "\u001b[32m[07/05 22:16:17 d2.evaluation.evaluator]: \u001b[0mInference done 1924/14460. Dataloading: 0.0022 s/iter. Inference: 0.0353 s/iter. Eval: 0.0388 s/iter. Total: 0.0764 s/iter. ETA=0:15:57\n",
      "\u001b[32m[07/05 22:16:22 d2.evaluation.evaluator]: \u001b[0mInference done 1988/14460. Dataloading: 0.0022 s/iter. Inference: 0.0353 s/iter. Eval: 0.0388 s/iter. Total: 0.0764 s/iter. ETA=0:15:53\n",
      "\u001b[32m[07/05 22:16:27 d2.evaluation.evaluator]: \u001b[0mInference done 2053/14460. Dataloading: 0.0022 s/iter. Inference: 0.0353 s/iter. Eval: 0.0389 s/iter. Total: 0.0765 s/iter. ETA=0:15:48\n",
      "\u001b[32m[07/05 22:16:32 d2.evaluation.evaluator]: \u001b[0mInference done 2118/14460. Dataloading: 0.0022 s/iter. Inference: 0.0353 s/iter. Eval: 0.0389 s/iter. Total: 0.0765 s/iter. ETA=0:15:44\n",
      "\u001b[32m[07/05 22:16:37 d2.evaluation.evaluator]: \u001b[0mInference done 2184/14460. Dataloading: 0.0022 s/iter. Inference: 0.0353 s/iter. Eval: 0.0389 s/iter. Total: 0.0765 s/iter. ETA=0:15:39\n",
      "\u001b[32m[07/05 22:16:42 d2.evaluation.evaluator]: \u001b[0mInference done 2249/14460. Dataloading: 0.0022 s/iter. Inference: 0.0353 s/iter. Eval: 0.0389 s/iter. Total: 0.0766 s/iter. ETA=0:15:34\n",
      "\u001b[32m[07/05 22:16:47 d2.evaluation.evaluator]: \u001b[0mInference done 2315/14460. Dataloading: 0.0022 s/iter. Inference: 0.0353 s/iter. Eval: 0.0389 s/iter. Total: 0.0766 s/iter. ETA=0:15:29\n",
      "\u001b[32m[07/05 22:16:52 d2.evaluation.evaluator]: \u001b[0mInference done 2381/14460. Dataloading: 0.0022 s/iter. Inference: 0.0353 s/iter. Eval: 0.0389 s/iter. Total: 0.0766 s/iter. ETA=0:15:24\n",
      "\u001b[32m[07/05 22:16:57 d2.evaluation.evaluator]: \u001b[0mInference done 2445/14460. Dataloading: 0.0022 s/iter. Inference: 0.0353 s/iter. Eval: 0.0389 s/iter. Total: 0.0766 s/iter. ETA=0:15:20\n",
      "\u001b[32m[07/05 22:17:03 d2.evaluation.evaluator]: \u001b[0mInference done 2510/14460. Dataloading: 0.0022 s/iter. Inference: 0.0353 s/iter. Eval: 0.0390 s/iter. Total: 0.0766 s/iter. ETA=0:15:15\n",
      "\u001b[32m[07/05 22:17:08 d2.evaluation.evaluator]: \u001b[0mInference done 2575/14460. Dataloading: 0.0023 s/iter. Inference: 0.0353 s/iter. Eval: 0.0390 s/iter. Total: 0.0767 s/iter. ETA=0:15:11\n",
      "\u001b[32m[07/05 22:17:13 d2.evaluation.evaluator]: \u001b[0mInference done 2639/14460. Dataloading: 0.0023 s/iter. Inference: 0.0354 s/iter. Eval: 0.0390 s/iter. Total: 0.0767 s/iter. ETA=0:15:06\n",
      "\u001b[32m[07/05 22:17:18 d2.evaluation.evaluator]: \u001b[0mInference done 2704/14460. Dataloading: 0.0023 s/iter. Inference: 0.0354 s/iter. Eval: 0.0390 s/iter. Total: 0.0767 s/iter. ETA=0:15:01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/05 22:17:23 d2.evaluation.evaluator]: \u001b[0mInference done 2769/14460. Dataloading: 0.0023 s/iter. Inference: 0.0354 s/iter. Eval: 0.0390 s/iter. Total: 0.0767 s/iter. ETA=0:14:57\n",
      "\u001b[32m[07/05 22:17:28 d2.evaluation.evaluator]: \u001b[0mInference done 2837/14460. Dataloading: 0.0023 s/iter. Inference: 0.0354 s/iter. Eval: 0.0390 s/iter. Total: 0.0767 s/iter. ETA=0:14:51\n",
      "\u001b[32m[07/05 22:17:33 d2.evaluation.evaluator]: \u001b[0mInference done 2902/14460. Dataloading: 0.0023 s/iter. Inference: 0.0354 s/iter. Eval: 0.0390 s/iter. Total: 0.0767 s/iter. ETA=0:14:46\n",
      "\u001b[32m[07/05 22:17:38 d2.evaluation.evaluator]: \u001b[0mInference done 2968/14460. Dataloading: 0.0023 s/iter. Inference: 0.0354 s/iter. Eval: 0.0390 s/iter. Total: 0.0767 s/iter. ETA=0:14:41\n",
      "\u001b[32m[07/05 22:17:43 d2.evaluation.evaluator]: \u001b[0mInference done 3033/14460. Dataloading: 0.0023 s/iter. Inference: 0.0354 s/iter. Eval: 0.0390 s/iter. Total: 0.0767 s/iter. ETA=0:14:36\n",
      "\u001b[32m[07/05 22:17:48 d2.evaluation.evaluator]: \u001b[0mInference done 3097/14460. Dataloading: 0.0023 s/iter. Inference: 0.0354 s/iter. Eval: 0.0390 s/iter. Total: 0.0767 s/iter. ETA=0:14:32\n",
      "\u001b[32m[07/05 22:17:53 d2.evaluation.evaluator]: \u001b[0mInference done 3162/14460. Dataloading: 0.0023 s/iter. Inference: 0.0354 s/iter. Eval: 0.0390 s/iter. Total: 0.0768 s/iter. ETA=0:14:27\n",
      "\u001b[32m[07/05 22:17:58 d2.evaluation.evaluator]: \u001b[0mInference done 3228/14460. Dataloading: 0.0023 s/iter. Inference: 0.0354 s/iter. Eval: 0.0390 s/iter. Total: 0.0768 s/iter. ETA=0:14:22\n",
      "\u001b[32m[07/05 22:18:03 d2.evaluation.evaluator]: \u001b[0mInference done 3292/14460. Dataloading: 0.0023 s/iter. Inference: 0.0354 s/iter. Eval: 0.0390 s/iter. Total: 0.0768 s/iter. ETA=0:14:17\n",
      "\u001b[32m[07/05 22:18:08 d2.evaluation.evaluator]: \u001b[0mInference done 3355/14460. Dataloading: 0.0023 s/iter. Inference: 0.0354 s/iter. Eval: 0.0391 s/iter. Total: 0.0768 s/iter. ETA=0:14:13\n",
      "\u001b[32m[07/05 22:18:13 d2.evaluation.evaluator]: \u001b[0mInference done 3416/14460. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0391 s/iter. Total: 0.0769 s/iter. ETA=0:14:09\n",
      "\u001b[32m[07/05 22:18:18 d2.evaluation.evaluator]: \u001b[0mInference done 3483/14460. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0391 s/iter. Total: 0.0769 s/iter. ETA=0:14:04\n",
      "\u001b[32m[07/05 22:18:23 d2.evaluation.evaluator]: \u001b[0mInference done 3549/14460. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0391 s/iter. Total: 0.0769 s/iter. ETA=0:13:59\n",
      "\u001b[32m[07/05 22:18:28 d2.evaluation.evaluator]: \u001b[0mInference done 3613/14460. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0391 s/iter. Total: 0.0769 s/iter. ETA=0:13:54\n",
      "\u001b[32m[07/05 22:18:33 d2.evaluation.evaluator]: \u001b[0mInference done 3677/14460. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0391 s/iter. Total: 0.0770 s/iter. ETA=0:13:49\n",
      "\u001b[32m[07/05 22:18:38 d2.evaluation.evaluator]: \u001b[0mInference done 3738/14460. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0392 s/iter. Total: 0.0771 s/iter. ETA=0:13:46\n",
      "\u001b[32m[07/05 22:18:43 d2.evaluation.evaluator]: \u001b[0mInference done 3803/14460. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0392 s/iter. Total: 0.0771 s/iter. ETA=0:13:41\n",
      "\u001b[32m[07/05 22:18:48 d2.evaluation.evaluator]: \u001b[0mInference done 3867/14460. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0393 s/iter. Total: 0.0771 s/iter. ETA=0:13:36\n",
      "\u001b[32m[07/05 22:18:53 d2.evaluation.evaluator]: \u001b[0mInference done 3932/14460. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0393 s/iter. Total: 0.0771 s/iter. ETA=0:13:31\n",
      "\u001b[32m[07/05 22:18:58 d2.evaluation.evaluator]: \u001b[0mInference done 3997/14460. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0393 s/iter. Total: 0.0771 s/iter. ETA=0:13:26\n",
      "\u001b[32m[07/05 22:19:03 d2.evaluation.evaluator]: \u001b[0mInference done 4063/14460. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0393 s/iter. Total: 0.0771 s/iter. ETA=0:13:21\n",
      "\u001b[32m[07/05 22:19:09 d2.evaluation.evaluator]: \u001b[0mInference done 4129/14460. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0393 s/iter. Total: 0.0771 s/iter. ETA=0:13:16\n",
      "\u001b[32m[07/05 22:19:14 d2.evaluation.evaluator]: \u001b[0mInference done 4194/14460. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0393 s/iter. Total: 0.0771 s/iter. ETA=0:13:11\n",
      "\u001b[32m[07/05 22:19:19 d2.evaluation.evaluator]: \u001b[0mInference done 4259/14460. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0392 s/iter. Total: 0.0771 s/iter. ETA=0:13:06\n",
      "\u001b[32m[07/05 22:19:24 d2.evaluation.evaluator]: \u001b[0mInference done 4324/14460. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0392 s/iter. Total: 0.0771 s/iter. ETA=0:13:01\n",
      "\u001b[32m[07/05 22:19:29 d2.evaluation.evaluator]: \u001b[0mInference done 4390/14460. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0392 s/iter. Total: 0.0771 s/iter. ETA=0:12:56\n",
      "\u001b[32m[07/05 22:19:34 d2.evaluation.evaluator]: \u001b[0mInference done 4457/14460. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0392 s/iter. Total: 0.0771 s/iter. ETA=0:12:50\n",
      "\u001b[32m[07/05 22:19:39 d2.evaluation.evaluator]: \u001b[0mInference done 4523/14460. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0392 s/iter. Total: 0.0770 s/iter. ETA=0:12:45\n",
      "\u001b[32m[07/05 22:19:44 d2.evaluation.evaluator]: \u001b[0mInference done 4590/14460. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0392 s/iter. Total: 0.0770 s/iter. ETA=0:12:40\n",
      "\u001b[32m[07/05 22:19:49 d2.evaluation.evaluator]: \u001b[0mInference done 4656/14460. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0391 s/iter. Total: 0.0770 s/iter. ETA=0:12:34\n",
      "\u001b[32m[07/05 22:19:54 d2.evaluation.evaluator]: \u001b[0mInference done 4722/14460. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0391 s/iter. Total: 0.0770 s/iter. ETA=0:12:29\n",
      "\u001b[32m[07/05 22:19:59 d2.evaluation.evaluator]: \u001b[0mInference done 4788/14460. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0391 s/iter. Total: 0.0770 s/iter. ETA=0:12:24\n",
      "\u001b[32m[07/05 22:20:04 d2.evaluation.evaluator]: \u001b[0mInference done 4854/14460. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0391 s/iter. Total: 0.0770 s/iter. ETA=0:12:19\n",
      "\u001b[32m[07/05 22:20:09 d2.evaluation.evaluator]: \u001b[0mInference done 4920/14460. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0391 s/iter. Total: 0.0770 s/iter. ETA=0:12:14\n",
      "\u001b[32m[07/05 22:20:14 d2.evaluation.evaluator]: \u001b[0mInference done 4986/14460. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0391 s/iter. Total: 0.0770 s/iter. ETA=0:12:09\n",
      "\u001b[32m[07/05 22:20:19 d2.evaluation.evaluator]: \u001b[0mInference done 5052/14460. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0391 s/iter. Total: 0.0770 s/iter. ETA=0:12:04\n",
      "\u001b[32m[07/05 22:20:24 d2.evaluation.evaluator]: \u001b[0mInference done 5118/14460. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0391 s/iter. Total: 0.0770 s/iter. ETA=0:11:58\n",
      "\u001b[32m[07/05 22:20:29 d2.evaluation.evaluator]: \u001b[0mInference done 5184/14460. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0391 s/iter. Total: 0.0770 s/iter. ETA=0:11:53\n",
      "\u001b[32m[07/05 22:20:34 d2.evaluation.evaluator]: \u001b[0mInference done 5250/14460. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0391 s/iter. Total: 0.0770 s/iter. ETA=0:11:48\n",
      "\u001b[32m[07/05 22:20:39 d2.evaluation.evaluator]: \u001b[0mInference done 5315/14460. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0391 s/iter. Total: 0.0770 s/iter. ETA=0:11:43\n",
      "\u001b[32m[07/05 22:20:44 d2.evaluation.evaluator]: \u001b[0mInference done 5381/14460. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0390 s/iter. Total: 0.0770 s/iter. ETA=0:11:38\n",
      "\u001b[32m[07/05 22:20:49 d2.evaluation.evaluator]: \u001b[0mInference done 5446/14460. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0390 s/iter. Total: 0.0770 s/iter. ETA=0:11:33\n",
      "\u001b[32m[07/05 22:20:54 d2.evaluation.evaluator]: \u001b[0mInference done 5512/14460. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0390 s/iter. Total: 0.0770 s/iter. ETA=0:11:28\n",
      "\u001b[32m[07/05 22:20:59 d2.evaluation.evaluator]: \u001b[0mInference done 5579/14460. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0390 s/iter. Total: 0.0769 s/iter. ETA=0:11:23\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/05 22:21:04 d2.evaluation.evaluator]: \u001b[0mInference done 5645/14460. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0390 s/iter. Total: 0.0769 s/iter. ETA=0:11:18\n",
      "\u001b[32m[07/05 22:21:09 d2.evaluation.evaluator]: \u001b[0mInference done 5712/14460. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0390 s/iter. Total: 0.0769 s/iter. ETA=0:11:12\n",
      "\u001b[32m[07/05 22:21:14 d2.evaluation.evaluator]: \u001b[0mInference done 5778/14460. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0390 s/iter. Total: 0.0769 s/iter. ETA=0:11:07\n",
      "\u001b[32m[07/05 22:21:19 d2.evaluation.evaluator]: \u001b[0mInference done 5844/14460. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0390 s/iter. Total: 0.0769 s/iter. ETA=0:11:02\n",
      "\u001b[32m[07/05 22:21:25 d2.evaluation.evaluator]: \u001b[0mInference done 5910/14460. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0390 s/iter. Total: 0.0769 s/iter. ETA=0:10:57\n",
      "\u001b[32m[07/05 22:21:30 d2.evaluation.evaluator]: \u001b[0mInference done 5976/14460. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0389 s/iter. Total: 0.0769 s/iter. ETA=0:10:52\n",
      "\u001b[32m[07/05 22:21:35 d2.evaluation.evaluator]: \u001b[0mInference done 6042/14460. Dataloading: 0.0023 s/iter. Inference: 0.0355 s/iter. Eval: 0.0389 s/iter. Total: 0.0769 s/iter. ETA=0:10:47\n",
      "\u001b[32m[07/05 22:21:40 d2.evaluation.evaluator]: \u001b[0mInference done 6108/14460. Dataloading: 0.0023 s/iter. Inference: 0.0356 s/iter. Eval: 0.0389 s/iter. Total: 0.0769 s/iter. ETA=0:10:41\n",
      "\u001b[32m[07/05 22:21:45 d2.evaluation.evaluator]: \u001b[0mInference done 6175/14460. Dataloading: 0.0023 s/iter. Inference: 0.0356 s/iter. Eval: 0.0389 s/iter. Total: 0.0769 s/iter. ETA=0:10:36\n",
      "\u001b[32m[07/05 22:21:50 d2.evaluation.evaluator]: \u001b[0mInference done 6241/14460. Dataloading: 0.0023 s/iter. Inference: 0.0356 s/iter. Eval: 0.0389 s/iter. Total: 0.0768 s/iter. ETA=0:10:31\n",
      "\u001b[32m[07/05 22:21:55 d2.evaluation.evaluator]: \u001b[0mInference done 6307/14460. Dataloading: 0.0023 s/iter. Inference: 0.0356 s/iter. Eval: 0.0389 s/iter. Total: 0.0768 s/iter. ETA=0:10:26\n",
      "\u001b[32m[07/05 22:22:00 d2.evaluation.evaluator]: \u001b[0mInference done 6373/14460. Dataloading: 0.0023 s/iter. Inference: 0.0356 s/iter. Eval: 0.0389 s/iter. Total: 0.0768 s/iter. ETA=0:10:21\n",
      "\u001b[32m[07/05 22:22:05 d2.evaluation.evaluator]: \u001b[0mInference done 6439/14460. Dataloading: 0.0023 s/iter. Inference: 0.0356 s/iter. Eval: 0.0389 s/iter. Total: 0.0768 s/iter. ETA=0:10:16\n",
      "\u001b[32m[07/05 22:22:10 d2.evaluation.evaluator]: \u001b[0mInference done 6505/14460. Dataloading: 0.0023 s/iter. Inference: 0.0356 s/iter. Eval: 0.0389 s/iter. Total: 0.0768 s/iter. ETA=0:10:11\n",
      "\u001b[32m[07/05 22:22:15 d2.evaluation.evaluator]: \u001b[0mInference done 6538/14460. Dataloading: 0.0023 s/iter. Inference: 0.0356 s/iter. Eval: 0.0393 s/iter. Total: 0.0772 s/iter. ETA=0:10:11\n",
      "\u001b[32m[07/05 22:22:20 d2.evaluation.evaluator]: \u001b[0mInference done 6565/14460. Dataloading: 0.0023 s/iter. Inference: 0.0356 s/iter. Eval: 0.0397 s/iter. Total: 0.0777 s/iter. ETA=0:10:13\n",
      "\u001b[32m[07/05 22:22:25 d2.evaluation.evaluator]: \u001b[0mInference done 6591/14460. Dataloading: 0.0023 s/iter. Inference: 0.0357 s/iter. Eval: 0.0401 s/iter. Total: 0.0782 s/iter. ETA=0:10:15\n",
      "\u001b[32m[07/05 22:22:30 d2.evaluation.evaluator]: \u001b[0mInference done 6617/14460. Dataloading: 0.0023 s/iter. Inference: 0.0357 s/iter. Eval: 0.0405 s/iter. Total: 0.0786 s/iter. ETA=0:10:16\n",
      "\u001b[32m[07/05 22:22:35 d2.evaluation.evaluator]: \u001b[0mInference done 6643/14460. Dataloading: 0.0023 s/iter. Inference: 0.0358 s/iter. Eval: 0.0409 s/iter. Total: 0.0791 s/iter. ETA=0:10:18\n",
      "\u001b[32m[07/05 22:22:41 d2.evaluation.evaluator]: \u001b[0mInference done 6669/14460. Dataloading: 0.0023 s/iter. Inference: 0.0358 s/iter. Eval: 0.0413 s/iter. Total: 0.0795 s/iter. ETA=0:10:19\n",
      "\u001b[32m[07/05 22:22:46 d2.evaluation.evaluator]: \u001b[0mInference done 6696/14460. Dataloading: 0.0023 s/iter. Inference: 0.0359 s/iter. Eval: 0.0417 s/iter. Total: 0.0800 s/iter. ETA=0:10:20\n",
      "\u001b[32m[07/05 22:22:51 d2.evaluation.evaluator]: \u001b[0mInference done 6724/14460. Dataloading: 0.0023 s/iter. Inference: 0.0359 s/iter. Eval: 0.0421 s/iter. Total: 0.0804 s/iter. ETA=0:10:22\n",
      "\u001b[32m[07/05 22:22:56 d2.evaluation.evaluator]: \u001b[0mInference done 6751/14460. Dataloading: 0.0023 s/iter. Inference: 0.0359 s/iter. Eval: 0.0425 s/iter. Total: 0.0809 s/iter. ETA=0:10:23\n",
      "\u001b[32m[07/05 22:23:01 d2.evaluation.evaluator]: \u001b[0mInference done 6780/14460. Dataloading: 0.0023 s/iter. Inference: 0.0360 s/iter. Eval: 0.0429 s/iter. Total: 0.0812 s/iter. ETA=0:10:23\n",
      "\u001b[32m[07/05 22:23:06 d2.evaluation.evaluator]: \u001b[0mInference done 6808/14460. Dataloading: 0.0023 s/iter. Inference: 0.0360 s/iter. Eval: 0.0433 s/iter. Total: 0.0817 s/iter. ETA=0:10:24\n",
      "\u001b[32m[07/05 22:23:11 d2.evaluation.evaluator]: \u001b[0mInference done 6836/14460. Dataloading: 0.0023 s/iter. Inference: 0.0361 s/iter. Eval: 0.0436 s/iter. Total: 0.0821 s/iter. ETA=0:10:25\n",
      "\u001b[32m[07/05 22:23:16 d2.evaluation.evaluator]: \u001b[0mInference done 6862/14460. Dataloading: 0.0023 s/iter. Inference: 0.0361 s/iter. Eval: 0.0440 s/iter. Total: 0.0825 s/iter. ETA=0:10:26\n",
      "\u001b[32m[07/05 22:23:21 d2.evaluation.evaluator]: \u001b[0mInference done 6887/14460. Dataloading: 0.0023 s/iter. Inference: 0.0361 s/iter. Eval: 0.0444 s/iter. Total: 0.0829 s/iter. ETA=0:10:28\n",
      "\u001b[32m[07/05 22:23:26 d2.evaluation.evaluator]: \u001b[0mInference done 6913/14460. Dataloading: 0.0023 s/iter. Inference: 0.0362 s/iter. Eval: 0.0448 s/iter. Total: 0.0834 s/iter. ETA=0:10:29\n",
      "\u001b[32m[07/05 22:23:32 d2.evaluation.evaluator]: \u001b[0mInference done 6939/14460. Dataloading: 0.0023 s/iter. Inference: 0.0362 s/iter. Eval: 0.0452 s/iter. Total: 0.0838 s/iter. ETA=0:10:30\n",
      "\u001b[32m[07/05 22:23:37 d2.evaluation.evaluator]: \u001b[0mInference done 6965/14460. Dataloading: 0.0023 s/iter. Inference: 0.0363 s/iter. Eval: 0.0456 s/iter. Total: 0.0842 s/iter. ETA=0:10:31\n",
      "\u001b[32m[07/05 22:23:42 d2.evaluation.evaluator]: \u001b[0mInference done 6991/14460. Dataloading: 0.0023 s/iter. Inference: 0.0363 s/iter. Eval: 0.0459 s/iter. Total: 0.0846 s/iter. ETA=0:10:32\n",
      "\u001b[32m[07/05 22:23:47 d2.evaluation.evaluator]: \u001b[0mInference done 7017/14460. Dataloading: 0.0023 s/iter. Inference: 0.0363 s/iter. Eval: 0.0463 s/iter. Total: 0.0850 s/iter. ETA=0:10:32\n",
      "\u001b[32m[07/05 22:23:52 d2.evaluation.evaluator]: \u001b[0mInference done 7044/14460. Dataloading: 0.0023 s/iter. Inference: 0.0364 s/iter. Eval: 0.0467 s/iter. Total: 0.0854 s/iter. ETA=0:10:33\n",
      "\u001b[32m[07/05 22:23:57 d2.evaluation.evaluator]: \u001b[0mInference done 7071/14460. Dataloading: 0.0023 s/iter. Inference: 0.0364 s/iter. Eval: 0.0470 s/iter. Total: 0.0858 s/iter. ETA=0:10:34\n",
      "\u001b[32m[07/05 22:24:02 d2.evaluation.evaluator]: \u001b[0mInference done 7098/14460. Dataloading: 0.0023 s/iter. Inference: 0.0365 s/iter. Eval: 0.0474 s/iter. Total: 0.0862 s/iter. ETA=0:10:34\n",
      "\u001b[32m[07/05 22:24:07 d2.evaluation.evaluator]: \u001b[0mInference done 7125/14460. Dataloading: 0.0023 s/iter. Inference: 0.0365 s/iter. Eval: 0.0477 s/iter. Total: 0.0866 s/iter. ETA=0:10:35\n",
      "\u001b[32m[07/05 22:24:12 d2.evaluation.evaluator]: \u001b[0mInference done 7150/14460. Dataloading: 0.0023 s/iter. Inference: 0.0365 s/iter. Eval: 0.0481 s/iter. Total: 0.0870 s/iter. ETA=0:10:36\n",
      "\u001b[32m[07/05 22:24:18 d2.evaluation.evaluator]: \u001b[0mInference done 7176/14460. Dataloading: 0.0023 s/iter. Inference: 0.0366 s/iter. Eval: 0.0485 s/iter. Total: 0.0874 s/iter. ETA=0:10:36\n",
      "\u001b[32m[07/05 22:24:23 d2.evaluation.evaluator]: \u001b[0mInference done 7202/14460. Dataloading: 0.0023 s/iter. Inference: 0.0366 s/iter. Eval: 0.0488 s/iter. Total: 0.0878 s/iter. ETA=0:10:37\n",
      "\u001b[32m[07/05 22:24:28 d2.evaluation.evaluator]: \u001b[0mInference done 7229/14460. Dataloading: 0.0023 s/iter. Inference: 0.0366 s/iter. Eval: 0.0492 s/iter. Total: 0.0882 s/iter. ETA=0:10:37\n",
      "\u001b[32m[07/05 22:24:33 d2.evaluation.evaluator]: \u001b[0mInference done 7254/14460. Dataloading: 0.0023 s/iter. Inference: 0.0367 s/iter. Eval: 0.0495 s/iter. Total: 0.0886 s/iter. ETA=0:10:38\n",
      "\u001b[32m[07/05 22:24:38 d2.evaluation.evaluator]: \u001b[0mInference done 7280/14460. Dataloading: 0.0023 s/iter. Inference: 0.0367 s/iter. Eval: 0.0499 s/iter. Total: 0.0890 s/iter. ETA=0:10:39\n",
      "\u001b[32m[07/05 22:24:43 d2.evaluation.evaluator]: \u001b[0mInference done 7305/14460. Dataloading: 0.0023 s/iter. Inference: 0.0368 s/iter. Eval: 0.0502 s/iter. Total: 0.0894 s/iter. ETA=0:10:39\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/05 22:24:48 d2.evaluation.evaluator]: \u001b[0mInference done 7331/14460. Dataloading: 0.0023 s/iter. Inference: 0.0368 s/iter. Eval: 0.0506 s/iter. Total: 0.0898 s/iter. ETA=0:10:40\n",
      "\u001b[32m[07/05 22:24:54 d2.evaluation.evaluator]: \u001b[0mInference done 7357/14460. Dataloading: 0.0023 s/iter. Inference: 0.0369 s/iter. Eval: 0.0509 s/iter. Total: 0.0902 s/iter. ETA=0:10:40\n",
      "\u001b[32m[07/05 22:24:59 d2.evaluation.evaluator]: \u001b[0mInference done 7383/14460. Dataloading: 0.0023 s/iter. Inference: 0.0369 s/iter. Eval: 0.0512 s/iter. Total: 0.0905 s/iter. ETA=0:10:40\n",
      "\u001b[32m[07/05 22:25:04 d2.evaluation.evaluator]: \u001b[0mInference done 7409/14460. Dataloading: 0.0023 s/iter. Inference: 0.0369 s/iter. Eval: 0.0516 s/iter. Total: 0.0909 s/iter. ETA=0:10:40\n",
      "\u001b[32m[07/05 22:25:09 d2.evaluation.evaluator]: \u001b[0mInference done 7436/14460. Dataloading: 0.0023 s/iter. Inference: 0.0370 s/iter. Eval: 0.0519 s/iter. Total: 0.0913 s/iter. ETA=0:10:40\n",
      "\u001b[32m[07/05 22:25:14 d2.evaluation.evaluator]: \u001b[0mInference done 7464/14460. Dataloading: 0.0023 s/iter. Inference: 0.0370 s/iter. Eval: 0.0522 s/iter. Total: 0.0916 s/iter. ETA=0:10:40\n",
      "\u001b[32m[07/05 22:25:19 d2.evaluation.evaluator]: \u001b[0mInference done 7490/14460. Dataloading: 0.0023 s/iter. Inference: 0.0370 s/iter. Eval: 0.0525 s/iter. Total: 0.0920 s/iter. ETA=0:10:41\n",
      "\u001b[32m[07/05 22:25:24 d2.evaluation.evaluator]: \u001b[0mInference done 7516/14460. Dataloading: 0.0023 s/iter. Inference: 0.0371 s/iter. Eval: 0.0529 s/iter. Total: 0.0923 s/iter. ETA=0:10:41\n",
      "\u001b[32m[07/05 22:25:29 d2.evaluation.evaluator]: \u001b[0mInference done 7542/14460. Dataloading: 0.0023 s/iter. Inference: 0.0371 s/iter. Eval: 0.0532 s/iter. Total: 0.0927 s/iter. ETA=0:10:41\n",
      "\u001b[32m[07/05 22:25:34 d2.evaluation.evaluator]: \u001b[0mInference done 7569/14460. Dataloading: 0.0023 s/iter. Inference: 0.0371 s/iter. Eval: 0.0535 s/iter. Total: 0.0931 s/iter. ETA=0:10:41\n",
      "\u001b[32m[07/05 22:25:40 d2.evaluation.evaluator]: \u001b[0mInference done 7596/14460. Dataloading: 0.0023 s/iter. Inference: 0.0372 s/iter. Eval: 0.0538 s/iter. Total: 0.0934 s/iter. ETA=0:10:41\n",
      "\u001b[32m[07/05 22:25:45 d2.evaluation.evaluator]: \u001b[0mInference done 7621/14460. Dataloading: 0.0023 s/iter. Inference: 0.0372 s/iter. Eval: 0.0542 s/iter. Total: 0.0938 s/iter. ETA=0:10:41\n",
      "\u001b[32m[07/05 22:25:50 d2.evaluation.evaluator]: \u001b[0mInference done 7647/14460. Dataloading: 0.0023 s/iter. Inference: 0.0372 s/iter. Eval: 0.0545 s/iter. Total: 0.0941 s/iter. ETA=0:10:41\n",
      "\u001b[32m[07/05 22:25:55 d2.evaluation.evaluator]: \u001b[0mInference done 7673/14460. Dataloading: 0.0023 s/iter. Inference: 0.0373 s/iter. Eval: 0.0548 s/iter. Total: 0.0944 s/iter. ETA=0:10:41\n",
      "\u001b[32m[07/05 22:26:00 d2.evaluation.evaluator]: \u001b[0mInference done 7699/14460. Dataloading: 0.0023 s/iter. Inference: 0.0373 s/iter. Eval: 0.0551 s/iter. Total: 0.0948 s/iter. ETA=0:10:40\n",
      "\u001b[32m[07/05 22:26:05 d2.evaluation.evaluator]: \u001b[0mInference done 7725/14460. Dataloading: 0.0023 s/iter. Inference: 0.0373 s/iter. Eval: 0.0554 s/iter. Total: 0.0951 s/iter. ETA=0:10:40\n",
      "\u001b[32m[07/05 22:26:10 d2.evaluation.evaluator]: \u001b[0mInference done 7751/14460. Dataloading: 0.0023 s/iter. Inference: 0.0374 s/iter. Eval: 0.0557 s/iter. Total: 0.0955 s/iter. ETA=0:10:40\n",
      "\u001b[32m[07/05 22:26:15 d2.evaluation.evaluator]: \u001b[0mInference done 7777/14460. Dataloading: 0.0023 s/iter. Inference: 0.0374 s/iter. Eval: 0.0560 s/iter. Total: 0.0958 s/iter. ETA=0:10:40\n",
      "\u001b[32m[07/05 22:26:20 d2.evaluation.evaluator]: \u001b[0mInference done 7804/14460. Dataloading: 0.0023 s/iter. Inference: 0.0374 s/iter. Eval: 0.0563 s/iter. Total: 0.0961 s/iter. ETA=0:10:39\n",
      "\u001b[32m[07/05 22:26:26 d2.evaluation.evaluator]: \u001b[0mInference done 7831/14460. Dataloading: 0.0023 s/iter. Inference: 0.0375 s/iter. Eval: 0.0566 s/iter. Total: 0.0965 s/iter. ETA=0:10:39\n",
      "\u001b[32m[07/05 22:26:31 d2.evaluation.evaluator]: \u001b[0mInference done 7858/14460. Dataloading: 0.0023 s/iter. Inference: 0.0375 s/iter. Eval: 0.0569 s/iter. Total: 0.0968 s/iter. ETA=0:10:38\n",
      "\u001b[32m[07/05 22:26:36 d2.evaluation.evaluator]: \u001b[0mInference done 7884/14460. Dataloading: 0.0023 s/iter. Inference: 0.0375 s/iter. Eval: 0.0572 s/iter. Total: 0.0971 s/iter. ETA=0:10:38\n",
      "\u001b[32m[07/05 22:26:41 d2.evaluation.evaluator]: \u001b[0mInference done 7909/14460. Dataloading: 0.0023 s/iter. Inference: 0.0375 s/iter. Eval: 0.0575 s/iter. Total: 0.0974 s/iter. ETA=0:10:38\n",
      "\u001b[32m[07/05 22:26:46 d2.evaluation.evaluator]: \u001b[0mInference done 7965/14460. Dataloading: 0.0023 s/iter. Inference: 0.0375 s/iter. Eval: 0.0574 s/iter. Total: 0.0974 s/iter. ETA=0:10:32\n",
      "\u001b[32m[07/05 22:26:51 d2.evaluation.evaluator]: \u001b[0mInference done 8030/14460. Dataloading: 0.0023 s/iter. Inference: 0.0375 s/iter. Eval: 0.0573 s/iter. Total: 0.0972 s/iter. ETA=0:10:25\n",
      "\u001b[32m[07/05 22:26:56 d2.evaluation.evaluator]: \u001b[0mInference done 8095/14460. Dataloading: 0.0023 s/iter. Inference: 0.0375 s/iter. Eval: 0.0572 s/iter. Total: 0.0971 s/iter. ETA=0:10:17\n",
      "\u001b[32m[07/05 22:27:01 d2.evaluation.evaluator]: \u001b[0mInference done 8159/14460. Dataloading: 0.0023 s/iter. Inference: 0.0375 s/iter. Eval: 0.0570 s/iter. Total: 0.0969 s/iter. ETA=0:10:10\n",
      "\u001b[32m[07/05 22:27:06 d2.evaluation.evaluator]: \u001b[0mInference done 8224/14460. Dataloading: 0.0023 s/iter. Inference: 0.0375 s/iter. Eval: 0.0569 s/iter. Total: 0.0968 s/iter. ETA=0:10:03\n",
      "\u001b[32m[07/05 22:27:11 d2.evaluation.evaluator]: \u001b[0mInference done 8288/14460. Dataloading: 0.0023 s/iter. Inference: 0.0374 s/iter. Eval: 0.0568 s/iter. Total: 0.0966 s/iter. ETA=0:09:56\n",
      "\u001b[32m[07/05 22:27:16 d2.evaluation.evaluator]: \u001b[0mInference done 8353/14460. Dataloading: 0.0023 s/iter. Inference: 0.0374 s/iter. Eval: 0.0566 s/iter. Total: 0.0965 s/iter. ETA=0:09:49\n",
      "\u001b[32m[07/05 22:27:21 d2.evaluation.evaluator]: \u001b[0mInference done 8420/14460. Dataloading: 0.0023 s/iter. Inference: 0.0374 s/iter. Eval: 0.0565 s/iter. Total: 0.0963 s/iter. ETA=0:09:41\n",
      "\u001b[32m[07/05 22:27:26 d2.evaluation.evaluator]: \u001b[0mInference done 8485/14460. Dataloading: 0.0023 s/iter. Inference: 0.0374 s/iter. Eval: 0.0564 s/iter. Total: 0.0962 s/iter. ETA=0:09:34\n",
      "\u001b[32m[07/05 22:27:31 d2.evaluation.evaluator]: \u001b[0mInference done 8550/14460. Dataloading: 0.0023 s/iter. Inference: 0.0374 s/iter. Eval: 0.0562 s/iter. Total: 0.0960 s/iter. ETA=0:09:27\n",
      "\u001b[32m[07/05 22:27:36 d2.evaluation.evaluator]: \u001b[0mInference done 8614/14460. Dataloading: 0.0023 s/iter. Inference: 0.0374 s/iter. Eval: 0.0561 s/iter. Total: 0.0959 s/iter. ETA=0:09:20\n",
      "\u001b[32m[07/05 22:27:41 d2.evaluation.evaluator]: \u001b[0mInference done 8678/14460. Dataloading: 0.0023 s/iter. Inference: 0.0374 s/iter. Eval: 0.0560 s/iter. Total: 0.0958 s/iter. ETA=0:09:13\n",
      "\u001b[32m[07/05 22:27:46 d2.evaluation.evaluator]: \u001b[0mInference done 8741/14460. Dataloading: 0.0023 s/iter. Inference: 0.0373 s/iter. Eval: 0.0559 s/iter. Total: 0.0957 s/iter. ETA=0:09:07\n",
      "\u001b[32m[07/05 22:27:51 d2.evaluation.evaluator]: \u001b[0mInference done 8804/14460. Dataloading: 0.0023 s/iter. Inference: 0.0373 s/iter. Eval: 0.0558 s/iter. Total: 0.0955 s/iter. ETA=0:09:00\n",
      "\u001b[32m[07/05 22:27:56 d2.evaluation.evaluator]: \u001b[0mInference done 8867/14460. Dataloading: 0.0023 s/iter. Inference: 0.0373 s/iter. Eval: 0.0557 s/iter. Total: 0.0954 s/iter. ETA=0:08:53\n",
      "\u001b[32m[07/05 22:28:01 d2.evaluation.evaluator]: \u001b[0mInference done 8930/14460. Dataloading: 0.0023 s/iter. Inference: 0.0373 s/iter. Eval: 0.0556 s/iter. Total: 0.0953 s/iter. ETA=0:08:47\n",
      "\u001b[32m[07/05 22:28:06 d2.evaluation.evaluator]: \u001b[0mInference done 8994/14460. Dataloading: 0.0023 s/iter. Inference: 0.0373 s/iter. Eval: 0.0555 s/iter. Total: 0.0952 s/iter. ETA=0:08:40\n",
      "\u001b[32m[07/05 22:28:11 d2.evaluation.evaluator]: \u001b[0mInference done 9057/14460. Dataloading: 0.0023 s/iter. Inference: 0.0373 s/iter. Eval: 0.0554 s/iter. Total: 0.0951 s/iter. ETA=0:08:33\n",
      "\u001b[32m[07/05 22:28:16 d2.evaluation.evaluator]: \u001b[0mInference done 9120/14460. Dataloading: 0.0023 s/iter. Inference: 0.0373 s/iter. Eval: 0.0553 s/iter. Total: 0.0950 s/iter. ETA=0:08:27\n",
      "\u001b[32m[07/05 22:28:21 d2.evaluation.evaluator]: \u001b[0mInference done 9183/14460. Dataloading: 0.0023 s/iter. Inference: 0.0372 s/iter. Eval: 0.0552 s/iter. Total: 0.0949 s/iter. ETA=0:08:20\n",
      "\u001b[32m[07/05 22:28:26 d2.evaluation.evaluator]: \u001b[0mInference done 9246/14460. Dataloading: 0.0023 s/iter. Inference: 0.0372 s/iter. Eval: 0.0551 s/iter. Total: 0.0948 s/iter. ETA=0:08:14\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/05 22:28:32 d2.evaluation.evaluator]: \u001b[0mInference done 9309/14460. Dataloading: 0.0023 s/iter. Inference: 0.0372 s/iter. Eval: 0.0550 s/iter. Total: 0.0947 s/iter. ETA=0:08:07\n",
      "\u001b[32m[07/05 22:28:37 d2.evaluation.evaluator]: \u001b[0mInference done 9371/14460. Dataloading: 0.0023 s/iter. Inference: 0.0372 s/iter. Eval: 0.0550 s/iter. Total: 0.0946 s/iter. ETA=0:08:01\n",
      "\u001b[32m[07/05 22:28:42 d2.evaluation.evaluator]: \u001b[0mInference done 9433/14460. Dataloading: 0.0023 s/iter. Inference: 0.0372 s/iter. Eval: 0.0549 s/iter. Total: 0.0945 s/iter. ETA=0:07:55\n",
      "\u001b[32m[07/05 22:28:47 d2.evaluation.evaluator]: \u001b[0mInference done 9498/14460. Dataloading: 0.0023 s/iter. Inference: 0.0372 s/iter. Eval: 0.0548 s/iter. Total: 0.0944 s/iter. ETA=0:07:48\n",
      "\u001b[32m[07/05 22:28:52 d2.evaluation.evaluator]: \u001b[0mInference done 9564/14460. Dataloading: 0.0023 s/iter. Inference: 0.0372 s/iter. Eval: 0.0547 s/iter. Total: 0.0943 s/iter. ETA=0:07:41\n",
      "\u001b[32m[07/05 22:28:57 d2.evaluation.evaluator]: \u001b[0mInference done 9630/14460. Dataloading: 0.0023 s/iter. Inference: 0.0372 s/iter. Eval: 0.0545 s/iter. Total: 0.0941 s/iter. ETA=0:07:34\n",
      "\u001b[32m[07/05 22:29:02 d2.evaluation.evaluator]: \u001b[0mInference done 9696/14460. Dataloading: 0.0023 s/iter. Inference: 0.0372 s/iter. Eval: 0.0544 s/iter. Total: 0.0940 s/iter. ETA=0:07:27\n",
      "\u001b[32m[07/05 22:29:07 d2.evaluation.evaluator]: \u001b[0mInference done 9760/14460. Dataloading: 0.0023 s/iter. Inference: 0.0371 s/iter. Eval: 0.0543 s/iter. Total: 0.0939 s/iter. ETA=0:07:21\n",
      "\u001b[32m[07/05 22:29:12 d2.evaluation.evaluator]: \u001b[0mInference done 9826/14460. Dataloading: 0.0023 s/iter. Inference: 0.0371 s/iter. Eval: 0.0542 s/iter. Total: 0.0938 s/iter. ETA=0:07:14\n",
      "\u001b[32m[07/05 22:29:17 d2.evaluation.evaluator]: \u001b[0mInference done 9890/14460. Dataloading: 0.0023 s/iter. Inference: 0.0371 s/iter. Eval: 0.0541 s/iter. Total: 0.0937 s/iter. ETA=0:07:08\n",
      "\u001b[32m[07/05 22:29:22 d2.evaluation.evaluator]: \u001b[0mInference done 9955/14460. Dataloading: 0.0023 s/iter. Inference: 0.0371 s/iter. Eval: 0.0541 s/iter. Total: 0.0936 s/iter. ETA=0:07:01\n",
      "\u001b[32m[07/05 22:29:27 d2.evaluation.evaluator]: \u001b[0mInference done 10021/14460. Dataloading: 0.0023 s/iter. Inference: 0.0371 s/iter. Eval: 0.0540 s/iter. Total: 0.0935 s/iter. ETA=0:06:54\n",
      "\u001b[32m[07/05 22:29:32 d2.evaluation.evaluator]: \u001b[0mInference done 10086/14460. Dataloading: 0.0023 s/iter. Inference: 0.0371 s/iter. Eval: 0.0539 s/iter. Total: 0.0934 s/iter. ETA=0:06:48\n",
      "\u001b[32m[07/05 22:29:37 d2.evaluation.evaluator]: \u001b[0mInference done 10150/14460. Dataloading: 0.0023 s/iter. Inference: 0.0371 s/iter. Eval: 0.0538 s/iter. Total: 0.0933 s/iter. ETA=0:06:42\n",
      "\u001b[32m[07/05 22:29:42 d2.evaluation.evaluator]: \u001b[0mInference done 10216/14460. Dataloading: 0.0024 s/iter. Inference: 0.0371 s/iter. Eval: 0.0537 s/iter. Total: 0.0932 s/iter. ETA=0:06:35\n",
      "\u001b[32m[07/05 22:29:47 d2.evaluation.evaluator]: \u001b[0mInference done 10281/14460. Dataloading: 0.0024 s/iter. Inference: 0.0371 s/iter. Eval: 0.0536 s/iter. Total: 0.0931 s/iter. ETA=0:06:28\n",
      "\u001b[32m[07/05 22:29:52 d2.evaluation.evaluator]: \u001b[0mInference done 10346/14460. Dataloading: 0.0024 s/iter. Inference: 0.0371 s/iter. Eval: 0.0535 s/iter. Total: 0.0930 s/iter. ETA=0:06:22\n",
      "\u001b[32m[07/05 22:29:57 d2.evaluation.evaluator]: \u001b[0mInference done 10411/14460. Dataloading: 0.0024 s/iter. Inference: 0.0370 s/iter. Eval: 0.0534 s/iter. Total: 0.0929 s/iter. ETA=0:06:16\n",
      "\u001b[32m[07/05 22:30:02 d2.evaluation.evaluator]: \u001b[0mInference done 10475/14460. Dataloading: 0.0024 s/iter. Inference: 0.0370 s/iter. Eval: 0.0533 s/iter. Total: 0.0928 s/iter. ETA=0:06:09\n",
      "\u001b[32m[07/05 22:30:07 d2.evaluation.evaluator]: \u001b[0mInference done 10540/14460. Dataloading: 0.0024 s/iter. Inference: 0.0370 s/iter. Eval: 0.0532 s/iter. Total: 0.0927 s/iter. ETA=0:06:03\n",
      "\u001b[32m[07/05 22:30:12 d2.evaluation.evaluator]: \u001b[0mInference done 10605/14460. Dataloading: 0.0024 s/iter. Inference: 0.0370 s/iter. Eval: 0.0532 s/iter. Total: 0.0926 s/iter. ETA=0:05:56\n",
      "\u001b[32m[07/05 22:30:17 d2.evaluation.evaluator]: \u001b[0mInference done 10669/14460. Dataloading: 0.0024 s/iter. Inference: 0.0370 s/iter. Eval: 0.0531 s/iter. Total: 0.0925 s/iter. ETA=0:05:50\n",
      "\u001b[32m[07/05 22:30:22 d2.evaluation.evaluator]: \u001b[0mInference done 10734/14460. Dataloading: 0.0024 s/iter. Inference: 0.0370 s/iter. Eval: 0.0530 s/iter. Total: 0.0924 s/iter. ETA=0:05:44\n",
      "\u001b[32m[07/05 22:30:27 d2.evaluation.evaluator]: \u001b[0mInference done 10800/14460. Dataloading: 0.0024 s/iter. Inference: 0.0370 s/iter. Eval: 0.0529 s/iter. Total: 0.0923 s/iter. ETA=0:05:37\n",
      "\u001b[32m[07/05 22:30:32 d2.evaluation.evaluator]: \u001b[0mInference done 10867/14460. Dataloading: 0.0024 s/iter. Inference: 0.0370 s/iter. Eval: 0.0528 s/iter. Total: 0.0922 s/iter. ETA=0:05:31\n",
      "\u001b[32m[07/05 22:30:37 d2.evaluation.evaluator]: \u001b[0mInference done 10934/14460. Dataloading: 0.0024 s/iter. Inference: 0.0370 s/iter. Eval: 0.0527 s/iter. Total: 0.0921 s/iter. ETA=0:05:24\n",
      "\u001b[32m[07/05 22:30:42 d2.evaluation.evaluator]: \u001b[0mInference done 11000/14460. Dataloading: 0.0024 s/iter. Inference: 0.0370 s/iter. Eval: 0.0526 s/iter. Total: 0.0920 s/iter. ETA=0:05:18\n",
      "\u001b[32m[07/05 22:30:47 d2.evaluation.evaluator]: \u001b[0mInference done 11067/14460. Dataloading: 0.0024 s/iter. Inference: 0.0370 s/iter. Eval: 0.0525 s/iter. Total: 0.0919 s/iter. ETA=0:05:11\n",
      "\u001b[32m[07/05 22:30:53 d2.evaluation.evaluator]: \u001b[0mInference done 11134/14460. Dataloading: 0.0024 s/iter. Inference: 0.0369 s/iter. Eval: 0.0525 s/iter. Total: 0.0918 s/iter. ETA=0:05:05\n",
      "\u001b[32m[07/05 22:30:58 d2.evaluation.evaluator]: \u001b[0mInference done 11201/14460. Dataloading: 0.0024 s/iter. Inference: 0.0369 s/iter. Eval: 0.0524 s/iter. Total: 0.0917 s/iter. ETA=0:04:58\n",
      "\u001b[32m[07/05 22:31:03 d2.evaluation.evaluator]: \u001b[0mInference done 11267/14460. Dataloading: 0.0024 s/iter. Inference: 0.0369 s/iter. Eval: 0.0523 s/iter. Total: 0.0916 s/iter. ETA=0:04:52\n",
      "\u001b[32m[07/05 22:31:08 d2.evaluation.evaluator]: \u001b[0mInference done 11334/14460. Dataloading: 0.0024 s/iter. Inference: 0.0369 s/iter. Eval: 0.0522 s/iter. Total: 0.0915 s/iter. ETA=0:04:46\n",
      "\u001b[32m[07/05 22:31:13 d2.evaluation.evaluator]: \u001b[0mInference done 11400/14460. Dataloading: 0.0024 s/iter. Inference: 0.0369 s/iter. Eval: 0.0521 s/iter. Total: 0.0915 s/iter. ETA=0:04:39\n",
      "\u001b[32m[07/05 22:31:18 d2.evaluation.evaluator]: \u001b[0mInference done 11466/14460. Dataloading: 0.0024 s/iter. Inference: 0.0369 s/iter. Eval: 0.0520 s/iter. Total: 0.0914 s/iter. ETA=0:04:33\n",
      "\u001b[32m[07/05 22:31:23 d2.evaluation.evaluator]: \u001b[0mInference done 11534/14460. Dataloading: 0.0024 s/iter. Inference: 0.0369 s/iter. Eval: 0.0519 s/iter. Total: 0.0913 s/iter. ETA=0:04:27\n",
      "\u001b[32m[07/05 22:31:28 d2.evaluation.evaluator]: \u001b[0mInference done 11600/14460. Dataloading: 0.0024 s/iter. Inference: 0.0369 s/iter. Eval: 0.0519 s/iter. Total: 0.0912 s/iter. ETA=0:04:20\n",
      "\u001b[32m[07/05 22:31:33 d2.evaluation.evaluator]: \u001b[0mInference done 11667/14460. Dataloading: 0.0024 s/iter. Inference: 0.0369 s/iter. Eval: 0.0518 s/iter. Total: 0.0911 s/iter. ETA=0:04:14\n",
      "\u001b[32m[07/05 22:31:38 d2.evaluation.evaluator]: \u001b[0mInference done 11734/14460. Dataloading: 0.0024 s/iter. Inference: 0.0369 s/iter. Eval: 0.0517 s/iter. Total: 0.0910 s/iter. ETA=0:04:08\n",
      "\u001b[32m[07/05 22:31:43 d2.evaluation.evaluator]: \u001b[0mInference done 11801/14460. Dataloading: 0.0024 s/iter. Inference: 0.0369 s/iter. Eval: 0.0516 s/iter. Total: 0.0909 s/iter. ETA=0:04:01\n",
      "\u001b[32m[07/05 22:31:48 d2.evaluation.evaluator]: \u001b[0mInference done 11868/14460. Dataloading: 0.0024 s/iter. Inference: 0.0369 s/iter. Eval: 0.0515 s/iter. Total: 0.0908 s/iter. ETA=0:03:55\n",
      "\u001b[32m[07/05 22:31:53 d2.evaluation.evaluator]: \u001b[0mInference done 11935/14460. Dataloading: 0.0024 s/iter. Inference: 0.0368 s/iter. Eval: 0.0514 s/iter. Total: 0.0907 s/iter. ETA=0:03:49\n",
      "\u001b[32m[07/05 22:31:58 d2.evaluation.evaluator]: \u001b[0mInference done 11998/14460. Dataloading: 0.0024 s/iter. Inference: 0.0369 s/iter. Eval: 0.0514 s/iter. Total: 0.0907 s/iter. ETA=0:03:43\n",
      "\u001b[32m[07/05 22:32:03 d2.evaluation.evaluator]: \u001b[0mInference done 12063/14460. Dataloading: 0.0024 s/iter. Inference: 0.0369 s/iter. Eval: 0.0513 s/iter. Total: 0.0906 s/iter. ETA=0:03:37\n",
      "\u001b[32m[07/05 22:32:08 d2.evaluation.evaluator]: \u001b[0mInference done 12129/14460. Dataloading: 0.0024 s/iter. Inference: 0.0368 s/iter. Eval: 0.0512 s/iter. Total: 0.0905 s/iter. ETA=0:03:31\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/05 22:32:13 d2.evaluation.evaluator]: \u001b[0mInference done 12195/14460. Dataloading: 0.0024 s/iter. Inference: 0.0368 s/iter. Eval: 0.0512 s/iter. Total: 0.0904 s/iter. ETA=0:03:24\n",
      "\u001b[32m[07/05 22:32:18 d2.evaluation.evaluator]: \u001b[0mInference done 12261/14460. Dataloading: 0.0024 s/iter. Inference: 0.0368 s/iter. Eval: 0.0511 s/iter. Total: 0.0904 s/iter. ETA=0:03:18\n",
      "\u001b[32m[07/05 22:32:23 d2.evaluation.evaluator]: \u001b[0mInference done 12327/14460. Dataloading: 0.0024 s/iter. Inference: 0.0368 s/iter. Eval: 0.0510 s/iter. Total: 0.0903 s/iter. ETA=0:03:12\n",
      "\u001b[32m[07/05 22:32:28 d2.evaluation.evaluator]: \u001b[0mInference done 12394/14460. Dataloading: 0.0024 s/iter. Inference: 0.0368 s/iter. Eval: 0.0510 s/iter. Total: 0.0902 s/iter. ETA=0:03:06\n",
      "\u001b[32m[07/05 22:32:33 d2.evaluation.evaluator]: \u001b[0mInference done 12460/14460. Dataloading: 0.0024 s/iter. Inference: 0.0368 s/iter. Eval: 0.0509 s/iter. Total: 0.0901 s/iter. ETA=0:03:00\n",
      "\u001b[32m[07/05 22:32:38 d2.evaluation.evaluator]: \u001b[0mInference done 12525/14460. Dataloading: 0.0024 s/iter. Inference: 0.0368 s/iter. Eval: 0.0508 s/iter. Total: 0.0901 s/iter. ETA=0:02:54\n",
      "\u001b[32m[07/05 22:32:43 d2.evaluation.evaluator]: \u001b[0mInference done 12591/14460. Dataloading: 0.0024 s/iter. Inference: 0.0368 s/iter. Eval: 0.0508 s/iter. Total: 0.0900 s/iter. ETA=0:02:48\n",
      "\u001b[32m[07/05 22:32:48 d2.evaluation.evaluator]: \u001b[0mInference done 12657/14460. Dataloading: 0.0024 s/iter. Inference: 0.0368 s/iter. Eval: 0.0507 s/iter. Total: 0.0899 s/iter. ETA=0:02:42\n",
      "\u001b[32m[07/05 22:32:53 d2.evaluation.evaluator]: \u001b[0mInference done 12721/14460. Dataloading: 0.0024 s/iter. Inference: 0.0368 s/iter. Eval: 0.0507 s/iter. Total: 0.0899 s/iter. ETA=0:02:36\n",
      "\u001b[32m[07/05 22:32:58 d2.evaluation.evaluator]: \u001b[0mInference done 12786/14460. Dataloading: 0.0024 s/iter. Inference: 0.0368 s/iter. Eval: 0.0506 s/iter. Total: 0.0898 s/iter. ETA=0:02:30\n",
      "\u001b[32m[07/05 22:33:04 d2.evaluation.evaluator]: \u001b[0mInference done 12851/14460. Dataloading: 0.0024 s/iter. Inference: 0.0368 s/iter. Eval: 0.0505 s/iter. Total: 0.0898 s/iter. ETA=0:02:24\n",
      "\u001b[32m[07/05 22:33:09 d2.evaluation.evaluator]: \u001b[0mInference done 12915/14460. Dataloading: 0.0024 s/iter. Inference: 0.0368 s/iter. Eval: 0.0505 s/iter. Total: 0.0897 s/iter. ETA=0:02:18\n",
      "\u001b[32m[07/05 22:33:14 d2.evaluation.evaluator]: \u001b[0mInference done 12979/14460. Dataloading: 0.0024 s/iter. Inference: 0.0368 s/iter. Eval: 0.0504 s/iter. Total: 0.0896 s/iter. ETA=0:02:12\n",
      "\u001b[32m[07/05 22:33:19 d2.evaluation.evaluator]: \u001b[0mInference done 13044/14460. Dataloading: 0.0024 s/iter. Inference: 0.0368 s/iter. Eval: 0.0504 s/iter. Total: 0.0896 s/iter. ETA=0:02:06\n",
      "\u001b[32m[07/05 22:33:24 d2.evaluation.evaluator]: \u001b[0mInference done 13110/14460. Dataloading: 0.0024 s/iter. Inference: 0.0367 s/iter. Eval: 0.0503 s/iter. Total: 0.0895 s/iter. ETA=0:02:00\n",
      "\u001b[32m[07/05 22:33:29 d2.evaluation.evaluator]: \u001b[0mInference done 13175/14460. Dataloading: 0.0024 s/iter. Inference: 0.0367 s/iter. Eval: 0.0503 s/iter. Total: 0.0895 s/iter. ETA=0:01:54\n",
      "\u001b[32m[07/05 22:33:34 d2.evaluation.evaluator]: \u001b[0mInference done 13240/14460. Dataloading: 0.0024 s/iter. Inference: 0.0367 s/iter. Eval: 0.0502 s/iter. Total: 0.0894 s/iter. ETA=0:01:49\n",
      "\u001b[32m[07/05 22:33:39 d2.evaluation.evaluator]: \u001b[0mInference done 13305/14460. Dataloading: 0.0024 s/iter. Inference: 0.0367 s/iter. Eval: 0.0502 s/iter. Total: 0.0893 s/iter. ETA=0:01:43\n",
      "\u001b[32m[07/05 22:33:44 d2.evaluation.evaluator]: \u001b[0mInference done 13370/14460. Dataloading: 0.0024 s/iter. Inference: 0.0367 s/iter. Eval: 0.0501 s/iter. Total: 0.0893 s/iter. ETA=0:01:37\n",
      "\u001b[32m[07/05 22:33:49 d2.evaluation.evaluator]: \u001b[0mInference done 13434/14460. Dataloading: 0.0024 s/iter. Inference: 0.0367 s/iter. Eval: 0.0501 s/iter. Total: 0.0892 s/iter. ETA=0:01:31\n",
      "\u001b[32m[07/05 22:33:54 d2.evaluation.evaluator]: \u001b[0mInference done 13498/14460. Dataloading: 0.0024 s/iter. Inference: 0.0367 s/iter. Eval: 0.0500 s/iter. Total: 0.0892 s/iter. ETA=0:01:25\n",
      "\u001b[32m[07/05 22:33:59 d2.evaluation.evaluator]: \u001b[0mInference done 13562/14460. Dataloading: 0.0024 s/iter. Inference: 0.0367 s/iter. Eval: 0.0500 s/iter. Total: 0.0891 s/iter. ETA=0:01:20\n",
      "\u001b[32m[07/05 22:34:04 d2.evaluation.evaluator]: \u001b[0mInference done 13626/14460. Dataloading: 0.0024 s/iter. Inference: 0.0367 s/iter. Eval: 0.0499 s/iter. Total: 0.0891 s/iter. ETA=0:01:14\n",
      "\u001b[32m[07/05 22:34:09 d2.evaluation.evaluator]: \u001b[0mInference done 13690/14460. Dataloading: 0.0024 s/iter. Inference: 0.0367 s/iter. Eval: 0.0499 s/iter. Total: 0.0890 s/iter. ETA=0:01:08\n",
      "\u001b[32m[07/05 22:34:14 d2.evaluation.evaluator]: \u001b[0mInference done 13753/14460. Dataloading: 0.0024 s/iter. Inference: 0.0367 s/iter. Eval: 0.0499 s/iter. Total: 0.0890 s/iter. ETA=0:01:02\n",
      "\u001b[32m[07/05 22:34:19 d2.evaluation.evaluator]: \u001b[0mInference done 13816/14460. Dataloading: 0.0024 s/iter. Inference: 0.0367 s/iter. Eval: 0.0498 s/iter. Total: 0.0889 s/iter. ETA=0:00:57\n",
      "\u001b[32m[07/05 22:34:24 d2.evaluation.evaluator]: \u001b[0mInference done 13877/14460. Dataloading: 0.0024 s/iter. Inference: 0.0367 s/iter. Eval: 0.0498 s/iter. Total: 0.0889 s/iter. ETA=0:00:51\n",
      "\u001b[32m[07/05 22:34:29 d2.evaluation.evaluator]: \u001b[0mInference done 13943/14460. Dataloading: 0.0024 s/iter. Inference: 0.0367 s/iter. Eval: 0.0497 s/iter. Total: 0.0889 s/iter. ETA=0:00:45\n",
      "\u001b[32m[07/05 22:34:34 d2.evaluation.evaluator]: \u001b[0mInference done 14008/14460. Dataloading: 0.0024 s/iter. Inference: 0.0367 s/iter. Eval: 0.0497 s/iter. Total: 0.0888 s/iter. ETA=0:00:40\n",
      "\u001b[32m[07/05 22:34:39 d2.evaluation.evaluator]: \u001b[0mInference done 14072/14460. Dataloading: 0.0024 s/iter. Inference: 0.0367 s/iter. Eval: 0.0497 s/iter. Total: 0.0888 s/iter. ETA=0:00:34\n",
      "\u001b[32m[07/05 22:34:44 d2.evaluation.evaluator]: \u001b[0mInference done 14137/14460. Dataloading: 0.0024 s/iter. Inference: 0.0367 s/iter. Eval: 0.0496 s/iter. Total: 0.0887 s/iter. ETA=0:00:28\n",
      "\u001b[32m[07/05 22:34:49 d2.evaluation.evaluator]: \u001b[0mInference done 14202/14460. Dataloading: 0.0024 s/iter. Inference: 0.0367 s/iter. Eval: 0.0496 s/iter. Total: 0.0887 s/iter. ETA=0:00:22\n",
      "\u001b[32m[07/05 22:34:54 d2.evaluation.evaluator]: \u001b[0mInference done 14266/14460. Dataloading: 0.0024 s/iter. Inference: 0.0366 s/iter. Eval: 0.0495 s/iter. Total: 0.0886 s/iter. ETA=0:00:17\n",
      "\u001b[32m[07/05 22:34:59 d2.evaluation.evaluator]: \u001b[0mInference done 14334/14460. Dataloading: 0.0024 s/iter. Inference: 0.0366 s/iter. Eval: 0.0495 s/iter. Total: 0.0885 s/iter. ETA=0:00:11\n",
      "\u001b[32m[07/05 22:35:04 d2.evaluation.evaluator]: \u001b[0mInference done 14401/14460. Dataloading: 0.0024 s/iter. Inference: 0.0366 s/iter. Eval: 0.0494 s/iter. Total: 0.0885 s/iter. ETA=0:00:05\n",
      "\u001b[32m[07/05 22:35:09 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:21:18.279608 (0.088432 s / iter per device, on 1 devices)\n",
      "\u001b[32m[07/05 22:35:09 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:08:49 (0.036632 s / iter per device, on 1 devices)\n",
      "\u001b[32m[07/05 22:35:11 d2.evaluation.sem_seg_evaluation]: \u001b[0mOrderedDict([('sem_seg', {'mIoU': 57.373962412497804, 'fwIoU': 82.66305498153986, 'IoU-Unlabeled': nan, 'IoU-Building': 77.993219766944, 'IoU-Fence': 31.77960612201226, 'IoU-Pedestrian': 71.02204708074348, 'IoU-Pole': 52.971897204963206, 'IoU-Road': 95.5866320365371, 'IoU-SideWalk': 70.78720896052103, 'IoU-Vegetation': 72.05380549819847, 'IoU-Vehicles': 83.46687908060395, 'IoU-Wall': 56.31784427013006, 'IoU-TrafficSign': 58.28732123566357, 'IoU-Sky': 84.89646155619597, 'IoU-TrafficLight': 58.12707660486816, 'IoU-Terrain': 24.44226382238454, 'IoU-ConstructionVehicle': 56.10233574354492, 'IoU-workzone_object': 66.41778825824619, 'IoU-Detour': 15.104973770905794, 'mACC': 72.6368594385374, 'pACC': 90.09976704678824, 'ACC-Unlabeled': nan, 'ACC-Building': 95.12893358528687, 'ACC-Fence': 52.34829496584621, 'ACC-Pedestrian': 84.32163251825011, 'ACC-Pole': 62.29406134822235, 'ACC-Road': 97.70065532422947, 'ACC-SideWalk': 85.56229728612573, 'ACC-Vegetation': 82.4611282242156, 'ACC-Vehicles': 91.46592696096825, 'ACC-Wall': 62.59500911651372, 'ACC-TrafficSign': 67.794748142962, 'ACC-Sky': 90.091692788157, 'ACC-TrafficLight': 67.64196965958016, 'ACC-Terrain': 25.474894880300408, 'ACC-ConstructionVehicle': 94.49825766654332, 'ACC-workzone_object': 86.26595525562556, 'ACC-Detour': 16.54429329377153})])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/05 22:35:11 d2.engine.defaults]: \u001b[0mEvaluation results for combined_all_night_val in csv format:\n",
      "\u001b[32m[07/05 22:35:11 d2.evaluation.testing]: \u001b[0mcopypaste: Task: sem_seg\n",
      "\u001b[32m[07/05 22:35:11 d2.evaluation.testing]: \u001b[0mcopypaste: mIoU,fwIoU,mACC,pACC\n",
      "\u001b[32m[07/05 22:35:11 d2.evaluation.testing]: \u001b[0mcopypaste: 57.3740,82.6631,72.6369,90.0998\n"
     ]
    }
   ],
   "source": [
    "trainer_both = Detectron2Trainer('combined_all_night_train', 'combined_all_night_val', output_folder='./output_both_40k')\n",
    "trainer_both.test()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fca1518",
   "metadata": {
    "id": "eCcw0VZ-Bzig"
   },
   "source": [
    "## 3. Model trained on all with carla night"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "9baa8d09",
   "metadata": {
    "id": "AhoGPVnKHiMw"
   },
   "outputs": [],
   "source": [
    "#trainer_all = Detectron2Trainer('combined_all_night_train', 'carla_rain_val', output_folder='./output_part_night_40k')\n",
    "#trainer_all.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "024cd308",
   "metadata": {
    "id": "67qzQSBbJK3G"
   },
   "outputs": [],
   "source": [
    "#trainer_all = Detectron2Trainer('combined_all_night_train', 'carla_night_rain_val', output_folder='./output_part_night_40k')\n",
    "#trainer_all.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "46a29dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainer_all = Detectron2Trainer('combined_all_night_train', 'cityscapes_rain_val', output_folder='./output_part_night_40k')\n",
    "#trainer_all.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "28a5c0dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainer_all = Detectron2Trainer('combined_all_night_train', 'cityscapes_clear_val', output_folder='./output_part_night_40k')\n",
    "#trainer_all.test()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f3745d",
   "metadata": {
    "id": "8BPrv2unBu_5",
    "tags": []
   },
   "source": [
    "## 2. Model trained on all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "2dcafb64",
   "metadata": {
    "id": "07d49a7f"
   },
   "outputs": [],
   "source": [
    "# trainer_all = Detectron2Trainer('combined_all_train', 'combined_all_val', output_folder='./output_combined_all_40k')\n",
    "# trainer_all.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "5c4a5332",
   "metadata": {
    "id": "5LBmVarGBljx"
   },
   "outputs": [],
   "source": [
    "# trainer_all = Detectron2Trainer('combined_all_train', 'combined_clear_val', output_folder='./output_combined_all_40k')\n",
    "# trainer_all.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "9ba149ab",
   "metadata": {
    "id": "qyXzC8KvEBHx"
   },
   "outputs": [],
   "source": [
    "# trainer_all = Detectron2Trainer('combined_all_train', 'combined_rain_val', output_folder='./output_combined_all_40k')\n",
    "# trainer_all.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "1eea3f94",
   "metadata": {
    "id": "AhoGPVnKHiMw"
   },
   "outputs": [],
   "source": [
    "# trainer_all = Detectron2Trainer('combined_all_train', 'carla_rain_val', output_folder='./output_combined_all_40k')\n",
    "# trainer_all.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "659b4030",
   "metadata": {
    "id": "67qzQSBbJK3G"
   },
   "outputs": [],
   "source": [
    "# trainer_all = Detectron2Trainer('combined_all_train', 'cityscapes_rain_val', output_folder='./output_combined_all_40k')\n",
    "# trainer_all.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "403e77f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer_all = Detectron2Trainer('combined_all_train', 'carla_clear_val', output_folder='./output_combined_all_40k')\n",
    "# trainer_all.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "aea3e23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer_all = Detectron2Trainer('combined_all_train', 'carla_night_rain_val', output_folder='./output_combined_all_40k')\n",
    "# trainer_all.test()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9367dd3b",
   "metadata": {
    "id": "eCcw0VZ-Bzig"
   },
   "source": [
    "## 1. Model trained on clear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "8aa5cac1",
   "metadata": {
    "id": "PlZ3ag3oEJoE"
   },
   "outputs": [],
   "source": [
    "#trainer_clear = Detectron2Trainer('combined_clear_train', 'combined_all_val', output_folder='./output_combined_clear_20k')\n",
    "#trainer_clear.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "2797baa4",
   "metadata": {
    "id": "Pca4DugyR6wJ"
   },
   "outputs": [],
   "source": [
    "#trainer_clear = Detectron2Trainer('combined_clear_train', 'combined_clear_val', output_folder='./output_combined_clear_20k')\n",
    "#trainer_clear.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "fe2e6053",
   "metadata": {
    "id": "RHbt_C-U0bzO"
   },
   "outputs": [],
   "source": [
    "#trainer_clear = Detectron2Trainer('combined_clear_train', 'combined_rain_val', output_folder='./output_combined_clear_20k')\n",
    "#trainer_clear.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "08aed8a8",
   "metadata": {
    "id": "AM8SDAduEQc0"
   },
   "outputs": [],
   "source": [
    "#trainer_clear = Detectron2Trainer('combined_clear_train', 'carla_rain_val', output_folder='./output_combined_clear_20k')\n",
    "#trainer_clear.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "e7d1f01e",
   "metadata": {
    "id": "C4geX49UE2Kn"
   },
   "outputs": [],
   "source": [
    "#trainer_clear = Detectron2Trainer('combined_clear_train', 'cityscapes_rain_val', output_folder='./output_combined_clear_20k')\n",
    "#trainer_clear.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "63f9b37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainer_clear = Detectron2Trainer('combined_clear_train', 'carla_clear_val', output_folder='./output_combined_clear_20k')\n",
    "#trainer_clear.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "72c3f667",
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainer_clear = Detectron2Trainer('combined_clear_train', 'carla_night_rain_val', output_folder='./output_combined_clear_20k')\n",
    "#trainer_clear.test()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "KVqmnxQOn4Nm"
   ],
   "name": "detectron2_trainer.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
