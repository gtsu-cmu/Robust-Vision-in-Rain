{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sm9l77kU-M7-"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U9DXzl_fo8N8"
      },
      "outputs": [],
      "source": [
        "!unzip /content/drive/MyDrive/data.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ktQ8ewHnZNmM"
      },
      "outputs": [],
      "source": [
        "train_raincityscapes_path = \"/content\"\n",
        "\n",
        "test_raincityscapes_path = \"/content\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "BtluDy0oasgo"
      },
      "outputs": [],
      "source": [
        "import datetime\n",
        "import os\n",
        "import torch\n",
        "import os.path\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "from torch.autograd import Variable\n",
        "from torch.backends import cudnn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms\n",
        "import random\n",
        "from PIL import Image\n",
        "import torch.nn.functional as F\n",
        "import torch.utils.data as data\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "vEkjz2hzeTwU"
      },
      "outputs": [],
      "source": [
        "class Compose(object):\n",
        "    def __init__(self, transforms):\n",
        "        self.transforms = transforms\n",
        "\n",
        "    def __call__(self, img, mask, depth):\n",
        "        assert img.size == mask.size\n",
        "        assert img.size == depth.size\n",
        "        for t in self.transforms:\n",
        "            img, mask, depth = t(img, mask, depth)\n",
        "        return img, mask, depth\n",
        "\n",
        "class Resize(object):\n",
        "    def __init__(self, size):\n",
        "        self.size = tuple(reversed(size))  # size: (h, w)\n",
        "\n",
        "    def __call__(self, img, mask, depth):\n",
        "        assert img.size == mask.size\n",
        "        assert img.size == depth.size\n",
        "        return img.resize(self.size, Image.BILINEAR), mask.resize(self.size, Image.BILINEAR), depth.resize(self.size, Image.BILINEAR)\n",
        "\n",
        "\n",
        "class RandomCrop(object):\n",
        "    def __init__(self, size):\n",
        "        self.size = size\n",
        "\n",
        "    def __call__(self, img, mask, depth):\n",
        "        assert img.size == mask.size\n",
        "        assert img.size == depth.size\n",
        "        w, h = img.size\n",
        "\n",
        "        x1 = random.randint(0, w - self.size)\n",
        "        y1 = random.randint(0, h - self.size)\n",
        "        return img.crop((x1, y1, x1 + self.size, y1 + self.size)), mask.crop((x1, y1, x1 + self.size, y1 + self.size)), depth.crop((x1, y1, x1 + self.size, y1 + self.size))\n",
        "\n",
        "\n",
        "class RandomHorizontallyFlip(object):\n",
        "    def __call__(self, img, mask, depth):\n",
        "        if random.random() < 0.5:\n",
        "            return img.transpose(Image.FLIP_LEFT_RIGHT), mask.transpose(Image.FLIP_LEFT_RIGHT), depth.transpose(Image.FLIP_LEFT_RIGHT)\n",
        "        return img, mask, depth"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "OzXatMQDeaAw"
      },
      "outputs": [],
      "source": [
        "class AvgMeter(object):\n",
        "    def __init__(self):\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.val = 0\n",
        "        self.avg = 0\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "\n",
        "    def update(self, val, n=1):\n",
        "        self.val = val\n",
        "        self.sum += val * n\n",
        "        self.count += n\n",
        "        self.avg = self.sum / self.count\n",
        "\n",
        "\n",
        "def check_mkdir(dir_name):\n",
        "    if not os.path.exists(dir_name):\n",
        "        os.mkdir(dir_name)\n",
        "\n",
        "\n",
        "class ReplayBuffer():\n",
        "    def __init__(self, max_size=50):\n",
        "        assert (max_size > 0), 'Empty buffer or trying to create a black hole. Be careful.'\n",
        "        self.max_size = max_size\n",
        "        self.data = []\n",
        "\n",
        "    def push_and_pop(self, data):\n",
        "        to_return = []\n",
        "        for element in data.data:\n",
        "            element = torch.unsqueeze(element, 0)\n",
        "            if len(self.data) < self.max_size:\n",
        "                self.data.append(element)\n",
        "                to_return.append(element)\n",
        "            else:\n",
        "                if random.uniform(0,1) > 0.5:\n",
        "                    i = random.randint(0, self.max_size-1)\n",
        "                    to_return.append(self.data[i].clone())\n",
        "                    self.data[i] = element\n",
        "                else:\n",
        "                    to_return.append(element)\n",
        "        return Variable(torch.cat(to_return))\n",
        "\n",
        "\n",
        "def mse_loss(input, target):\n",
        "    return torch.sum((input - target)**2) / input.data.nelement()\n",
        "\n",
        "\n",
        "def weights_init_normal(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find('Conv') != -1:\n",
        "        torch.nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
        "    elif classname.find('BatchNorm2d') != -1:\n",
        "        torch.nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
        "        torch.nn.init.constant_(m.bias.data, 0.0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "qbHZp7bYeg3j"
      },
      "outputs": [],
      "source": [
        "def make_dataset(root, is_train):\n",
        "    if is_train:\n",
        "\n",
        "        input = open(os.path.join(root, 'data/train_images.txt'))\n",
        "        ground_t = open(os.path.join(root, 'data/train_gt.txt'))\n",
        "        depth_t = open(os.path.join(root, 'data/train_depth.txt'))\n",
        "        image = [(os.path.join(root, img_name.strip('\\n'))) for img_name in\n",
        "                 input]\n",
        "        gt = [(os.path.join(root,  img_name.strip('\\n'))) for img_name in\n",
        "                 ground_t]\n",
        "        depth = [(os.path.join(root, img_name.strip('\\n'))) for img_name in\n",
        "              depth_t]\n",
        "\n",
        "        input.close()\n",
        "        ground_t.close()\n",
        "        depth_t.close()\n",
        "\n",
        "        return [[image[i], gt[i], depth[i]]for i in range(len(image))]\n",
        "\n",
        "    else:\n",
        "\n",
        "        input = open(os.path.join(root, 'data/test_images.txt'))\n",
        "        ground_t = open(os.path.join(root, 'data/test_gt.txt'))\n",
        "        depth_t = open(os.path.join(root, 'data/test_depth.txt'))\n",
        "\n",
        "        image = [(os.path.join(root, img_name.strip('\\n'))) for img_name in\n",
        "                 input]\n",
        "        gt = [(os.path.join(root, img_name.strip('\\n'))) for img_name in\n",
        "              ground_t]\n",
        "        depth = [(os.path.join(root, img_name.strip('\\n'))) for img_name in\n",
        "                 depth_t]\n",
        "\n",
        "        input.close()\n",
        "        ground_t.close()\n",
        "        depth_t.close()\n",
        "        \n",
        "  \n",
        "        return [[image[i], gt[i], depth[i]]for i in range(len(image))]\n",
        "\n",
        "\n",
        "\n",
        "class ImageFolder(data.Dataset):\n",
        "    def __init__(self, root, triple_transform=None, transform=None, target_transform=None, is_train=True):\n",
        "        self.root = root\n",
        "        self.imgs = make_dataset(root, is_train)\n",
        "        self.triple_transform = triple_transform\n",
        "        self.transform = transform\n",
        "        self.target_transform = target_transform\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        img_path, gt_path, depth_path = self.imgs[index]\n",
        "        \n",
        "        img = Image.open(img_path)\n",
        "        target = Image.open(gt_path)\n",
        "        depth = Image.open(depth_path)\n",
        "\n",
        "        if len(img.getbands()) == 4:\n",
        "          temp = np.asarray(img)\n",
        "          temp = temp[:,:,:3]\n",
        "          img = Image.fromarray(temp)\n",
        "        if len(target.getbands()) == 4:\n",
        "          temp = np.asarray(target)\n",
        "          temp = temp[:,:,:3]\n",
        "          target = Image.fromarray(temp)\n",
        "          \n",
        "        if self.triple_transform is not None:\n",
        "            img, target, depth = self.triple_transform(img, target, depth)\n",
        "        if self.transform is not None:\n",
        "            img = self.transform(img)\n",
        "        if self.target_transform is not None:\n",
        "            target = self.target_transform(target)\n",
        "            depth = self.target_transform(depth)\n",
        "          \n",
        "        return img, target, depth\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.imgs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "aYufnMOOfbi1"
      },
      "outputs": [],
      "source": [
        "cudnn.benchmark = True\n",
        "\n",
        "ckpt_path = '/content/drive/MyDrive/ckpt'\n",
        "exp_name = 'DGNLNet'\n",
        "\n",
        "args = {\n",
        "    'iter_num': 20,\n",
        "    'train_batch_size': 2,\n",
        "    'last_iter': 0,\n",
        "    'lr': 5e-4,\n",
        "    'lr_decay': 0.9,\n",
        "    'weight_decay': 0,\n",
        "    'momentum': 0.9,\n",
        "    'resume_snapshot': '',\n",
        "    'val_freq': 50000000,\n",
        "    'img_size_h': 512,\n",
        "\t'img_size_w': 1024,\n",
        "\t'crop_size': 512,\n",
        "    'snapshot_epochs': 1\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "m5GIfGipfnLH"
      },
      "outputs": [],
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor()\n",
        "    #transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "to_pil = transforms.ToPILImage()\n",
        "triple_transform = Compose([\n",
        "    Resize((args['img_size_h'], args['img_size_w'])),\n",
        "    #triple_transforms.RandomCrop(args['crop_size']),\n",
        "    RandomHorizontallyFlip()\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "xXcR12-7fx5V"
      },
      "outputs": [],
      "source": [
        "train_set = ImageFolder(train_raincityscapes_path, transform=transform, target_transform=transform, is_train = True,triple_transform=triple_transform)\n",
        "train_loader = DataLoader(train_set, batch_size=args['train_batch_size'], num_workers=4, shuffle=True)\n",
        "test1_set = ImageFolder(test_raincityscapes_path, transform=transform, target_transform=transform, is_train=False)\n",
        "test1_loader = DataLoader(test1_set, batch_size=2)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_set)"
      ],
      "metadata": {
        "id": "IbsKM5o0YUvP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb2a3ed8-ccc9-4904-ccc9-7cf8483f5742"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12595"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "Ko-FegnQmv1W"
      },
      "outputs": [],
      "source": [
        "criterion = nn.L1Loss()\n",
        "criterion_depth = nn.L1Loss()\n",
        "log_path = os.path.join(ckpt_path, exp_name, str(datetime.datetime.now()) + '.txt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "wvnXN-PJrfGM"
      },
      "outputs": [],
      "source": [
        "class DGNL(nn.Module):\n",
        "    def __init__(self, in_channels):\n",
        "        super(DGNL, self).__init__()\n",
        "\n",
        "        self.eps = 1e-6\n",
        "        self.sigma_pow2 = 100\n",
        "\n",
        "        self.theta = nn.Conv2d(in_channels, int(in_channels / 2), kernel_size=1)\n",
        "        self.phi = nn.Conv2d(in_channels, int(in_channels / 2), kernel_size=1)\n",
        "        self.g = nn.Conv2d(in_channels, int(in_channels / 2), kernel_size=1)\n",
        "\n",
        "        self.down = nn.Conv2d(in_channels, in_channels, kernel_size=4, stride=4, groups=in_channels, bias=False)\n",
        "        self.down.weight.data.fill_(1. / 16)\n",
        "\n",
        "        self.z = nn.Conv2d(int(in_channels / 2), in_channels, kernel_size=1)\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, x, depth_map):\n",
        "        n, c, h, w = x.size()\n",
        "        x_down = self.down(x)\n",
        "\n",
        "\t\t# [n, (h / 8) * (w / 8), c / 2]\n",
        "        g = F.max_pool2d(self.g(x_down), kernel_size=2, stride=2).view(n, int(c / 2), -1).transpose(1, 2)\n",
        "\n",
        "        ### appearance relation map\n",
        "        # [n, (h / 4) * (w / 4), c / 2]\n",
        "        theta = self.theta(x_down).view(n, int(c / 2), -1).transpose(1, 2)\n",
        "        # [n, c / 2, (h / 8) * (w / 8)]\n",
        "        phi = F.max_pool2d(self.phi(x_down), kernel_size=2, stride=2).view(n, int(c / 2), -1)\n",
        "\n",
        "\t\t# [n, (h / 4) * (w / 4), (h / 8) * (w / 8)]\n",
        "        Ra = F.softmax(torch.bmm(theta, phi), 2)\n",
        "\n",
        "\n",
        "        ### depth relation map\n",
        "        depth1 = F.interpolate(depth_map, size=[int(h / 4), int(w / 4)], mode='bilinear', align_corners = True).view(n, 1, int(h / 4)*int(w / 4)).transpose(1,2)\n",
        "        depth2 = F.interpolate(depth_map, size=[int(h / 8), int(w / 8)], mode='bilinear', align_corners = True).view(n, 1, int(h / 8)*int(w / 8))\n",
        "\n",
        "        # n, (h / 4) * (w / 4), (h / 8) * (w / 8)\n",
        "        depth1_expand = depth1.expand(n, int(h / 4) * int(w / 4), int(h / 8) * int(w / 8))\n",
        "        depth2_expand = depth2.expand(n, int(h / 4) * int(w / 4), int(h / 8) * int(w / 8))\n",
        "\n",
        "        Rd = torch.min(depth1_expand / (depth2_expand + self.eps), depth2_expand / (depth1_expand + self.eps))\n",
        "\n",
        "        Rd = F.softmax(Rd, 2)\n",
        "\n",
        "        S = F.softmax(Ra * Rd, 2)\n",
        "\n",
        "\n",
        "        # [n, c / 2, h / 4, w / 4]\n",
        "        y = torch.bmm(S, g).transpose(1, 2).contiguous().view(n, int(c / 2), int(h / 4), int(w / 4))\n",
        "\n",
        "        return x + F.upsample(self.z(y), size=x.size()[2:], mode='bilinear', align_corners = True)\n",
        "\n",
        "\n",
        "\n",
        "class NLB(nn.Module):\n",
        "    def __init__(self, in_channels):\n",
        "        super(NLB, self).__init__()\n",
        "        self.theta = nn.Conv2d(in_channels, int(in_channels / 2), kernel_size=1)\n",
        "        self.phi = nn.Conv2d(in_channels, int(in_channels / 2), kernel_size=1)\n",
        "        self.g = nn.Conv2d(in_channels, int(in_channels / 2), kernel_size=1)\n",
        "\n",
        "        self.down = nn.Conv2d(in_channels, in_channels, kernel_size=4, stride=4, groups=in_channels, bias=False)\n",
        "        self.down.weight.data.fill_(1. / 16)\n",
        "\n",
        "        self.z = nn.Conv2d(int(in_channels / 2), in_channels, kernel_size=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        n, c, h, w = x.size()\n",
        "        x_down = self.down(x)\n",
        "\n",
        "        # [n, (h / 4) * (w / 4), c / 2]\n",
        "        theta = self.theta(x_down).view(n, int(c / 2), -1).transpose(1, 2)\n",
        "        # [n, c / 2, (h / 8) * (w / 8)]\n",
        "        phi = F.max_pool2d(self.phi(x_down), kernel_size=2, stride=2).view(n, int(c / 2), -1)\n",
        "        # [n, (h / 8) * (w / 8), c / 2]\n",
        "        g = F.max_pool2d(self.g(x_down), kernel_size=2, stride=2).view(n, int(c / 2), -1).transpose(1, 2)\n",
        "        # [n, (h / 4) * (w / 4), (h / 8) * (w / 8)]\n",
        "        f = F.softmax(torch.bmm(theta, phi), 2)\n",
        "        # [n, c / 2, h / 4, w / 4]\n",
        "        y = torch.bmm(f, g).transpose(1, 2).contiguous().view(n, int(c / 2), int(h / 4), int(w / 4))\n",
        "\n",
        "        return x + F.upsample(self.z(y), size=x.size()[2:], mode='bilinear', align_corners=True)\n",
        "\n",
        "\n",
        "class DepthWiseDilatedResidualBlock(nn.Module):\n",
        "    def __init__(self, reduced_channels, channels, dilation):\n",
        "        super(DepthWiseDilatedResidualBlock, self).__init__()\n",
        "        self.conv0 = nn.Sequential(\n",
        "\n",
        "\t\t    # pw\n",
        "\t\t    nn.Conv2d(channels, channels * 2, 1, 1, 0, 1, bias=False),\n",
        "\t\t\tnn.ReLU6(inplace=True),\n",
        "\t\t    # dw\n",
        "\t\t    nn.Conv2d(channels*2, channels*2, kernel_size=3, padding=dilation, dilation=dilation, groups=channels, bias=False),\n",
        "\t\t    nn.ReLU6(inplace=True),\n",
        "\t\t    # pw-linear\n",
        "\t\t    nn.Conv2d(channels*2, channels, 1, 1, 0, 1, 1, bias=False)\n",
        "        )\n",
        "\n",
        "        self.conv1 = nn.Sequential(\n",
        "\t\n",
        "\t\t\tnn.Conv2d(channels, channels, kernel_size=3, padding=dilation, dilation=dilation, groups=channels,\n",
        "\t\t\t\t\t  bias=False),\n",
        "\t\t\tnn.ReLU6(inplace=True),\n",
        "\t\t\t# pw-linear\n",
        "\t\t\tnn.Conv2d(channels, channels, 1, 1, 0, 1, 1, bias=False)\n",
        "\t\t)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        res = self.conv1(self.conv0(x))\n",
        "        return res + x\n",
        "\n",
        "\n",
        "class DilatedResidualBlock(nn.Module):\n",
        "    def __init__(self, channels, dilation):\n",
        "        super(DilatedResidualBlock, self).__init__()\n",
        "        self.conv0 = nn.Sequential(\n",
        "            nn.Conv2d(channels, channels, kernel_size=3, padding=dilation, dilation=dilation), nn.ReLU()\n",
        "        )\n",
        "        self.conv1 = nn.Conv2d(channels, channels, kernel_size=3, padding=dilation, dilation=dilation)\n",
        "\n",
        "    def forward(self, x):\n",
        "        conv0 = self.conv0(x)\n",
        "        conv1 = self.conv1(conv0)\n",
        "        return x + conv1\n",
        "\n",
        "\n",
        "class SpatialRNN(nn.Module):\n",
        "\t\"\"\"\n",
        "\tSpatialRNN model for one direction only\n",
        "\t\"\"\"\n",
        "\tdef __init__(self, alpha = 1.0, channel_num = 1, direction = \"right\"):\n",
        "\t\tsuper(SpatialRNN, self).__init__()\n",
        "\t\tself.alpha = nn.Parameter(torch.Tensor([alpha] * channel_num))\n",
        "\t\tself.direction = direction\n",
        "\n",
        "\tdef __getitem__(self, item):\n",
        "\t\treturn self.alpha[item]\n",
        "\n",
        "\tdef __len__(self):\n",
        "\t\treturn len(self.alpha)\n",
        "\n",
        "\n",
        "\tdef forward(self, x):\n",
        "\t\t\"\"\"\n",
        "\t\t:param x: (N,C,H,W)\n",
        "\t\t:return:\n",
        "\t\t\"\"\"\n",
        "\t\theight = x.size(2)\n",
        "\t\tweight = x.size(3)\n",
        "\t\tx_out = []\n",
        "\n",
        "\t\t# from left to right\n",
        "\t\tif self.direction == \"right\":\n",
        "\t\t\tx_out = [x[:, :, :, 0].clamp(min=0)]\n",
        "\n",
        "\t\t\tfor i in range(1, weight):\n",
        "\t\t\t\ttemp = (self.alpha.unsqueeze(1) * x_out[i - 1] + x[:, :, :, i]).clamp(min=0)\n",
        "\t\t\t\tx_out.append(temp)  # a list of tensor\n",
        "\n",
        "\t\t\treturn torch.stack(x_out, 3)  # merge into one tensor\n",
        "\n",
        "\t\t# from right to left\n",
        "\t\telif self.direction == \"left\":\n",
        "\t\t\tx_out = [x[:, :, :, -1].clamp(min=0)]\n",
        "\n",
        "\t\t\tfor i in range(1, weight):\n",
        "\t\t\t\ttemp = (self.alpha.unsqueeze(1) * x_out[i - 1] + x[:, :, :, -i - 1]).clamp(min=0)\n",
        "\t\t\t\tx_out.append(temp)\n",
        "\n",
        "\t\t\tx_out.reverse()\n",
        "\t\t\treturn torch.stack(x_out, 3)\n",
        "\n",
        "\t\t# from up to down\n",
        "\t\telif self.direction == \"down\":\n",
        "\t\t\tx_out = [x[:, :, 0, :].clamp(min=0)]\n",
        "\n",
        "\t\t\tfor i in range(1, height):\n",
        "\t\t\t\ttemp = (self.alpha.unsqueeze(1) * x_out[i - 1] + x[:, :, i, :]).clamp(min=0)\n",
        "\t\t\t\tx_out.append(temp)\n",
        "\n",
        "\t\t\treturn torch.stack(x_out, 2)\n",
        "\n",
        "\t\t# from down to up\n",
        "\t\telif self.direction == \"up\":\n",
        "\t\t\tx_out = [x[:, :, -1, :].clamp(min=0)]\n",
        "\n",
        "\t\t\tfor i in range(1, height):\n",
        "\t\t\t\ttemp = (self.alpha.unsqueeze(1) * x_out[i - 1] + x[:, :, -i - 1, :]).clamp(min=0)\n",
        "\t\t\t\tx_out.append(temp)\n",
        "\n",
        "\t\t\tx_out.reverse()\n",
        "\t\t\treturn torch.stack(x_out, 2)\n",
        "\n",
        "\t\telse:\n",
        "\t\t\tprint(\"Invalid direction in SpatialRNN!\")\n",
        "\t\t\treturn KeyError\n",
        "\n",
        "\n",
        "\n",
        "class TVLoss(nn.Module):\n",
        "    def __init__(self, tv_loss_weight=1):\n",
        "        super(TVLoss, self).__init__()\n",
        "        self.tv_loss_weight = tv_loss_weight\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch_size = x.size()[0]\n",
        "        h_x = x.size()[2]\n",
        "        w_x = x.size()[3]\n",
        "        count_h = self.tensor_size(x[:, :, 1:, :])\n",
        "        count_w = self.tensor_size(x[:, :, :, 1:])\n",
        "        h_tv = torch.pow((x[:, :, 1:, :] - x[:, :, :h_x - 1, :]), 2).sum()\n",
        "        w_tv = torch.pow((x[:, :, :, 1:] - x[:, :, :, :w_x - 1]), 2).sum()\n",
        "        return self.tv_loss_weight * 2 * (h_tv / count_h + w_tv / count_w) / batch_size\n",
        "\n",
        "    @staticmethod\n",
        "    def tensor_size(t):\n",
        "        return t.size()[1] * t.size()[2] * t.size()[3]\n",
        "\n",
        "\n",
        "class NLB(nn.Module):\n",
        "    def __init__(self, in_channels):\n",
        "        super(NLB, self).__init__()\n",
        "        self.theta = nn.Conv2d(in_channels, int(in_channels / 2), kernel_size=1)\n",
        "        self.phi = nn.Conv2d(in_channels, int(in_channels / 2), kernel_size=1)\n",
        "        self.g = nn.Conv2d(in_channels, int(in_channels / 2), kernel_size=1)\n",
        "\n",
        "        self.down = nn.Conv2d(in_channels, in_channels, kernel_size=4, stride=4, groups=in_channels, bias=False)\n",
        "        self.down.weight.data.fill_(1. / 16)\n",
        "\n",
        "        self.z = nn.Conv2d(int(in_channels / 2), in_channels, kernel_size=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        n, c, h, w = x.size()\n",
        "        x_down = self.down(x)\n",
        "\n",
        "        # [n, (h / 4) * (w / 4), c / 2]\n",
        "        theta = self.theta(x_down).view(n, int(c / 2), -1).transpose(1, 2)\n",
        "        # [n, c / 2, (h / 8) * (w / 8)]\n",
        "        phi = F.max_pool2d(self.phi(x_down), kernel_size=2, stride=2).view(n, int(c / 2), -1)\n",
        "        # [n, (h / 8) * (w / 8), c / 2]\n",
        "        g = F.max_pool2d(self.g(x_down), kernel_size=2, stride=2).view(n, int(c / 2), -1).transpose(1, 2)\n",
        "        # [n, (h / 4) * (w / 4), (h / 8) * (w / 8)]\n",
        "        f = F.softmax(torch.bmm(theta, phi), 2)\n",
        "        # [n, c / 2, h / 4, w / 4]\n",
        "        y = torch.bmm(f, g).transpose(1, 2).contiguous().view(n, int(c / 2), int(h / 4), int(w / 4))\n",
        "\n",
        "        return x + F.upsample(self.z(y), size=x.size()[2:], mode='bilinear', align_corners=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "_Zc-2FTEsX8r"
      },
      "outputs": [],
      "source": [
        "class DGNLNet_fast(nn.Module):\n",
        "    def __init__(self, num_features=64):\n",
        "        super(DGNLNet_fast, self).__init__()\n",
        "        self.mean = torch.zeros(1, 3, 1, 1)\n",
        "        self.std = torch.zeros(1, 3, 1, 1)\n",
        "        self.mean[0, 0, 0, 0] = 0.485\n",
        "        self.mean[0, 1, 0, 0] = 0.456\n",
        "        self.mean[0, 2, 0, 0] = 0.406\n",
        "        self.std[0, 0, 0, 0] = 0.229\n",
        "        self.std[0, 1, 0, 0] = 0.224\n",
        "        self.std[0, 2, 0, 0] = 0.225\n",
        "\n",
        "        self.mean = nn.Parameter(self.mean)\n",
        "        self.std = nn.Parameter(self.std)\n",
        "        self.mean.requires_grad = False\n",
        "        self.std.requires_grad = False\n",
        "\n",
        "        ############################################ Depth prediction network\n",
        "        self.conv1 = nn.Sequential(\n",
        "\t\t\tnn.Conv2d(3, 32, 8, stride=4, padding=2),\n",
        "\t\t\tnn.GroupNorm(num_groups=32, num_channels=32),\n",
        "\t\t\tnn.SELU(inplace=True)\n",
        "\t\t)\n",
        "\n",
        "        self.conv2 = nn.Sequential(\n",
        "\t\t\tnn.Conv2d(32, 64, 4, stride=2, padding=1),\n",
        "\t\t\tnn.GroupNorm(num_groups=32, num_channels=64),\n",
        "\t\t\tnn.SELU(inplace=True)\n",
        "\t\t)\n",
        "\n",
        "        self.conv3 = nn.Sequential(\n",
        "\t\t\tnn.Conv2d(64, 128, 4, stride=2, padding=1),\n",
        "\t\t\tnn.GroupNorm(num_groups=32, num_channels=128),\n",
        "\t\t\tnn.SELU(inplace=True)\n",
        "\t\t)\n",
        "\n",
        "        self.conv5 = nn.Sequential(\n",
        "\t\t\tnn.Conv2d(128, 128, 3, padding=2, dilation=2),\n",
        "\t\t\tnn.GroupNorm(num_groups=32, num_channels=128),\n",
        "\t\t\tnn.SELU(inplace=True)\n",
        "\t\t)\n",
        "\n",
        "        self.conv8 = nn.Sequential(\n",
        "\t\t\tnn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1),\n",
        "\t\t\tnn.GroupNorm(num_groups=32, num_channels=64),\n",
        "\t\t\tnn.SELU(inplace=True)\n",
        "\t\t)\n",
        "\n",
        "        self.conv9 = nn.Sequential(\n",
        "\t\t\tnn.ConvTranspose2d(64, 32, kernel_size=4, stride=2, padding=1),\n",
        "\t\t\tnn.GroupNorm(num_groups=32, num_channels=32),\n",
        "\t\t\tnn.SELU(inplace=True)\n",
        "\t\t)\n",
        "\n",
        "\n",
        "        self.depth_pred = nn.Sequential(\n",
        "\t\t\tnn.Conv2d(32, 32, kernel_size=3, padding=1),\n",
        "\t\t\tnn.GroupNorm(num_groups=32, num_channels=32),\n",
        "\t\t\tnn.SELU(inplace=True),\n",
        "\t\t\tnn.Conv2d(32, 1, kernel_size=1, stride=1, padding=0),\n",
        "\t\t\tnn.Sigmoid()\n",
        "\t\t)\n",
        "\n",
        "\t############################################ Rain removal network\n",
        "\n",
        "\n",
        "        self.head = nn.Sequential(\n",
        "\t\t\t# pw\n",
        "\t\t\tnn.Conv2d(3, 32, 1, 1, 0, 1, bias=False),\n",
        "\t\t\tnn.ReLU6(inplace=True),\n",
        "\t\t\t# dw\n",
        "\t\t\tnn.Conv2d(32, 32, kernel_size=8, stride=4, padding=2, groups=32, bias=False),\n",
        "\t\t\tnn.ReLU6(inplace=True),\n",
        "\t\t\t# pw-linear\n",
        "\t\t\tnn.Conv2d(32, num_features, 1, 1, 0, 1, 1, bias=False),\n",
        "\t\t)\n",
        "\n",
        "        self.body = nn.Sequential(\n",
        "\t\t\tDepthWiseDilatedResidualBlock(num_features, num_features, 1),\n",
        "\t\t\t# DepthWiseDilatedResidualBlock(num_features, num_features, 1),\n",
        "\t\t\tDepthWiseDilatedResidualBlock(num_features, num_features, 2),\n",
        "\t\t\tDepthWiseDilatedResidualBlock(num_features, num_features, 2),\n",
        "\t\t\tDepthWiseDilatedResidualBlock(num_features, num_features, 4),\n",
        "\t\t\tDepthWiseDilatedResidualBlock(num_features, num_features, 8),\n",
        "\t\t\tDepthWiseDilatedResidualBlock(num_features, num_features, 4),\n",
        "\t\t\tDepthWiseDilatedResidualBlock(num_features, num_features, 2),\n",
        "\t\t\tDepthWiseDilatedResidualBlock(num_features, num_features, 2),\n",
        "\t\t\t# DepthWiseDilatedResidualBlock(num_features, num_features, 1),\n",
        "\t\t\tDepthWiseDilatedResidualBlock(num_features, num_features, 1)\n",
        "\t\t)\n",
        "\n",
        "\n",
        "        self.dgnlb = DGNL(num_features)\n",
        "\n",
        "\n",
        "        self.tail = nn.Sequential(\n",
        "\t\t\t# dw\n",
        "\t\t\tnn.ConvTranspose2d(num_features, 32, kernel_size=8, stride=4, padding=2, groups=32, bias=False),\n",
        "\t\t\tnn.ReLU6(inplace=True),\n",
        "\t\t\t# pw-linear\n",
        "\t\t\tnn.Conv2d(32, 3, 1, 1, 0, 1, bias=False),\n",
        "\t\t)\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.ReLU):\n",
        "                m.inplace = True\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = (x - self.mean) / self.std\n",
        "\n",
        "        ################################## depth prediction\n",
        "        d_f1 = self.conv1(x)\n",
        "        d_f2 = self.conv2(d_f1)\n",
        "        d_f3 = self.conv3(d_f2)\n",
        "        d_f5 = self.conv5(d_f3)\n",
        "        d_f8 = self.conv8(d_f5)\n",
        "        d_f9 = self.conv9(d_f8 + d_f2)\n",
        "        depth_pred = self.depth_pred(d_f9 + d_f1)\n",
        "\n",
        "        ################################## rain removal\n",
        "\n",
        "        f = self.head(x)\n",
        "        f = self.body(f)\n",
        "        f = self.dgnlb(f, depth_pred.detach())\n",
        "        r = self.tail(f)\n",
        "        x = x + r\n",
        "\n",
        "        x = (x * self.std + self.mean).clamp(min=0, max=1)\n",
        "\n",
        "        if self.training:\n",
        "            return x, F.upsample(depth_pred, size=x.size()[2:], mode='bilinear', align_corners=True)\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "\n",
        "class DGNLNet(nn.Module):\n",
        "    def __init__(self, num_features=64):\n",
        "        super(DGNLNet, self).__init__()\n",
        "        self.mean = torch.zeros(1, 3, 1, 1)\n",
        "        self.std = torch.zeros(1, 3, 1, 1)\n",
        "        self.mean[0, 0, 0, 0] = 0.485\n",
        "        self.mean[0, 1, 0, 0] = 0.456\n",
        "        self.mean[0, 2, 0, 0] = 0.406\n",
        "        self.std[0, 0, 0, 0] = 0.229\n",
        "        self.std[0, 1, 0, 0] = 0.224\n",
        "        self.std[0, 2, 0, 0] = 0.225\n",
        "\n",
        "        self.mean = nn.Parameter(self.mean)\n",
        "        self.std = nn.Parameter(self.std)\n",
        "        self.mean.requires_grad = False\n",
        "        self.std.requires_grad = False\n",
        "\n",
        "        ############################################ Depth prediction network\n",
        "        self.conv1 = nn.Sequential(\n",
        "\t\t\tnn.Conv2d(3, 32, 4, stride=2, padding=1),\n",
        "\t\t\tnn.GroupNorm(num_groups=32, num_channels=32),\n",
        "\t\t\tnn.SELU(inplace=True)\n",
        "\t\t)\n",
        "\n",
        "        self.conv2 = nn.Sequential(\n",
        "\t\t\tnn.Conv2d(32, 64, 4, stride=2, padding=1),\n",
        "\t\t\tnn.GroupNorm(num_groups=32, num_channels=64),\n",
        "\t\t\tnn.SELU(inplace=True)\n",
        "\t\t)\n",
        "\n",
        "        self.conv3 = nn.Sequential(\n",
        "\t\t\tnn.Conv2d(64, 128, 4, stride=2, padding=1),\n",
        "\t\t\tnn.GroupNorm(num_groups=32, num_channels=128),\n",
        "\t\t\tnn.SELU(inplace=True)\n",
        "\t\t)\n",
        "\n",
        "        self.conv4 = nn.Sequential(\n",
        "\t\t\tnn.Conv2d(128, 256, 4, stride=2, padding=1),\n",
        "\t\t\tnn.GroupNorm(num_groups=32, num_channels=256),\n",
        "\t\t\tnn.SELU(inplace=True)\n",
        "\t\t)\n",
        "\n",
        "        self.conv5 = nn.Sequential(\n",
        "\t\t\tnn.Conv2d(256, 256, 3, padding=2, dilation=2),\n",
        "\t\t\tnn.GroupNorm(num_groups=32, num_channels=256),\n",
        "\t\t\tnn.SELU(inplace=True)\n",
        "\t\t)\n",
        "\n",
        "        self.conv6 = nn.Sequential(\n",
        "\t\t\tnn.Conv2d(256, 256, 3, padding=4, dilation=4),\n",
        "\t\t\tnn.GroupNorm(num_groups=32, num_channels=256),\n",
        "\t\t\tnn.SELU(inplace=True)\n",
        "\t\t)\n",
        "\n",
        "        self.conv7 = nn.Sequential(\n",
        "\t\t\tnn.Conv2d(256, 256, 3, padding=2, dilation=2),\n",
        "\t\t\tnn.GroupNorm(num_groups=32, num_channels=256),\n",
        "\t\t\tnn.SELU(inplace=True)\n",
        "\t\t)\n",
        "\n",
        "        self.conv8 = nn.Sequential(\n",
        "\t\t\tnn.ConvTranspose2d(256, 128, kernel_size=4, stride=2, padding=1),\n",
        "\t\t\tnn.GroupNorm(num_groups=32, num_channels=128),\n",
        "\t\t\tnn.SELU(inplace=True)\n",
        "\t\t)\n",
        "\n",
        "        self.conv9 = nn.Sequential(\n",
        "\t\t\tnn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1),\n",
        "\t\t\tnn.GroupNorm(num_groups=32, num_channels=64),\n",
        "\t\t\tnn.SELU(inplace=True)\n",
        "\t\t)\n",
        "\n",
        "        self.conv10 = nn.Sequential(\n",
        "\t\t\tnn.ConvTranspose2d(64, 32, kernel_size=4, stride=2, padding=1),\n",
        "\t\t\tnn.GroupNorm(num_groups=32, num_channels=32),\n",
        "\t\t\tnn.SELU(inplace=True)\n",
        "\t\t)\n",
        "\n",
        "        self.depth_pred = nn.Sequential(\n",
        "\t\t\tnn.ConvTranspose2d(32, 32, kernel_size=4, stride=2, padding=1),\n",
        "\t\t\tnn.GroupNorm(num_groups=32, num_channels=32),\n",
        "\t\t\tnn.SELU(inplace=True),\n",
        "\t\t\tnn.Conv2d(32, 32, kernel_size=3, padding=1),\n",
        "\t\t\tnn.SELU(inplace=True),\n",
        "\t\t\tnn.Conv2d(32, 1, kernel_size=1, stride=1, padding=0),\n",
        "\t\t\tnn.Sigmoid()\n",
        "\t\t)\n",
        "\n",
        "\t############################################ Rain removal network\n",
        "\n",
        "        self.head = nn.Sequential(\n",
        "            nn.Conv2d(3, 32, kernel_size=4, stride=2, padding=1), nn.ReLU(),\n",
        "            nn.Conv2d(32, num_features, kernel_size=1, stride=1, padding=0), nn.ReLU()\n",
        "        )\n",
        "        self.body = nn.Sequential(\n",
        "            DilatedResidualBlock(num_features, 1),\n",
        "            DilatedResidualBlock(num_features, 1),\n",
        "            DilatedResidualBlock(num_features, 2),\n",
        "            DilatedResidualBlock(num_features, 2),\n",
        "            DilatedResidualBlock(num_features, 4),\n",
        "            DilatedResidualBlock(num_features, 8),\n",
        "            DilatedResidualBlock(num_features, 4),\n",
        "            DilatedResidualBlock(num_features, 2),\n",
        "            DilatedResidualBlock(num_features, 2),\n",
        "            DilatedResidualBlock(num_features, 1),\n",
        "            DilatedResidualBlock(num_features, 1)\n",
        "        )\n",
        "\n",
        "        self.dgnlb = DGNL(num_features)\n",
        "\n",
        "        self.tail = nn.Sequential(\n",
        "            # nn.Conv2d(num_features, num_features, kernel_size=3, padding=1), nn.ReLU(),\n",
        "            nn.ConvTranspose2d(num_features, 32, kernel_size=4, stride=2, padding=1), nn.ReLU(),\n",
        "            nn.Conv2d(32, 3, kernel_size=3, padding=1)\n",
        "        )\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.ReLU):\n",
        "                m.inplace = True\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = (x - self.mean) / self.std\n",
        "\n",
        "        ################################## depth prediction\n",
        "        d_f1 = self.conv1(x)\n",
        "        d_f2 = self.conv2(d_f1)\n",
        "        d_f3 = self.conv3(d_f2)\n",
        "        d_f4 = self.conv4(d_f3)\n",
        "        d_f5 = self.conv5(d_f4)\n",
        "        d_f6 = self.conv6(d_f5)\n",
        "        d_f7 = self.conv7(d_f6)\n",
        "        d_f8 = self.conv8(d_f7)\n",
        "        d_f9 = self.conv9(d_f8 + d_f3)\n",
        "        d_f10 = self.conv10(d_f9 + d_f2)\n",
        "        depth_pred = self.depth_pred(d_f10 + d_f1)\n",
        "\n",
        "        ################################## rain removal\n",
        "\n",
        "        f = self.head(x)\n",
        "        f = self.body(f)\n",
        "        f = self.dgnlb(f, depth_pred.detach())\n",
        "        r = self.tail(f)\n",
        "        x = x + r\n",
        "\n",
        "        x = (x * self.std + self.mean).clamp(min=0, max=1)\n",
        "\n",
        "        if self.training:\n",
        "            return x, depth_pred\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "class basic_NL(nn.Module):\n",
        "    def __init__(self, num_features=64):\n",
        "        super(basic_NL, self).__init__()\n",
        "        self.mean = torch.zeros(1, 3, 1, 1)\n",
        "        self.std = torch.zeros(1, 3, 1, 1)\n",
        "        self.mean[0, 0, 0, 0] = 0.485\n",
        "        self.mean[0, 1, 0, 0] = 0.456\n",
        "        self.mean[0, 2, 0, 0] = 0.406\n",
        "        self.std[0, 0, 0, 0] = 0.229\n",
        "        self.std[0, 1, 0, 0] = 0.224\n",
        "        self.std[0, 2, 0, 0] = 0.225\n",
        "\n",
        "        self.mean = nn.Parameter(self.mean)\n",
        "        self.std = nn.Parameter(self.std)\n",
        "        self.mean.requires_grad = False\n",
        "        self.std.requires_grad = False\n",
        "\n",
        "        self.head = nn.Sequential(\n",
        "            nn.Conv2d(3, 32, kernel_size=4, stride=2, padding=1), nn.ReLU(),\n",
        "            nn.Conv2d(32, num_features, kernel_size=1, stride=1, padding=0), nn.ReLU()\n",
        "        )\n",
        "        self.body = nn.Sequential(\n",
        "            DilatedResidualBlock(num_features, 1),\n",
        "            DilatedResidualBlock(num_features, 1),\n",
        "            DilatedResidualBlock(num_features, 2),\n",
        "            DilatedResidualBlock(num_features, 2),\n",
        "            DilatedResidualBlock(num_features, 4),\n",
        "            DilatedResidualBlock(num_features, 8),\n",
        "            DilatedResidualBlock(num_features, 4),\n",
        "            DilatedResidualBlock(num_features, 2),\n",
        "            DilatedResidualBlock(num_features, 2),\n",
        "            DilatedResidualBlock(num_features, 1),\n",
        "            DilatedResidualBlock(num_features, 1)\n",
        "        )\n",
        "\n",
        "        self.nlb = NLB(num_features)\n",
        "\n",
        "        self.tail = nn.Sequential(\n",
        "            # nn.Conv2d(num_features, num_features, kernel_size=3, padding=1), nn.ReLU(),\n",
        "            nn.ConvTranspose2d(num_features, 32, kernel_size=4, stride=2, padding=1), nn.ReLU(),\n",
        "            nn.Conv2d(32, 3, kernel_size=3, padding=1)\n",
        "        )\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.ReLU):\n",
        "                m.inplace = True\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = (x - self.mean) / self.std\n",
        "\n",
        "        f = self.head(x)\n",
        "        f = self.body(f)\n",
        "        f = self.nlb(f)\n",
        "        r = self.tail(f)\n",
        "        x = x + r\n",
        "\n",
        "        x = (x * self.std + self.mean).clamp(min=0, max=1)\n",
        "        return x\n",
        "\n",
        "\n",
        "\n",
        "class basic(nn.Module):\n",
        "    def __init__(self, num_features=64):\n",
        "        super(basic, self).__init__()\n",
        "        self.mean = torch.zeros(1, 3, 1, 1)\n",
        "        self.std = torch.zeros(1, 3, 1, 1)\n",
        "        self.mean[0, 0, 0, 0] = 0.485\n",
        "        self.mean[0, 1, 0, 0] = 0.456\n",
        "        self.mean[0, 2, 0, 0] = 0.406\n",
        "        self.std[0, 0, 0, 0] = 0.229\n",
        "        self.std[0, 1, 0, 0] = 0.224\n",
        "        self.std[0, 2, 0, 0] = 0.225\n",
        "\n",
        "        self.mean = nn.Parameter(self.mean)\n",
        "        self.std = nn.Parameter(self.std)\n",
        "        self.mean.requires_grad = False\n",
        "        self.std.requires_grad = False\n",
        "\n",
        "        self.head = nn.Sequential(\n",
        "            nn.Conv2d(3, 32, kernel_size=4, stride = 2 ,padding=1), nn.ReLU(),\n",
        "\t\t\tnn.Conv2d(32, num_features, kernel_size=1, stride=1, padding=0), nn.ReLU()\n",
        "        )\n",
        "        self.body = nn.Sequential(\n",
        "            DilatedResidualBlock(num_features, 1),\n",
        "            DilatedResidualBlock(num_features, 1),\n",
        "            DilatedResidualBlock(num_features, 2),\n",
        "            DilatedResidualBlock(num_features, 2),\n",
        "            DilatedResidualBlock(num_features, 4),\n",
        "            DilatedResidualBlock(num_features, 8),\n",
        "            DilatedResidualBlock(num_features, 4),\n",
        "            DilatedResidualBlock(num_features, 2),\n",
        "            DilatedResidualBlock(num_features, 2),\n",
        "            DilatedResidualBlock(num_features, 1),\n",
        "            DilatedResidualBlock(num_features, 1)\n",
        "        )\n",
        "\n",
        "        self.tail = nn.Sequential(\n",
        "            #nn.Conv2d(num_features, num_features, kernel_size=3, padding=1), nn.ReLU(),\n",
        "            nn.ConvTranspose2d(num_features, 32, kernel_size=4, stride=2, padding=1), nn.ReLU(),\n",
        "            nn.Conv2d(32, 3, kernel_size=3, padding=1)\n",
        "        )\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.ReLU):\n",
        "                m.inplace = True\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = (x - self.mean) / self.std\n",
        "\n",
        "        f = self.head(x)\n",
        "        f = self.body(f)\n",
        "        r = self.tail(f)\n",
        "        x = x + r\n",
        "\n",
        "        x = (x * self.std + self.mean).clamp(min=0, max=1)\n",
        "        return x\n",
        "\n",
        "\n",
        "\n",
        "class depth_predciton(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(depth_predciton, self).__init__()\n",
        "        self.mean = torch.zeros(1, 3, 1, 1)\n",
        "        self.std = torch.zeros(1, 3, 1, 1)\n",
        "        self.mean[0, 0, 0, 0] = 0.485\n",
        "        self.mean[0, 1, 0, 0] = 0.456\n",
        "        self.mean[0, 2, 0, 0] = 0.406\n",
        "        self.std[0, 0, 0, 0] = 0.229\n",
        "        self.std[0, 1, 0, 0] = 0.224\n",
        "        self.std[0, 2, 0, 0] = 0.225\n",
        "\n",
        "        self.mean = nn.Parameter(self.mean)\n",
        "        self.std = nn.Parameter(self.std)\n",
        "        self.mean.requires_grad = False\n",
        "        self.std.requires_grad = False\n",
        "\n",
        "\n",
        "        self.conv1 = nn.Sequential(\n",
        "            nn.Conv2d(3, 32, 4, stride=2, padding=1),\n",
        "            nn.GroupNorm(num_groups=32, num_channels=32),\n",
        "            nn.SELU(inplace=True)\n",
        "        )\n",
        "\n",
        "        self.conv2 = nn.Sequential(\n",
        "            nn.Conv2d(32, 64, 4, stride=2, padding=1),\n",
        "            nn.GroupNorm(num_groups=32, num_channels=64),\n",
        "            nn.SELU(inplace=True)\n",
        "        )\n",
        "\n",
        "        self.conv3 = nn.Sequential(\n",
        "            nn.Conv2d(64, 128, 4, stride=2, padding=1),\n",
        "            nn.GroupNorm(num_groups=32, num_channels=128),\n",
        "            nn.SELU(inplace=True)\n",
        "        )\n",
        "\n",
        "        self.conv4 = nn.Sequential(\n",
        "            nn.Conv2d(128, 256, 4, stride=2, padding=1),\n",
        "            nn.GroupNorm(num_groups=32, num_channels=256),\n",
        "            nn.SELU(inplace=True)\n",
        "        )\n",
        "\n",
        "        self.conv5 = nn.Sequential(\n",
        "            nn.Conv2d(256, 256, 3, padding=2, dilation=2),\n",
        "            nn.GroupNorm(num_groups=32, num_channels=256),\n",
        "            nn.SELU(inplace=True)\n",
        "        )\n",
        "\n",
        "        self.conv6 = nn.Sequential(\n",
        "            nn.Conv2d(256, 256, 3, padding=4, dilation=4),\n",
        "            nn.GroupNorm(num_groups=32, num_channels=256),\n",
        "            nn.SELU(inplace=True)\n",
        "        )\n",
        "\n",
        "        self.conv7 = nn.Sequential(\n",
        "            nn.Conv2d(256, 256, 3, padding=2, dilation=2),\n",
        "            nn.GroupNorm(num_groups=32, num_channels=256),\n",
        "            nn.SELU(inplace=True)\n",
        "        )\n",
        "\n",
        "        self.conv8 = nn.Sequential(\n",
        "            nn.ConvTranspose2d(256, 128, kernel_size=4, stride=2, padding=1),\n",
        "            nn.GroupNorm(num_groups=32, num_channels=128),\n",
        "            nn.SELU(inplace=True)\n",
        "        )\n",
        "\n",
        "        self.conv9 = nn.Sequential(\n",
        "            nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1),\n",
        "            nn.GroupNorm(num_groups=32, num_channels=64),\n",
        "            nn.SELU(inplace=True)\n",
        "        )\n",
        "\n",
        "        self.conv10 = nn.Sequential(\n",
        "            nn.ConvTranspose2d(64, 32, kernel_size=4, stride=2, padding=1),\n",
        "            nn.GroupNorm(num_groups=32, num_channels=32),\n",
        "            nn.SELU(inplace=True)\n",
        "        )\n",
        "\n",
        "        self.depth_pred = nn.Sequential(\n",
        "            nn.ConvTranspose2d(32, 32, kernel_size=4, stride=2, padding=1),\n",
        "            nn.GroupNorm(num_groups=32, num_channels=32),\n",
        "            nn.SELU(inplace=True),\n",
        "            nn.Conv2d(32, 32, kernel_size=3, padding=1), nn.SELU(inplace=True),\n",
        "            nn.Conv2d(32, 1, kernel_size=1, stride=1, padding=0),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        x = (x - self.mean) / self.std\n",
        "\n",
        "        d_f1 = self.conv1(x)\n",
        "        d_f2 = self.conv2(d_f1)\n",
        "        d_f3 = self.conv3(d_f2)\n",
        "        d_f4 = self.conv4(d_f3)\n",
        "        d_f5 = self.conv5(d_f4)\n",
        "        d_f6 = self.conv6(d_f5)\n",
        "        d_f7 = self.conv7(d_f6)\n",
        "        d_f8 = self.conv8(d_f7)\n",
        "        d_f9 = self.conv9(d_f8+d_f3)\n",
        "        d_f10 = self.conv10(d_f9+d_f2)\n",
        "        depth_pred = self.depth_pred(d_f10+d_f1)\n",
        "\n",
        "\n",
        "        return depth_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "sRT549bjseB4"
      },
      "outputs": [],
      "source": [
        "def main():\n",
        "    net = DGNLNet().cuda().train()\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "    optimizer = optim.Adam([\n",
        "        {'params': [param for name, param in net.named_parameters() if name[-4:] == 'bias' and param.requires_grad],\n",
        "         'lr': 2 * args['lr']},\n",
        "        {'params': [param for name, param in net.named_parameters() if name[-4:] != 'bias' and param.requires_grad],\n",
        "         'lr': args['lr'], 'weight_decay': args['weight_decay']}\n",
        "    ])\n",
        "\n",
        "    if len(args['resume_snapshot']) > 0:\n",
        "        print('training resumes from \\'%s\\'' % args['resume_snapshot'])\n",
        "        net.load_state_dict(torch.load(os.path.join(ckpt_path, exp_name, args['resume_snapshot'] + '.pth')))\n",
        "        optimizer.load_state_dict(torch.load(os.path.join(ckpt_path, exp_name, args['resume_snapshot'] + '_optim.pth')))\n",
        "        optimizer.param_groups[0]['lr'] = 2 * args['lr']\n",
        "        optimizer.param_groups[1]['lr'] = args['lr']\n",
        "\n",
        "    check_mkdir(ckpt_path)\n",
        "    check_mkdir(os.path.join(ckpt_path, exp_name))\n",
        "    open(log_path, 'w').write(str(args) + '\\n\\n')\n",
        "    train(net, optimizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "3eKy3yz8sjFo"
      },
      "outputs": [],
      "source": [
        "def train(net, optimizer):\n",
        "    curr_iter = args['last_iter']\n",
        "    while True:\n",
        "        train_loss_record = AvgMeter()\n",
        "        train_net_loss_record = AvgMeter()\n",
        "        train_depth_loss_record = AvgMeter()\n",
        "\n",
        "        for i, data in enumerate(train_loader):\n",
        "            optimizer.param_groups[0]['lr'] = 2 * args['lr'] * (1 - float(curr_iter) / args['iter_num']\n",
        "                                                                ) ** args['lr_decay']\n",
        "            optimizer.param_groups[1]['lr'] = args['lr'] * (1 - float(curr_iter) / args['iter_num']\n",
        "                                                            ) ** args['lr_decay']\n",
        "\n",
        "            inputs, gts, dps = data\n",
        "            batch_size = inputs.size(0)\n",
        "            inputs = Variable(inputs).cuda()\n",
        "            gts = Variable(gts).cuda()\n",
        "            dps = Variable(dps).cuda()\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            result, depth_pred = net(inputs)\n",
        "\n",
        "            loss_net = criterion(result, gts)\n",
        "            loss_depth = criterion_depth(depth_pred, dps)\n",
        "\n",
        "            loss = loss_net + loss_depth\n",
        "\n",
        "            loss.backward()\n",
        "\n",
        "            optimizer.step()\n",
        "\n",
        "            train_loss_record.update(loss.data, batch_size)\n",
        "            train_net_loss_record.update(loss_net.data, batch_size)\n",
        "            train_depth_loss_record.update(loss_depth.data, batch_size)\n",
        "\n",
        "            curr_iter += 1\n",
        "\n",
        "            log = '[iter %d], [train loss %.5f], [lr %.13f], [loss_net %.5f], [loss_depth %.5f]' % \\\n",
        "                  (curr_iter, train_loss_record.avg, optimizer.param_groups[1]['lr'],\n",
        "                   train_net_loss_record.avg, train_depth_loss_record.avg)\n",
        "            print(log)\n",
        "            open(log_path, 'a').write(log + '\\n')\n",
        "\n",
        "            if (curr_iter + 1) % args['val_freq'] == 0:\n",
        "                validate(net, curr_iter, optimizer)\n",
        "\n",
        "            if (curr_iter + 1) % args['snapshot_epochs'] == 0:\n",
        "                torch.save(net.state_dict(), os.path.join(ckpt_path, exp_name, ('%d_test.pth' % (curr_iter + 1) )))\n",
        "                torch.save(optimizer.state_dict(), os.path.join(ckpt_path, exp_name, ('%d_optim_test.pth' % (curr_iter + 1) )))\n",
        "\n",
        "            if curr_iter > args['iter_num']:\n",
        "                return"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "y2nS3G3lsl7Q"
      },
      "outputs": [],
      "source": [
        "def validate(net, curr_iter, optimizer):\n",
        "    print('validating...')\n",
        "    net.eval()\n",
        "\n",
        "    loss_record1, loss_record2 = AvgMeter(), AvgMeter()\n",
        "    iter_num1 = len(test1_loader)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, data in enumerate(test1_loader):\n",
        "            inputs, gts, dps = data\n",
        "            inputs = Variable(inputs).cuda()\n",
        "            gts = Variable(gts).cuda()\n",
        "            dps = Variable(dps).cuda()\n",
        "\n",
        "            res = net(inputs)\n",
        "\n",
        "            loss = criterion(res, gts)\n",
        "            loss_record1.update(loss.data, inputs.size(0))\n",
        "\n",
        "            print('processed test1 %d / %d' % (i + 1, iter_num1))\n",
        "\n",
        "\n",
        "    snapshot_name = 'iter_%d_loss1_%.5f_loss2_%.5f_lr_%.6f' % (curr_iter + 1, loss_record1.avg, loss_record2.avg,\n",
        "                                                               optimizer.param_groups[1]['lr'])\n",
        "    print('[validate]: [iter %d], [loss1 %.5f], [loss2 %.5f]' % (curr_iter + 1, loss_record1.avg, loss_record2.avg))\n",
        "    torch.save(net.state_dict(), os.path.join(ckpt_path, exp_name, snapshot_name + '.pth'))\n",
        "    torch.save(optimizer.state_dict(), os.path.join(ckpt_path, exp_name, snapshot_name + '_optim.pth'))\n",
        "\n",
        "    net.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bLSsBMNsXi2F"
      },
      "outputs": [],
      "source": [
        "main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nJaEWpBenwnZ"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import time\n",
        "import sys\n",
        "import torch\n",
        "from PIL import Image\n",
        "from torch.autograd import Variable\n",
        "from torchvision import transforms\n",
        "from pathlib import Path\n",
        "# from nets import DGNLNet_fast\n",
        "# from misc import check_mkdir\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "ckpt = \"/content/drive/MyDrive/ckpt/DGNLNet/22_test.pth\"\n",
        "\n",
        "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
        "\n",
        "torch.manual_seed(2019)\n",
        "torch.cuda.set_device(0)\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize([512,1024]),\n",
        "    transforms.ToTensor() ])\n",
        "\n",
        "to_pil = transforms.ToPILImage()\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    root = \"/content\"\n",
        "    input = open(os.path.join(root, 'data/test_images.txt'))\n",
        "    i = 0\n",
        "    image = [(os.path.join(root, 'data/images', img_name.strip('\\n'))) for img_name in\n",
        "                 input]\n",
        "    input.close()\n",
        "\n",
        "    # image = image[1000:]\n",
        "\n",
        "    for img in image:\n",
        "    # img = \"/content/drive/MyDrive/test images/test_carla_H.png\"\n",
        "\n",
        "      net = DGNLNet().cuda()\n",
        "\n",
        "      net.load_state_dict(torch.load(ckpt,map_location=lambda storage,loc: storage.cuda(0)))\n",
        "\n",
        "      net.eval()\n",
        "      \n",
        "      name = img.split(\"/\")[-1]\n",
        "      img = Image.open(Path(img))\n",
        "      if len(img.getbands()) == 4:\n",
        "        temp = np.asarray(img)\n",
        "        temp = temp[:,:,:3]\n",
        "        img = Image.fromarray(temp)\n",
        "      # if isinstance(img,Image.Image):\n",
        "      #     img = img.convert(\"RGB\")\n",
        "      # else:\n",
        "      #     img = Image.open(Path(img))\n",
        "      #     img = img.convert(\"RGB\")\n",
        "      # # plt.figure(figsize=(12,6))\n",
        "      # plt.axis(\"off\")\n",
        "      # plt.imshow(img)\n",
        "      with torch.no_grad():\n",
        "\n",
        "          w, h = img.size\n",
        "          img_var = Variable(transform(img).unsqueeze(0)).cuda()\n",
        "          \n",
        "          res = net(img_var)\n",
        "\n",
        "          torch.cuda.synchronize()\n",
        "\n",
        "          result = transforms.Resize((h, w))(to_pil(res.data.squeeze(0).cpu()))\n",
        "          # fig = plt.figure(figsize=(16, 8))\n",
        "          # fig.add_subplot(2,1,1)\n",
        "          # plt.figure(figsize=(12,6))\n",
        "          # plt.axis(\"off\")\n",
        "          # plt.imshow(img)\n",
        "          # # fig.add_subplot(2,1,2)\n",
        "          # plt.figure(figsize=(12,6))\n",
        "          # plt.axis(\"off\")\n",
        "          # plt.imshow(result)\n",
        "          i += 1\n",
        "          print(i)\n",
        "          result.save(\"/content/drive/MyDrive/generated_test/\"+ name) "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import time\n",
        "import sys\n",
        "import torch\n",
        "from PIL import Image\n",
        "from torch.autograd import Variable\n",
        "from torchvision import transforms\n",
        "from pathlib import Path\n",
        "# from nets import DGNLNet_fast\n",
        "# from misc import check_mkdir\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "ckpt = \"/content/drive/MyDrive/ckpt/DGNLNet/22_test.pth\"\n",
        "\n",
        "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
        "\n",
        "torch.manual_seed(2019)\n",
        "torch.cuda.set_device(0)\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize([512,1024]),\n",
        "    transforms.ToTensor() ])\n",
        "\n",
        "to_pil = transforms.ToPILImage()\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    root = \"/content\"\n",
        "    \n",
        "    \n",
        "    img = \"/content/drive/MyDrive/generated_test/1647760644.0353005_rain_M.png\"\n",
        "\n",
        "    # net = DGNLNet().cuda()\n",
        "\n",
        "    # net.load_state_dict(torch.load(ckpt,map_location=lambda storage,loc: storage.cuda(0)))\n",
        "\n",
        "    # net.eval()\n",
        "    \n",
        "    # name = img.split(\"/\")[-1]\n",
        "\n",
        "    if len(img.getbands()) == 4:\n",
        "      temp = np.asarray(img)\n",
        "      temp = temp[:,:,:3]\n",
        "      img = Image.fromarray(temp)\n",
        "    if isinstance(img,Image.Image):\n",
        "        img = img.convert(\"RGB\")\n",
        "    else:\n",
        "        img = Image.open(Path(img))\n",
        "        img = img.convert(\"RGB\")\n",
        "    # # # plt.figure(figsize=(12,6))\n",
        "    # # plt.axis(\"off\")\n",
        "    # # plt.imshow(img)\n",
        "    # with torch.no_grad():\n",
        "\n",
        "    #     w, h = img.size\n",
        "    #     img_var = Variable(transform(img).unsqueeze(0)).cuda()\n",
        "        \n",
        "    #     res = net(img_var)\n",
        "\n",
        "    #     torch.cuda.synchronize()\n",
        "\n",
        "    #     result = transforms.Resize((h, w))(to_pil(res.data.squeeze(0).cpu()))\n",
        "    #     fig = plt.figure(figsize=(16, 8))\n",
        "    #     fig.add_subplot(2,1,1)\n",
        "    #     plt.figure(figsize=(12,6))\n",
        "    #     plt.axis(\"off\")\n",
        "    #     plt.imshow(img)\n",
        "    #     # fig.add_subplot(2,1,2)\n",
        "    #     plt.figure(figsize=(12,6))\n",
        "    #     plt.axis(\"off\")\n",
        "    #     plt.imshow(result)"
      ],
      "metadata": {
        "id": "e6p3SrZaVeqb"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import math\n",
        "import numpy as np\n",
        "\n",
        "def ssim(img1,img2):\n",
        "\n",
        "    C1 = (0.01 * 255)**2\n",
        "    C2 = (0.03 * 255)**2\n",
        "\n",
        "    img1 = img1.astype(np.float64)\n",
        "    img2 = img2.astype(np.float64)\n",
        "    kernel = cv2.getGaussianKernel(11, 1.5)\n",
        "    window = np.outer(kernel, kernel.transpose())\n",
        "\n",
        "    mu1 = cv2.filter2D(img1, -1, window)[5:-5, 5:-5]  # valid\n",
        "    mu2 = cv2.filter2D(img2, -1, window)[5:-5, 5:-5]\n",
        "    mu1_sq = mu1**2\n",
        "    mu2_sq = mu2**2\n",
        "    mu1_mu2 = mu1 * mu2\n",
        "\n",
        "    sigma1_sq = cv2.filter2D(img1**2, -1, window)[5:-5, 5:-5] - mu1_sq\n",
        "    sigma2_sq = cv2.filter2D(img2**2, -1, window)[5:-5, 5:-5] - mu2_sq\n",
        "    sigma12 = cv2.filter2D(img1 * img2, -1, window)[5:-5, 5:-5] - mu1_mu2\n",
        "\n",
        "    ssim_map = ((2 * mu1_mu2 + C1) * (2 * sigma12 + C2)) / ((mu1_sq + mu2_sq + C1) *\n",
        "                                                            (sigma1_sq + sigma2_sq + C2))\n",
        "    return ssim_map.mean()\n",
        "\n",
        "def psnr(img1,img2):\n",
        "\n",
        "    img1 = img1.astype(np.float64)\n",
        "    img2 = img2.astype(np.float64)\n",
        "    mse = np.mean((img1 - img2)**2)\n",
        "    if mse == 0:\n",
        "        return float('inf')\n",
        "    return 20 * math.log10(255.0 / math.sqrt(mse))"
      ],
      "metadata": {
        "id": "Qat1x0-bVTLh"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img1 = cv2.imread(\"/content/data/images/val/carla/1647760470.3255076_rain_H.png\")\n",
        "img2 = cv2.imread(\"/content/drive/MyDrive/generated_test/1647760470.3255076_rain_H.png\")\n",
        "\n",
        "psnr(img1,img2),ssim(img1,img2)"
      ],
      "metadata": {
        "id": "NtJfBDguor-_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import time\n",
        "import sys\n",
        "import torch\n",
        "from PIL import Image\n",
        "from torch.autograd import Variable\n",
        "from torchvision import transforms\n",
        "from pathlib import Path\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "# from nets import DGNLNet\n",
        "\n",
        "class RainRemoval:\n",
        "    def __init__(self,model):\n",
        "        self.model = model\n",
        "\n",
        "    def infer(self,img,flag = True):\n",
        "\n",
        "        os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
        "\n",
        "        torch.manual_seed(2019)\n",
        "        torch.cuda.set_device(0)\n",
        "\n",
        "        transform = transforms.Compose([\n",
        "            transforms.Resize([512,1024]),\n",
        "            transforms.ToTensor() ])\n",
        "\n",
        "        to_pil = transforms.ToPILImage()    \n",
        "\n",
        "\n",
        "        if type(img) == str:\n",
        "          img = np.asarray(Image.open(img))\n",
        "          \n",
        "        net = DGNLNet().cuda()\n",
        "\n",
        "        net.load_state_dict(torch.load(self.model,map_location=lambda storage,loc: storage.cuda(0)))\n",
        "\n",
        "        net.eval()\n",
        "\n",
        "        if img.shape[-1] == 4:\n",
        "            img = img[:,:,:-1]\n",
        "\n",
        "        self.img_infer = Image.fromarray(img)\n",
        "\n",
        "        with torch.no_grad():\n",
        "\n",
        "            w, h = self.img_infer.size\n",
        "            img_var = Variable(transform(self.img_infer).unsqueeze(0)).cuda()\n",
        "            \n",
        "            res = net(img_var)\n",
        "\n",
        "            torch.cuda.synchronize()\n",
        "\n",
        "            self.result = transforms.Resize((h, w))(to_pil(res.data.squeeze(0).cpu()))\n",
        "\n",
        "            self.result_np = np.array(self.result)\n",
        "        \n",
        "        if flag:\n",
        "            return self.result_np\n",
        "        else:\n",
        "            return self.result\n",
        "    \n",
        "    def displayRes(self):\n",
        "\n",
        "        fig = plt.figure(figsize=(14, 7))\n",
        "        \n",
        "        fig.add_subplot(1,2,1)\n",
        "        plt.axis(\"off\")\n",
        "        plt.imshow(self.img_infer)\n",
        "        \n",
        "        fig.add_subplot(1,2,2)\n",
        "        plt.axis(\"off\")\n",
        "        plt.imshow(self.result)"
      ],
      "metadata": {
        "id": "LS3HCixO_UVh"
      },
      "execution_count": 80,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "Rain Removal.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}